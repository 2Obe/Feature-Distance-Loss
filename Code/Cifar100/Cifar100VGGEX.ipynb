{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CEyUcTGlE5YL"},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","from tensorflow import keras\n","from sklearn import model_selection\n","from sklearn.metrics import classification_report\n","import imgaug.augmenters as iaa\n","import imgaug as ia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TGGKlSyFBJn"},"outputs":[],"source":["#image augmentation methods\n","ia.seed(1)\n","def Data_Aug(samples):\n","    randomaug = iaa.Sometimes(\n","        0.5,\n","        iaa.OneOf([\n","            iaa.Sequential([\n","                iaa.AllChannelsCLAHE(clip_limit=(1, 10)),\n","                iaa.Affine(rotate=(-5, 5))\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(translate_percent={\n","                    \"x\": (-0.2, 0.2),\n","                    \"y\": (-0.2, 0.2)\n","                }),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(rotate=(-10, 10)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.PerspectiveTransform(scale=(0, 0.15)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ])\n","        ]))\n","\n","\n","    return randomaug.augment_images(samples)\n","\n","def resize_images(imgs, hight, width):\n","    seq = iaa.Resize({\"height\": hight, \"width\": width})\n","    aug = seq.augment_images(imgs)\n","    return aug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RJ3uDY9FgNZ"},"outputs":[],"source":["class cifar100data(keras.utils.Sequence):\n","    '''\n","    generate data batch of cifar10\n","    10 classes\n","    '''\n","    def __init__(self, data_x, data_y, batch_size, train):\n","        self.data_x = data_x\n","        self.data_y = data_y\n","        self.train = train\n","        self.batch_size = batch_size\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","\n","        batch_x = self.data_x[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        batch_y = self.data_y[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        if self.train == True:\n","            batch_x = Data_Aug(batch_x)\n","\n","        batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","        batch_y = keras.utils.to_categorical(np.array(batch_y), 100)\n","        return batch_x, [batch_y, batch_y, batch_y, batch_y, batch_y]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4U_n_3bce9u4"},"outputs":[],"source":["#callback for saving best model\n","class CustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(CustomEarlyStoppingAndSave, self).__init__()\n","        self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_model_accuracy') + logs.get(\n","            'val_model_1_accuracy') + logs.get(\n","                'val_model_2_accuracy') + logs.get(\n","                    'val_model_3_accuracy') + logs.get('val_model_4_accuracy')\n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch > 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1BPrwTrBVE2"},"outputs":[],"source":["#Cosine&Euclidean distance loss\n","def descriptor(X, mask = False, max_norm = False):\n","  X = tf.reduce_mean(X, axis=-1)\n","  if mask:\n","    mean_X = tf.reduce_mean(X, axis = [1,2], keepdims= True)\n","    X = tf.where(X > mean_X, X , tf.zeros_like(X, dtype=tf.float32))\n","  if max_norm:\n","    max_X = tf.reduce_max(X, axis = [1,2], keepdims= True)\n","    X = tf.math.divide_no_nan(X, max_X)\n","  return X \n","  \n","def compute_euclidean_sum(X, Y):\n","  L2_distance = tf.reduce_mean(tf.exp(-(X - Y)**2), axis= [1,2])\n","  return tf.reduce_mean(L2_distance)\n","\n","def compute_cosine_sum(X, Y):\n","  X = tf.reshape(X, [tf.shape(X)[0], -1])\n","  Y = tf.reshape(Y, [tf.shape(Y)[0], -1])\n","  loss = -keras.losses.cosine_similarity(X,Y,axis=-1)\n","  return tf.reduce_mean(loss)\n","\n","def cosine_euclidean_sum_loss(x, cosine_weight, euclidean_weight, mask, max_norm):\n","  descriptor0 = descriptor(x[0], mask=mask, max_norm=max_norm)\n","  descriptor1 = descriptor(x[1], mask=mask, max_norm=max_norm)\n","  descriptor2 = descriptor(x[2], mask=mask, max_norm=max_norm)\n","  descriptor3 = descriptor(x[3], mask=mask, max_norm=max_norm)\n","  descriptor4 = descriptor(x[4], mask=mask, max_norm=max_norm)\n","  cosine_sum = compute_cosine_sum(descriptor0, descriptor1)+compute_cosine_sum(descriptor0, descriptor2)+compute_cosine_sum(descriptor0, descriptor3)+compute_cosine_sum(descriptor0, descriptor4)+compute_cosine_sum(descriptor1, descriptor2)+compute_cosine_sum(descriptor1, descriptor3)+compute_cosine_sum(descriptor1, descriptor4)+compute_cosine_sum(descriptor2, descriptor3)+compute_cosine_sum(descriptor2, descriptor4)+compute_cosine_sum(descriptor3, descriptor4)\n","  euclidean_sum = compute_euclidean_sum(descriptor0, descriptor1)+compute_euclidean_sum(descriptor0, descriptor2)+compute_euclidean_sum(descriptor0, descriptor3)+compute_euclidean_sum(descriptor0, descriptor4)+compute_euclidean_sum(descriptor1, descriptor2)+compute_euclidean_sum(descriptor1, descriptor3)+compute_euclidean_sum(descriptor1, descriptor4)+compute_euclidean_sum(descriptor2, descriptor3)+compute_euclidean_sum(descriptor2, descriptor4)+compute_euclidean_sum(descriptor3, descriptor4)\n","  return cosine_sum, euclidean_sum, cosine_weight*cosine_sum+euclidean_weight*euclidean_sum  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMRptakCHOr_"},"outputs":[],"source":["#create single VGG model\n","def create_VGGNet(input_shape, num_classes,  random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  x = keras.layers.Conv2D(64, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(64, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.2)(x)\n","\n","  x = keras.layers.Conv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.3)(x)\n","\n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  p3 = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.4)(p3)\n","\n","\n","    \n","  '''x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.5)(x)'''\n","\n","\n"," \n","  #x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  #x = keras.layers.BatchNormalization()(x)\n","  #x = keras.layers.Activation('relu')(x)\n","  #x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  #x = keras.layers.BatchNormalization()(x)\n","  #x = keras.layers.Activation('relu')(x)\n","  #x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  #x = keras.layers.BatchNormalization()(x)\n","  #x = keras.layers.Activation('relu')(x)\n","  #x = keras.layers.MaxPooling2D((2, 2))(x)\n","  #x = keras.layers.Dropout(0.5)(x) \n"," \n","\n","  #x = keras.layers.GlobalAveragePooling2D()(x)\n","  x = keras.layers.Flatten()(x)\n","  x = keras.layers.Dense(512,  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Dropout(0.5)(x)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n","  return keras.Model(inputs=inputs, outputs=[outputs, p3])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nf634qPVt_Mq","outputId":"d9ae1b99-764c-4b6b-912f-79130b04c9a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169009152/169001437 [==============================] - 6s 0us/step\n","169017344/169001437 [==============================] - 6s 0us/step\n","Epoch 1/150\n","4000/4000 [==============================] - 245s 57ms/step - loss: 40.1112 - model_loss: 4.3474 - model_1_loss: 4.3620 - model_2_loss: 4.3571 - model_3_loss: 4.3272 - model_4_loss: 4.3521 - model_accuracy: 0.0633 - model_1_accuracy: 0.0619 - model_2_accuracy: 0.0624 - model_3_accuracy: 0.0659 - model_4_accuracy: 0.0624 - loss1: 2.3988 - loss2: 3.6251 - val_loss: 36.7713 - val_model_loss: 3.7286 - val_model_1_loss: 3.6961 - val_model_2_loss: 3.5113 - val_model_3_loss: 3.6181 - val_model_4_loss: 3.5212 - val_model_accuracy: 0.1355 - val_model_1_accuracy: 0.1550 - val_model_2_accuracy: 0.1655 - val_model_3_accuracy: 0.1515 - val_model_4_accuracy: 0.1615 - val_loss1: 2.0256 - val_loss2: 3.6987\n","Epoch 2/150\n","4000/4000 [==============================] - 225s 56ms/step - loss: 37.3807 - model_loss: 3.6684 - model_1_loss: 3.7160 - model_2_loss: 3.6738 - model_3_loss: 3.6639 - model_4_loss: 3.7004 - model_accuracy: 0.1370 - model_1_accuracy: 0.1308 - model_2_accuracy: 0.1388 - model_3_accuracy: 0.1399 - model_4_accuracy: 0.1328 - loss1: 1.9996 - loss2: 3.7516 - val_loss: 35.1633 - val_model_loss: 3.1338 - val_model_1_loss: 3.0564 - val_model_2_loss: 3.0847 - val_model_3_loss: 3.0872 - val_model_4_loss: 3.1226 - val_model_accuracy: 0.2245 - val_model_1_accuracy: 0.2425 - val_model_2_accuracy: 0.2300 - val_model_3_accuracy: 0.2285 - val_model_4_accuracy: 0.2175 - val_loss1: 1.8887 - val_loss2: 3.8980\n","Epoch 3/150\n","4000/4000 [==============================] - 225s 56ms/step - loss: 36.9247 - model_loss: 3.3494 - model_1_loss: 3.3909 - model_2_loss: 3.3366 - model_3_loss: 3.3592 - model_4_loss: 3.3572 - model_accuracy: 0.1930 - model_1_accuracy: 0.1854 - model_2_accuracy: 0.1932 - model_3_accuracy: 0.1893 - model_4_accuracy: 0.1926 - loss1: 1.6603 - loss2: 3.9931 - val_loss: 34.5400 - val_model_loss: 2.6626 - val_model_1_loss: 2.7866 - val_model_2_loss: 2.6977 - val_model_3_loss: 2.7971 - val_model_4_loss: 2.7154 - val_model_accuracy: 0.3020 - val_model_1_accuracy: 0.2885 - val_model_2_accuracy: 0.3085 - val_model_3_accuracy: 0.2845 - val_model_4_accuracy: 0.2985 - val_loss1: 1.5315 - val_loss2: 4.1455\n","Epoch 4/150\n","4000/4000 [==============================] - 215s 54ms/step - loss: 36.9077 - model_loss: 3.1245 - model_1_loss: 3.1547 - model_2_loss: 3.1155 - model_3_loss: 3.1490 - model_4_loss: 3.1284 - model_accuracy: 0.2320 - model_1_accuracy: 0.2248 - model_2_accuracy: 0.2350 - model_3_accuracy: 0.2221 - model_4_accuracy: 0.2301 - loss1: 1.4751 - loss2: 4.2176 - val_loss: 34.4282 - val_model_loss: 2.5330 - val_model_1_loss: 2.4884 - val_model_2_loss: 2.5274 - val_model_3_loss: 2.5875 - val_model_4_loss: 2.4245 - val_model_accuracy: 0.3350 - val_model_1_accuracy: 0.3470 - val_model_2_accuracy: 0.3360 - val_model_3_accuracy: 0.3360 - val_model_4_accuracy: 0.3580 - val_loss1: 1.4309 - val_loss2: 4.3449\n","Epoch 5/150\n","4000/4000 [==============================] - 214s 54ms/step - loss: 37.2624 - model_loss: 2.9659 - model_1_loss: 2.9969 - model_2_loss: 2.9647 - model_3_loss: 2.9908 - model_4_loss: 2.9696 - model_accuracy: 0.2630 - model_1_accuracy: 0.2552 - model_2_accuracy: 0.2633 - model_3_accuracy: 0.2582 - model_4_accuracy: 0.2581 - loss1: 1.3159 - loss2: 4.4486 - val_loss: 35.2115 - val_model_loss: 2.3500 - val_model_1_loss: 2.6518 - val_model_2_loss: 2.3972 - val_model_3_loss: 2.4400 - val_model_4_loss: 2.6987 - val_model_accuracy: 0.3805 - val_model_1_accuracy: 0.3275 - val_model_2_accuracy: 0.3740 - val_model_3_accuracy: 0.3635 - val_model_4_accuracy: 0.3105 - val_loss1: 1.3209 - val_loss2: 4.5084\n","Epoch 6/150\n","4000/4000 [==============================] - 217s 54ms/step - loss: 37.5317 - model_loss: 2.8363 - model_1_loss: 2.8630 - model_2_loss: 2.8345 - model_3_loss: 2.8771 - model_4_loss: 2.8471 - model_accuracy: 0.2882 - model_1_accuracy: 0.2805 - model_2_accuracy: 0.2870 - model_3_accuracy: 0.2803 - model_4_accuracy: 0.2837 - loss1: 1.1871 - loss2: 4.6310 - val_loss: 34.5927 - val_model_loss: 2.2766 - val_model_1_loss: 2.2573 - val_model_2_loss: 2.2030 - val_model_3_loss: 2.1961 - val_model_4_loss: 2.2466 - val_model_accuracy: 0.3900 - val_model_1_accuracy: 0.3930 - val_model_2_accuracy: 0.4110 - val_model_3_accuracy: 0.4095 - val_model_4_accuracy: 0.3955 - val_loss1: 1.2232 - val_loss2: 4.6582\n","Epoch 7/150\n","4000/4000 [==============================] - 217s 54ms/step - loss: 37.6812 - model_loss: 2.7332 - model_1_loss: 2.7556 - model_2_loss: 2.7185 - model_3_loss: 2.7676 - model_4_loss: 2.7395 - model_accuracy: 0.3121 - model_1_accuracy: 0.3014 - model_2_accuracy: 0.3113 - model_3_accuracy: 0.3000 - model_4_accuracy: 0.3057 - loss1: 1.0932 - loss2: 4.7715 - val_loss: 35.4680 - val_model_loss: 2.1702 - val_model_1_loss: 2.1980 - val_model_2_loss: 2.3982 - val_model_3_loss: 2.1570 - val_model_4_loss: 2.2589 - val_model_accuracy: 0.4195 - val_model_1_accuracy: 0.4040 - val_model_2_accuracy: 0.3755 - val_model_3_accuracy: 0.4175 - val_model_4_accuracy: 0.4020 - val_loss1: 1.0612 - val_loss2: 4.8359\n","Epoch 8/150\n","4000/4000 [==============================] - 217s 54ms/step - loss: 37.6463 - model_loss: 2.6485 - model_1_loss: 2.6834 - model_2_loss: 2.6445 - model_3_loss: 2.6874 - model_4_loss: 2.6577 - model_accuracy: 0.3247 - model_1_accuracy: 0.3159 - model_2_accuracy: 0.3273 - model_3_accuracy: 0.3137 - model_4_accuracy: 0.3231 - loss1: 1.0448 - loss2: 4.8441 - val_loss: 34.2370 - val_model_loss: 2.0707 - val_model_1_loss: 2.0975 - val_model_2_loss: 2.1115 - val_model_3_loss: 2.0626 - val_model_4_loss: 2.0288 - val_model_accuracy: 0.4420 - val_model_1_accuracy: 0.4345 - val_model_2_accuracy: 0.4360 - val_model_3_accuracy: 0.4360 - val_model_4_accuracy: 0.4465 - val_loss1: 1.2086 - val_loss2: 4.7490\n","Epoch 9/150\n","4000/4000 [==============================] - 218s 54ms/step - loss: 37.4198 - model_loss: 2.5756 - model_1_loss: 2.6025 - model_2_loss: 2.5674 - model_3_loss: 2.6097 - model_4_loss: 2.5805 - model_accuracy: 0.3393 - model_1_accuracy: 0.3350 - model_2_accuracy: 0.3415 - model_3_accuracy: 0.3327 - model_4_accuracy: 0.3380 - loss1: 1.0387 - loss2: 4.8761 - val_loss: 34.6694 - val_model_loss: 1.9539 - val_model_1_loss: 2.0492 - val_model_2_loss: 2.0063 - val_model_3_loss: 2.0203 - val_model_4_loss: 2.1849 - val_model_accuracy: 0.4710 - val_model_1_accuracy: 0.4440 - val_model_2_accuracy: 0.4720 - val_model_3_accuracy: 0.4695 - val_model_4_accuracy: 0.4215 - val_loss1: 1.1467 - val_loss2: 4.8680\n","Epoch 10/150\n","4000/4000 [==============================] - 218s 55ms/step - loss: 37.2353 - model_loss: 2.5111 - model_1_loss: 2.5390 - model_2_loss: 2.5069 - model_3_loss: 2.5466 - model_4_loss: 2.5162 - model_accuracy: 0.3532 - model_1_accuracy: 0.3483 - model_2_accuracy: 0.3575 - model_3_accuracy: 0.3443 - model_4_accuracy: 0.3545 - loss1: 1.0205 - loss2: 4.9027 - val_loss: 34.1394 - val_model_loss: 1.9971 - val_model_1_loss: 1.9562 - val_model_2_loss: 1.9801 - val_model_3_loss: 2.0211 - val_model_4_loss: 1.9626 - val_model_accuracy: 0.4545 - val_model_1_accuracy: 0.4690 - val_model_2_accuracy: 0.4700 - val_model_3_accuracy: 0.4565 - val_model_4_accuracy: 0.4605 - val_loss1: 1.1767 - val_loss2: 4.8209\n","Epoch 11/150\n","4000/4000 [==============================] - 218s 54ms/step - loss: 36.9758 - model_loss: 2.4307 - model_1_loss: 2.4728 - model_2_loss: 2.4372 - model_3_loss: 2.4843 - model_4_loss: 2.4421 - model_accuracy: 0.3733 - model_1_accuracy: 0.3636 - model_2_accuracy: 0.3738 - model_3_accuracy: 0.3578 - model_4_accuracy: 0.3664 - loss1: 1.0179 - loss2: 4.9214 - val_loss: 34.0702 - val_model_loss: 1.9377 - val_model_1_loss: 1.9078 - val_model_2_loss: 1.9046 - val_model_3_loss: 1.9114 - val_model_4_loss: 1.8980 - val_model_accuracy: 0.4760 - val_model_1_accuracy: 0.4820 - val_model_2_accuracy: 0.4815 - val_model_3_accuracy: 0.4810 - val_model_4_accuracy: 0.4785 - val_loss1: 1.1247 - val_loss2: 4.8796\n","Epoch 12/150\n","4000/4000 [==============================] - 217s 54ms/step - loss: 36.7638 - model_loss: 2.3777 - model_1_loss: 2.4079 - model_2_loss: 2.3900 - model_3_loss: 2.4265 - model_4_loss: 2.3940 - model_accuracy: 0.3811 - model_1_accuracy: 0.3762 - model_2_accuracy: 0.3800 - model_3_accuracy: 0.3722 - model_4_accuracy: 0.3767 - loss1: 1.0114 - loss2: 4.9333 - val_loss: 34.0382 - val_model_loss: 1.8911 - val_model_1_loss: 1.9779 - val_model_2_loss: 1.8464 - val_model_3_loss: 2.0765 - val_model_4_loss: 1.9577 - val_model_accuracy: 0.4765 - val_model_1_accuracy: 0.4630 - val_model_2_accuracy: 0.4990 - val_model_3_accuracy: 0.4460 - val_model_4_accuracy: 0.4735 - val_loss1: 1.1919 - val_loss2: 4.8339\n","Epoch 13/150\n","4000/4000 [==============================] - 216s 54ms/step - loss: 36.6272 - model_loss: 2.3369 - model_1_loss: 2.3658 - model_2_loss: 2.3278 - model_3_loss: 2.3862 - model_4_loss: 2.3492 - model_accuracy: 0.3903 - model_1_accuracy: 0.3864 - model_2_accuracy: 0.3966 - model_3_accuracy: 0.3800 - model_4_accuracy: 0.3900 - loss1: 1.0239 - loss2: 4.9518 - val_loss: 34.8018 - val_model_loss: 1.9602 - val_model_1_loss: 1.9340 - val_model_2_loss: 1.9140 - val_model_3_loss: 2.1085 - val_model_4_loss: 1.9474 - val_model_accuracy: 0.4685 - val_model_1_accuracy: 0.4845 - val_model_2_accuracy: 0.4780 - val_model_3_accuracy: 0.4480 - val_model_4_accuracy: 0.4775 - val_loss1: 1.1404 - val_loss2: 4.9647\n","Epoch 14/150\n","4000/4000 [==============================] - 217s 54ms/step - loss: 36.9166 - model_loss: 2.2920 - model_1_loss: 2.3146 - model_2_loss: 2.2891 - model_3_loss: 2.3304 - model_4_loss: 2.2883 - model_accuracy: 0.4016 - model_1_accuracy: 0.3957 - model_2_accuracy: 0.4039 - model_3_accuracy: 0.3933 - model_4_accuracy: 0.4059 - loss1: 0.9478 - loss2: 5.0615 - val_loss: 34.2868 - val_model_loss: 1.8819 - val_model_1_loss: 1.8218 - val_model_2_loss: 1.8258 - val_model_3_loss: 1.8264 - val_model_4_loss: 1.7910 - val_model_accuracy: 0.4905 - val_model_1_accuracy: 0.5025 - val_model_2_accuracy: 0.5140 - val_model_3_accuracy: 0.5010 - val_model_4_accuracy: 0.5150 - val_loss1: 1.0895 - val_loss2: 5.0062\n","Epoch 15/150\n","4000/4000 [==============================] - 215s 54ms/step - loss: 36.7679 - model_loss: 2.2347 - model_1_loss: 2.2722 - model_2_loss: 2.2442 - model_3_loss: 2.2890 - model_4_loss: 2.2532 - model_accuracy: 0.4135 - model_1_accuracy: 0.4106 - model_2_accuracy: 0.4124 - model_3_accuracy: 0.4023 - model_4_accuracy: 0.4087 - loss1: 0.9372 - loss2: 5.0762 - val_loss: 34.0273 - val_model_loss: 1.8055 - val_model_1_loss: 1.8130 - val_model_2_loss: 1.7841 - val_model_3_loss: 1.8365 - val_model_4_loss: 1.8157 - val_model_accuracy: 0.5145 - val_model_1_accuracy: 0.5075 - val_model_2_accuracy: 0.5215 - val_model_3_accuracy: 0.5035 - val_model_4_accuracy: 0.5050 - val_loss1: 1.1552 - val_loss2: 4.9714\n","Epoch 16/150\n","4000/4000 [==============================] - 221s 55ms/step - loss: 36.5083 - model_loss: 2.1931 - model_1_loss: 2.2173 - model_2_loss: 2.2004 - model_3_loss: 2.2433 - model_4_loss: 2.2050 - model_accuracy: 0.4245 - model_1_accuracy: 0.4201 - model_2_accuracy: 0.4198 - model_3_accuracy: 0.4108 - model_4_accuracy: 0.4208 - loss1: 0.9571 - loss2: 5.0707 - val_loss: 34.8828 - val_model_loss: 1.8705 - val_model_1_loss: 1.8917 - val_model_2_loss: 1.9409 - val_model_3_loss: 1.9186 - val_model_4_loss: 2.0097 - val_model_accuracy: 0.5030 - val_model_1_accuracy: 0.5110 - val_model_2_accuracy: 0.4845 - val_model_3_accuracy: 0.4930 - val_model_4_accuracy: 0.4715 - val_loss1: 1.0848 - val_loss2: 5.0286\n","Epoch 17/150\n","4000/4000 [==============================] - 225s 56ms/step - loss: 36.5348 - model_loss: 2.1638 - model_1_loss: 2.1887 - model_2_loss: 2.1643 - model_3_loss: 2.2101 - model_4_loss: 2.1655 - model_accuracy: 0.4286 - model_1_accuracy: 0.4251 - model_2_accuracy: 0.4283 - model_3_accuracy: 0.4216 - model_4_accuracy: 0.4306 - loss1: 0.9211 - loss2: 5.1101 - val_loss: 34.1821 - val_model_loss: 1.8464 - val_model_1_loss: 1.7466 - val_model_2_loss: 1.7401 - val_model_3_loss: 1.7483 - val_model_4_loss: 1.8445 - val_model_accuracy: 0.5125 - val_model_1_accuracy: 0.5190 - val_model_2_accuracy: 0.5370 - val_model_3_accuracy: 0.5235 - val_model_4_accuracy: 0.4990 - val_loss1: 1.1387 - val_loss2: 5.0284\n","Epoch 18/150\n","4000/4000 [==============================] - 224s 56ms/step - loss: 36.4506 - model_loss: 2.1153 - model_1_loss: 2.1484 - model_2_loss: 2.1272 - model_3_loss: 2.1687 - model_4_loss: 2.1376 - model_accuracy: 0.4402 - model_1_accuracy: 0.4340 - model_2_accuracy: 0.4378 - model_3_accuracy: 0.4292 - model_4_accuracy: 0.4365 - loss1: 0.9157 - loss2: 5.1324 - val_loss: 33.9367 - val_model_loss: 1.7273 - val_model_1_loss: 1.7530 - val_model_2_loss: 1.7413 - val_model_3_loss: 1.7492 - val_model_4_loss: 1.7957 - val_model_accuracy: 0.5265 - val_model_1_accuracy: 0.5285 - val_model_2_accuracy: 0.5320 - val_model_3_accuracy: 0.5185 - val_model_4_accuracy: 0.5260 - val_loss1: 1.1483 - val_loss2: 5.0111\n","Epoch 19/150\n","4000/4000 [==============================] - 222s 55ms/step - loss: 36.5256 - model_loss: 2.0933 - model_1_loss: 2.1134 - model_2_loss: 2.1017 - model_3_loss: 2.1446 - model_4_loss: 2.1120 - model_accuracy: 0.4433 - model_1_accuracy: 0.4413 - model_2_accuracy: 0.4449 - model_3_accuracy: 0.4347 - model_4_accuracy: 0.4423 - loss1: 0.8897 - loss2: 5.1743 - val_loss: 34.2627 - val_model_loss: 1.7080 - val_model_1_loss: 1.7644 - val_model_2_loss: 1.7393 - val_model_3_loss: 1.8186 - val_model_4_loss: 1.7567 - val_model_accuracy: 0.5480 - val_model_1_accuracy: 0.5240 - val_model_2_accuracy: 0.5340 - val_model_3_accuracy: 0.5130 - val_model_4_accuracy: 0.5370 - val_loss1: 1.1637 - val_loss2: 5.0719\n","Epoch 20/150\n","4000/4000 [==============================] - 222s 55ms/step - loss: 36.2514 - model_loss: 2.0502 - model_1_loss: 2.0713 - model_2_loss: 2.0579 - model_3_loss: 2.0969 - model_4_loss: 2.0638 - model_accuracy: 0.4545 - model_1_accuracy: 0.4513 - model_2_accuracy: 0.4527 - model_3_accuracy: 0.4429 - model_4_accuracy: 0.4522 - loss1: 0.9133 - loss2: 5.1640 - val_loss: 33.9294 - val_model_loss: 1.7006 - val_model_1_loss: 1.7010 - val_model_2_loss: 1.7316 - val_model_3_loss: 1.7643 - val_model_4_loss: 1.6528 - val_model_accuracy: 0.5470 - val_model_1_accuracy: 0.5370 - val_model_2_accuracy: 0.5410 - val_model_3_accuracy: 0.5295 - val_model_4_accuracy: 0.5465 - val_loss1: 1.1816 - val_loss2: 5.0522\n","Epoch 21/150\n","4000/4000 [==============================] - 217s 54ms/step - loss: 36.0796 - model_loss: 2.0112 - model_1_loss: 2.0351 - model_2_loss: 2.0214 - model_3_loss: 2.0692 - model_4_loss: 2.0153 - model_accuracy: 0.4652 - model_1_accuracy: 0.4617 - model_2_accuracy: 0.4639 - model_3_accuracy: 0.4511 - model_4_accuracy: 0.4667 - loss1: 0.9176 - loss2: 5.1672 - val_loss: 33.8656 - val_model_loss: 1.7193 - val_model_1_loss: 1.6518 - val_model_2_loss: 1.7123 - val_model_3_loss: 1.6668 - val_model_4_loss: 1.7033 - val_model_accuracy: 0.5380 - val_model_1_accuracy: 0.5475 - val_model_2_accuracy: 0.5475 - val_model_3_accuracy: 0.5540 - val_model_4_accuracy: 0.5335 - val_loss1: 1.1736 - val_loss2: 5.0590\n","Epoch 22/150\n","4000/4000 [==============================] - 211s 53ms/step - loss: 35.9735 - model_loss: 1.9928 - model_1_loss: 2.0220 - model_2_loss: 2.0014 - model_3_loss: 2.0327 - model_4_loss: 1.9924 - model_accuracy: 0.4682 - model_1_accuracy: 0.4640 - model_2_accuracy: 0.4677 - model_3_accuracy: 0.4582 - model_4_accuracy: 0.4697 - loss1: 0.9230 - loss2: 5.1680 - val_loss: 34.1619 - val_model_loss: 1.7736 - val_model_1_loss: 1.7175 - val_model_2_loss: 1.7443 - val_model_3_loss: 1.6953 - val_model_4_loss: 1.7480 - val_model_accuracy: 0.5325 - val_model_1_accuracy: 0.5320 - val_model_2_accuracy: 0.5390 - val_model_3_accuracy: 0.5310 - val_model_4_accuracy: 0.5195 - val_loss1: 1.1645 - val_loss2: 5.0733\n","Epoch 23/150\n","4000/4000 [==============================] - 215s 54ms/step - loss: 35.8200 - model_loss: 1.9756 - model_1_loss: 1.9878 - model_2_loss: 1.9721 - model_3_loss: 2.0223 - model_4_loss: 1.9819 - model_accuracy: 0.4754 - model_1_accuracy: 0.4686 - model_2_accuracy: 0.4750 - model_3_accuracy: 0.4634 - model_4_accuracy: 0.4733 - loss1: 0.9361 - loss2: 5.1573 - val_loss: 33.9994 - val_model_loss: 1.6951 - val_model_1_loss: 1.7747 - val_model_2_loss: 1.7673 - val_model_3_loss: 1.6973 - val_model_4_loss: 1.6636 - val_model_accuracy: 0.5545 - val_model_1_accuracy: 0.5385 - val_model_2_accuracy: 0.5425 - val_model_3_accuracy: 0.5445 - val_model_4_accuracy: 0.5440 - val_loss1: 1.1695 - val_loss2: 5.0569\n","Epoch 24/150\n","4000/4000 [==============================] - 213s 53ms/step - loss: 35.5593 - model_loss: 1.9336 - model_1_loss: 1.9516 - model_2_loss: 1.9303 - model_3_loss: 1.9826 - model_4_loss: 1.9416 - model_accuracy: 0.4826 - model_1_accuracy: 0.4781 - model_2_accuracy: 0.4821 - model_3_accuracy: 0.4696 - model_4_accuracy: 0.4782 - loss1: 0.9566 - loss2: 5.1448 - val_loss: 33.8578 - val_model_loss: 1.7045 - val_model_1_loss: 1.6196 - val_model_2_loss: 1.7314 - val_model_3_loss: 1.7540 - val_model_4_loss: 1.6671 - val_model_accuracy: 0.5570 - val_model_1_accuracy: 0.5605 - val_model_2_accuracy: 0.5445 - val_model_3_accuracy: 0.5300 - val_model_4_accuracy: 0.5535 - val_loss1: 1.1735 - val_loss2: 5.0528\n","Epoch 25/150\n","4000/4000 [==============================] - 217s 54ms/step - loss: 35.3919 - model_loss: 1.9077 - model_1_loss: 1.9319 - model_2_loss: 1.9246 - model_3_loss: 1.9571 - model_4_loss: 1.9155 - model_accuracy: 0.4870 - model_1_accuracy: 0.4848 - model_2_accuracy: 0.4849 - model_3_accuracy: 0.4796 - model_4_accuracy: 0.4871 - loss1: 0.9803 - loss2: 5.1314 - val_loss: 33.6824 - val_model_loss: 1.6788 - val_model_1_loss: 1.6715 - val_model_2_loss: 1.7109 - val_model_3_loss: 1.6635 - val_model_4_loss: 1.6288 - val_model_accuracy: 0.5510 - val_model_1_accuracy: 0.5530 - val_model_2_accuracy: 0.5465 - val_model_3_accuracy: 0.5495 - val_model_4_accuracy: 0.5610 - val_loss1: 1.2189 - val_loss2: 5.0414\n","Epoch 26/150\n","4000/4000 [==============================] - 214s 53ms/step - loss: 35.2007 - model_loss: 1.8815 - model_1_loss: 1.9089 - model_2_loss: 1.8883 - model_3_loss: 1.9360 - model_4_loss: 1.8868 - model_accuracy: 0.4958 - model_1_accuracy: 0.4893 - model_2_accuracy: 0.4954 - model_3_accuracy: 0.4823 - model_4_accuracy: 0.4923 - loss1: 1.0007 - loss2: 5.1198 - val_loss: 33.9957 - val_model_loss: 1.6921 - val_model_1_loss: 1.6628 - val_model_2_loss: 1.7085 - val_model_3_loss: 1.8487 - val_model_4_loss: 1.6225 - val_model_accuracy: 0.5615 - val_model_1_accuracy: 0.5520 - val_model_2_accuracy: 0.5370 - val_model_3_accuracy: 0.5270 - val_model_4_accuracy: 0.5560 - val_loss1: 1.1340 - val_loss2: 5.0695\n","Epoch 27/150\n","4000/4000 [==============================] - 215s 54ms/step - loss: 34.9706 - model_loss: 1.8628 - model_1_loss: 1.8872 - model_2_loss: 1.8623 - model_3_loss: 1.9010 - model_4_loss: 1.8565 - model_accuracy: 0.5006 - model_1_accuracy: 0.4947 - model_2_accuracy: 0.4990 - model_3_accuracy: 0.4897 - model_4_accuracy: 0.5011 - loss1: 1.0337 - loss2: 5.0995 - val_loss: 33.9120 - val_model_loss: 1.6957 - val_model_1_loss: 1.7809 - val_model_2_loss: 1.7326 - val_model_3_loss: 1.8316 - val_model_4_loss: 1.6957 - val_model_accuracy: 0.5625 - val_model_1_accuracy: 0.5325 - val_model_2_accuracy: 0.5395 - val_model_3_accuracy: 0.5235 - val_model_4_accuracy: 0.5530 - val_loss1: 1.2525 - val_loss2: 5.0101\n","Epoch 28/150\n","4000/4000 [==============================] - 211s 53ms/step - loss: 34.6629 - model_loss: 1.8367 - model_1_loss: 1.8549 - model_2_loss: 1.8269 - model_3_loss: 1.8798 - model_4_loss: 1.8359 - model_accuracy: 0.5072 - model_1_accuracy: 0.5043 - model_2_accuracy: 0.5060 - model_3_accuracy: 0.4957 - model_4_accuracy: 0.5041 - loss1: 1.0840 - loss2: 5.0641 - val_loss: 33.4459 - val_model_loss: 1.6418 - val_model_1_loss: 1.6724 - val_model_2_loss: 1.6192 - val_model_3_loss: 1.7303 - val_model_4_loss: 1.6540 - val_model_accuracy: 0.5710 - val_model_1_accuracy: 0.5495 - val_model_2_accuracy: 0.5640 - val_model_3_accuracy: 0.5435 - val_model_4_accuracy: 0.5565 - val_loss1: 1.2931 - val_loss2: 4.9998\n","Epoch 29/150\n","4000/4000 [==============================] - 211s 53ms/step - loss: 34.5993 - model_loss: 1.8067 - model_1_loss: 1.8250 - model_2_loss: 1.8095 - model_3_loss: 1.8545 - model_4_loss: 1.8099 - model_accuracy: 0.5146 - model_1_accuracy: 0.5084 - model_2_accuracy: 0.5125 - model_3_accuracy: 0.4985 - model_4_accuracy: 0.5113 - loss1: 1.0806 - loss2: 5.0771 - val_loss: 33.2177 - val_model_loss: 1.6643 - val_model_1_loss: 1.6798 - val_model_2_loss: 1.6556 - val_model_3_loss: 1.6592 - val_model_4_loss: 1.6021 - val_model_accuracy: 0.5550 - val_model_1_accuracy: 0.5570 - val_model_2_accuracy: 0.5665 - val_model_3_accuracy: 0.5695 - val_model_4_accuracy: 0.5680 - val_loss1: 1.3489 - val_loss2: 4.9644\n","Epoch 30/150\n","4000/4000 [==============================] - 212s 53ms/step - loss: 34.4153 - model_loss: 1.7865 - model_1_loss: 1.8165 - model_2_loss: 1.7980 - model_3_loss: 1.8376 - model_4_loss: 1.7903 - model_accuracy: 0.5187 - model_1_accuracy: 0.5116 - model_2_accuracy: 0.5135 - model_3_accuracy: 0.5027 - model_4_accuracy: 0.5150 - loss1: 1.1087 - loss2: 5.0551 - val_loss: 33.2880 - val_model_loss: 1.6646 - val_model_1_loss: 1.7155 - val_model_2_loss: 1.6848 - val_model_3_loss: 1.6428 - val_model_4_loss: 1.6333 - val_model_accuracy: 0.5570 - val_model_1_accuracy: 0.5560 - val_model_2_accuracy: 0.5605 - val_model_3_accuracy: 0.5690 - val_model_4_accuracy: 0.5725 - val_loss1: 1.3366 - val_loss2: 4.9626\n","Epoch 31/150\n","4000/4000 [==============================] - 213s 53ms/step - loss: 34.2503 - model_loss: 1.7624 - model_1_loss: 1.7723 - model_2_loss: 1.7733 - model_3_loss: 1.8156 - model_4_loss: 1.7584 - model_accuracy: 0.5221 - model_1_accuracy: 0.5211 - model_2_accuracy: 0.5224 - model_3_accuracy: 0.5079 - model_4_accuracy: 0.5223 - loss1: 1.1126 - loss2: 5.0514 - val_loss: 33.0875 - val_model_loss: 1.6218 - val_model_1_loss: 1.6457 - val_model_2_loss: 1.6189 - val_model_3_loss: 1.6289 - val_model_4_loss: 1.6097 - val_model_accuracy: 0.5855 - val_model_1_accuracy: 0.5690 - val_model_2_accuracy: 0.5795 - val_model_3_accuracy: 0.5865 - val_model_4_accuracy: 0.5765 - val_loss1: 1.3558 - val_loss2: 4.9654\n","Epoch 32/150\n","4000/4000 [==============================] - 213s 53ms/step - loss: 34.0922 - model_loss: 1.7426 - model_1_loss: 1.7676 - model_2_loss: 1.7627 - model_3_loss: 1.7926 - model_4_loss: 1.7469 - model_accuracy: 0.5275 - model_1_accuracy: 0.5213 - model_2_accuracy: 0.5224 - model_3_accuracy: 0.5153 - model_4_accuracy: 0.5256 - loss1: 1.1406 - loss2: 5.0332 - val_loss: 32.8475 - val_model_loss: 1.6156 - val_model_1_loss: 1.6811 - val_model_2_loss: 1.7166 - val_model_3_loss: 1.6663 - val_model_4_loss: 1.5942 - val_model_accuracy: 0.5690 - val_model_1_accuracy: 0.5655 - val_model_2_accuracy: 0.5615 - val_model_3_accuracy: 0.5535 - val_model_4_accuracy: 0.5720 - val_loss1: 1.4336 - val_loss2: 4.8861\n","Epoch 33/150\n","4000/4000 [==============================] - 214s 53ms/step - loss: 33.9506 - model_loss: 1.7243 - model_1_loss: 1.7411 - model_2_loss: 1.7285 - model_3_loss: 1.7740 - model_4_loss: 1.7263 - model_accuracy: 0.5311 - model_1_accuracy: 0.5296 - model_2_accuracy: 0.5322 - model_3_accuracy: 0.5211 - model_4_accuracy: 0.5329 - loss1: 1.1424 - loss2: 5.0284 - val_loss: 32.8020 - val_model_loss: 1.6281 - val_model_1_loss: 1.6491 - val_model_2_loss: 1.6225 - val_model_3_loss: 1.6022 - val_model_4_loss: 1.5316 - val_model_accuracy: 0.5715 - val_model_1_accuracy: 0.5575 - val_model_2_accuracy: 0.5785 - val_model_3_accuracy: 0.5660 - val_model_4_accuracy: 0.5890 - val_loss1: 1.3848 - val_loss2: 4.9260\n","Epoch 34/150\n","4000/4000 [==============================] - 212s 53ms/step - loss: 33.8394 - model_loss: 1.7231 - model_1_loss: 1.7388 - model_2_loss: 1.7264 - model_3_loss: 1.7617 - model_4_loss: 1.7093 - model_accuracy: 0.5307 - model_1_accuracy: 0.5261 - model_2_accuracy: 0.5319 - model_3_accuracy: 0.5233 - model_4_accuracy: 0.5335 - loss1: 1.1589 - loss2: 5.0128 - val_loss: 33.0931 - val_model_loss: 1.6239 - val_model_1_loss: 1.6714 - val_model_2_loss: 1.7400 - val_model_3_loss: 1.6600 - val_model_4_loss: 1.6353 - val_model_accuracy: 0.5800 - val_model_1_accuracy: 0.5610 - val_model_2_accuracy: 0.5370 - val_model_3_accuracy: 0.5670 - val_model_4_accuracy: 0.5740 - val_loss1: 1.3879 - val_loss2: 4.9247\n","Epoch 35/150\n","4000/4000 [==============================] - 213s 53ms/step - loss: 33.6804 - model_loss: 1.6856 - model_1_loss: 1.7090 - model_2_loss: 1.7091 - model_3_loss: 1.7402 - model_4_loss: 1.6896 - model_accuracy: 0.5427 - model_1_accuracy: 0.5366 - model_2_accuracy: 0.5379 - model_3_accuracy: 0.5276 - model_4_accuracy: 0.5436 - loss1: 1.1665 - loss2: 5.0061 - val_loss: 33.0813 - val_model_loss: 1.6373 - val_model_1_loss: 1.6372 - val_model_2_loss: 1.7210 - val_model_3_loss: 1.6639 - val_model_4_loss: 1.5742 - val_model_accuracy: 0.5890 - val_model_1_accuracy: 0.5745 - val_model_2_accuracy: 0.5680 - val_model_3_accuracy: 0.5810 - val_model_4_accuracy: 0.5965 - val_loss1: 1.3672 - val_loss2: 4.9422\n","Epoch 36/150\n","4000/4000 [==============================] - 214s 54ms/step - loss: 33.6007 - model_loss: 1.6736 - model_1_loss: 1.6947 - model_2_loss: 1.6880 - model_3_loss: 1.7297 - model_4_loss: 1.6803 - model_accuracy: 0.5457 - model_1_accuracy: 0.5398 - model_2_accuracy: 0.5396 - model_3_accuracy: 0.5297 - model_4_accuracy: 0.5403 - loss1: 1.1619 - loss2: 5.0036 - val_loss: 32.7640 - val_model_loss: 1.6080 - val_model_1_loss: 1.6310 - val_model_2_loss: 1.6386 - val_model_3_loss: 1.6074 - val_model_4_loss: 1.6194 - val_model_accuracy: 0.5800 - val_model_1_accuracy: 0.5745 - val_model_2_accuracy: 0.5835 - val_model_3_accuracy: 0.5790 - val_model_4_accuracy: 0.5735 - val_loss1: 1.3916 - val_loss2: 4.9041\n","Epoch 37/150\n","4000/4000 [==============================] - 212s 53ms/step - loss: 33.4970 - model_loss: 1.6522 - model_1_loss: 1.6786 - model_2_loss: 1.6612 - model_3_loss: 1.7115 - model_4_loss: 1.6567 - model_accuracy: 0.5523 - model_1_accuracy: 0.5410 - model_2_accuracy: 0.5476 - model_3_accuracy: 0.5357 - model_4_accuracy: 0.5489 - loss1: 1.1704 - loss2: 5.0040 - val_loss: 32.9331 - val_model_loss: 1.6572 - val_model_1_loss: 1.6580 - val_model_2_loss: 1.7266 - val_model_3_loss: 1.5884 - val_model_4_loss: 1.6634 - val_model_accuracy: 0.5795 - val_model_1_accuracy: 0.5820 - val_model_2_accuracy: 0.5695 - val_model_3_accuracy: 0.5845 - val_model_4_accuracy: 0.5880 - val_loss1: 1.4629 - val_loss2: 4.8986\n","Epoch 38/150\n","4000/4000 [==============================] - 212s 53ms/step - loss: 33.5034 - model_loss: 1.6475 - model_1_loss: 1.6740 - model_2_loss: 1.6620 - model_3_loss: 1.6955 - model_4_loss: 1.6419 - model_accuracy: 0.5507 - model_1_accuracy: 0.5450 - model_2_accuracy: 0.5481 - model_3_accuracy: 0.5385 - model_4_accuracy: 0.5555 - loss1: 1.1550 - loss2: 5.0134 - val_loss: 33.0367 - val_model_loss: 1.5908 - val_model_1_loss: 1.6561 - val_model_2_loss: 1.6487 - val_model_3_loss: 1.6310 - val_model_4_loss: 1.5873 - val_model_accuracy: 0.5850 - val_model_1_accuracy: 0.5745 - val_model_2_accuracy: 0.5725 - val_model_3_accuracy: 0.5660 - val_model_4_accuracy: 0.5805 - val_loss1: 1.3137 - val_loss2: 4.9583\n","Epoch 39/150\n","4000/4000 [==============================] - 213s 53ms/step - loss: 33.4078 - model_loss: 1.6317 - model_1_loss: 1.6422 - model_2_loss: 1.6459 - model_3_loss: 1.6835 - model_4_loss: 1.6313 - model_accuracy: 0.5547 - model_1_accuracy: 0.5514 - model_2_accuracy: 0.5506 - model_3_accuracy: 0.5416 - model_4_accuracy: 0.5576 - loss1: 1.1598 - loss2: 5.0114 - val_loss: 32.9242 - val_model_loss: 1.6255 - val_model_1_loss: 1.6901 - val_model_2_loss: 1.6119 - val_model_3_loss: 1.6044 - val_model_4_loss: 1.6081 - val_model_accuracy: 0.5915 - val_model_1_accuracy: 0.5715 - val_model_2_accuracy: 0.5830 - val_model_3_accuracy: 0.5825 - val_model_4_accuracy: 0.5870 - val_loss1: 1.3865 - val_loss2: 4.9291\n","Epoch 40/150\n","4000/4000 [==============================] - 214s 53ms/step - loss: 33.3437 - model_loss: 1.6261 - model_1_loss: 1.6325 - model_2_loss: 1.6288 - model_3_loss: 1.6652 - model_4_loss: 1.6175 - model_accuracy: 0.5570 - model_1_accuracy: 0.5548 - model_2_accuracy: 0.5546 - model_3_accuracy: 0.5483 - model_4_accuracy: 0.5600 - loss1: 1.1537 - loss2: 5.0116 - val_loss: 32.9363 - val_model_loss: 1.6025 - val_model_1_loss: 1.7406 - val_model_2_loss: 1.6433 - val_model_3_loss: 1.6550 - val_model_4_loss: 1.5982 - val_model_accuracy: 0.5845 - val_model_1_accuracy: 0.5695 - val_model_2_accuracy: 0.5850 - val_model_3_accuracy: 0.5745 - val_model_4_accuracy: 0.5895 - val_loss1: 1.3859 - val_loss2: 4.9116\n","Epoch 41/150\n","4000/4000 [==============================] - 214s 53ms/step - loss: 33.2430 - model_loss: 1.5916 - model_1_loss: 1.6170 - model_2_loss: 1.6052 - model_3_loss: 1.6536 - model_4_loss: 1.5953 - model_accuracy: 0.5657 - model_1_accuracy: 0.5615 - model_2_accuracy: 0.5628 - model_3_accuracy: 0.5500 - model_4_accuracy: 0.5671 - loss1: 1.1498 - loss2: 5.0130 - val_loss: 32.7903 - val_model_loss: 1.6363 - val_model_1_loss: 1.6514 - val_model_2_loss: 1.6266 - val_model_3_loss: 1.6059 - val_model_4_loss: 1.5778 - val_model_accuracy: 0.5720 - val_model_1_accuracy: 0.5725 - val_model_2_accuracy: 0.5875 - val_model_3_accuracy: 0.5865 - val_model_4_accuracy: 0.5925 - val_loss1: 1.3928 - val_loss2: 4.9106\n","Epoch 42/150\n","4000/4000 [==============================] - 213s 53ms/step - loss: 33.1083 - model_loss: 1.5770 - model_1_loss: 1.6056 - model_2_loss: 1.5977 - model_3_loss: 1.6399 - model_4_loss: 1.5814 - model_accuracy: 0.5678 - model_1_accuracy: 0.5602 - model_2_accuracy: 0.5646 - model_3_accuracy: 0.5538 - model_4_accuracy: 0.5668 - loss1: 1.1615 - loss2: 4.9981 - val_loss: 32.9546 - val_model_loss: 1.6291 - val_model_1_loss: 1.6209 - val_model_2_loss: 1.5869 - val_model_3_loss: 1.5693 - val_model_4_loss: 1.7059 - val_model_accuracy: 0.5935 - val_model_1_accuracy: 0.5830 - val_model_2_accuracy: 0.5925 - val_model_3_accuracy: 0.5870 - val_model_4_accuracy: 0.5770 - val_loss1: 1.3659 - val_loss2: 4.9412\n","Epoch 43/150\n","4000/4000 [==============================] - 215s 54ms/step - loss: 32.9978 - model_loss: 1.5617 - model_1_loss: 1.5860 - model_2_loss: 1.5681 - model_3_loss: 1.6214 - model_4_loss: 1.5633 - model_accuracy: 0.5714 - model_1_accuracy: 0.5678 - model_2_accuracy: 0.5699 - model_3_accuracy: 0.5596 - model_4_accuracy: 0.5708 - loss1: 1.1621 - loss2: 4.9962 - val_loss: 32.7304 - val_model_loss: 1.6356 - val_model_1_loss: 1.6320 - val_model_2_loss: 1.6311 - val_model_3_loss: 1.5992 - val_model_4_loss: 1.6232 - val_model_accuracy: 0.5915 - val_model_1_accuracy: 0.5895 - val_model_2_accuracy: 0.5855 - val_model_3_accuracy: 0.5855 - val_model_4_accuracy: 0.5855 - val_loss1: 1.4198 - val_loss2: 4.8935\n","Epoch 44/150\n","4000/4000 [==============================] - 215s 54ms/step - loss: 32.9369 - model_loss: 1.5584 - model_1_loss: 1.5697 - model_2_loss: 1.5580 - model_3_loss: 1.6000 - model_4_loss: 1.5606 - model_accuracy: 0.5735 - model_1_accuracy: 0.5696 - model_2_accuracy: 0.5736 - model_3_accuracy: 0.5613 - model_4_accuracy: 0.5729 - loss1: 1.1733 - loss2: 4.9946 - val_loss: 32.8373 - val_model_loss: 1.5732 - val_model_1_loss: 1.6830 - val_model_2_loss: 1.6028 - val_model_3_loss: 1.6308 - val_model_4_loss: 1.6264 - val_model_accuracy: 0.5925 - val_model_1_accuracy: 0.5735 - val_model_2_accuracy: 0.5790 - val_model_3_accuracy: 0.5785 - val_model_4_accuracy: 0.5820 - val_loss1: 1.3984 - val_loss2: 4.9162\n","Epoch 45/150\n","4000/4000 [==============================] - 217s 54ms/step - loss: 32.9799 - model_loss: 1.5616 - model_1_loss: 1.5754 - model_2_loss: 1.5728 - model_3_loss: 1.6081 - model_4_loss: 1.5543 - model_accuracy: 0.5759 - model_1_accuracy: 0.5692 - model_2_accuracy: 0.5686 - model_3_accuracy: 0.5633 - model_4_accuracy: 0.5730 - loss1: 1.1602 - loss2: 4.9984 - val_loss: 33.0097 - val_model_loss: 1.6298 - val_model_1_loss: 1.6668 - val_model_2_loss: 1.7248 - val_model_3_loss: 1.6434 - val_model_4_loss: 1.6060 - val_model_accuracy: 0.5935 - val_model_1_accuracy: 0.5825 - val_model_2_accuracy: 0.5835 - val_model_3_accuracy: 0.5800 - val_model_4_accuracy: 0.5880 - val_loss1: 1.3861 - val_loss2: 4.9200\n","Epoch 46/150\n","4000/4000 [==============================] - 221s 55ms/step - loss: 32.8106 - model_loss: 1.5254 - model_1_loss: 1.5533 - model_2_loss: 1.5414 - model_3_loss: 1.5731 - model_4_loss: 1.5323 - model_accuracy: 0.5834 - model_1_accuracy: 0.5755 - model_2_accuracy: 0.5756 - model_3_accuracy: 0.5717 - model_4_accuracy: 0.5790 - loss1: 1.1665 - loss2: 4.9937 - val_loss: 33.0802 - val_model_loss: 1.6253 - val_model_1_loss: 1.6229 - val_model_2_loss: 1.6720 - val_model_3_loss: 1.6309 - val_model_4_loss: 1.6012 - val_model_accuracy: 0.5960 - val_model_1_accuracy: 0.5945 - val_model_2_accuracy: 0.5795 - val_model_3_accuracy: 0.5860 - val_model_4_accuracy: 0.5915 - val_loss1: 1.3615 - val_loss2: 4.9584\n","Epoch 47/150\n","4000/4000 [==============================] - 216s 54ms/step - loss: 32.7963 - model_loss: 1.5124 - model_1_loss: 1.5301 - model_2_loss: 1.5266 - model_3_loss: 1.5616 - model_4_loss: 1.5149 - model_accuracy: 0.5855 - model_1_accuracy: 0.5794 - model_2_accuracy: 0.5806 - model_3_accuracy: 0.5706 - model_4_accuracy: 0.5870 - loss1: 1.1457 - loss2: 5.0072 - val_loss: 33.0416 - val_model_loss: 1.6495 - val_model_1_loss: 1.6378 - val_model_2_loss: 1.6570 - val_model_3_loss: 1.6439 - val_model_4_loss: 1.6043 - val_model_accuracy: 0.6040 - val_model_1_accuracy: 0.5885 - val_model_2_accuracy: 0.5950 - val_model_3_accuracy: 0.5875 - val_model_4_accuracy: 0.5940 - val_loss1: 1.3777 - val_loss2: 4.9423\n","Epoch 48/150\n","4000/4000 [==============================] - 216s 54ms/step - loss: 32.7491 - model_loss: 1.5076 - model_1_loss: 1.5104 - model_2_loss: 1.5148 - model_3_loss: 1.5447 - model_4_loss: 1.4985 - model_accuracy: 0.5878 - model_1_accuracy: 0.5871 - model_2_accuracy: 0.5849 - model_3_accuracy: 0.5790 - model_4_accuracy: 0.5874 - loss1: 1.1447 - loss2: 5.0117 - val_loss: 32.8587 - val_model_loss: 1.5982 - val_model_1_loss: 1.6327 - val_model_2_loss: 1.6194 - val_model_3_loss: 1.7004 - val_model_4_loss: 1.5698 - val_model_accuracy: 0.5955 - val_model_1_accuracy: 0.5875 - val_model_2_accuracy: 0.5885 - val_model_3_accuracy: 0.5805 - val_model_4_accuracy: 0.6030 - val_loss1: 1.3927 - val_loss2: 4.9198\n","Epoch 49/150\n","4000/4000 [==============================] - 214s 54ms/step - loss: 32.7159 - model_loss: 1.4923 - model_1_loss: 1.5098 - model_2_loss: 1.5137 - model_3_loss: 1.5420 - model_4_loss: 1.5026 - model_accuracy: 0.5929 - model_1_accuracy: 0.5853 - model_2_accuracy: 0.5840 - model_3_accuracy: 0.5764 - model_4_accuracy: 0.5885 - loss1: 1.1413 - loss2: 5.0083 - val_loss: 33.1273 - val_model_loss: 1.6774 - val_model_1_loss: 1.7010 - val_model_2_loss: 1.6496 - val_model_3_loss: 1.6286 - val_model_4_loss: 1.6551 - val_model_accuracy: 0.6015 - val_model_1_accuracy: 0.5830 - val_model_2_accuracy: 0.5930 - val_model_3_accuracy: 0.5975 - val_model_4_accuracy: 0.5885 - val_loss1: 1.3702 - val_loss2: 4.9357\n","Epoch 50/150\n","4000/4000 [==============================] - 215s 54ms/step - loss: 32.6076 - model_loss: 1.4763 - model_1_loss: 1.5023 - model_2_loss: 1.4994 - model_3_loss: 1.5289 - model_4_loss: 1.4844 - model_accuracy: 0.5969 - model_1_accuracy: 0.5880 - model_2_accuracy: 0.5886 - model_3_accuracy: 0.5793 - model_4_accuracy: 0.5945 - loss1: 1.1583 - loss2: 5.0001 - val_loss: 32.8512 - val_model_loss: 1.6091 - val_model_1_loss: 1.6822 - val_model_2_loss: 1.6253 - val_model_3_loss: 1.6617 - val_model_4_loss: 1.5919 - val_model_accuracy: 0.6005 - val_model_1_accuracy: 0.5795 - val_model_2_accuracy: 0.5920 - val_model_3_accuracy: 0.5785 - val_model_4_accuracy: 0.5990 - val_loss1: 1.4121 - val_loss2: 4.9079\n","Epoch 51/150\n","4000/4000 [==============================] - 216s 54ms/step - loss: 32.5333 - model_loss: 1.4677 - model_1_loss: 1.4792 - model_2_loss: 1.4843 - model_3_loss: 1.5198 - model_4_loss: 1.4747 - model_accuracy: 0.5965 - model_1_accuracy: 0.5947 - model_2_accuracy: 0.5900 - model_3_accuracy: 0.5846 - model_4_accuracy: 0.5961 - loss1: 1.1565 - loss2: 4.9984 - val_loss: 33.0124 - val_model_loss: 1.7942 - val_model_1_loss: 1.7178 - val_model_2_loss: 1.5884 - val_model_3_loss: 1.6382 - val_model_4_loss: 1.6438 - val_model_accuracy: 0.5835 - val_model_1_accuracy: 0.5810 - val_model_2_accuracy: 0.5880 - val_model_3_accuracy: 0.5860 - val_model_4_accuracy: 0.6015 - val_loss1: 1.3850 - val_loss2: 4.8983\n","Epoch 52/150\n","4000/4000 [==============================] - 224s 56ms/step - loss: 32.4899 - model_loss: 1.4529 - model_1_loss: 1.4728 - model_2_loss: 1.4738 - model_3_loss: 1.5104 - model_4_loss: 1.4542 - model_accuracy: 0.5988 - model_1_accuracy: 0.5959 - model_2_accuracy: 0.5916 - model_3_accuracy: 0.5856 - model_4_accuracy: 0.6010 - loss1: 1.1513 - loss2: 5.0021 - val_loss: 33.1085 - val_model_loss: 1.7224 - val_model_1_loss: 1.6571 - val_model_2_loss: 1.6732 - val_model_3_loss: 1.6326 - val_model_4_loss: 1.6489 - val_model_accuracy: 0.5910 - val_model_1_accuracy: 0.5845 - val_model_2_accuracy: 0.5985 - val_model_3_accuracy: 0.5905 - val_model_4_accuracy: 0.5960 - val_loss1: 1.3774 - val_loss2: 4.9273\n","Epoch 53/150\n","4000/4000 [==============================] - 221s 55ms/step - loss: 32.4389 - model_loss: 1.4490 - model_1_loss: 1.4678 - model_2_loss: 1.4528 - model_3_loss: 1.4867 - model_4_loss: 1.4415 - model_accuracy: 0.6013 - model_1_accuracy: 0.5954 - model_2_accuracy: 0.5979 - model_3_accuracy: 0.5897 - model_4_accuracy: 0.6040 - loss1: 1.1496 - loss2: 5.0052 - val_loss: 32.8907 - val_model_loss: 1.6423 - val_model_1_loss: 1.7232 - val_model_2_loss: 1.6488 - val_model_3_loss: 1.6657 - val_model_4_loss: 1.6179 - val_model_accuracy: 0.6045 - val_model_1_accuracy: 0.5905 - val_model_2_accuracy: 0.6090 - val_model_3_accuracy: 0.5810 - val_model_4_accuracy: 0.6065 - val_loss1: 1.4399 - val_loss2: 4.8898\n","Epoch 54/150\n","4000/4000 [==============================] - 219s 55ms/step - loss: 32.4525 - model_loss: 1.4458 - model_1_loss: 1.4601 - model_2_loss: 1.4469 - model_3_loss: 1.4829 - model_4_loss: 1.4409 - model_accuracy: 0.6058 - model_1_accuracy: 0.5978 - model_2_accuracy: 0.6053 - model_3_accuracy: 0.5911 - model_4_accuracy: 0.6043 - loss1: 1.1334 - loss2: 5.0125 - val_loss: 32.9410 - val_model_loss: 1.6533 - val_model_1_loss: 1.6694 - val_model_2_loss: 1.6700 - val_model_3_loss: 1.6298 - val_model_4_loss: 1.6392 - val_model_accuracy: 0.5935 - val_model_1_accuracy: 0.5870 - val_model_2_accuracy: 0.5960 - val_model_3_accuracy: 0.5920 - val_model_4_accuracy: 0.5920 - val_loss1: 1.4080 - val_loss2: 4.9077\n","Epoch 55/150\n","4000/4000 [==============================] - 223s 56ms/step - loss: 32.4405 - model_loss: 1.4308 - model_1_loss: 1.4487 - model_2_loss: 1.4430 - model_3_loss: 1.4791 - model_4_loss: 1.4316 - model_accuracy: 0.6064 - model_1_accuracy: 0.6024 - model_2_accuracy: 0.6027 - model_3_accuracy: 0.5965 - model_4_accuracy: 0.6080 - loss1: 1.1320 - loss2: 5.0188 - val_loss: 33.1927 - val_model_loss: 1.5701 - val_model_1_loss: 1.6494 - val_model_2_loss: 1.6127 - val_model_3_loss: 1.7219 - val_model_4_loss: 1.7104 - val_model_accuracy: 0.6100 - val_model_1_accuracy: 0.5820 - val_model_2_accuracy: 0.6070 - val_model_3_accuracy: 0.5805 - val_model_4_accuracy: 0.6010 - val_loss1: 1.3405 - val_loss2: 4.9588\n","Epoch 56/150\n","4000/4000 [==============================] - 221s 55ms/step - loss: 32.3381 - model_loss: 1.4260 - model_1_loss: 1.4339 - model_2_loss: 1.4289 - model_3_loss: 1.4593 - model_4_loss: 1.4140 - model_accuracy: 0.6104 - model_1_accuracy: 0.6060 - model_2_accuracy: 0.6026 - model_3_accuracy: 0.5989 - model_4_accuracy: 0.6092 - loss1: 1.1426 - loss2: 5.0123 - val_loss: 33.0232 - val_model_loss: 1.6621 - val_model_1_loss: 1.6791 - val_model_2_loss: 1.6719 - val_model_3_loss: 1.6265 - val_model_4_loss: 1.6110 - val_model_accuracy: 0.6060 - val_model_1_accuracy: 0.5995 - val_model_2_accuracy: 0.5975 - val_model_3_accuracy: 0.6025 - val_model_4_accuracy: 0.6095 - val_loss1: 1.3743 - val_loss2: 4.9270\n","Epoch 57/150\n","4000/4000 [==============================] - 223s 56ms/step - loss: 32.3321 - model_loss: 1.4211 - model_1_loss: 1.4314 - model_2_loss: 1.4218 - model_3_loss: 1.4524 - model_4_loss: 1.4186 - model_accuracy: 0.6099 - model_1_accuracy: 0.6046 - model_2_accuracy: 0.6100 - model_3_accuracy: 0.6030 - model_4_accuracy: 0.6088 - loss1: 1.1346 - loss2: 5.0146 - val_loss: 33.0795 - val_model_loss: 1.6527 - val_model_1_loss: 1.7699 - val_model_2_loss: 1.7337 - val_model_3_loss: 1.6377 - val_model_4_loss: 1.6102 - val_model_accuracy: 0.6000 - val_model_1_accuracy: 0.5795 - val_model_2_accuracy: 0.5935 - val_model_3_accuracy: 0.5920 - val_model_4_accuracy: 0.5990 - val_loss1: 1.4336 - val_loss2: 4.9064\n","Epoch 58/150\n","4000/4000 [==============================] - 224s 56ms/step - loss: 32.2514 - model_loss: 1.4119 - model_1_loss: 1.4248 - model_2_loss: 1.4196 - model_3_loss: 1.4617 - model_4_loss: 1.4118 - model_accuracy: 0.6145 - model_1_accuracy: 0.6106 - model_2_accuracy: 0.6089 - model_3_accuracy: 0.6000 - model_4_accuracy: 0.6103 - loss1: 1.1462 - loss2: 5.0014 - val_loss: 32.9024 - val_model_loss: 1.7886 - val_model_1_loss: 1.6830 - val_model_2_loss: 1.6330 - val_model_3_loss: 1.6830 - val_model_4_loss: 1.5900 - val_model_accuracy: 0.5830 - val_model_1_accuracy: 0.5980 - val_model_2_accuracy: 0.6060 - val_model_3_accuracy: 0.5930 - val_model_4_accuracy: 0.6065 - val_loss1: 1.4354 - val_loss2: 4.8763\n","Epoch 59/150\n","4000/4000 [==============================] - 226s 56ms/step - loss: 32.1527 - model_loss: 1.3900 - model_1_loss: 1.4096 - model_2_loss: 1.4078 - model_3_loss: 1.4410 - model_4_loss: 1.3851 - model_accuracy: 0.6150 - model_1_accuracy: 0.6092 - model_2_accuracy: 0.6120 - model_3_accuracy: 0.6014 - model_4_accuracy: 0.6175 - loss1: 1.1428 - loss2: 5.0010 - val_loss: 33.3678 - val_model_loss: 1.7939 - val_model_1_loss: 1.7089 - val_model_2_loss: 1.6661 - val_model_3_loss: 1.7117 - val_model_4_loss: 1.7040 - val_model_accuracy: 0.5885 - val_model_1_accuracy: 0.5810 - val_model_2_accuracy: 0.5935 - val_model_3_accuracy: 0.6005 - val_model_4_accuracy: 0.6070 - val_loss1: 1.3451 - val_loss2: 4.9297\n","Epoch 60/150\n","4000/4000 [==============================] - 223s 56ms/step - loss: 32.2103 - model_loss: 1.3933 - model_1_loss: 1.4022 - model_2_loss: 1.3988 - model_3_loss: 1.4230 - model_4_loss: 1.3910 - model_accuracy: 0.6168 - model_1_accuracy: 0.6158 - model_2_accuracy: 0.6143 - model_3_accuracy: 0.6080 - model_4_accuracy: 0.6166 - loss1: 1.1384 - loss2: 5.0176 - val_loss: 32.9678 - val_model_loss: 1.6418 - val_model_1_loss: 1.6478 - val_model_2_loss: 1.6210 - val_model_3_loss: 1.6951 - val_model_4_loss: 1.5618 - val_model_accuracy: 0.5990 - val_model_1_accuracy: 0.5960 - val_model_2_accuracy: 0.5970 - val_model_3_accuracy: 0.5940 - val_model_4_accuracy: 0.6160 - val_loss1: 1.3642 - val_loss2: 4.9328\n","Epoch 61/150\n","4000/4000 [==============================] - 223s 56ms/step - loss: 32.1109 - model_loss: 1.3835 - model_1_loss: 1.3990 - model_2_loss: 1.4048 - model_3_loss: 1.4271 - model_4_loss: 1.3865 - model_accuracy: 0.6215 - model_1_accuracy: 0.6171 - model_2_accuracy: 0.6162 - model_3_accuracy: 0.6081 - model_4_accuracy: 0.6185 - loss1: 1.1591 - loss2: 4.9988 - val_loss: 32.9810 - val_model_loss: 1.6725 - val_model_1_loss: 1.6765 - val_model_2_loss: 1.6504 - val_model_3_loss: 1.7557 - val_model_4_loss: 1.6251 - val_model_accuracy: 0.6040 - val_model_1_accuracy: 0.5890 - val_model_2_accuracy: 0.6085 - val_model_3_accuracy: 0.5865 - val_model_4_accuracy: 0.6170 - val_loss1: 1.4354 - val_loss2: 4.8914\n","Epoch 62/150\n","4000/4000 [==============================] - 222s 55ms/step - loss: 32.0174 - model_loss: 1.3797 - model_1_loss: 1.3965 - model_2_loss: 1.3992 - model_3_loss: 1.4181 - model_4_loss: 1.3833 - model_accuracy: 0.6226 - model_1_accuracy: 0.6194 - model_2_accuracy: 0.6177 - model_3_accuracy: 0.6085 - model_4_accuracy: 0.6209 - loss1: 1.1598 - loss2: 4.9849 - val_loss: 33.0461 - val_model_loss: 1.7409 - val_model_1_loss: 1.6875 - val_model_2_loss: 1.7043 - val_model_3_loss: 1.7559 - val_model_4_loss: 1.6297 - val_model_accuracy: 0.6015 - val_model_1_accuracy: 0.5825 - val_model_2_accuracy: 0.5940 - val_model_3_accuracy: 0.5930 - val_model_4_accuracy: 0.6090 - val_loss1: 1.3953 - val_loss2: 4.8777\n","Epoch 63/150\n","4000/4000 [==============================] - 223s 56ms/step - loss: 31.9530 - model_loss: 1.3539 - model_1_loss: 1.3737 - model_2_loss: 1.3768 - model_3_loss: 1.4065 - model_4_loss: 1.3597 - model_accuracy: 0.6233 - model_1_accuracy: 0.6219 - model_2_accuracy: 0.6211 - model_3_accuracy: 0.6109 - model_4_accuracy: 0.6223 - loss1: 1.1446 - loss2: 4.9936 - val_loss: 32.9401 - val_model_loss: 1.7153 - val_model_1_loss: 1.6592 - val_model_2_loss: 1.6366 - val_model_3_loss: 1.6803 - val_model_4_loss: 1.6183 - val_model_accuracy: 0.6010 - val_model_1_accuracy: 0.6055 - val_model_2_accuracy: 0.6030 - val_model_3_accuracy: 0.5980 - val_model_4_accuracy: 0.6125 - val_loss1: 1.4140 - val_loss2: 4.8978\n","Epoch 64/150\n","4000/4000 [==============================] - 221s 55ms/step - loss: 31.9315 - model_loss: 1.3577 - model_1_loss: 1.3656 - model_2_loss: 1.3679 - model_3_loss: 1.3915 - model_4_loss: 1.3569 - model_accuracy: 0.6245 - model_1_accuracy: 0.6252 - model_2_accuracy: 0.6252 - model_3_accuracy: 0.6157 - model_4_accuracy: 0.6301 - loss1: 1.1374 - loss2: 4.9956 - val_loss: 32.9485 - val_model_loss: 1.6398 - val_model_1_loss: 1.5883 - val_model_2_loss: 1.5841 - val_model_3_loss: 1.6806 - val_model_4_loss: 1.7059 - val_model_accuracy: 0.6090 - val_model_1_accuracy: 0.6080 - val_model_2_accuracy: 0.6070 - val_model_3_accuracy: 0.6005 - val_model_4_accuracy: 0.6015 - val_loss1: 1.3604 - val_loss2: 4.9228\n","Epoch 65/150\n","4000/4000 [==============================] - 224s 56ms/step - loss: 31.9862 - model_loss: 1.3421 - model_1_loss: 1.3705 - model_2_loss: 1.3534 - model_3_loss: 1.3862 - model_4_loss: 1.3493 - model_accuracy: 0.6282 - model_1_accuracy: 0.6227 - model_2_accuracy: 0.6248 - model_3_accuracy: 0.6173 - model_4_accuracy: 0.6291 - loss1: 1.1212 - loss2: 5.0145 - val_loss: 33.2094 - val_model_loss: 1.7024 - val_model_1_loss: 1.6725 - val_model_2_loss: 1.6025 - val_model_3_loss: 1.7415 - val_model_4_loss: 1.7062 - val_model_accuracy: 0.5915 - val_model_1_accuracy: 0.5925 - val_model_2_accuracy: 0.6095 - val_model_3_accuracy: 0.5965 - val_model_4_accuracy: 0.6065 - val_loss1: 1.4096 - val_loss2: 4.9287\n","Epoch 66/150\n","4000/4000 [==============================] - 229s 57ms/step - loss: 31.8716 - model_loss: 1.3311 - model_1_loss: 1.3314 - model_2_loss: 1.3508 - model_3_loss: 1.3760 - model_4_loss: 1.3335 - model_accuracy: 0.6298 - model_1_accuracy: 0.6294 - model_2_accuracy: 0.6264 - model_3_accuracy: 0.6216 - model_4_accuracy: 0.6319 - loss1: 1.1270 - loss2: 5.0072 - val_loss: 33.2777 - val_model_loss: 1.6923 - val_model_1_loss: 1.7564 - val_model_2_loss: 1.6703 - val_model_3_loss: 1.7286 - val_model_4_loss: 1.6627 - val_model_accuracy: 0.5970 - val_model_1_accuracy: 0.5905 - val_model_2_accuracy: 0.6100 - val_model_3_accuracy: 0.5905 - val_model_4_accuracy: 0.6155 - val_loss1: 1.3546 - val_loss2: 4.9264\n","Epoch 67/150\n","4000/4000 [==============================] - 231s 58ms/step - loss: 31.7867 - model_loss: 1.3193 - model_1_loss: 1.3354 - model_2_loss: 1.3278 - model_3_loss: 1.3638 - model_4_loss: 1.3222 - model_accuracy: 0.6388 - model_1_accuracy: 0.6295 - model_2_accuracy: 0.6325 - model_3_accuracy: 0.6233 - model_4_accuracy: 0.6376 - loss1: 1.1353 - loss2: 5.0009 - val_loss: 32.8683 - val_model_loss: 1.6473 - val_model_1_loss: 1.6668 - val_model_2_loss: 1.6126 - val_model_3_loss: 1.7166 - val_model_4_loss: 1.7047 - val_model_accuracy: 0.6095 - val_model_1_accuracy: 0.5990 - val_model_2_accuracy: 0.6095 - val_model_3_accuracy: 0.5925 - val_model_4_accuracy: 0.5985 - val_loss1: 1.4165 - val_loss2: 4.8758\n","Epoch 68/150\n","4000/4000 [==============================] - 231s 58ms/step - loss: 31.7991 - model_loss: 1.3387 - model_1_loss: 1.3470 - model_2_loss: 1.3407 - model_3_loss: 1.3682 - model_4_loss: 1.3298 - model_accuracy: 0.6313 - model_1_accuracy: 0.6306 - model_2_accuracy: 0.6316 - model_3_accuracy: 0.6245 - model_4_accuracy: 0.6333 - loss1: 1.1375 - loss2: 4.9922 - val_loss: 32.9931 - val_model_loss: 1.7475 - val_model_1_loss: 1.6786 - val_model_2_loss: 1.6467 - val_model_3_loss: 1.7362 - val_model_4_loss: 1.5948 - val_model_accuracy: 0.5840 - val_model_1_accuracy: 0.5985 - val_model_2_accuracy: 0.6040 - val_model_3_accuracy: 0.5865 - val_model_4_accuracy: 0.6205 - val_loss1: 1.4178 - val_loss2: 4.8895\n","Epoch 69/150\n","4000/4000 [==============================] - 235s 59ms/step - loss: 31.0210 - model_loss: 1.3180 - model_1_loss: 1.3350 - model_2_loss: 1.3466 - model_3_loss: 1.3620 - model_4_loss: 1.3237 - model_accuracy: 0.6360 - model_1_accuracy: 0.6310 - model_2_accuracy: 0.6285 - model_3_accuracy: 0.6256 - model_4_accuracy: 0.6341 - loss1: 1.2353 - loss2: 4.8424 - val_loss: 32.3808 - val_model_loss: 1.6739 - val_model_1_loss: 1.6774 - val_model_2_loss: 1.6693 - val_model_3_loss: 1.7056 - val_model_4_loss: 1.6922 - val_model_accuracy: 0.6090 - val_model_1_accuracy: 0.6020 - val_model_2_accuracy: 0.6000 - val_model_3_accuracy: 0.6025 - val_model_4_accuracy: 0.6095 - val_loss1: 1.4465 - val_loss2: 4.7635\n","Epoch 70/150\n","4000/4000 [==============================] - 232s 58ms/step - loss: 30.9142 - model_loss: 1.3204 - model_1_loss: 1.3292 - model_2_loss: 1.3298 - model_3_loss: 1.3463 - model_4_loss: 1.3229 - model_accuracy: 0.6372 - model_1_accuracy: 0.6308 - model_2_accuracy: 0.6315 - model_3_accuracy: 0.6270 - model_4_accuracy: 0.6322 - loss1: 1.2181 - loss2: 4.8287 - val_loss: 32.1796 - val_model_loss: 1.6754 - val_model_1_loss: 1.7453 - val_model_2_loss: 1.6372 - val_model_3_loss: 1.7082 - val_model_4_loss: 1.6754 - val_model_accuracy: 0.6080 - val_model_1_accuracy: 0.6015 - val_model_2_accuracy: 0.6105 - val_model_3_accuracy: 0.5910 - val_model_4_accuracy: 0.6075 - val_loss1: 1.4809 - val_loss2: 4.7180\n","Epoch 71/150\n","4000/4000 [==============================] - 228s 57ms/step - loss: 30.7429 - model_loss: 1.3031 - model_1_loss: 1.3117 - model_2_loss: 1.3244 - model_3_loss: 1.3390 - model_4_loss: 1.2963 - model_accuracy: 0.6410 - model_1_accuracy: 0.6412 - model_2_accuracy: 0.6348 - model_3_accuracy: 0.6309 - model_4_accuracy: 0.6407 - loss1: 1.2124 - loss2: 4.8094 - val_loss: 32.1509 - val_model_loss: 1.6496 - val_model_1_loss: 1.6743 - val_model_2_loss: 1.6932 - val_model_3_loss: 1.6873 - val_model_4_loss: 1.6533 - val_model_accuracy: 0.6080 - val_model_1_accuracy: 0.6000 - val_model_2_accuracy: 0.5975 - val_model_3_accuracy: 0.6025 - val_model_4_accuracy: 0.6175 - val_loss1: 1.4620 - val_loss2: 4.7294\n","Epoch 72/150\n","4000/4000 [==============================] - 229s 57ms/step - loss: 30.6896 - model_loss: 1.2927 - model_1_loss: 1.3038 - model_2_loss: 1.3010 - model_3_loss: 1.3263 - model_4_loss: 1.2910 - model_accuracy: 0.6401 - model_1_accuracy: 0.6387 - model_2_accuracy: 0.6396 - model_3_accuracy: 0.6320 - model_4_accuracy: 0.6437 - loss1: 1.2184 - loss2: 4.8106 - val_loss: 32.0551 - val_model_loss: 1.6656 - val_model_1_loss: 1.6903 - val_model_2_loss: 1.6061 - val_model_3_loss: 1.6657 - val_model_4_loss: 1.6824 - val_model_accuracy: 0.6035 - val_model_1_accuracy: 0.5960 - val_model_2_accuracy: 0.6120 - val_model_3_accuracy: 0.6025 - val_model_4_accuracy: 0.6200 - val_loss1: 1.4675 - val_loss2: 4.7197\n","Epoch 73/150\n","4000/4000 [==============================] - 230s 57ms/step - loss: 30.6287 - model_loss: 1.2917 - model_1_loss: 1.2919 - model_2_loss: 1.3052 - model_3_loss: 1.3162 - model_4_loss: 1.2884 - model_accuracy: 0.6442 - model_1_accuracy: 0.6433 - model_2_accuracy: 0.6387 - model_3_accuracy: 0.6348 - model_4_accuracy: 0.6434 - loss1: 1.2196 - loss2: 4.8027 - val_loss: 32.3186 - val_model_loss: 1.6976 - val_model_1_loss: 1.7019 - val_model_2_loss: 1.6487 - val_model_3_loss: 1.6766 - val_model_4_loss: 1.6696 - val_model_accuracy: 0.6080 - val_model_1_accuracy: 0.6090 - val_model_2_accuracy: 0.6085 - val_model_3_accuracy: 0.5955 - val_model_4_accuracy: 0.6095 - val_loss1: 1.4365 - val_loss2: 4.7561\n","Epoch 74/150\n","4000/4000 [==============================] - 230s 57ms/step - loss: 30.5113 - model_loss: 1.2820 - model_1_loss: 1.2763 - model_2_loss: 1.2911 - model_3_loss: 1.3150 - model_4_loss: 1.2751 - model_accuracy: 0.6502 - model_1_accuracy: 0.6463 - model_2_accuracy: 0.6434 - model_3_accuracy: 0.6353 - model_4_accuracy: 0.6474 - loss1: 1.2225 - loss2: 4.7899 - val_loss: 31.9147 - val_model_loss: 1.6288 - val_model_1_loss: 1.7185 - val_model_2_loss: 1.5959 - val_model_3_loss: 1.7478 - val_model_4_loss: 1.6470 - val_model_accuracy: 0.6030 - val_model_1_accuracy: 0.6015 - val_model_2_accuracy: 0.6110 - val_model_3_accuracy: 0.6030 - val_model_4_accuracy: 0.6020 - val_loss1: 1.4951 - val_loss2: 4.6855\n","Epoch 75/150\n","4000/4000 [==============================] - 228s 57ms/step - loss: 30.3762 - model_loss: 1.2765 - model_1_loss: 1.2756 - model_2_loss: 1.2747 - model_3_loss: 1.2953 - model_4_loss: 1.2707 - model_accuracy: 0.6484 - model_1_accuracy: 0.6482 - model_2_accuracy: 0.6474 - model_3_accuracy: 0.6407 - model_4_accuracy: 0.6468 - loss1: 1.2379 - loss2: 4.7719 - val_loss: 32.2304 - val_model_loss: 1.6989 - val_model_1_loss: 1.7498 - val_model_2_loss: 1.6576 - val_model_3_loss: 1.7275 - val_model_4_loss: 1.6134 - val_model_accuracy: 0.6050 - val_model_1_accuracy: 0.5965 - val_model_2_accuracy: 0.6060 - val_model_3_accuracy: 0.6105 - val_model_4_accuracy: 0.6150 - val_loss1: 1.4577 - val_loss2: 4.7275\n","Epoch 76/150\n","4000/4000 [==============================] - 229s 57ms/step - loss: 30.4688 - model_loss: 1.2798 - model_1_loss: 1.2910 - model_2_loss: 1.3009 - model_3_loss: 1.3159 - model_4_loss: 1.2903 - model_accuracy: 0.6476 - model_1_accuracy: 0.6427 - model_2_accuracy: 0.6429 - model_3_accuracy: 0.6359 - model_4_accuracy: 0.6466 - loss1: 1.2205 - loss2: 4.7738 - val_loss: 32.0646 - val_model_loss: 1.7388 - val_model_1_loss: 1.7160 - val_model_2_loss: 1.6765 - val_model_3_loss: 1.6724 - val_model_4_loss: 1.6736 - val_model_accuracy: 0.6185 - val_model_1_accuracy: 0.5980 - val_model_2_accuracy: 0.6065 - val_model_3_accuracy: 0.6160 - val_model_4_accuracy: 0.6115 - val_loss1: 1.4760 - val_loss2: 4.6879\n","Epoch 77/150\n","4000/4000 [==============================] - 227s 57ms/step - loss: 30.3600 - model_loss: 1.2688 - model_1_loss: 1.2659 - model_2_loss: 1.2672 - model_3_loss: 1.2918 - model_4_loss: 1.2611 - model_accuracy: 0.6510 - model_1_accuracy: 0.6542 - model_2_accuracy: 0.6486 - model_3_accuracy: 0.6409 - model_4_accuracy: 0.6533 - loss1: 1.2162 - loss2: 4.7767 - val_loss: 32.2743 - val_model_loss: 1.6853 - val_model_1_loss: 1.6977 - val_model_2_loss: 1.7126 - val_model_3_loss: 1.7168 - val_model_4_loss: 1.6810 - val_model_accuracy: 0.6090 - val_model_1_accuracy: 0.5970 - val_model_2_accuracy: 0.6085 - val_model_3_accuracy: 0.6045 - val_model_4_accuracy: 0.6050 - val_loss1: 1.4258 - val_loss2: 4.7277\n","Epoch 78/150\n","4000/4000 [==============================] - 227s 57ms/step - loss: 30.5060 - model_loss: 1.2740 - model_1_loss: 1.2734 - model_2_loss: 1.2742 - model_3_loss: 1.3023 - model_4_loss: 1.2570 - model_accuracy: 0.6513 - model_1_accuracy: 0.6497 - model_2_accuracy: 0.6482 - model_3_accuracy: 0.6420 - model_4_accuracy: 0.6556 - loss1: 1.1981 - loss2: 4.8011 - val_loss: 32.5613 - val_model_loss: 1.6956 - val_model_1_loss: 1.8038 - val_model_2_loss: 1.7160 - val_model_3_loss: 1.7769 - val_model_4_loss: 1.7285 - val_model_accuracy: 0.6140 - val_model_1_accuracy: 0.5990 - val_model_2_accuracy: 0.6090 - val_model_3_accuracy: 0.5995 - val_model_4_accuracy: 0.6125 - val_loss1: 1.4039 - val_loss2: 4.7400\n","Epoch 79/150\n","4000/4000 [==============================] - 226s 56ms/step - loss: 30.4837 - model_loss: 1.2637 - model_1_loss: 1.2648 - model_2_loss: 1.2693 - model_3_loss: 1.2966 - model_4_loss: 1.2584 - model_accuracy: 0.6510 - model_1_accuracy: 0.6538 - model_2_accuracy: 0.6507 - model_3_accuracy: 0.6447 - model_4_accuracy: 0.6556 - loss1: 1.1919 - loss2: 4.8023 - val_loss: 32.6516 - val_model_loss: 1.7423 - val_model_1_loss: 1.7940 - val_model_2_loss: 1.6637 - val_model_3_loss: 1.7208 - val_model_4_loss: 1.7353 - val_model_accuracy: 0.6100 - val_model_1_accuracy: 0.6015 - val_model_2_accuracy: 0.6145 - val_model_3_accuracy: 0.5980 - val_model_4_accuracy: 0.6170 - val_loss1: 1.3511 - val_loss2: 4.7721\n","Epoch 80/150\n","4000/4000 [==============================] - 231s 58ms/step - loss: 30.4719 - model_loss: 1.2413 - model_1_loss: 1.2476 - model_2_loss: 1.2499 - model_3_loss: 1.2851 - model_4_loss: 1.2468 - model_accuracy: 0.6553 - model_1_accuracy: 0.6557 - model_2_accuracy: 0.6544 - model_3_accuracy: 0.6439 - model_4_accuracy: 0.6584 - loss1: 1.1809 - loss2: 4.8166 - val_loss: 32.1939 - val_model_loss: 1.7008 - val_model_1_loss: 1.6878 - val_model_2_loss: 1.5949 - val_model_3_loss: 1.6954 - val_model_4_loss: 1.6517 - val_model_accuracy: 0.6040 - val_model_1_accuracy: 0.5980 - val_model_2_accuracy: 0.6180 - val_model_3_accuracy: 0.6025 - val_model_4_accuracy: 0.6135 - val_loss1: 1.4234 - val_loss2: 4.7442\n","Epoch 81/150\n","4000/4000 [==============================] - 237s 59ms/step - loss: 30.4247 - model_loss: 1.2475 - model_1_loss: 1.2494 - model_2_loss: 1.2407 - model_3_loss: 1.2698 - model_4_loss: 1.2395 - model_accuracy: 0.6568 - model_1_accuracy: 0.6574 - model_2_accuracy: 0.6587 - model_3_accuracy: 0.6488 - model_4_accuracy: 0.6580 - loss1: 1.1826 - loss2: 4.8119 - val_loss: 32.2670 - val_model_loss: 1.7097 - val_model_1_loss: 1.7246 - val_model_2_loss: 1.6470 - val_model_3_loss: 1.7329 - val_model_4_loss: 1.6403 - val_model_accuracy: 0.6040 - val_model_1_accuracy: 0.6040 - val_model_2_accuracy: 0.6160 - val_model_3_accuracy: 0.6145 - val_model_4_accuracy: 0.6210 - val_loss1: 1.4026 - val_loss2: 4.7345\n","Epoch 82/150\n","4000/4000 [==============================] - 237s 59ms/step - loss: 30.4523 - model_loss: 1.2424 - model_1_loss: 1.2417 - model_2_loss: 1.2470 - model_3_loss: 1.2782 - model_4_loss: 1.2456 - model_accuracy: 0.6590 - model_1_accuracy: 0.6574 - model_2_accuracy: 0.6548 - model_3_accuracy: 0.6485 - model_4_accuracy: 0.6560 - loss1: 1.1682 - loss2: 4.8161 - val_loss: 32.2680 - val_model_loss: 1.7227 - val_model_1_loss: 1.7424 - val_model_2_loss: 1.6622 - val_model_3_loss: 1.6979 - val_model_4_loss: 1.6247 - val_model_accuracy: 0.6025 - val_model_1_accuracy: 0.6040 - val_model_2_accuracy: 0.6030 - val_model_3_accuracy: 0.6115 - val_model_4_accuracy: 0.6285 - val_loss1: 1.4030 - val_loss2: 4.7355\n","Epoch 83/150\n","4000/4000 [==============================] - 240s 60ms/step - loss: 30.4071 - model_loss: 1.2380 - model_1_loss: 1.2355 - model_2_loss: 1.2412 - model_3_loss: 1.2541 - model_4_loss: 1.2188 - model_accuracy: 0.6610 - model_1_accuracy: 0.6615 - model_2_accuracy: 0.6562 - model_3_accuracy: 0.6524 - model_4_accuracy: 0.6634 - loss1: 1.1636 - loss2: 4.8206 - val_loss: 32.7453 - val_model_loss: 1.7128 - val_model_1_loss: 1.8108 - val_model_2_loss: 1.7808 - val_model_3_loss: 1.7620 - val_model_4_loss: 1.7978 - val_model_accuracy: 0.6115 - val_model_1_accuracy: 0.6015 - val_model_2_accuracy: 0.6080 - val_model_3_accuracy: 0.6175 - val_model_4_accuracy: 0.6185 - val_loss1: 1.3876 - val_loss2: 4.7485\n","Epoch 84/150\n","4000/4000 [==============================] - 239s 60ms/step - loss: 30.3067 - model_loss: 1.2287 - model_1_loss: 1.2353 - model_2_loss: 1.2394 - model_3_loss: 1.2546 - model_4_loss: 1.2282 - model_accuracy: 0.6592 - model_1_accuracy: 0.6585 - model_2_accuracy: 0.6572 - model_3_accuracy: 0.6577 - model_4_accuracy: 0.6583 - loss1: 1.1727 - loss2: 4.8006 - val_loss: 32.6131 - val_model_loss: 1.7154 - val_model_1_loss: 1.7650 - val_model_2_loss: 1.7108 - val_model_3_loss: 1.7727 - val_model_4_loss: 1.6792 - val_model_accuracy: 0.6010 - val_model_1_accuracy: 0.6080 - val_model_2_accuracy: 0.6015 - val_model_3_accuracy: 0.6085 - val_model_4_accuracy: 0.6215 - val_loss1: 1.3542 - val_loss2: 4.7669\n","Epoch 85/150\n","4000/4000 [==============================] - 243s 61ms/step - loss: 30.3491 - model_loss: 1.2113 - model_1_loss: 1.2081 - model_2_loss: 1.2148 - model_3_loss: 1.2472 - model_4_loss: 1.1990 - model_accuracy: 0.6674 - model_1_accuracy: 0.6665 - model_2_accuracy: 0.6638 - model_3_accuracy: 0.6529 - model_4_accuracy: 0.6679 - loss1: 1.1538 - loss2: 4.8307 - val_loss: 32.7775 - val_model_loss: 1.7697 - val_model_1_loss: 1.7539 - val_model_2_loss: 1.7461 - val_model_3_loss: 1.7523 - val_model_4_loss: 1.7475 - val_model_accuracy: 0.6070 - val_model_1_accuracy: 0.6145 - val_model_2_accuracy: 0.6105 - val_model_3_accuracy: 0.6060 - val_model_4_accuracy: 0.6205 - val_loss1: 1.4149 - val_loss2: 4.7733\n","Epoch 86/150\n","4000/4000 [==============================] - 242s 60ms/step - loss: 30.4381 - model_loss: 1.2223 - model_1_loss: 1.2195 - model_2_loss: 1.2192 - model_3_loss: 1.2596 - model_4_loss: 1.2263 - model_accuracy: 0.6615 - model_1_accuracy: 0.6632 - model_2_accuracy: 0.6628 - model_3_accuracy: 0.6517 - model_4_accuracy: 0.6605 - loss1: 1.1398 - loss2: 4.8355 - val_loss: 32.4920 - val_model_loss: 1.7187 - val_model_1_loss: 1.7463 - val_model_2_loss: 1.7113 - val_model_3_loss: 1.7005 - val_model_4_loss: 1.6749 - val_model_accuracy: 0.6180 - val_model_1_accuracy: 0.6135 - val_model_2_accuracy: 0.6205 - val_model_3_accuracy: 0.6125 - val_model_4_accuracy: 0.6200 - val_loss1: 1.3822 - val_loss2: 4.7604\n","Epoch 87/150\n","4000/4000 [==============================] - 239s 60ms/step - loss: 30.3952 - model_loss: 1.2223 - model_1_loss: 1.2343 - model_2_loss: 1.2286 - model_3_loss: 1.2506 - model_4_loss: 1.2169 - model_accuracy: 0.6648 - model_1_accuracy: 0.6643 - model_2_accuracy: 0.6617 - model_3_accuracy: 0.6545 - model_4_accuracy: 0.6631 - loss1: 1.1400 - loss2: 4.8257 - val_loss: 32.6050 - val_model_loss: 1.7270 - val_model_1_loss: 1.7374 - val_model_2_loss: 1.7464 - val_model_3_loss: 1.8241 - val_model_4_loss: 1.7284 - val_model_accuracy: 0.6105 - val_model_1_accuracy: 0.6110 - val_model_2_accuracy: 0.6200 - val_model_3_accuracy: 0.6060 - val_model_4_accuracy: 0.6200 - val_loss1: 1.4246 - val_loss2: 4.7399\n","Epoch 88/150\n","4000/4000 [==============================] - 240s 60ms/step - loss: 30.3717 - model_loss: 1.2026 - model_1_loss: 1.2088 - model_2_loss: 1.2112 - model_3_loss: 1.2364 - model_4_loss: 1.1946 - model_accuracy: 0.6667 - model_1_accuracy: 0.6635 - model_2_accuracy: 0.6675 - model_3_accuracy: 0.6586 - model_4_accuracy: 0.6663 - loss1: 1.1224 - loss2: 4.8412 - val_loss: 32.9709 - val_model_loss: 1.7026 - val_model_1_loss: 1.7875 - val_model_2_loss: 1.7366 - val_model_3_loss: 1.8121 - val_model_4_loss: 1.9076 - val_model_accuracy: 0.6060 - val_model_1_accuracy: 0.6155 - val_model_2_accuracy: 0.6025 - val_model_3_accuracy: 0.6060 - val_model_4_accuracy: 0.6090 - val_loss1: 1.3652 - val_loss2: 4.7776\n","Epoch 89/150\n","4000/4000 [==============================] - 238s 59ms/step - loss: 30.3265 - model_loss: 1.2057 - model_1_loss: 1.2013 - model_2_loss: 1.2141 - model_3_loss: 1.2345 - model_4_loss: 1.2051 - model_accuracy: 0.6662 - model_1_accuracy: 0.6676 - model_2_accuracy: 0.6635 - model_3_accuracy: 0.6571 - model_4_accuracy: 0.6681 - loss1: 1.1411 - loss2: 4.8303 - val_loss: 32.8365 - val_model_loss: 1.8455 - val_model_1_loss: 1.8175 - val_model_2_loss: 1.7056 - val_model_3_loss: 1.7703 - val_model_4_loss: 1.7262 - val_model_accuracy: 0.5935 - val_model_1_accuracy: 0.6035 - val_model_2_accuracy: 0.6090 - val_model_3_accuracy: 0.6140 - val_model_4_accuracy: 0.6225 - val_loss1: 1.3722 - val_loss2: 4.7668\n","Epoch 90/150\n","4000/4000 [==============================] - 240s 60ms/step - loss: 30.3900 - model_loss: 1.1964 - model_1_loss: 1.2008 - model_2_loss: 1.2028 - model_3_loss: 1.2449 - model_4_loss: 1.2042 - model_accuracy: 0.6697 - model_1_accuracy: 0.6691 - model_2_accuracy: 0.6662 - model_3_accuracy: 0.6562 - model_4_accuracy: 0.6689 - loss1: 1.1247 - loss2: 4.8457 - val_loss: 32.6641 - val_model_loss: 1.7950 - val_model_1_loss: 1.7271 - val_model_2_loss: 1.7101 - val_model_3_loss: 1.7715 - val_model_4_loss: 1.6850 - val_model_accuracy: 0.6015 - val_model_1_accuracy: 0.6165 - val_model_2_accuracy: 0.6130 - val_model_3_accuracy: 0.6025 - val_model_4_accuracy: 0.6210 - val_loss1: 1.3964 - val_loss2: 4.7672\n","Epoch 91/150\n","4000/4000 [==============================] - 247s 62ms/step - loss: 30.2773 - model_loss: 1.1835 - model_1_loss: 1.1927 - model_2_loss: 1.1880 - model_3_loss: 1.2285 - model_4_loss: 1.1901 - model_accuracy: 0.6737 - model_1_accuracy: 0.6697 - model_2_accuracy: 0.6705 - model_3_accuracy: 0.6619 - model_4_accuracy: 0.6723 - loss1: 1.1265 - loss2: 4.8364 - val_loss: 32.6968 - val_model_loss: 1.7773 - val_model_1_loss: 1.7444 - val_model_2_loss: 1.7060 - val_model_3_loss: 1.6888 - val_model_4_loss: 1.7441 - val_model_accuracy: 0.6050 - val_model_1_accuracy: 0.6000 - val_model_2_accuracy: 0.6240 - val_model_3_accuracy: 0.6060 - val_model_4_accuracy: 0.6150 - val_loss1: 1.3671 - val_loss2: 4.7799\n","Epoch 92/150\n","4000/4000 [==============================] - 246s 61ms/step - loss: 30.2155 - model_loss: 1.1830 - model_1_loss: 1.1834 - model_2_loss: 1.1860 - model_3_loss: 1.2133 - model_4_loss: 1.1900 - model_accuracy: 0.6738 - model_1_accuracy: 0.6733 - model_2_accuracy: 0.6745 - model_3_accuracy: 0.6636 - model_4_accuracy: 0.6695 - loss1: 1.1316 - loss2: 4.8293 - val_loss: 32.9171 - val_model_loss: 1.8051 - val_model_1_loss: 1.8486 - val_model_2_loss: 1.7508 - val_model_3_loss: 1.7711 - val_model_4_loss: 1.8003 - val_model_accuracy: 0.6095 - val_model_1_accuracy: 0.6090 - val_model_2_accuracy: 0.6130 - val_model_3_accuracy: 0.6120 - val_model_4_accuracy: 0.6140 - val_loss1: 1.3486 - val_loss2: 4.7613\n","Epoch 93/150\n","4000/4000 [==============================] - 250s 63ms/step - loss: 30.2165 - model_loss: 1.1860 - model_1_loss: 1.1862 - model_2_loss: 1.1903 - model_3_loss: 1.2095 - model_4_loss: 1.1836 - model_accuracy: 0.6718 - model_1_accuracy: 0.6728 - model_2_accuracy: 0.6687 - model_3_accuracy: 0.6655 - model_4_accuracy: 0.6716 - loss1: 1.1385 - loss2: 4.8294 - val_loss: 32.5093 - val_model_loss: 1.6485 - val_model_1_loss: 1.7743 - val_model_2_loss: 1.6574 - val_model_3_loss: 1.7532 - val_model_4_loss: 1.7254 - val_model_accuracy: 0.6165 - val_model_1_accuracy: 0.6160 - val_model_2_accuracy: 0.6225 - val_model_3_accuracy: 0.6210 - val_model_4_accuracy: 0.6195 - val_loss1: 1.3587 - val_loss2: 4.7629\n","Epoch 94/150\n","4000/4000 [==============================] - 246s 62ms/step - loss: 30.3064 - model_loss: 1.1755 - model_1_loss: 1.1871 - model_2_loss: 1.1828 - model_3_loss: 1.2151 - model_4_loss: 1.1769 - model_accuracy: 0.6749 - model_1_accuracy: 0.6729 - model_2_accuracy: 0.6752 - model_3_accuracy: 0.6637 - model_4_accuracy: 0.6759 - loss1: 1.1203 - loss2: 4.8514 - val_loss: 32.6959 - val_model_loss: 1.6975 - val_model_1_loss: 1.7409 - val_model_2_loss: 1.7218 - val_model_3_loss: 1.7657 - val_model_4_loss: 1.7676 - val_model_accuracy: 0.5850 - val_model_1_accuracy: 0.6140 - val_model_2_accuracy: 0.6145 - val_model_3_accuracy: 0.6055 - val_model_4_accuracy: 0.6080 - val_loss1: 1.3782 - val_loss2: 4.7729\n","Epoch 95/150\n","4000/4000 [==============================] - 248s 62ms/step - loss: 30.1701 - model_loss: 1.1708 - model_1_loss: 1.1809 - model_2_loss: 1.1796 - model_3_loss: 1.2044 - model_4_loss: 1.1687 - model_accuracy: 0.6781 - model_1_accuracy: 0.6747 - model_2_accuracy: 0.6740 - model_3_accuracy: 0.6689 - model_4_accuracy: 0.6783 - loss1: 1.1392 - loss2: 4.8303 - val_loss: 32.9693 - val_model_loss: 1.8156 - val_model_1_loss: 1.7389 - val_model_2_loss: 1.7612 - val_model_3_loss: 1.8397 - val_model_4_loss: 1.7409 - val_model_accuracy: 0.6045 - val_model_1_accuracy: 0.6100 - val_model_2_accuracy: 0.6200 - val_model_3_accuracy: 0.5935 - val_model_4_accuracy: 0.6135 - val_loss1: 1.3754 - val_loss2: 4.7871\n","Epoch 96/150\n","4000/4000 [==============================] - 251s 63ms/step - loss: 30.2885 - model_loss: 1.1830 - model_1_loss: 1.1815 - model_2_loss: 1.1837 - model_3_loss: 1.2108 - model_4_loss: 1.1789 - model_accuracy: 0.6725 - model_1_accuracy: 0.6750 - model_2_accuracy: 0.6736 - model_3_accuracy: 0.6656 - model_4_accuracy: 0.6745 - loss1: 1.1192 - loss2: 4.8477 - val_loss: 32.8742 - val_model_loss: 1.7322 - val_model_1_loss: 1.8270 - val_model_2_loss: 1.7308 - val_model_3_loss: 1.7510 - val_model_4_loss: 1.6708 - val_model_accuracy: 0.6140 - val_model_1_accuracy: 0.6045 - val_model_2_accuracy: 0.6055 - val_model_3_accuracy: 0.6170 - val_model_4_accuracy: 0.6185 - val_loss1: 1.3254 - val_loss2: 4.8060\n","Epoch 97/150\n","4000/4000 [==============================] - 249s 62ms/step - loss: 30.2066 - model_loss: 1.1761 - model_1_loss: 1.1719 - model_2_loss: 1.1846 - model_3_loss: 1.1920 - model_4_loss: 1.1659 - model_accuracy: 0.6776 - model_1_accuracy: 0.6776 - model_2_accuracy: 0.6752 - model_3_accuracy: 0.6710 - model_4_accuracy: 0.6783 - loss1: 1.1328 - loss2: 4.8406 - val_loss: 32.9231 - val_model_loss: 1.8340 - val_model_1_loss: 1.7950 - val_model_2_loss: 1.7199 - val_model_3_loss: 1.8223 - val_model_4_loss: 1.7737 - val_model_accuracy: 0.6000 - val_model_1_accuracy: 0.6055 - val_model_2_accuracy: 0.6130 - val_model_3_accuracy: 0.6060 - val_model_4_accuracy: 0.6115 - val_loss1: 1.3739 - val_loss2: 4.7682\n","Epoch 98/150\n","4000/4000 [==============================] - 252s 63ms/step - loss: 30.1210 - model_loss: 1.1582 - model_1_loss: 1.1603 - model_2_loss: 1.1635 - model_3_loss: 1.1895 - model_4_loss: 1.1581 - model_accuracy: 0.6817 - model_1_accuracy: 0.6831 - model_2_accuracy: 0.6770 - model_3_accuracy: 0.6726 - model_4_accuracy: 0.6812 - loss1: 1.1329 - loss2: 4.8356 - val_loss: 32.4253 - val_model_loss: 1.6723 - val_model_1_loss: 1.7927 - val_model_2_loss: 1.6919 - val_model_3_loss: 1.7493 - val_model_4_loss: 1.7192 - val_model_accuracy: 0.6115 - val_model_1_accuracy: 0.6075 - val_model_2_accuracy: 0.6160 - val_model_3_accuracy: 0.6230 - val_model_4_accuracy: 0.6120 - val_loss1: 1.3712 - val_loss2: 4.7326\n","Epoch 99/150\n","4000/4000 [==============================] - 255s 64ms/step - loss: 30.1642 - model_loss: 1.1655 - model_1_loss: 1.1720 - model_2_loss: 1.1673 - model_3_loss: 1.1915 - model_4_loss: 1.1697 - model_accuracy: 0.6783 - model_1_accuracy: 0.6741 - model_2_accuracy: 0.6754 - model_3_accuracy: 0.6698 - model_4_accuracy: 0.6809 - loss1: 1.1218 - loss2: 4.8372 - val_loss: 32.6164 - val_model_loss: 1.6951 - val_model_1_loss: 1.7537 - val_model_2_loss: 1.7258 - val_model_3_loss: 1.7374 - val_model_4_loss: 1.7033 - val_model_accuracy: 0.6135 - val_model_1_accuracy: 0.6045 - val_model_2_accuracy: 0.6145 - val_model_3_accuracy: 0.6150 - val_model_4_accuracy: 0.6220 - val_loss1: 1.3456 - val_loss2: 4.7733\n","Epoch 100/150\n","4000/4000 [==============================] - 253s 63ms/step - loss: 30.2461 - model_loss: 1.1571 - model_1_loss: 1.1639 - model_2_loss: 1.1588 - model_3_loss: 1.1837 - model_4_loss: 1.1597 - model_accuracy: 0.6824 - model_1_accuracy: 0.6773 - model_2_accuracy: 0.6783 - model_3_accuracy: 0.6718 - model_4_accuracy: 0.6808 - loss1: 1.1046 - loss2: 4.8625 - val_loss: 33.1083 - val_model_loss: 1.7863 - val_model_1_loss: 1.7747 - val_model_2_loss: 1.7493 - val_model_3_loss: 1.8172 - val_model_4_loss: 1.8385 - val_model_accuracy: 0.6080 - val_model_1_accuracy: 0.6045 - val_model_2_accuracy: 0.6115 - val_model_3_accuracy: 0.6130 - val_model_4_accuracy: 0.6140 - val_loss1: 1.3182 - val_loss2: 4.8021\n","Epoch 101/150\n","4000/4000 [==============================] - 253s 63ms/step - loss: 30.2207 - model_loss: 1.1572 - model_1_loss: 1.1574 - model_2_loss: 1.1581 - model_3_loss: 1.1933 - model_4_loss: 1.1730 - model_accuracy: 0.6827 - model_1_accuracy: 0.6806 - model_2_accuracy: 0.6832 - model_3_accuracy: 0.6721 - model_4_accuracy: 0.6767 - loss1: 1.1120 - loss2: 4.8541 - val_loss: 32.8129 - val_model_loss: 1.7325 - val_model_1_loss: 1.7272 - val_model_2_loss: 1.7322 - val_model_3_loss: 1.7427 - val_model_4_loss: 1.6752 - val_model_accuracy: 0.6130 - val_model_1_accuracy: 0.6125 - val_model_2_accuracy: 0.5980 - val_model_3_accuracy: 0.6120 - val_model_4_accuracy: 0.6300 - val_loss1: 1.3337 - val_loss2: 4.8140\n","Epoch 102/150\n","4000/4000 [==============================] - 253s 63ms/step - loss: 30.1753 - model_loss: 1.1512 - model_1_loss: 1.1515 - model_2_loss: 1.1533 - model_3_loss: 1.1759 - model_4_loss: 1.1448 - model_accuracy: 0.6835 - model_1_accuracy: 0.6829 - model_2_accuracy: 0.6830 - model_3_accuracy: 0.6781 - model_4_accuracy: 0.6863 - loss1: 1.0967 - loss2: 4.8578 - val_loss: 32.6730 - val_model_loss: 1.7093 - val_model_1_loss: 1.7570 - val_model_2_loss: 1.7100 - val_model_3_loss: 1.7503 - val_model_4_loss: 1.7013 - val_model_accuracy: 0.6120 - val_model_1_accuracy: 0.6175 - val_model_2_accuracy: 0.6130 - val_model_3_accuracy: 0.6150 - val_model_4_accuracy: 0.6210 - val_loss1: 1.3514 - val_loss2: 4.7820\n","Epoch 103/150\n","4000/4000 [==============================] - 258s 64ms/step - loss: 30.0378 - model_loss: 1.1486 - model_1_loss: 1.1550 - model_2_loss: 1.1456 - model_3_loss: 1.1753 - model_4_loss: 1.1382 - model_accuracy: 0.6830 - model_1_accuracy: 0.6801 - model_2_accuracy: 0.6849 - model_3_accuracy: 0.6748 - model_4_accuracy: 0.6865 - loss1: 1.1174 - loss2: 4.8326 - val_loss: 32.8955 - val_model_loss: 1.8066 - val_model_1_loss: 1.7882 - val_model_2_loss: 1.7206 - val_model_3_loss: 1.7516 - val_model_4_loss: 1.7784 - val_model_accuracy: 0.6080 - val_model_1_accuracy: 0.6130 - val_model_2_accuracy: 0.6190 - val_model_3_accuracy: 0.6230 - val_model_4_accuracy: 0.6120 - val_loss1: 1.3300 - val_loss2: 4.7834\n","Epoch 104/150\n","4000/4000 [==============================] - 256s 64ms/step - loss: 30.0738 - model_loss: 1.1420 - model_1_loss: 1.1391 - model_2_loss: 1.1359 - model_3_loss: 1.1610 - model_4_loss: 1.1420 - model_accuracy: 0.6869 - model_1_accuracy: 0.6871 - model_2_accuracy: 0.6859 - model_3_accuracy: 0.6772 - model_4_accuracy: 0.6834 - loss1: 1.0973 - loss2: 4.8488 - val_loss: 32.7606 - val_model_loss: 1.8046 - val_model_1_loss: 1.8014 - val_model_2_loss: 1.7485 - val_model_3_loss: 1.7582 - val_model_4_loss: 1.7395 - val_model_accuracy: 0.6055 - val_model_1_accuracy: 0.6065 - val_model_2_accuracy: 0.5990 - val_model_3_accuracy: 0.6165 - val_model_4_accuracy: 0.6155 - val_loss1: 1.3649 - val_loss2: 4.7544\n","Epoch 105/150\n","4000/4000 [==============================] - 256s 64ms/step - loss: 30.0837 - model_loss: 1.1339 - model_1_loss: 1.1350 - model_2_loss: 1.1333 - model_3_loss: 1.1559 - model_4_loss: 1.1265 - model_accuracy: 0.6868 - model_1_accuracy: 0.6875 - model_2_accuracy: 0.6875 - model_3_accuracy: 0.6792 - model_4_accuracy: 0.6893 - loss1: 1.0951 - loss2: 4.8579 - val_loss: 33.0789 - val_model_loss: 1.8109 - val_model_1_loss: 1.7861 - val_model_2_loss: 1.7546 - val_model_3_loss: 1.7490 - val_model_4_loss: 1.7404 - val_model_accuracy: 0.6110 - val_model_1_accuracy: 0.6080 - val_model_2_accuracy: 0.6085 - val_model_3_accuracy: 0.6205 - val_model_4_accuracy: 0.6245 - val_loss1: 1.2786 - val_loss2: 4.8220\n","Epoch 106/150\n","4000/4000 [==============================] - 256s 64ms/step - loss: 30.0767 - model_loss: 1.1353 - model_1_loss: 1.1417 - model_2_loss: 1.1371 - model_3_loss: 1.1612 - model_4_loss: 1.1366 - model_accuracy: 0.6858 - model_1_accuracy: 0.6864 - model_2_accuracy: 0.6827 - model_3_accuracy: 0.6820 - model_4_accuracy: 0.6867 - loss1: 1.1068 - loss2: 4.8508 - val_loss: 32.9684 - val_model_loss: 1.8097 - val_model_1_loss: 1.7967 - val_model_2_loss: 1.7366 - val_model_3_loss: 1.7905 - val_model_4_loss: 1.7696 - val_model_accuracy: 0.6035 - val_model_1_accuracy: 0.6090 - val_model_2_accuracy: 0.6160 - val_model_3_accuracy: 0.6190 - val_model_4_accuracy: 0.6110 - val_loss1: 1.3437 - val_loss2: 4.7862\n","Epoch 107/150\n","4000/4000 [==============================] - 255s 64ms/step - loss: 30.1162 - model_loss: 1.1334 - model_1_loss: 1.1407 - model_2_loss: 1.1341 - model_3_loss: 1.1554 - model_4_loss: 1.1261 - model_accuracy: 0.6888 - model_1_accuracy: 0.6848 - model_2_accuracy: 0.6866 - model_3_accuracy: 0.6794 - model_4_accuracy: 0.6910 - loss1: 1.0907 - loss2: 4.8635 - val_loss: 33.1784 - val_model_loss: 1.7846 - val_model_1_loss: 1.9297 - val_model_2_loss: 1.8565 - val_model_3_loss: 1.8153 - val_model_4_loss: 1.7239 - val_model_accuracy: 0.6120 - val_model_1_accuracy: 0.5955 - val_model_2_accuracy: 0.6030 - val_model_3_accuracy: 0.6125 - val_model_4_accuracy: 0.6185 - val_loss1: 1.3538 - val_loss2: 4.7866\n","Epoch 108/150\n","4000/4000 [==============================] - 254s 64ms/step - loss: 30.0720 - model_loss: 1.1254 - model_1_loss: 1.1115 - model_2_loss: 1.1163 - model_3_loss: 1.1485 - model_4_loss: 1.1156 - model_accuracy: 0.6915 - model_1_accuracy: 0.6947 - model_2_accuracy: 0.6926 - model_3_accuracy: 0.6830 - model_4_accuracy: 0.6930 - loss1: 1.0983 - loss2: 4.8690 - val_loss: 33.1982 - val_model_loss: 1.8662 - val_model_1_loss: 1.8151 - val_model_2_loss: 1.8045 - val_model_3_loss: 1.8066 - val_model_4_loss: 1.8253 - val_model_accuracy: 0.6035 - val_model_1_accuracy: 0.6090 - val_model_2_accuracy: 0.6130 - val_model_3_accuracy: 0.6210 - val_model_4_accuracy: 0.6180 - val_loss1: 1.3420 - val_loss2: 4.7892\n","Epoch 109/150\n","4000/4000 [==============================] - 258s 65ms/step - loss: 30.0561 - model_loss: 1.1189 - model_1_loss: 1.1265 - model_2_loss: 1.1359 - model_3_loss: 1.1565 - model_4_loss: 1.1289 - model_accuracy: 0.6925 - model_1_accuracy: 0.6901 - model_2_accuracy: 0.6895 - model_3_accuracy: 0.6797 - model_4_accuracy: 0.6915 - loss1: 1.1005 - loss2: 4.8558 - val_loss: 32.9315 - val_model_loss: 1.7638 - val_model_1_loss: 1.8632 - val_model_2_loss: 1.7411 - val_model_3_loss: 1.8053 - val_model_4_loss: 1.7041 - val_model_accuracy: 0.6145 - val_model_1_accuracy: 0.6135 - val_model_2_accuracy: 0.6215 - val_model_3_accuracy: 0.6280 - val_model_4_accuracy: 0.6195 - val_loss1: 1.3264 - val_loss2: 4.7843\n","Epoch 110/150\n","4000/4000 [==============================] - 258s 64ms/step - loss: 30.0676 - model_loss: 1.1164 - model_1_loss: 1.1287 - model_2_loss: 1.1237 - model_3_loss: 1.1511 - model_4_loss: 1.1216 - model_accuracy: 0.6944 - model_1_accuracy: 0.6909 - model_2_accuracy: 0.6886 - model_3_accuracy: 0.6823 - model_4_accuracy: 0.6888 - loss1: 1.0904 - loss2: 4.8634 - val_loss: 33.1909 - val_model_loss: 1.8199 - val_model_1_loss: 1.8265 - val_model_2_loss: 1.8052 - val_model_3_loss: 1.9010 - val_model_4_loss: 1.7442 - val_model_accuracy: 0.6170 - val_model_1_accuracy: 0.6175 - val_model_2_accuracy: 0.6125 - val_model_3_accuracy: 0.6080 - val_model_4_accuracy: 0.6345 - val_loss1: 1.3166 - val_loss2: 4.7925\n","Epoch 111/150\n","4000/4000 [==============================] - 256s 64ms/step - loss: 30.0922 - model_loss: 1.1234 - model_1_loss: 1.1122 - model_2_loss: 1.1200 - model_3_loss: 1.1450 - model_4_loss: 1.1223 - model_accuracy: 0.6908 - model_1_accuracy: 0.6931 - model_2_accuracy: 0.6920 - model_3_accuracy: 0.6856 - model_4_accuracy: 0.6921 - loss1: 1.0809 - loss2: 4.8722 - val_loss: 33.2890 - val_model_loss: 1.7855 - val_model_1_loss: 1.9014 - val_model_2_loss: 1.7697 - val_model_3_loss: 1.8413 - val_model_4_loss: 1.7532 - val_model_accuracy: 0.6180 - val_model_1_accuracy: 0.6030 - val_model_2_accuracy: 0.6190 - val_model_3_accuracy: 0.6220 - val_model_4_accuracy: 0.6295 - val_loss1: 1.2698 - val_loss2: 4.8222\n","Epoch 112/150\n","4000/4000 [==============================] - 258s 65ms/step - loss: 30.0965 - model_loss: 1.1057 - model_1_loss: 1.1178 - model_2_loss: 1.1081 - model_3_loss: 1.1344 - model_4_loss: 1.1059 - model_accuracy: 0.6959 - model_1_accuracy: 0.6934 - model_2_accuracy: 0.6927 - model_3_accuracy: 0.6849 - model_4_accuracy: 0.6941 - loss1: 1.0647 - loss2: 4.8836 - val_loss: 33.1051 - val_model_loss: 1.7410 - val_model_1_loss: 1.8837 - val_model_2_loss: 1.7611 - val_model_3_loss: 1.8343 - val_model_4_loss: 1.8078 - val_model_accuracy: 0.6080 - val_model_1_accuracy: 0.5990 - val_model_2_accuracy: 0.6190 - val_model_3_accuracy: 0.6145 - val_model_4_accuracy: 0.6130 - val_loss1: 1.3390 - val_loss2: 4.7887\n","Epoch 113/150\n","4000/4000 [==============================] - 258s 65ms/step - loss: 30.0231 - model_loss: 1.1146 - model_1_loss: 1.1089 - model_2_loss: 1.1119 - model_3_loss: 1.1304 - model_4_loss: 1.1112 - model_accuracy: 0.6957 - model_1_accuracy: 0.6926 - model_2_accuracy: 0.6927 - model_3_accuracy: 0.6904 - model_4_accuracy: 0.6945 - loss1: 1.0866 - loss2: 4.8675 - val_loss: 33.1879 - val_model_loss: 1.8625 - val_model_1_loss: 1.8101 - val_model_2_loss: 1.7774 - val_model_3_loss: 1.7669 - val_model_4_loss: 1.7641 - val_model_accuracy: 0.6150 - val_model_1_accuracy: 0.6135 - val_model_2_accuracy: 0.6110 - val_model_3_accuracy: 0.6210 - val_model_4_accuracy: 0.6210 - val_loss1: 1.3118 - val_loss2: 4.8151\n","Epoch 114/150\n","4000/4000 [==============================] - 257s 64ms/step - loss: 30.0737 - model_loss: 1.0981 - model_1_loss: 1.1007 - model_2_loss: 1.0977 - model_3_loss: 1.1266 - model_4_loss: 1.0883 - model_accuracy: 0.6980 - model_1_accuracy: 0.6989 - model_2_accuracy: 0.6954 - model_3_accuracy: 0.6895 - model_4_accuracy: 0.7023 - loss1: 1.0611 - loss2: 4.8912 - val_loss: 33.5334 - val_model_loss: 1.8821 - val_model_1_loss: 1.8450 - val_model_2_loss: 1.8849 - val_model_3_loss: 1.8384 - val_model_4_loss: 1.8539 - val_model_accuracy: 0.6185 - val_model_1_accuracy: 0.6065 - val_model_2_accuracy: 0.6075 - val_model_3_accuracy: 0.6225 - val_model_4_accuracy: 0.6240 - val_loss1: 1.2898 - val_loss2: 4.8200\n","Epoch 115/150\n","4000/4000 [==============================] - 257s 64ms/step - loss: 30.0171 - model_loss: 1.1040 - model_1_loss: 1.1016 - model_2_loss: 1.1112 - model_3_loss: 1.1347 - model_4_loss: 1.0941 - model_accuracy: 0.6975 - model_1_accuracy: 0.6967 - model_2_accuracy: 0.6934 - model_3_accuracy: 0.6872 - model_4_accuracy: 0.6977 - loss1: 1.0854 - loss2: 4.8726 - val_loss: 33.1312 - val_model_loss: 1.7800 - val_model_1_loss: 1.8481 - val_model_2_loss: 1.7372 - val_model_3_loss: 1.7716 - val_model_4_loss: 1.8048 - val_model_accuracy: 0.6115 - val_model_1_accuracy: 0.5995 - val_model_2_accuracy: 0.6150 - val_model_3_accuracy: 0.6180 - val_model_4_accuracy: 0.6145 - val_loss1: 1.3013 - val_loss2: 4.8119\n","Epoch 116/150\n","4000/4000 [==============================] - 257s 64ms/step - loss: 30.0624 - model_loss: 1.1021 - model_1_loss: 1.0951 - model_2_loss: 1.0998 - model_3_loss: 1.1237 - model_4_loss: 1.0967 - model_accuracy: 0.6983 - model_1_accuracy: 0.6988 - model_2_accuracy: 0.6945 - model_3_accuracy: 0.6898 - model_4_accuracy: 0.6980 - loss1: 1.0594 - loss2: 4.8878 - val_loss: 33.3153 - val_model_loss: 1.8629 - val_model_1_loss: 1.8880 - val_model_2_loss: 1.8231 - val_model_3_loss: 1.8137 - val_model_4_loss: 1.7976 - val_model_accuracy: 0.6200 - val_model_1_accuracy: 0.6100 - val_model_2_accuracy: 0.6225 - val_model_3_accuracy: 0.6250 - val_model_4_accuracy: 0.6165 - val_loss1: 1.3371 - val_loss2: 4.7992\n","Epoch 117/150\n","4000/4000 [==============================] - 258s 65ms/step - loss: 29.9819 - model_loss: 1.0993 - model_1_loss: 1.1022 - model_2_loss: 1.1045 - model_3_loss: 1.1271 - model_4_loss: 1.0947 - model_accuracy: 0.6985 - model_1_accuracy: 0.6995 - model_2_accuracy: 0.6975 - model_3_accuracy: 0.6903 - model_4_accuracy: 0.6989 - loss1: 1.0762 - loss2: 4.8693 - val_loss: 33.1750 - val_model_loss: 1.7648 - val_model_1_loss: 1.8319 - val_model_2_loss: 1.7915 - val_model_3_loss: 1.8779 - val_model_4_loss: 1.7963 - val_model_accuracy: 0.6160 - val_model_1_accuracy: 0.6070 - val_model_2_accuracy: 0.6090 - val_model_3_accuracy: 0.5995 - val_model_4_accuracy: 0.6185 - val_loss1: 1.3309 - val_loss2: 4.7959\n","Epoch 118/150\n","4000/4000 [==============================] - 260s 65ms/step - loss: 29.8950 - model_loss: 1.0865 - model_1_loss: 1.0886 - model_2_loss: 1.0897 - model_3_loss: 1.1047 - model_4_loss: 1.0936 - model_accuracy: 0.7011 - model_1_accuracy: 0.7010 - model_2_accuracy: 0.6972 - model_3_accuracy: 0.6954 - model_4_accuracy: 0.6985 - loss1: 1.0713 - loss2: 4.8650 - val_loss: 33.2981 - val_model_loss: 1.8348 - val_model_1_loss: 1.8072 - val_model_2_loss: 1.8390 - val_model_3_loss: 1.9029 - val_model_4_loss: 1.7733 - val_model_accuracy: 0.6160 - val_model_1_accuracy: 0.6130 - val_model_2_accuracy: 0.6235 - val_model_3_accuracy: 0.6180 - val_model_4_accuracy: 0.6225 - val_loss1: 1.3185 - val_loss2: 4.8018\n","Epoch 119/150\n","4000/4000 [==============================] - 258s 65ms/step - loss: 29.9016 - model_loss: 1.0876 - model_1_loss: 1.0832 - model_2_loss: 1.0902 - model_3_loss: 1.1070 - model_4_loss: 1.0778 - model_accuracy: 0.7020 - model_1_accuracy: 0.7002 - model_2_accuracy: 0.7006 - model_3_accuracy: 0.6957 - model_4_accuracy: 0.7047 - loss1: 1.0729 - loss2: 4.8697 - val_loss: 33.2647 - val_model_loss: 1.8298 - val_model_1_loss: 1.8152 - val_model_2_loss: 1.8268 - val_model_3_loss: 1.8841 - val_model_4_loss: 1.7863 - val_model_accuracy: 0.6125 - val_model_1_accuracy: 0.6055 - val_model_2_accuracy: 0.6160 - val_model_3_accuracy: 0.6185 - val_model_4_accuracy: 0.6325 - val_loss1: 1.3233 - val_loss2: 4.7981\n","Epoch 120/150\n","4000/4000 [==============================] - 259s 65ms/step - loss: 29.9364 - model_loss: 1.0924 - model_1_loss: 1.0897 - model_2_loss: 1.0839 - model_3_loss: 1.1111 - model_4_loss: 1.0805 - model_accuracy: 0.6999 - model_1_accuracy: 0.7009 - model_2_accuracy: 0.7006 - model_3_accuracy: 0.6922 - model_4_accuracy: 0.7037 - loss1: 1.0734 - loss2: 4.8743 - val_loss: 33.2460 - val_model_loss: 1.8184 - val_model_1_loss: 1.8251 - val_model_2_loss: 1.7993 - val_model_3_loss: 1.7699 - val_model_4_loss: 1.8429 - val_model_accuracy: 0.6205 - val_model_1_accuracy: 0.6140 - val_model_2_accuracy: 0.6150 - val_model_3_accuracy: 0.6280 - val_model_4_accuracy: 0.6210 - val_loss1: 1.2929 - val_loss2: 4.8123\n","Epoch 121/150\n","4000/4000 [==============================] - 258s 64ms/step - loss: 29.9280 - model_loss: 1.0861 - model_1_loss: 1.0962 - model_2_loss: 1.1054 - model_3_loss: 1.1202 - model_4_loss: 1.0877 - model_accuracy: 0.7005 - model_1_accuracy: 0.6969 - model_2_accuracy: 0.6964 - model_3_accuracy: 0.6915 - model_4_accuracy: 0.6993 - loss1: 1.0721 - loss2: 4.8651 - val_loss: 33.2163 - val_model_loss: 1.8384 - val_model_1_loss: 1.7788 - val_model_2_loss: 1.7511 - val_model_3_loss: 1.8408 - val_model_4_loss: 1.8139 - val_model_accuracy: 0.6220 - val_model_1_accuracy: 0.6050 - val_model_2_accuracy: 0.6205 - val_model_3_accuracy: 0.6235 - val_model_4_accuracy: 0.6245 - val_loss1: 1.2786 - val_loss2: 4.8131\n","Epoch 122/150\n","4000/4000 [==============================] - 257s 64ms/step - loss: 29.8624 - model_loss: 1.0756 - model_1_loss: 1.0714 - model_2_loss: 1.0758 - model_3_loss: 1.1014 - model_4_loss: 1.0695 - model_accuracy: 0.7035 - model_1_accuracy: 0.7034 - model_2_accuracy: 0.7038 - model_3_accuracy: 0.6972 - model_4_accuracy: 0.7067 - loss1: 1.0716 - loss2: 4.8723 - val_loss: 33.3504 - val_model_loss: 1.8143 - val_model_1_loss: 1.9103 - val_model_2_loss: 1.7961 - val_model_3_loss: 1.8580 - val_model_4_loss: 1.7723 - val_model_accuracy: 0.6105 - val_model_1_accuracy: 0.6085 - val_model_2_accuracy: 0.6170 - val_model_3_accuracy: 0.6160 - val_model_4_accuracy: 0.6320 - val_loss1: 1.2591 - val_loss2: 4.8147\n","Epoch 123/150\n","4000/4000 [==============================] - 259s 65ms/step - loss: 29.7944 - model_loss: 1.0749 - model_1_loss: 1.0817 - model_2_loss: 1.0869 - model_3_loss: 1.0992 - model_4_loss: 1.0683 - model_accuracy: 0.7045 - model_1_accuracy: 0.7010 - model_2_accuracy: 0.6996 - model_3_accuracy: 0.6937 - model_4_accuracy: 0.7043 - loss1: 1.0727 - loss2: 4.8552 - val_loss: 33.2528 - val_model_loss: 1.7908 - val_model_1_loss: 1.8246 - val_model_2_loss: 1.7794 - val_model_3_loss: 1.8589 - val_model_4_loss: 1.8164 - val_model_accuracy: 0.6060 - val_model_1_accuracy: 0.6135 - val_model_2_accuracy: 0.6190 - val_model_3_accuracy: 0.6200 - val_model_4_accuracy: 0.6230 - val_loss1: 1.2487 - val_loss2: 4.8116\n","Epoch 124/150\n","4000/4000 [==============================] - 260s 65ms/step - loss: 29.7542 - model_loss: 1.0744 - model_1_loss: 1.0746 - model_2_loss: 1.0787 - model_3_loss: 1.1073 - model_4_loss: 1.0661 - model_accuracy: 0.7036 - model_1_accuracy: 0.7043 - model_2_accuracy: 0.7058 - model_3_accuracy: 0.6945 - model_4_accuracy: 0.7060 - loss1: 1.0789 - loss2: 4.8490 - val_loss: 33.6943 - val_model_loss: 1.8407 - val_model_1_loss: 1.8998 - val_model_2_loss: 1.8100 - val_model_3_loss: 1.8572 - val_model_4_loss: 1.8385 - val_model_accuracy: 0.6185 - val_model_1_accuracy: 0.6090 - val_model_2_accuracy: 0.6135 - val_model_3_accuracy: 0.6275 - val_model_4_accuracy: 0.6220 - val_loss1: 1.2538 - val_loss2: 4.8645\n","Epoch 125/150\n","4000/4000 [==============================] - 259s 65ms/step - loss: 29.9642 - model_loss: 1.0839 - model_1_loss: 1.0696 - model_2_loss: 1.0832 - model_3_loss: 1.1094 - model_4_loss: 1.0756 - model_accuracy: 0.7045 - model_1_accuracy: 0.7061 - model_2_accuracy: 0.7021 - model_3_accuracy: 0.6960 - model_4_accuracy: 0.7039 - loss1: 1.0579 - loss2: 4.8873 - val_loss: 33.4860 - val_model_loss: 1.9001 - val_model_1_loss: 1.8892 - val_model_2_loss: 1.7258 - val_model_3_loss: 1.9208 - val_model_4_loss: 1.7486 - val_model_accuracy: 0.6035 - val_model_1_accuracy: 0.6120 - val_model_2_accuracy: 0.6205 - val_model_3_accuracy: 0.6215 - val_model_4_accuracy: 0.6265 - val_loss1: 1.2478 - val_loss2: 4.8353\n","Epoch 126/150\n","4000/4000 [==============================] - 259s 65ms/step - loss: 29.9385 - model_loss: 1.0688 - model_1_loss: 1.0658 - model_2_loss: 1.0662 - model_3_loss: 1.0955 - model_4_loss: 1.0641 - model_accuracy: 0.7070 - model_1_accuracy: 0.7085 - model_2_accuracy: 0.7056 - model_3_accuracy: 0.6982 - model_4_accuracy: 0.7057 - loss1: 1.0467 - loss2: 4.8947 - val_loss: 33.2171 - val_model_loss: 1.8064 - val_model_1_loss: 1.8497 - val_model_2_loss: 1.7848 - val_model_3_loss: 1.8175 - val_model_4_loss: 1.8276 - val_model_accuracy: 0.6200 - val_model_1_accuracy: 0.6095 - val_model_2_accuracy: 0.6130 - val_model_3_accuracy: 0.6240 - val_model_4_accuracy: 0.6140 - val_loss1: 1.3371 - val_loss2: 4.7995\n","Epoch 127/150\n","4000/4000 [==============================] - 262s 65ms/step - loss: 29.7469 - model_loss: 1.0581 - model_1_loss: 1.0588 - model_2_loss: 1.0545 - model_3_loss: 1.0795 - model_4_loss: 1.0555 - model_accuracy: 0.7096 - model_1_accuracy: 0.7086 - model_2_accuracy: 0.7096 - model_3_accuracy: 0.7024 - model_4_accuracy: 0.7087 - loss1: 1.0729 - loss2: 4.8667 - val_loss: 33.3524 - val_model_loss: 1.9275 - val_model_1_loss: 1.8365 - val_model_2_loss: 1.8410 - val_model_3_loss: 1.8244 - val_model_4_loss: 1.7991 - val_model_accuracy: 0.6190 - val_model_1_accuracy: 0.6035 - val_model_2_accuracy: 0.6125 - val_model_3_accuracy: 0.6230 - val_model_4_accuracy: 0.6360 - val_loss1: 1.3036 - val_loss2: 4.7987\n","Epoch 128/150\n","4000/4000 [==============================] - 262s 66ms/step - loss: 29.7327 - model_loss: 1.0638 - model_1_loss: 1.0633 - model_2_loss: 1.0633 - model_3_loss: 1.0944 - model_4_loss: 1.0491 - model_accuracy: 0.7072 - model_1_accuracy: 0.7059 - model_2_accuracy: 0.7040 - model_3_accuracy: 0.6987 - model_4_accuracy: 0.7100 - loss1: 1.0825 - loss2: 4.8581 - val_loss: 33.4209 - val_model_loss: 1.8436 - val_model_1_loss: 1.8483 - val_model_2_loss: 1.7972 - val_model_3_loss: 1.8337 - val_model_4_loss: 1.8547 - val_model_accuracy: 0.6280 - val_model_1_accuracy: 0.6155 - val_model_2_accuracy: 0.6340 - val_model_3_accuracy: 0.6195 - val_model_4_accuracy: 0.6300 - val_loss1: 1.2791 - val_loss2: 4.8231\n","Epoch 129/150\n","4000/4000 [==============================] - 262s 65ms/step - loss: 29.7896 - model_loss: 1.0628 - model_1_loss: 1.0605 - model_2_loss: 1.0646 - model_3_loss: 1.0891 - model_4_loss: 1.0584 - model_accuracy: 0.7077 - model_1_accuracy: 0.7101 - model_2_accuracy: 0.7093 - model_3_accuracy: 0.7013 - model_4_accuracy: 0.7103 - loss1: 1.0661 - loss2: 4.8695 - val_loss: 33.3582 - val_model_loss: 1.8052 - val_model_1_loss: 1.8997 - val_model_2_loss: 1.7724 - val_model_3_loss: 1.8144 - val_model_4_loss: 1.7536 - val_model_accuracy: 0.6175 - val_model_1_accuracy: 0.6100 - val_model_2_accuracy: 0.6110 - val_model_3_accuracy: 0.6160 - val_model_4_accuracy: 0.6360 - val_loss1: 1.2871 - val_loss2: 4.8368\n","Epoch 130/150\n","4000/4000 [==============================] - 260s 65ms/step - loss: 29.9245 - model_loss: 1.0640 - model_1_loss: 1.0706 - model_2_loss: 1.0689 - model_3_loss: 1.0882 - model_4_loss: 1.0616 - model_accuracy: 0.7071 - model_1_accuracy: 0.7086 - model_2_accuracy: 0.7058 - model_3_accuracy: 0.7004 - model_4_accuracy: 0.7095 - loss1: 1.0524 - loss2: 4.8932 - val_loss: 33.5399 - val_model_loss: 1.8677 - val_model_1_loss: 1.8437 - val_model_2_loss: 1.8482 - val_model_3_loss: 1.9213 - val_model_4_loss: 1.7566 - val_model_accuracy: 0.6130 - val_model_1_accuracy: 0.6100 - val_model_2_accuracy: 0.6190 - val_model_3_accuracy: 0.6145 - val_model_4_accuracy: 0.6310 - val_loss1: 1.2656 - val_loss2: 4.8351\n","Epoch 131/150\n","4000/4000 [==============================] - 260s 65ms/step - loss: 29.8884 - model_loss: 1.0562 - model_1_loss: 1.0514 - model_2_loss: 1.0547 - model_3_loss: 1.0785 - model_4_loss: 1.0492 - model_accuracy: 0.7087 - model_1_accuracy: 0.7097 - model_2_accuracy: 0.7092 - model_3_accuracy: 0.7055 - model_4_accuracy: 0.7110 - loss1: 1.0417 - loss2: 4.8988 - val_loss: 33.2239 - val_model_loss: 1.7736 - val_model_1_loss: 1.8659 - val_model_2_loss: 1.8067 - val_model_3_loss: 1.8642 - val_model_4_loss: 1.7275 - val_model_accuracy: 0.6170 - val_model_1_accuracy: 0.6020 - val_model_2_accuracy: 0.6110 - val_model_3_accuracy: 0.6165 - val_model_4_accuracy: 0.6295 - val_loss1: 1.2940 - val_loss2: 4.8113\n","Epoch 132/150\n","4000/4000 [==============================] - 261s 65ms/step - loss: 29.6691 - model_loss: 1.0428 - model_1_loss: 1.0410 - model_2_loss: 1.0410 - model_3_loss: 1.0629 - model_4_loss: 1.0351 - model_accuracy: 0.7122 - model_1_accuracy: 0.7143 - model_2_accuracy: 0.7132 - model_3_accuracy: 0.7058 - model_4_accuracy: 0.7139 - loss1: 1.0741 - loss2: 4.8677 - val_loss: 33.5817 - val_model_loss: 1.9363 - val_model_1_loss: 1.9416 - val_model_2_loss: 1.8356 - val_model_3_loss: 1.8992 - val_model_4_loss: 1.7941 - val_model_accuracy: 0.6125 - val_model_1_accuracy: 0.5995 - val_model_2_accuracy: 0.6125 - val_model_3_accuracy: 0.6075 - val_model_4_accuracy: 0.6310 - val_loss1: 1.3075 - val_loss2: 4.8089\n","Epoch 133/150\n","4000/4000 [==============================] - 261s 65ms/step - loss: 29.7322 - model_loss: 1.0435 - model_1_loss: 1.0452 - model_2_loss: 1.0513 - model_3_loss: 1.0738 - model_4_loss: 1.0468 - model_accuracy: 0.7164 - model_1_accuracy: 0.7121 - model_2_accuracy: 0.7114 - model_3_accuracy: 0.7020 - model_4_accuracy: 0.7112 - loss1: 1.0670 - loss2: 4.8730 - val_loss: 33.6602 - val_model_loss: 1.8979 - val_model_1_loss: 1.9335 - val_model_2_loss: 1.8418 - val_model_3_loss: 1.9211 - val_model_4_loss: 1.8553 - val_model_accuracy: 0.6070 - val_model_1_accuracy: 0.6045 - val_model_2_accuracy: 0.6040 - val_model_3_accuracy: 0.6125 - val_model_4_accuracy: 0.6275 - val_loss1: 1.2763 - val_loss2: 4.8166\n","Epoch 134/150\n","4000/4000 [==============================] - 262s 66ms/step - loss: 29.7657 - model_loss: 1.0486 - model_1_loss: 1.0500 - model_2_loss: 1.0591 - model_3_loss: 1.0715 - model_4_loss: 1.0466 - model_accuracy: 0.7113 - model_1_accuracy: 0.7098 - model_2_accuracy: 0.7088 - model_3_accuracy: 0.7065 - model_4_accuracy: 0.7134 - loss1: 1.0537 - loss2: 4.8769 - val_loss: 33.6565 - val_model_loss: 1.9143 - val_model_1_loss: 1.9023 - val_model_2_loss: 1.8493 - val_model_3_loss: 1.9001 - val_model_4_loss: 1.8384 - val_model_accuracy: 0.6100 - val_model_1_accuracy: 0.6015 - val_model_2_accuracy: 0.6105 - val_model_3_accuracy: 0.6260 - val_model_4_accuracy: 0.6230 - val_loss1: 1.2597 - val_loss2: 4.8252\n","Epoch 135/150\n","4000/4000 [==============================] - 259s 65ms/step - loss: 29.8088 - model_loss: 1.0504 - model_1_loss: 1.0556 - model_2_loss: 1.0542 - model_3_loss: 1.0858 - model_4_loss: 1.0461 - model_accuracy: 0.7118 - model_1_accuracy: 0.7095 - model_2_accuracy: 0.7110 - model_3_accuracy: 0.7005 - model_4_accuracy: 0.7125 - loss1: 1.0558 - loss2: 4.8822 - val_loss: 33.4408 - val_model_loss: 1.8654 - val_model_1_loss: 1.8954 - val_model_2_loss: 1.8422 - val_model_3_loss: 1.8866 - val_model_4_loss: 1.7596 - val_model_accuracy: 0.6130 - val_model_1_accuracy: 0.6155 - val_model_2_accuracy: 0.6140 - val_model_3_accuracy: 0.6140 - val_model_4_accuracy: 0.6190 - val_loss1: 1.2538 - val_loss2: 4.8132\n","Epoch 136/150\n","4000/4000 [==============================] - 261s 65ms/step - loss: 29.7824 - model_loss: 1.0343 - model_1_loss: 1.0409 - model_2_loss: 1.0520 - model_3_loss: 1.0676 - model_4_loss: 1.0398 - model_accuracy: 0.7153 - model_1_accuracy: 0.7122 - model_2_accuracy: 0.7081 - model_3_accuracy: 0.7047 - model_4_accuracy: 0.7148 - loss1: 1.0469 - loss2: 4.8886 - val_loss: 33.6026 - val_model_loss: 1.8769 - val_model_1_loss: 1.8973 - val_model_2_loss: 1.8295 - val_model_3_loss: 1.8703 - val_model_4_loss: 1.8266 - val_model_accuracy: 0.6055 - val_model_1_accuracy: 0.6090 - val_model_2_accuracy: 0.6120 - val_model_3_accuracy: 0.6315 - val_model_4_accuracy: 0.6270 - val_loss1: 1.2511 - val_loss2: 4.8354\n","Epoch 137/150\n","4000/4000 [==============================] - 263s 66ms/step - loss: 29.7182 - model_loss: 1.0392 - model_1_loss: 1.0401 - model_2_loss: 1.0436 - model_3_loss: 1.0575 - model_4_loss: 1.0482 - model_accuracy: 0.7109 - model_1_accuracy: 0.7141 - model_2_accuracy: 0.7124 - model_3_accuracy: 0.7092 - model_4_accuracy: 0.7129 - loss1: 1.0498 - loss2: 4.8769 - val_loss: 33.6210 - val_model_loss: 1.9109 - val_model_1_loss: 1.9744 - val_model_2_loss: 1.9190 - val_model_3_loss: 1.9383 - val_model_4_loss: 1.8078 - val_model_accuracy: 0.6000 - val_model_1_accuracy: 0.6060 - val_model_2_accuracy: 0.6055 - val_model_3_accuracy: 0.6085 - val_model_4_accuracy: 0.6300 - val_loss1: 1.3081 - val_loss2: 4.7880\n","Epoch 138/150\n","4000/4000 [==============================] - 263s 66ms/step - loss: 29.7118 - model_loss: 1.0335 - model_1_loss: 1.0458 - model_2_loss: 1.0269 - model_3_loss: 1.0602 - model_4_loss: 1.0313 - model_accuracy: 0.7154 - model_1_accuracy: 0.7119 - model_2_accuracy: 0.7171 - model_3_accuracy: 0.7078 - model_4_accuracy: 0.7181 - loss1: 1.0466 - loss2: 4.8819 - val_loss: 33.5907 - val_model_loss: 1.8491 - val_model_1_loss: 1.8894 - val_model_2_loss: 1.9398 - val_model_3_loss: 1.9191 - val_model_4_loss: 1.8266 - val_model_accuracy: 0.6085 - val_model_1_accuracy: 0.6150 - val_model_2_accuracy: 0.6035 - val_model_3_accuracy: 0.6095 - val_model_4_accuracy: 0.6175 - val_loss1: 1.2976 - val_loss2: 4.8074\n","Epoch 139/150\n","4000/4000 [==============================] - 267s 67ms/step - loss: 29.6932 - model_loss: 1.0303 - model_1_loss: 1.0326 - model_2_loss: 1.0352 - model_3_loss: 1.0524 - model_4_loss: 1.0265 - model_accuracy: 0.7178 - model_1_accuracy: 0.7171 - model_2_accuracy: 0.7150 - model_3_accuracy: 0.7087 - model_4_accuracy: 0.7172 - loss1: 1.0479 - loss2: 4.8823 - val_loss: 33.7127 - val_model_loss: 1.8260 - val_model_1_loss: 2.0121 - val_model_2_loss: 1.8423 - val_model_3_loss: 1.8516 - val_model_4_loss: 1.8529 - val_model_accuracy: 0.6130 - val_model_1_accuracy: 0.6025 - val_model_2_accuracy: 0.6200 - val_model_3_accuracy: 0.6275 - val_model_4_accuracy: 0.6285 - val_loss1: 1.2721 - val_loss2: 4.8401\n","Epoch 140/150\n","4000/4000 [==============================] - 263s 66ms/step - loss: 29.7382 - model_loss: 1.0317 - model_1_loss: 1.0389 - model_2_loss: 1.0453 - model_3_loss: 1.0538 - model_4_loss: 1.0336 - model_accuracy: 0.7174 - model_1_accuracy: 0.7154 - model_2_accuracy: 0.7137 - model_3_accuracy: 0.7088 - model_4_accuracy: 0.7142 - loss1: 1.0469 - loss2: 4.8860 - val_loss: 33.4760 - val_model_loss: 1.8598 - val_model_1_loss: 1.7825 - val_model_2_loss: 1.8358 - val_model_3_loss: 1.9714 - val_model_4_loss: 1.8095 - val_model_accuracy: 0.6005 - val_model_1_accuracy: 0.6065 - val_model_2_accuracy: 0.6190 - val_model_3_accuracy: 0.6180 - val_model_4_accuracy: 0.6210 - val_loss1: 1.3069 - val_loss2: 4.8172\n","Epoch 141/150\n","4000/4000 [==============================] - 259s 65ms/step - loss: 29.6846 - model_loss: 1.0233 - model_1_loss: 1.0360 - model_2_loss: 1.0289 - model_3_loss: 1.0502 - model_4_loss: 1.0362 - model_accuracy: 0.7175 - model_1_accuracy: 0.7166 - model_2_accuracy: 0.7169 - model_3_accuracy: 0.7109 - model_4_accuracy: 0.7147 - loss1: 1.0462 - loss2: 4.8811 - val_loss: 33.7844 - val_model_loss: 1.8613 - val_model_1_loss: 1.9459 - val_model_2_loss: 1.8382 - val_model_3_loss: 1.9915 - val_model_4_loss: 1.8255 - val_model_accuracy: 0.6100 - val_model_1_accuracy: 0.6065 - val_model_2_accuracy: 0.6115 - val_model_3_accuracy: 0.6235 - val_model_4_accuracy: 0.6250 - val_loss1: 1.2544 - val_loss2: 4.8393\n","Epoch 142/150\n","4000/4000 [==============================] - 259s 65ms/step - loss: 29.6254 - model_loss: 1.0267 - model_1_loss: 1.0342 - model_2_loss: 1.0338 - model_3_loss: 1.0443 - model_4_loss: 1.0232 - model_accuracy: 0.7164 - model_1_accuracy: 0.7166 - model_2_accuracy: 0.7165 - model_3_accuracy: 0.7109 - model_4_accuracy: 0.7188 - loss1: 1.0611 - loss2: 4.8714 - val_loss: 33.5632 - val_model_loss: 1.8999 - val_model_1_loss: 1.9369 - val_model_2_loss: 1.7852 - val_model_3_loss: 1.9720 - val_model_4_loss: 1.9178 - val_model_accuracy: 0.6080 - val_model_1_accuracy: 0.6090 - val_model_2_accuracy: 0.6190 - val_model_3_accuracy: 0.6195 - val_model_4_accuracy: 0.6160 - val_loss1: 1.3156 - val_loss2: 4.7840\n","Epoch 143/150\n","4000/4000 [==============================] - 260s 65ms/step - loss: 29.6584 - model_loss: 1.0284 - model_1_loss: 1.0304 - model_2_loss: 1.0240 - model_3_loss: 1.0492 - model_4_loss: 1.0278 - model_accuracy: 0.7172 - model_1_accuracy: 0.7183 - model_2_accuracy: 0.7179 - model_3_accuracy: 0.7097 - model_4_accuracy: 0.7169 - loss1: 1.0537 - loss2: 4.8786 - val_loss: 33.5431 - val_model_loss: 1.7987 - val_model_1_loss: 1.8625 - val_model_2_loss: 1.9002 - val_model_3_loss: 1.9269 - val_model_4_loss: 1.8199 - val_model_accuracy: 0.6140 - val_model_1_accuracy: 0.6175 - val_model_2_accuracy: 0.6120 - val_model_3_accuracy: 0.6120 - val_model_4_accuracy: 0.6205 - val_loss1: 1.2620 - val_loss2: 4.8217\n","Epoch 144/150\n","4000/4000 [==============================] - 262s 65ms/step - loss: 29.6903 - model_loss: 1.0325 - model_1_loss: 1.0337 - model_2_loss: 1.0194 - model_3_loss: 1.0481 - model_4_loss: 1.0213 - model_accuracy: 0.7168 - model_1_accuracy: 0.7190 - model_2_accuracy: 0.7180 - model_3_accuracy: 0.7126 - model_4_accuracy: 0.7168 - loss1: 1.0535 - loss2: 4.8860 - val_loss: 33.3320 - val_model_loss: 1.7964 - val_model_1_loss: 1.8377 - val_model_2_loss: 1.9263 - val_model_3_loss: 1.9315 - val_model_4_loss: 1.7627 - val_model_accuracy: 0.6145 - val_model_1_accuracy: 0.6180 - val_model_2_accuracy: 0.6075 - val_model_3_accuracy: 0.6220 - val_model_4_accuracy: 0.6270 - val_loss1: 1.2771 - val_loss2: 4.7899\n","Epoch 145/150\n","4000/4000 [==============================] - 262s 65ms/step - loss: 29.6782 - model_loss: 1.0320 - model_1_loss: 1.0275 - model_2_loss: 1.0187 - model_3_loss: 1.0457 - model_4_loss: 1.0322 - model_accuracy: 0.7195 - model_1_accuracy: 0.7171 - model_2_accuracy: 0.7178 - model_3_accuracy: 0.7136 - model_4_accuracy: 0.7155 - loss1: 1.0401 - loss2: 4.8836 - val_loss: 33.7845 - val_model_loss: 1.8316 - val_model_1_loss: 1.9597 - val_model_2_loss: 1.9033 - val_model_3_loss: 1.9225 - val_model_4_loss: 1.8524 - val_model_accuracy: 0.6175 - val_model_1_accuracy: 0.6185 - val_model_2_accuracy: 0.6130 - val_model_3_accuracy: 0.6220 - val_model_4_accuracy: 0.6250 - val_loss1: 1.2197 - val_loss2: 4.8386\n","Epoch 146/150\n","4000/4000 [==============================] - 266s 66ms/step - loss: 29.6625 - model_loss: 1.0116 - model_1_loss: 1.0194 - model_2_loss: 1.0175 - model_3_loss: 1.0445 - model_4_loss: 1.0169 - model_accuracy: 0.7230 - model_1_accuracy: 0.7182 - model_2_accuracy: 0.7177 - model_3_accuracy: 0.7116 - model_4_accuracy: 0.7205 - loss1: 1.0359 - loss2: 4.8898 - val_loss: 33.7993 - val_model_loss: 1.8428 - val_model_1_loss: 1.9402 - val_model_2_loss: 1.8546 - val_model_3_loss: 1.9721 - val_model_4_loss: 1.8741 - val_model_accuracy: 0.6165 - val_model_1_accuracy: 0.6230 - val_model_2_accuracy: 0.6205 - val_model_3_accuracy: 0.6205 - val_model_4_accuracy: 0.6300 - val_loss1: 1.2299 - val_loss2: 4.8385\n","Epoch 147/150\n","4000/4000 [==============================] - 265s 66ms/step - loss: 29.6178 - model_loss: 1.0178 - model_1_loss: 1.0084 - model_2_loss: 1.0110 - model_3_loss: 1.0406 - model_4_loss: 1.0173 - model_accuracy: 0.7179 - model_1_accuracy: 0.7189 - model_2_accuracy: 0.7215 - model_3_accuracy: 0.7148 - model_4_accuracy: 0.7217 - loss1: 1.0476 - loss2: 4.8836 - val_loss: 33.7922 - val_model_loss: 1.8708 - val_model_1_loss: 1.9195 - val_model_2_loss: 1.9002 - val_model_3_loss: 1.9221 - val_model_4_loss: 1.8654 - val_model_accuracy: 0.6165 - val_model_1_accuracy: 0.6070 - val_model_2_accuracy: 0.6190 - val_model_3_accuracy: 0.6215 - val_model_4_accuracy: 0.6200 - val_loss1: 1.2425 - val_loss2: 4.8380\n","Epoch 148/150\n","4000/4000 [==============================] - 262s 66ms/step - loss: 29.6123 - model_loss: 1.0015 - model_1_loss: 1.0104 - model_2_loss: 1.0108 - model_3_loss: 1.0323 - model_4_loss: 1.0023 - model_accuracy: 0.7270 - model_1_accuracy: 0.7223 - model_2_accuracy: 0.7199 - model_3_accuracy: 0.7158 - model_4_accuracy: 0.7263 - loss1: 1.0379 - loss2: 4.8902 - val_loss: 33.8308 - val_model_loss: 1.9285 - val_model_1_loss: 1.9231 - val_model_2_loss: 1.8777 - val_model_3_loss: 1.9237 - val_model_4_loss: 1.8825 - val_model_accuracy: 0.6165 - val_model_1_accuracy: 0.6105 - val_model_2_accuracy: 0.6145 - val_model_3_accuracy: 0.6110 - val_model_4_accuracy: 0.6210 - val_loss1: 1.2668 - val_loss2: 4.8337\n","Epoch 149/150\n","4000/4000 [==============================] - 265s 66ms/step - loss: 29.6542 - model_loss: 1.0176 - model_1_loss: 1.0114 - model_2_loss: 1.0192 - model_3_loss: 1.0413 - model_4_loss: 1.0219 - model_accuracy: 0.7211 - model_1_accuracy: 0.7210 - model_2_accuracy: 0.7201 - model_3_accuracy: 0.7124 - model_4_accuracy: 0.7216 - loss1: 1.0444 - loss2: 4.8877 - val_loss: 33.8589 - val_model_loss: 1.9166 - val_model_1_loss: 1.9164 - val_model_2_loss: 1.9029 - val_model_3_loss: 1.9354 - val_model_4_loss: 1.8926 - val_model_accuracy: 0.6095 - val_model_1_accuracy: 0.6150 - val_model_2_accuracy: 0.6100 - val_model_3_accuracy: 0.6270 - val_model_4_accuracy: 0.6180 - val_loss1: 1.2572 - val_loss2: 4.8339\n","Epoch 150/150\n","4000/4000 [==============================] - 267s 67ms/step - loss: 29.5904 - model_loss: 1.0068 - model_1_loss: 1.0075 - model_2_loss: 1.0172 - model_3_loss: 1.0359 - model_4_loss: 1.0119 - model_accuracy: 0.7196 - model_1_accuracy: 0.7231 - model_2_accuracy: 0.7226 - model_3_accuracy: 0.7134 - model_4_accuracy: 0.7202 - loss1: 1.0375 - loss2: 4.8815 - val_loss: 33.7281 - val_model_loss: 1.9169 - val_model_1_loss: 1.9167 - val_model_2_loss: 1.9471 - val_model_3_loss: 1.9114 - val_model_4_loss: 1.8105 - val_model_accuracy: 0.6200 - val_model_1_accuracy: 0.6190 - val_model_2_accuracy: 0.6150 - val_model_3_accuracy: 0.6230 - val_model_4_accuracy: 0.6215 - val_loss1: 1.2725 - val_loss2: 4.8196\n","Epoch 00128: early stopping and save the model\n"]}],"source":["#construct joint training model for the five base models\n","input_size = (32, 32, 3)\n","model0 = create_VGGNet(input_shape=input_size, num_classes=100,  random_seed=1) #random_seed: initialization\n","model1 = create_VGGNet(input_shape=input_size, num_classes=100,  random_seed=2)\n","model2 = create_VGGNet(input_shape=input_size, num_classes=100,  random_seed=3)\n","model3 = create_VGGNet(input_shape=input_size, num_classes=100,  random_seed=4)\n","model4 = create_VGGNet(input_shape=input_size, num_classes=100,  random_seed=5)\n","allinputs = keras.Input(shape=input_size)\n","output0, feature_maps0 = model0(allinputs)\n","output1, feature_maps1 = model1(allinputs)\n","output2, feature_maps2 = model2(allinputs)\n","output3, feature_maps3 = model3(allinputs)\n","output4, feature_maps4 = model4(allinputs)\n","model_train = keras.Model(\n","    inputs=allinputs, outputs=[output0, output1, output2, output3, output4])\n","\n","#implement distance loss\n","loss1, loss2, loss = cosine_euclidean_sum_loss(x=[feature_maps0, feature_maps1, feature_maps2, feature_maps3, feature_maps4], \n","                                      cosine_weight=0.1, euclidean_weight=5, mask=True, max_norm=False)\n","\n","\n","model_train.add_loss(loss)\n","model_train.add_metric(loss1, name=\"loss1\", aggregation='mean')\n","model_train.add_metric(loss2, name=\"loss2\", aggregation='mean')\n","\n","model_train.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","                    loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'],\n","                    metrics=['accuracy'])\n","\n","#load Cifar100 data\n","(x_origin_train, y_origin_train), (x_test,y_test) = keras.datasets.cifar100.load_data()\n","y_origin_train = y_origin_train.reshape(-1,)\n","y_test = y_test.reshape(-1,)\n","\n","x_train, x_val, y_train, y_val = model_selection.train_test_split(\n","    x_origin_train,\n","    y_origin_train,\n","    test_size=10000,\n","    random_state=0,\n","    stratify=y_origin_train)\n","_, x_val, _, y_val = model_selection.train_test_split(\n","    x_val,\n","    y_val,\n","    test_size=2000,\n","    random_state=0,\n","    stratify=y_val)\n","#select training samples\n","train_index = []\n","random.seed(0)\n","for i in range(100):\n","    train_index += (random.sample(list(np.where(y_train == i)[0]), 100))#number of training samples\n","random.shuffle(train_index)\n","sampled_x_train = x_train[train_index]\n","sampled_y_train = y_train[train_index]\n","del train_index\n","\n","#construct training and validation samples\n","train_sequence = cifar100data(sampled_x_train, sampled_y_train, batch_size=10, train=True)\n","validation_sequence = cifar100data(x_val, y_val, batch_size=10, train=False)\n","\n","#training\n","history = model_train.fit(\n","    train_sequence,\n","    epochs=300,\n","    validation_data=validation_sequence,\n","    callbacks=CustomEarlyStoppingAndSave(\n","        save_path='/content/drive/MyDrive/cifar100experiment/vgg16/experiment/400_samples_seed_fix_m0.1_m5.h5',\n","        patience=10))\n","frame = pd.DataFrame({\n","    'loss':\n","    history.history['loss'],\n","    'loss1':\n","    history.history['loss1'],\n","    'loss2':\n","    history.history['loss2'],\n","    'model_0_loss':\n","    history.history['model_loss'],\n","    'model_1_loss':\n","    history.history['model_1_loss'],\n","    'model_2_loss':\n","    history.history['model_2_loss'],\n","    'model_3_loss':\n","    history.history['model_3_loss'],\n","    'model_4_loss':\n","    history.history['model_4_loss'],\n","    'model_0_accuracy':\n","    history.history['model_accuracy'],\n","    'model_1_accuracy':\n","    history.history['model_1_accuracy'],\n","    'model_2_accuracy':\n","    history.history['model_2_accuracy'],\n","    'model_3_accuracy':\n","    history.history['model_3_accuracy'],\n","    'model_4_accuracy':\n","    history.history['model_4_accuracy'],\n","    'val_loss':\n","    history.history['val_loss'],\n","    'val_loss1':\n","    history.history['val_loss1'],\n","    'val_loss2':\n","    history.history['val_loss2'],\n","    'val_model_0_loss':\n","    history.history['val_model_loss'],\n","    'val_model_1_loss':\n","    history.history['val_model_1_loss'],\n","    'val_model_2_loss':\n","    history.history['val_model_2_loss'],\n","    'val_model_3_loss':\n","    history.history['val_model_3_loss'],\n","    'val_model_4_loss':\n","    history.history['val_model_4_loss'],\n","    'val_model_0_accuracy':\n","    history.history['val_model_accuracy'],\n","    'val_model_1_accuracy':\n","    history.history['val_model_1_accuracy'],\n","    'val_model_2_accuracy':\n","    history.history['val_model_2_accuracy'],\n","    'val_model_3_accuracy':\n","    history.history['val_model_3_accuracy'],\n","    'val_model_4_accuracy':\n","    history.history['val_model_4_accuracy'],\n","})\n","#frame.to_excel('/content/drive/MyDrive/cifar100experiment/vgg16/5models300s/table_300_samples_seed_fix_m0.1_m1.xlsx')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"D8Q68bw0VAfd","outputId":"82103095-4ad9-4b43-ef34-6d806479bae2"},"outputs":[{"name":"stdout","output_type":"stream","text":["1000/1000 [==============================] - 15s 13ms/step - loss: 33.1337 - model_loss: 1.7417 - model_1_loss: 1.7368 - model_2_loss: 1.8006 - model_3_loss: 1.7756 - model_4_loss: 1.8239 - model_accuracy: 0.6281 - model_1_accuracy: 0.6223 - model_2_accuracy: 0.6210 - model_3_accuracy: 0.6156 - model_4_accuracy: 0.6287 - loss1: 1.2670 - loss2: 4.8257\n"]}],"source":["#evaluation of the base models\n","x_test = x_test/255.0\n","evaluate = model_train.evaluate(x_test,[keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test)],batch_size=10)\n","evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mW1xEi9mVP08","outputId":"3aac2f29-d69f-4eee-e70b-3efebc2cd9cf"},"outputs":[{"data":{"text/plain":["0.6638"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#hard voting ensemble\n","class HardVotingEnsemble:\n","    def __init__(self, model, testdata ,batch_size):\n","        self.ensemble_model = model\n","        self.testdata = testdata\n","        self.batch_size = batch_size\n","        self.data_size = testdata[1].shape[0]\n","    def prediction(self):\n","        predictions =[]\n","        for i in range(int(self.data_size/self.batch_size)):\n","            batch_predictions = np.argmax(self.ensemble_model.predict(self.testdata[0][i*self.batch_size:(i+1)*self.batch_size]),axis=2) \n","            batch_predictions = np.stack(batch_predictions, axis=1)\n","            batch_predictions = [np.argmax(np.bincount(pre)) for pre in batch_predictions]\n","            predictions = predictions+batch_predictions\n","        return np.array(predictions)\n","\n","    def evaluate(self):\n","        predictions = self.prediction()\n","        accuracy = np.sum(\n","            predictions == self.testdata[1]) / self.data_size\n","        return accuracy\n","HEnsemble = HardVotingEnsemble(model = model_train,testdata = (x_test, y_test),batch_size=10)\n","HEnsemble.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"p79zKgdTxTgO","outputId":"d625cff8-3502-4cab-b533-74cec83eb61d"},"outputs":[{"data":{"text/plain":["0.6671"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#soft voting ensemble\n","def SoftVotingEnsemble(model, x, y):\n","  data_size = x.shape[0]\n","  predictions = tf.argmax(tf.reduce_mean(model.predict(x), axis = 0),axis=1)\n","  accuracy = np.sum(\n","     predictions == y) / data_size\n","  return accuracy\n","SoftVotingEnsemble(model_train, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6ML_FZOLCe79"},"outputs":[],"source":["#callback for ensemble learning\n","class eCustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(eCustomEarlyStoppingAndSave, self).__init__()\n","        self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_accuracy') \n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rXwnG-CQCfbJ"},"outputs":[],"source":["class ecifar100data(keras.utils.Sequence):\n","    '''\n","    generate data batch of cifar10\n","    10 classes\n","    '''\n","    def __init__(self, data_x, data_y, batch_size, train):\n","        self.data_x = data_x\n","        self.data_y = data_y\n","        self.train = train\n","        self.batch_size = batch_size\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","\n","        batch_x = self.data_x[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        batch_y = self.data_y[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        if self.train == True:\n","            batch_x = Data_Aug(batch_x)\n","\n","        batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","        batch_y = keras.utils.to_categorical(np.array(batch_y), 100)\n","        return batch_x, batch_y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3405458,"status":"ok","timestamp":1649929248523,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"},"user_tz":-120},"id":"Oql4eIoXC5mF","outputId":"e22528bd-1011-481f-8810-6a481ba5252a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","4000/4000 [==============================] - 114s 28ms/step - loss: 1.5695 - accuracy: 0.6106 - val_loss: 1.2913 - val_accuracy: 0.6490\n","Epoch 2/50\n","4000/4000 [==============================] - 112s 28ms/step - loss: 0.9384 - accuracy: 0.7555 - val_loss: 1.2499 - val_accuracy: 0.6620\n","Epoch 3/50\n","4000/4000 [==============================] - 111s 28ms/step - loss: 0.7824 - accuracy: 0.7929 - val_loss: 1.2825 - val_accuracy: 0.6635\n","Epoch 4/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.6959 - accuracy: 0.8154 - val_loss: 1.2823 - val_accuracy: 0.6695\n","Epoch 5/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.6384 - accuracy: 0.8298 - val_loss: 1.2873 - val_accuracy: 0.6715\n","Epoch 6/50\n","4000/4000 [==============================] - 109s 27ms/step - loss: 0.6161 - accuracy: 0.8349 - val_loss: 1.3145 - val_accuracy: 0.6740\n","Epoch 7/50\n","4000/4000 [==============================] - 109s 27ms/step - loss: 0.5813 - accuracy: 0.8426 - val_loss: 1.3533 - val_accuracy: 0.6710\n","Epoch 8/50\n","4000/4000 [==============================] - 109s 27ms/step - loss: 0.5674 - accuracy: 0.8474 - val_loss: 1.3581 - val_accuracy: 0.6730\n","Epoch 9/50\n","4000/4000 [==============================] - 111s 28ms/step - loss: 0.5433 - accuracy: 0.8523 - val_loss: 1.3795 - val_accuracy: 0.6715\n","Epoch 10/50\n","4000/4000 [==============================] - 109s 27ms/step - loss: 0.5278 - accuracy: 0.8579 - val_loss: 1.4070 - val_accuracy: 0.6695\n","Epoch 11/50\n","4000/4000 [==============================] - 109s 27ms/step - loss: 0.5060 - accuracy: 0.8612 - val_loss: 1.4250 - val_accuracy: 0.6635\n","Epoch 12/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.4957 - accuracy: 0.8647 - val_loss: 1.4538 - val_accuracy: 0.6655\n","Epoch 13/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.5009 - accuracy: 0.8645 - val_loss: 1.4533 - val_accuracy: 0.6685\n","Epoch 14/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.4840 - accuracy: 0.8691 - val_loss: 1.4625 - val_accuracy: 0.6620\n","Epoch 15/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.4727 - accuracy: 0.8725 - val_loss: 1.4495 - val_accuracy: 0.6670\n","Epoch 16/50\n","4000/4000 [==============================] - 109s 27ms/step - loss: 0.4668 - accuracy: 0.8723 - val_loss: 1.4813 - val_accuracy: 0.6750\n","Epoch 17/50\n","4000/4000 [==============================] - 109s 27ms/step - loss: 0.4632 - accuracy: 0.8746 - val_loss: 1.4935 - val_accuracy: 0.6680\n","Epoch 18/50\n","4000/4000 [==============================] - 109s 27ms/step - loss: 0.4550 - accuracy: 0.8754 - val_loss: 1.5059 - val_accuracy: 0.6770\n","Epoch 19/50\n","4000/4000 [==============================] - 107s 27ms/step - loss: 0.4492 - accuracy: 0.8767 - val_loss: 1.5112 - val_accuracy: 0.6805\n","Epoch 20/50\n","4000/4000 [==============================] - 107s 27ms/step - loss: 0.4470 - accuracy: 0.8765 - val_loss: 1.5657 - val_accuracy: 0.6615\n","Epoch 21/50\n","4000/4000 [==============================] - 111s 28ms/step - loss: 0.4432 - accuracy: 0.8787 - val_loss: 1.5044 - val_accuracy: 0.6670\n","Epoch 22/50\n","4000/4000 [==============================] - 111s 28ms/step - loss: 0.4433 - accuracy: 0.8802 - val_loss: 1.5405 - val_accuracy: 0.6700\n","Epoch 23/50\n","4000/4000 [==============================] - 111s 28ms/step - loss: 0.4322 - accuracy: 0.8821 - val_loss: 1.5427 - val_accuracy: 0.6695\n","Epoch 24/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.4157 - accuracy: 0.8870 - val_loss: 1.5535 - val_accuracy: 0.6735\n","Epoch 25/50\n","4000/4000 [==============================] - 114s 28ms/step - loss: 0.4254 - accuracy: 0.8835 - val_loss: 1.5680 - val_accuracy: 0.6725\n","Epoch 26/50\n","4000/4000 [==============================] - 110s 28ms/step - loss: 0.4214 - accuracy: 0.8829 - val_loss: 1.5945 - val_accuracy: 0.6660\n","Epoch 27/50\n","4000/4000 [==============================] - 109s 27ms/step - loss: 0.4283 - accuracy: 0.8818 - val_loss: 1.6046 - val_accuracy: 0.6715\n","Epoch 28/50\n","4000/4000 [==============================] - 110s 28ms/step - loss: 0.4224 - accuracy: 0.8843 - val_loss: 1.6124 - val_accuracy: 0.6680\n","Epoch 29/50\n","4000/4000 [==============================] - 111s 28ms/step - loss: 0.4215 - accuracy: 0.8851 - val_loss: 1.6180 - val_accuracy: 0.6690\n","Epoch 30/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.3940 - accuracy: 0.8912 - val_loss: 1.6236 - val_accuracy: 0.6790\n","Epoch 31/50\n","4000/4000 [==============================] - 110s 28ms/step - loss: 0.3992 - accuracy: 0.8892 - val_loss: 1.6600 - val_accuracy: 0.6685\n","Epoch 32/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.4008 - accuracy: 0.8890 - val_loss: 1.6543 - val_accuracy: 0.6695\n","Epoch 33/50\n","4000/4000 [==============================] - 109s 27ms/step - loss: 0.3905 - accuracy: 0.8910 - val_loss: 1.6440 - val_accuracy: 0.6690\n","Epoch 34/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.3962 - accuracy: 0.8904 - val_loss: 1.6562 - val_accuracy: 0.6690\n","Epoch 35/50\n","4000/4000 [==============================] - 110s 27ms/step - loss: 0.3799 - accuracy: 0.8933 - val_loss: 1.6567 - val_accuracy: 0.6720\n","Epoch 36/50\n","4000/4000 [==============================] - 112s 28ms/step - loss: 0.3914 - accuracy: 0.8920 - val_loss: 1.6653 - val_accuracy: 0.6685\n","Epoch 37/50\n","4000/4000 [==============================] - 111s 28ms/step - loss: 0.3825 - accuracy: 0.8944 - val_loss: 1.6525 - val_accuracy: 0.6670\n","Epoch 38/50\n","4000/4000 [==============================] - 119s 30ms/step - loss: 0.3803 - accuracy: 0.8936 - val_loss: 1.6757 - val_accuracy: 0.6660\n","Epoch 39/50\n","4000/4000 [==============================] - 113s 28ms/step - loss: 0.3797 - accuracy: 0.8950 - val_loss: 1.6779 - val_accuracy: 0.6660\n","Epoch 40/50\n","4000/4000 [==============================] - 113s 28ms/step - loss: 0.3772 - accuracy: 0.8949 - val_loss: 1.6836 - val_accuracy: 0.6670\n","Epoch 41/50\n","4000/4000 [==============================] - 115s 29ms/step - loss: 0.3692 - accuracy: 0.8967 - val_loss: 1.6783 - val_accuracy: 0.6725\n","Epoch 42/50\n","4000/4000 [==============================] - 113s 28ms/step - loss: 0.3684 - accuracy: 0.8968 - val_loss: 1.7194 - val_accuracy: 0.6680\n","Epoch 43/50\n","4000/4000 [==============================] - 116s 29ms/step - loss: 0.3722 - accuracy: 0.8971 - val_loss: 1.6994 - val_accuracy: 0.6710\n","Epoch 44/50\n","4000/4000 [==============================] - 116s 29ms/step - loss: 0.3744 - accuracy: 0.8961 - val_loss: 1.6839 - val_accuracy: 0.6775\n","Epoch 45/50\n","4000/4000 [==============================] - 116s 29ms/step - loss: 0.3633 - accuracy: 0.8986 - val_loss: 1.7154 - val_accuracy: 0.6735\n","Epoch 46/50\n","4000/4000 [==============================] - 113s 28ms/step - loss: 0.3610 - accuracy: 0.8991 - val_loss: 1.7215 - val_accuracy: 0.6680\n","Epoch 47/50\n","4000/4000 [==============================] - 113s 28ms/step - loss: 0.3641 - accuracy: 0.8997 - val_loss: 1.7165 - val_accuracy: 0.6705\n","Epoch 48/50\n","4000/4000 [==============================] - 113s 28ms/step - loss: 0.3606 - accuracy: 0.8992 - val_loss: 1.7444 - val_accuracy: 0.6705\n","Epoch 49/50\n","4000/4000 [==============================] - 110s 28ms/step - loss: 0.3623 - accuracy: 0.8989 - val_loss: 1.7353 - val_accuracy: 0.6700\n","Epoch 50/50\n","4000/4000 [==============================] - 111s 28ms/step - loss: 0.3668 - accuracy: 0.8998 - val_loss: 1.7654 - val_accuracy: 0.6680\n","Epoch 00019: early stopping and save the model\n","1000/1000 [==============================] - 9s 8ms/step - loss: 1.4806 - accuracy: 0.6784\n"]}],"source":["#feature fusion model\n","model_path = '/content/drive/MyDrive/cifar100experiment/vgg16/experiment/400_samples_seed_fix_m0.1_m5.h5'\n","model = keras.models.load_model(model_path)\n","extractor_1 = keras.models.Model(inputs=model.layers[1].inputs,outputs=model.layers[1].layers[27].output)\n","extractor_2 = keras.models.Model(inputs=model.layers[2].inputs,outputs=model.layers[2].layers[27].output)\n","extractor_3 = keras.models.Model(inputs=model.layers[3].inputs,outputs=model.layers[3].layers[27].output)\n","extractor_4 = keras.models.Model(inputs=model.layers[4].inputs,outputs=model.layers[4].layers[27].output)\n","extractor_5 = keras.models.Model(inputs=model.layers[5].inputs,outputs=model.layers[5].layers[27].output)\n","extractor_1.trainable = False\n","extractor_2.trainable = False\n","extractor_3.trainable = False\n","extractor_4.trainable = False\n","extractor_5.trainable = False\n","inputs = keras.Input(shape = input_size)\n","features_1 = extractor_1(inputs, training = False)\n","features_2 = extractor_2(inputs, training = False)\n","features_3 = extractor_3(inputs, training = False)\n","features_4 = extractor_4(inputs, training = False)\n","features_5 = extractor_5(inputs, training = False)\n","\n","#avg_1 = keras.layers.GlobalAvgPool2D()(features_1)\n","#max_1 = keras.layers.GlobalMaxPool2D()(features_1)\n","#avg_2 = keras.layers.GlobalAvgPool2D()(features_2)\n","#max_2 = keras.layers.GlobalMaxPool2D()(features_2)\n","#avg_3 = keras.layers.GlobalAvgPool2D()(features_3)\n","#max_3 = keras.layers.GlobalMaxPool2D()(features_3)\n","#avg_4 = keras.layers.GlobalAvgPool2D()(features_4)\n","#max_4 = keras.layers.GlobalMaxPool2D()(features_4)\n","#avg_5 = keras.layers.GlobalAvgPool2D()(features_5)\n","#max_5 = keras.layers.GlobalMaxPool2D()(features_5)\n","#avg_1 = keras.layers.Lambda(lambda x: tf.math.l2_normalize(x,axis=1))(avg_1)\n","#max_1 = keras.layers.Lambda(lambda x: tf.math.l2_normalize(x,axis=1))(max_1)\n","#avg_2 = keras.layers.Lambda(lambda x: tf.math.l2_normalize(x,axis=1))(avg_2)\n","#max_2 = keras.layers.Lambda(lambda x: tf.math.l2_normalize(x,axis=1))(max_2)\n","#avg_3 = keras.layers.Lambda(lambda x: tf.math.l2_normalize(x,axis=1))(avg_3)\n","#max_3 = keras.layers.Lambda(lambda x: tf.math.l2_normalize(x,axis=1))(max_3)\n","#avg_4 = keras.layers.Lambda(lambda x: tf.math.l2_normalize(x,axis=1))(avg_4)\n","#max_4 = keras.layers.Lambda(lambda x: tf.math.l2_normalize(x,axis=1))(max_4)\n","#avg_5 = keras.layers.Lambda(lambda x: tf.math.l2_normalize(x,axis=1))(avg_5)\n","#max_5 = keras.layers.Lambda(lambda x: tf.math.l2_normalize(x,axis=1))(max_5)\n","#x = keras.layers.Concatenate(axis=-1)([avg_1,max_1,avg_2,max_2,avg_3,max_3,avg_4,max_4,avg_5,max_5])\n","\n","x = keras.layers.Concatenate(axis=-1)([features_1,features_2,features_3,features_4,features_5])\n","#x = keras.layers.add([features_1,features_2,features_3,features_4,features_5])\n","#x = keras.layers.SeparableConv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeUniform(seed=None))(x)\n","#x = keras.layers.BatchNormalization()(x)\n","#x = keras.layers.Activation('relu')(x)\n","#x = keras.layers.Dropout(0.4)(x)\n","x = keras.layers.Flatten()(x)\n","x = keras.layers.Dense(512,  name='dense_100')(x)\n","x = keras.layers.BatchNormalization()(x)\n","x = keras.layers.Activation('relu')(x)\n","x = keras.layers.Dropout(0.5)(x)\n","outputs = keras.layers.Dense(100, activation='softmax', name='dense_101')(x)\n","ensemble = keras.Model(inputs = inputs, outputs = outputs)\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","train_sequence = ecifar100data(sampled_x_train, sampled_y_train, batch_size=10, train=True)\n","validation_sequence = ecifar100data(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=50,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FH_Ry7tpC_G_","outputId":"a101cf93-57c9-4f73-9715-7b2059488c22"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","4000/4000 [==============================] - 149s 36ms/step - loss: 0.4293 - accuracy: 0.8813 - val_loss: 1.4938 - val_accuracy: 0.6840\n","Epoch 2/20\n","4000/4000 [==============================] - 142s 35ms/step - loss: 0.4214 - accuracy: 0.8835 - val_loss: 1.5028 - val_accuracy: 0.6825\n","Epoch 3/20\n","4000/4000 [==============================] - 142s 35ms/step - loss: 0.4107 - accuracy: 0.8864 - val_loss: 1.5136 - val_accuracy: 0.6770\n","Epoch 4/20\n","4000/4000 [==============================] - 139s 35ms/step - loss: 0.3914 - accuracy: 0.8917 - val_loss: 1.5032 - val_accuracy: 0.6795\n","Epoch 5/20\n","4000/4000 [==============================] - 140s 35ms/step - loss: 0.3837 - accuracy: 0.8950 - val_loss: 1.4999 - val_accuracy: 0.6795\n","Epoch 6/20\n","4000/4000 [==============================] - 139s 35ms/step - loss: 0.3782 - accuracy: 0.8969 - val_loss: 1.5034 - val_accuracy: 0.6795\n","Epoch 7/20\n","4000/4000 [==============================] - 141s 35ms/step - loss: 0.3814 - accuracy: 0.8965 - val_loss: 1.5267 - val_accuracy: 0.6825\n","Epoch 8/20\n","4000/4000 [==============================] - 142s 35ms/step - loss: 0.3653 - accuracy: 0.8989 - val_loss: 1.5104 - val_accuracy: 0.6840\n","Epoch 9/20\n","4000/4000 [==============================] - 142s 35ms/step - loss: 0.3706 - accuracy: 0.8971 - val_loss: 1.5239 - val_accuracy: 0.6820\n","Epoch 10/20\n","4000/4000 [==============================] - 142s 35ms/step - loss: 0.3657 - accuracy: 0.9003 - val_loss: 1.5096 - val_accuracy: 0.6840\n","Epoch 11/20\n","4000/4000 [==============================] - 141s 35ms/step - loss: 0.3715 - accuracy: 0.8979 - val_loss: 1.5267 - val_accuracy: 0.6795\n","Epoch 12/20\n","4000/4000 [==============================] - 141s 35ms/step - loss: 0.3629 - accuracy: 0.9007 - val_loss: 1.5236 - val_accuracy: 0.6740\n","Epoch 13/20\n","4000/4000 [==============================] - 140s 35ms/step - loss: 0.3509 - accuracy: 0.9025 - val_loss: 1.5221 - val_accuracy: 0.6800\n","Epoch 14/20\n","4000/4000 [==============================] - 138s 34ms/step - loss: 0.3550 - accuracy: 0.9007 - val_loss: 1.5315 - val_accuracy: 0.6775\n","Epoch 15/20\n","4000/4000 [==============================] - 138s 34ms/step - loss: 0.3537 - accuracy: 0.9033 - val_loss: 1.5339 - val_accuracy: 0.6780\n","Epoch 16/20\n","4000/4000 [==============================] - 137s 34ms/step - loss: 0.3504 - accuracy: 0.9034 - val_loss: 1.5284 - val_accuracy: 0.6765\n","Epoch 17/20\n","4000/4000 [==============================] - 138s 34ms/step - loss: 0.3497 - accuracy: 0.9034 - val_loss: 1.5347 - val_accuracy: 0.6800\n","Epoch 18/20\n","4000/4000 [==============================] - 137s 34ms/step - loss: 0.3389 - accuracy: 0.9060 - val_loss: 1.5247 - val_accuracy: 0.6800\n","Epoch 19/20\n","4000/4000 [==============================] - 137s 34ms/step - loss: 0.3382 - accuracy: 0.9075 - val_loss: 1.5385 - val_accuracy: 0.6795\n","Epoch 20/20\n","4000/4000 [==============================] - 137s 34ms/step - loss: 0.3338 - accuracy: 0.9096 - val_loss: 1.5423 - val_accuracy: 0.6785\n","Epoch 00001: early stopping and save the model\n"]}],"source":["#finetuning\n","extractor_1.trainable = True\n","extractor_2.trainable = True\n","extractor_3.trainable = True\n","extractor_4.trainable = True\n","extractor_5.trainable = True\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","#train_sequence = ecifar10data(sampled_x_train, sampled_y_train, batch_size=10, train=False)\n","#validation_sequence = ecifar10data(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=20,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"y1W3vPZQppO3","outputId":"83e2982d-02cc-4473-83bf-9d82b600f37c"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'              precision    recall  f1-score   support\\n\\n           0     0.9355    0.8700    0.9016       100\\n           1     0.7830    0.8300    0.8058       100\\n           2     0.5657    0.5600    0.5628       100\\n           3     0.5146    0.5300    0.5222       100\\n           4     0.5510    0.5400    0.5455       100\\n           5     0.6827    0.7100    0.6961       100\\n           6     0.7358    0.7800    0.7573       100\\n           7     0.7021    0.6600    0.6804       100\\n           8     0.7885    0.8200    0.8039       100\\n           9     0.7736    0.8200    0.7961       100\\n          10     0.6264    0.5700    0.5969       100\\n          11     0.5189    0.5500    0.5340       100\\n          12     0.7500    0.7500    0.7500       100\\n          13     0.6593    0.6000    0.6283       100\\n          14     0.6737    0.6400    0.6564       100\\n          15     0.6604    0.7000    0.6796       100\\n          16     0.7059    0.7200    0.7129       100\\n          17     0.8300    0.8300    0.8300       100\\n          18     0.6566    0.6500    0.6533       100\\n          19     0.6316    0.6000    0.6154       100\\n          20     0.8416    0.8500    0.8458       100\\n          21     0.7570    0.8100    0.7826       100\\n          22     0.7468    0.5900    0.6592       100\\n          23     0.7547    0.8000    0.7767       100\\n          24     0.8571    0.7800    0.8168       100\\n          25     0.5644    0.5700    0.5672       100\\n          26     0.7303    0.6500    0.6878       100\\n          27     0.4186    0.5400    0.4716       100\\n          28     0.8085    0.7600    0.7835       100\\n          29     0.6634    0.6700    0.6667       100\\n          30     0.5377    0.5700    0.5534       100\\n          31     0.7157    0.7300    0.7228       100\\n          32     0.6139    0.6200    0.6169       100\\n          33     0.6250    0.6500    0.6373       100\\n          34     0.6697    0.7300    0.6986       100\\n          35     0.4725    0.4300    0.4503       100\\n          36     0.8280    0.7700    0.7979       100\\n          37     0.7500    0.6600    0.7021       100\\n          38     0.5140    0.5500    0.5314       100\\n          39     0.8876    0.7900    0.8360       100\\n          40     0.6316    0.6000    0.6154       100\\n          41     0.9149    0.8600    0.8866       100\\n          42     0.6818    0.6000    0.6383       100\\n          43     0.7653    0.7500    0.7576       100\\n          44     0.4722    0.5100    0.4904       100\\n          45     0.6383    0.6000    0.6186       100\\n          46     0.5476    0.4600    0.5000       100\\n          47     0.6854    0.6100    0.6455       100\\n          48     0.8304    0.9300    0.8774       100\\n          49     0.6949    0.8200    0.7523       100\\n          50     0.4623    0.4900    0.4757       100\\n          51     0.6979    0.6700    0.6837       100\\n          52     0.6262    0.6700    0.6473       100\\n          53     0.7826    0.9000    0.8372       100\\n          54     0.6864    0.8100    0.7431       100\\n          55     0.3465    0.3500    0.3483       100\\n          56     0.9231    0.8400    0.8796       100\\n          57     0.7255    0.7400    0.7327       100\\n          58     0.8144    0.7900    0.8020       100\\n          59     0.6907    0.6700    0.6802       100\\n          60     0.8269    0.8600    0.8431       100\\n          61     0.6981    0.7400    0.7184       100\\n          62     0.6604    0.7000    0.6796       100\\n          63     0.6897    0.6000    0.6417       100\\n          64     0.5263    0.5000    0.5128       100\\n          65     0.4831    0.4300    0.4550       100\\n          66     0.7075    0.7500    0.7282       100\\n          67     0.5446    0.5500    0.5473       100\\n          68     0.8304    0.9300    0.8774       100\\n          69     0.7453    0.7900    0.7670       100\\n          70     0.7333    0.6600    0.6947       100\\n          71     0.7364    0.8100    0.7714       100\\n          72     0.4019    0.4300    0.4155       100\\n          73     0.5321    0.5800    0.5550       100\\n          74     0.4234    0.4700    0.4455       100\\n          75     0.8925    0.8300    0.8601       100\\n          76     0.8113    0.8600    0.8350       100\\n          77     0.7444    0.6700    0.7053       100\\n          78     0.5941    0.6000    0.5970       100\\n          79     0.6822    0.7300    0.7053       100\\n          80     0.4706    0.4800    0.4752       100\\n          81     0.7404    0.7700    0.7549       100\\n          82     0.9286    0.9100    0.9192       100\\n          83     0.7273    0.6400    0.6809       100\\n          84     0.7333    0.6600    0.6947       100\\n          85     0.7727    0.8500    0.8095       100\\n          86     0.8228    0.6500    0.7263       100\\n          87     0.7453    0.7900    0.7670       100\\n          88     0.7889    0.7100    0.7474       100\\n          89     0.7523    0.8200    0.7847       100\\n          90     0.7549    0.7700    0.7624       100\\n          91     0.8295    0.7300    0.7766       100\\n          92     0.5377    0.5700    0.5534       100\\n          93     0.5843    0.5200    0.5503       100\\n          94     0.8624    0.9400    0.8995       100\\n          95     0.6355    0.6800    0.6570       100\\n          96     0.5882    0.6000    0.5941       100\\n          97     0.7159    0.6300    0.6702       100\\n          98     0.4510    0.4600    0.4554       100\\n          99     0.7374    0.7300    0.7337       100\\n\\n    accuracy                         0.6832     10000\\n   macro avg     0.6856    0.6832    0.6831     10000\\nweighted avg     0.6856    0.6832    0.6831     10000\\n'"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#f1 score\n","predict = tf.argmax(ensemble.predict(x_test),axis=-1)\n","classification_report(y_test, predict,digits=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKQImHeaekmX"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"cifar100VGG16EX.ipynb","provenance":[],"mount_file_id":"1FpvzlCGVLwzUshOQ85lAUgCMSstIKftp","authorship_tag":"ABX9TyMTPcYUesoqLQ4p552Xl4Ia"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}