{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1650575546482,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"},"user_tz":-120},"id":"tt00VOZ_d5dq","outputId":"6090839b-fb27-4fdf-8045-65f94c7a339f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n!unzip '/content/drive/MyDrive/NEU/100_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/NEU/NEU_validation.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/NEU/NEU_test.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/NEU/50_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/NEU/20_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/NEU/10_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/NEU/5_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/NEU/3_samples.zip' -d '/content'\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["#unzip NEU dataset\n","!unzip '/content/drive/MyDrive/NEU/100_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/NEU/NEU_validation.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/NEU/NEU_test.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/NEU/50_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/NEU/20_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/NEU/10_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/NEU/5_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/NEU/3_samples.zip' -d '/content'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlirJGkod7y0"},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","from tensorflow import keras\n","from sklearn import model_selection\n","from sklearn.metrics import classification_report\n","import imgaug.augmenters as iaa\n","import imgaug as ia\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TGGKlSyFBJn"},"outputs":[],"source":["ia.seed(1)\n","def Data_Aug(samples):\n","    randomaug = iaa.Sometimes(\n","        0.5,\n","        iaa.OneOf([\n","            iaa.Sequential([\n","                iaa.AllChannelsCLAHE(clip_limit=(1, 10)),\n","                iaa.Affine(rotate=(-5, 5))\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(translate_percent={\n","                    \"x\": (-0.2, 0.2),\n","                    \"y\": (-0.2, 0.2)\n","                }),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(rotate=(-10, 10)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.PerspectiveTransform(scale=(0, 0.15)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ])\n","        ]))\n","\n","\n","    return randomaug.augment_images(samples)\n","\n","def resize_images(imgs, hight, width):\n","    seq = iaa.Resize({\"height\": hight, \"width\": width})\n","    aug = seq.augment_images(imgs)\n","    return aug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RJ3uDY9FgNZ"},"outputs":[],"source":["def load_data(dir_path, labels_dict):\n","  all_names = os.listdir(dir_path)\n","  data_x = []\n","  data_y = []\n","  for name in all_names:\n","    img = keras.preprocessing.image.load_img(os.path.join(dir_path, name))\n","    img = keras.preprocessing.image.img_to_array(img,dtype='uint8')\n","    data_x.append(img)\n","    lab = labels_dict[name[:2]]\n","    data_y.append(lab)\n","  data_x = np.array(data_x)\n","  data_y = np.array(data_y)\n","  return data_x, data_y\n","class NEUdata(keras.utils.Sequence):\n","    def __init__(self, data_x, data_y, batch_size, train):\n","      self.data_x = data_x\n","      self.data_y = data_y\n","      self.train = train\n","      self.batch_size = batch_size\n","\n","    def __len__(self):\n","      return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","      batch_x = self.data_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n","                            \n","      batch_y = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n","      if self.train == True:\n","          batch_x = Data_Aug(batch_x)\n","\n","      batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","      batch_y = keras.utils.to_categorical(batch_y, 6)\n","      return batch_x, [batch_y, batch_y, batch_y, batch_y, batch_y]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4U_n_3bce9u4"},"outputs":[],"source":["#save the best model during training \n","class CustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(CustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_model_accuracy') + logs.get(\n","            'val_model_1_accuracy') + logs.get(\n","                'val_model_2_accuracy') \n","                #+ logs.get(\n","                 #   'val_model_3_accuracy') + logs.get('val_model_4_accuracy')\n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1BPrwTrBVE2"},"outputs":[],"source":["#Cosine&Euclidean distance loss\n","def descriptor(X, mask = False, max_norm = False):\n","  X = tf.reduce_mean(X, axis=3)\n","  if mask:\n","    mean_X = tf.reduce_mean(X, axis = [1,2], keepdims= True)\n","    X = tf.where(X > mean_X, X , tf.zeros_like(X, dtype=tf.float32))\n","  if max_norm:\n","    max_X=tf.reduce_max(X, axis = [1,2], keepdims= True)\n","    X = tf.math.divide_no_nan(X, max_X)\n","  return X \n","  \n","def compute_euclidean_sum(X, Y):\n","  L2_distance = tf.reduce_mean(tf.exp(-(X - Y)**2), axis= [1,2])\n","  return tf.reduce_mean(L2_distance)\n","\n","def compute_cosine_sum(X, Y):\n","  X = tf.reshape(X, [tf.shape(X)[0], -1])\n","  Y = tf.reshape(Y, [tf.shape(Y)[0], -1])\n","  loss = -keras.losses.cosine_similarity(X,Y,axis=-1)\n","  return tf.reduce_mean(loss)\n","\n","def cosine_euclidean_sum_loss(x, cosine_weight, euclidean_weight, mask, max_norm):\n","  descriptor0 = descriptor(x[0], mask=mask, max_norm=max_norm)\n","  descriptor1 = descriptor(x[1], mask=mask, max_norm=max_norm)\n","  descriptor2 = descriptor(x[2], mask=mask, max_norm=max_norm)\n","  descriptor3 = descriptor(x[3], mask=mask, max_norm=max_norm)\n","  descriptor4 = descriptor(x[4], mask=mask, max_norm=max_norm)\n","  cosine_sum = compute_cosine_sum(descriptor0, descriptor1)+compute_cosine_sum(descriptor0, descriptor2)+compute_cosine_sum(descriptor0, descriptor3)+compute_cosine_sum(descriptor0, descriptor4)+compute_cosine_sum(descriptor1, descriptor2)+compute_cosine_sum(descriptor1, descriptor3)+compute_cosine_sum(descriptor1, descriptor4)+compute_cosine_sum(descriptor2, descriptor3)+compute_cosine_sum(descriptor2, descriptor4)+compute_cosine_sum(descriptor3, descriptor4)\n","  euclidean_sum = compute_euclidean_sum(descriptor0, descriptor1)+compute_euclidean_sum(descriptor0, descriptor2)+compute_euclidean_sum(descriptor0, descriptor3)+compute_euclidean_sum(descriptor0, descriptor4)+compute_euclidean_sum(descriptor1, descriptor2)+compute_euclidean_sum(descriptor1, descriptor3)+compute_euclidean_sum(descriptor1, descriptor4)+compute_euclidean_sum(descriptor2, descriptor3)+compute_euclidean_sum(descriptor2, descriptor4)+compute_euclidean_sum(descriptor3, descriptor4)\n","  return cosine_sum, euclidean_sum, cosine_weight*cosine_sum+euclidean_weight*euclidean_sum  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMRptakCHOr_"},"outputs":[],"source":["#create single ResNet model\n","def create_ResNet(input_shape, num_classes=6, num_filters = 64, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x)\n","\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(2*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(4*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(8*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  last_acti = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  x = keras.layers.GlobalAveragePooling2D()(last_acti)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  model = keras.Model(inputs=inputs, outputs=[outputs,last_acti])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8mni5GQeq_2"},"outputs":[],"source":["#load training, validation and testing images\n","training_data_path = '5_samples'\n","validation_data_path = 'NEU_validation'\n","test_data_path = 'NEU_test'\n","labels_dict = {'Cr': 0, 'In': 1, 'Pa': 2, 'PS': 3, 'RS': 4, 'Sc': 5}\n","x_train, y_train = load_data(training_data_path, labels_dict)\n","x_val, y_val = load_data(validation_data_path, labels_dict)\n","x_test, y_test = load_data(test_data_path, labels_dict)\n","x_test = x_test/255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nf634qPVt_Mq","executionInfo":{"status":"ok","timestamp":1650577560014,"user_tz":-120,"elapsed":2009811,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"6b34ba13-cb6f-454b-d4a6-a65d86e7875d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","3/3 [==============================] - 30s 4s/step - loss: 12.0082 - model_loss: 2.3813 - model_1_loss: 2.3395 - model_2_loss: 2.5251 - model_3_loss: 2.1967 - model_4_loss: 2.5657 - model_accuracy: 0.3000 - model_1_accuracy: 0.2000 - model_2_accuracy: 0.2000 - model_3_accuracy: 0.2000 - model_4_accuracy: 0.2333 - loss1: 8.6036 - loss2: 8.9407 - val_loss: 48.6301 - val_model_loss: 8.5624 - val_model_1_loss: 7.3219 - val_model_2_loss: 11.7844 - val_model_3_loss: 9.2954 - val_model_4_loss: 11.6661 - val_model_accuracy: 0.1667 - val_model_1_accuracy: 0.1667 - val_model_2_accuracy: 0.1667 - val_model_3_accuracy: 0.1667 - val_model_4_accuracy: 0.1667 - val_loss1: 9.5888 - val_loss2: 8.6162\n","Epoch 2/300\n","3/3 [==============================] - 5s 2s/step - loss: 7.5035 - model_loss: 1.4895 - model_1_loss: 1.4862 - model_2_loss: 1.4941 - model_3_loss: 1.5558 - model_4_loss: 1.4779 - model_accuracy: 0.5667 - model_1_accuracy: 0.4000 - model_2_accuracy: 0.4333 - model_3_accuracy: 0.4667 - model_4_accuracy: 0.5667 - loss1: 8.6240 - loss2: 9.0343 - val_loss: 51.2090 - val_model_loss: 8.4572 - val_model_1_loss: 10.1224 - val_model_2_loss: 11.4938 - val_model_3_loss: 8.7831 - val_model_4_loss: 12.3526 - val_model_accuracy: 0.1667 - val_model_1_accuracy: 0.1667 - val_model_2_accuracy: 0.1667 - val_model_3_accuracy: 0.2583 - val_model_4_accuracy: 0.1667 - val_loss1: 9.6167 - val_loss2: 8.6836\n","Epoch 3/300\n","3/3 [==============================] - 5s 2s/step - loss: 7.5023 - model_loss: 1.5765 - model_1_loss: 1.3466 - model_2_loss: 1.4853 - model_3_loss: 1.4554 - model_4_loss: 1.6385 - model_accuracy: 0.4333 - model_1_accuracy: 0.5667 - model_2_accuracy: 0.4000 - model_3_accuracy: 0.4333 - model_4_accuracy: 0.5000 - loss1: 8.7621 - loss2: 9.1628 - val_loss: 57.4626 - val_model_loss: 9.8554 - val_model_1_loss: 12.6316 - val_model_2_loss: 12.6784 - val_model_3_loss: 9.1444 - val_model_4_loss: 13.1528 - val_model_accuracy: 0.1111 - val_model_1_accuracy: 0.1667 - val_model_2_accuracy: 0.1667 - val_model_3_accuracy: 0.1667 - val_model_4_accuracy: 0.1667 - val_loss1: 9.6534 - val_loss2: 8.7129\n","Epoch 4/300\n","3/3 [==============================] - 5s 2s/step - loss: 5.8104 - model_loss: 1.2638 - model_1_loss: 1.1435 - model_2_loss: 1.1328 - model_3_loss: 1.1399 - model_4_loss: 1.1304 - model_accuracy: 0.6000 - model_1_accuracy: 0.6333 - model_2_accuracy: 0.6000 - model_3_accuracy: 0.6333 - model_4_accuracy: 0.5667 - loss1: 8.7443 - loss2: 9.1426 - val_loss: 55.9560 - val_model_loss: 9.5752 - val_model_1_loss: 12.7954 - val_model_2_loss: 11.2744 - val_model_3_loss: 9.5441 - val_model_4_loss: 12.7669 - val_model_accuracy: 0.1667 - val_model_1_accuracy: 0.1667 - val_model_2_accuracy: 0.1667 - val_model_3_accuracy: 0.1667 - val_model_4_accuracy: 0.1778 - val_loss1: 9.6669 - val_loss2: 8.7698\n","Epoch 5/300\n","3/3 [==============================] - 5s 2s/step - loss: 6.2293 - model_loss: 1.2380 - model_1_loss: 1.2234 - model_2_loss: 1.2738 - model_3_loss: 1.1772 - model_4_loss: 1.3169 - model_accuracy: 0.6000 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.4667 - loss1: 8.7027 - loss2: 9.1442 - val_loss: 45.7762 - val_model_loss: 7.9636 - val_model_1_loss: 8.6815 - val_model_2_loss: 6.8473 - val_model_3_loss: 9.2744 - val_model_4_loss: 13.0094 - val_model_accuracy: 0.1667 - val_model_1_accuracy: 0.1667 - val_model_2_accuracy: 0.1667 - val_model_3_accuracy: 0.1667 - val_model_4_accuracy: 0.1667 - val_loss1: 9.6987 - val_loss2: 8.8428\n","Epoch 6/300\n","3/3 [==============================] - 6s 3s/step - loss: 4.9914 - model_loss: 1.1533 - model_1_loss: 0.9449 - model_2_loss: 0.8945 - model_3_loss: 0.9635 - model_4_loss: 1.0352 - model_accuracy: 0.6333 - model_1_accuracy: 0.7333 - model_2_accuracy: 0.7000 - model_3_accuracy: 0.6333 - model_4_accuracy: 0.6667 - loss1: 8.6510 - loss2: 9.0917 - val_loss: 35.1184 - val_model_loss: 6.7300 - val_model_1_loss: 6.0534 - val_model_2_loss: 5.1685 - val_model_3_loss: 6.5860 - val_model_4_loss: 10.5806 - val_model_accuracy: 0.2000 - val_model_1_accuracy: 0.1806 - val_model_2_accuracy: 0.1694 - val_model_3_accuracy: 0.1667 - val_model_4_accuracy: 0.1667 - val_loss1: 9.7094 - val_loss2: 8.8691\n","Epoch 7/300\n","3/3 [==============================] - 5s 2s/step - loss: 5.4709 - model_loss: 1.0708 - model_1_loss: 0.9009 - model_2_loss: 1.2055 - model_3_loss: 1.1721 - model_4_loss: 1.1216 - model_accuracy: 0.7667 - model_1_accuracy: 0.7333 - model_2_accuracy: 0.5333 - model_3_accuracy: 0.7333 - model_4_accuracy: 0.6667 - loss1: 8.5200 - loss2: 9.0014 - val_loss: 27.5156 - val_model_loss: 5.8018 - val_model_1_loss: 4.3976 - val_model_2_loss: 4.1839 - val_model_3_loss: 4.8261 - val_model_4_loss: 8.3062 - val_model_accuracy: 0.1833 - val_model_1_accuracy: 0.1833 - val_model_2_accuracy: 0.1667 - val_model_3_accuracy: 0.1667 - val_model_4_accuracy: 0.1667 - val_loss1: 9.7033 - val_loss2: 8.9015\n","Epoch 8/300\n","3/3 [==============================] - 5s 2s/step - loss: 5.6081 - model_loss: 1.0199 - model_1_loss: 1.0933 - model_2_loss: 1.1814 - model_3_loss: 1.0591 - model_4_loss: 1.2545 - model_accuracy: 0.7000 - model_1_accuracy: 0.7333 - model_2_accuracy: 0.6000 - model_3_accuracy: 0.6333 - model_4_accuracy: 0.7000 - loss1: 8.7499 - loss2: 9.0963 - val_loss: 22.4958 - val_model_loss: 4.5286 - val_model_1_loss: 3.6368 - val_model_2_loss: 3.4377 - val_model_3_loss: 4.3331 - val_model_4_loss: 6.5596 - val_model_accuracy: 0.1750 - val_model_1_accuracy: 0.1917 - val_model_2_accuracy: 0.1528 - val_model_3_accuracy: 0.1694 - val_model_4_accuracy: 0.1722 - val_loss1: 9.6786 - val_loss2: 8.9839\n","Epoch 9/300\n","3/3 [==============================] - 5s 2s/step - loss: 3.7152 - model_loss: 0.7704 - model_1_loss: 0.5860 - model_2_loss: 0.8586 - model_3_loss: 0.8074 - model_4_loss: 0.6927 - model_accuracy: 0.8000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.7333 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.7000 - loss1: 8.4440 - loss2: 8.9410 - val_loss: 19.6111 - val_model_loss: 4.1044 - val_model_1_loss: 3.8439 - val_model_2_loss: 2.8475 - val_model_3_loss: 4.1760 - val_model_4_loss: 4.6393 - val_model_accuracy: 0.1250 - val_model_1_accuracy: 0.1833 - val_model_2_accuracy: 0.0889 - val_model_3_accuracy: 0.1528 - val_model_4_accuracy: 0.1750 - val_loss1: 9.6352 - val_loss2: 9.0835\n","Epoch 10/300\n","3/3 [==============================] - 5s 3s/step - loss: 6.3093 - model_loss: 1.4772 - model_1_loss: 1.2479 - model_2_loss: 1.1465 - model_3_loss: 1.0987 - model_4_loss: 1.3390 - model_accuracy: 0.5667 - model_1_accuracy: 0.5333 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.5667 - model_4_accuracy: 0.6000 - loss1: 8.5413 - loss2: 9.0534 - val_loss: 19.3839 - val_model_loss: 3.9216 - val_model_1_loss: 3.7926 - val_model_2_loss: 2.8057 - val_model_3_loss: 4.5058 - val_model_4_loss: 4.3583 - val_model_accuracy: 0.0472 - val_model_1_accuracy: 0.1889 - val_model_2_accuracy: 0.0389 - val_model_3_accuracy: 0.0972 - val_model_4_accuracy: 0.1750 - val_loss1: 9.5776 - val_loss2: 9.1859\n","Epoch 11/300\n","3/3 [==============================] - 5s 2s/step - loss: 3.5316 - model_loss: 0.7753 - model_1_loss: 0.7523 - model_2_loss: 0.6771 - model_3_loss: 0.6097 - model_4_loss: 0.7172 - model_accuracy: 0.7333 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.7333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.7333 - loss1: 8.5287 - loss2: 9.0162 - val_loss: 19.8887 - val_model_loss: 3.9458 - val_model_1_loss: 3.2445 - val_model_2_loss: 3.8767 - val_model_3_loss: 4.5468 - val_model_4_loss: 4.2749 - val_model_accuracy: 0.0472 - val_model_1_accuracy: 0.1944 - val_model_2_accuracy: 0.1444 - val_model_3_accuracy: 0.1167 - val_model_4_accuracy: 0.1778 - val_loss1: 9.4872 - val_loss2: 9.2637\n","Epoch 12/300\n","3/3 [==============================] - 5s 2s/step - loss: 3.0784 - model_loss: 0.6154 - model_1_loss: 0.5162 - model_2_loss: 0.6801 - model_3_loss: 0.6336 - model_4_loss: 0.6331 - model_accuracy: 0.8000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.7667 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.7667 - loss1: 8.4991 - loss2: 8.9906 - val_loss: 19.9014 - val_model_loss: 3.7237 - val_model_1_loss: 3.2205 - val_model_2_loss: 4.2816 - val_model_3_loss: 4.3685 - val_model_4_loss: 4.3072 - val_model_accuracy: 0.2000 - val_model_1_accuracy: 0.1444 - val_model_2_accuracy: 0.1667 - val_model_3_accuracy: 0.1222 - val_model_4_accuracy: 0.1889 - val_loss1: 9.3508 - val_loss2: 9.2721\n","Epoch 13/300\n","3/3 [==============================] - 6s 3s/step - loss: 4.8315 - model_loss: 0.9850 - model_1_loss: 0.9300 - model_2_loss: 0.9719 - model_3_loss: 1.0015 - model_4_loss: 0.9430 - model_accuracy: 0.7000 - model_1_accuracy: 0.7333 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.7333 - loss1: 8.2899 - loss2: 8.9178 - val_loss: 18.5996 - val_model_loss: 3.4958 - val_model_1_loss: 3.4444 - val_model_2_loss: 3.9729 - val_model_3_loss: 3.6007 - val_model_4_loss: 4.0858 - val_model_accuracy: 0.2139 - val_model_1_accuracy: 0.2111 - val_model_2_accuracy: 0.1694 - val_model_3_accuracy: 0.1028 - val_model_4_accuracy: 0.2222 - val_loss1: 9.2110 - val_loss2: 9.2975\n","Epoch 14/300\n","3/3 [==============================] - 6s 3s/step - loss: 3.1577 - model_loss: 0.7170 - model_1_loss: 0.4593 - model_2_loss: 0.7302 - model_3_loss: 0.6054 - model_4_loss: 0.6458 - model_accuracy: 0.7667 - model_1_accuracy: 0.8000 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.7000 - model_4_accuracy: 0.7000 - loss1: 8.4243 - loss2: 8.9543 - val_loss: 19.7331 - val_model_loss: 3.8810 - val_model_1_loss: 3.8164 - val_model_2_loss: 3.8266 - val_model_3_loss: 3.5754 - val_model_4_loss: 4.6338 - val_model_accuracy: 0.2139 - val_model_1_accuracy: 0.2472 - val_model_2_accuracy: 0.1750 - val_model_3_accuracy: 0.1444 - val_model_4_accuracy: 0.2472 - val_loss1: 9.0603 - val_loss2: 9.3291\n","Epoch 15/300\n","3/3 [==============================] - 6s 3s/step - loss: 3.0593 - model_loss: 0.6730 - model_1_loss: 0.6123 - model_2_loss: 0.5833 - model_3_loss: 0.6320 - model_4_loss: 0.5588 - model_accuracy: 0.7667 - model_1_accuracy: 0.7667 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.7333 - model_4_accuracy: 0.7667 - loss1: 8.3812 - loss2: 8.9092 - val_loss: 19.9685 - val_model_loss: 4.0039 - val_model_1_loss: 3.9315 - val_model_2_loss: 3.7578 - val_model_3_loss: 3.6351 - val_model_4_loss: 4.6401 - val_model_accuracy: 0.2278 - val_model_1_accuracy: 0.2361 - val_model_2_accuracy: 0.1833 - val_model_3_accuracy: 0.1250 - val_model_4_accuracy: 0.2556 - val_loss1: 8.9192 - val_loss2: 9.3591\n","Epoch 16/300\n","3/3 [==============================] - 6s 3s/step - loss: 2.5915 - model_loss: 0.5386 - model_1_loss: 0.5177 - model_2_loss: 0.4975 - model_3_loss: 0.5209 - model_4_loss: 0.5168 - model_accuracy: 0.8333 - model_1_accuracy: 0.8000 - model_2_accuracy: 0.7667 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8667 - loss1: 8.4423 - loss2: 8.9919 - val_loss: 19.3846 - val_model_loss: 3.7784 - val_model_1_loss: 3.8201 - val_model_2_loss: 4.1238 - val_model_3_loss: 3.6460 - val_model_4_loss: 4.0163 - val_model_accuracy: 0.2222 - val_model_1_accuracy: 0.3028 - val_model_2_accuracy: 0.1806 - val_model_3_accuracy: 0.1361 - val_model_4_accuracy: 0.2556 - val_loss1: 8.8178 - val_loss2: 9.3906\n","Epoch 17/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.9069 - model_loss: 0.6134 - model_1_loss: 0.4930 - model_2_loss: 0.6550 - model_3_loss: 0.5590 - model_4_loss: 0.5864 - model_accuracy: 0.7333 - model_1_accuracy: 0.7667 - model_2_accuracy: 0.7333 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.7333 - loss1: 8.5311 - loss2: 8.9815 - val_loss: 19.4461 - val_model_loss: 3.9477 - val_model_1_loss: 3.8408 - val_model_2_loss: 4.2811 - val_model_3_loss: 3.6818 - val_model_4_loss: 3.6948 - val_model_accuracy: 0.2056 - val_model_1_accuracy: 0.2722 - val_model_2_accuracy: 0.1833 - val_model_3_accuracy: 0.1417 - val_model_4_accuracy: 0.3111 - val_loss1: 8.7578 - val_loss2: 9.4071\n","Epoch 18/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.8932 - model_loss: 0.5953 - model_1_loss: 0.5562 - model_2_loss: 0.5766 - model_3_loss: 0.5858 - model_4_loss: 0.5793 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.8000 - loss1: 8.4319 - loss2: 8.9732 - val_loss: 19.9108 - val_model_loss: 4.1436 - val_model_1_loss: 3.8459 - val_model_2_loss: 4.2761 - val_model_3_loss: 3.9228 - val_model_4_loss: 3.7224 - val_model_accuracy: 0.0806 - val_model_1_accuracy: 0.1611 - val_model_2_accuracy: 0.1833 - val_model_3_accuracy: 0.1583 - val_model_4_accuracy: 0.2306 - val_loss1: 8.7263 - val_loss2: 9.4396\n","Epoch 19/300\n","3/3 [==============================] - 5s 2s/step - loss: 4.3745 - model_loss: 0.9275 - model_1_loss: 0.9133 - model_2_loss: 0.8013 - model_3_loss: 0.8164 - model_4_loss: 0.9160 - model_accuracy: 0.7333 - model_1_accuracy: 0.6333 - model_2_accuracy: 0.7000 - model_3_accuracy: 0.6333 - model_4_accuracy: 0.7000 - loss1: 8.2711 - loss2: 8.8122 - val_loss: 18.8681 - val_model_loss: 3.6474 - val_model_1_loss: 3.5641 - val_model_2_loss: 3.5242 - val_model_3_loss: 4.5353 - val_model_4_loss: 3.5971 - val_model_accuracy: 0.1639 - val_model_1_accuracy: 0.1778 - val_model_2_accuracy: 0.1806 - val_model_3_accuracy: 0.1750 - val_model_4_accuracy: 0.2417 - val_loss1: 8.7680 - val_loss2: 9.4762\n","Epoch 20/300\n","3/3 [==============================] - 6s 3s/step - loss: 2.9472 - model_loss: 0.6109 - model_1_loss: 0.5522 - model_2_loss: 0.5989 - model_3_loss: 0.5550 - model_4_loss: 0.6302 - model_accuracy: 0.7333 - model_1_accuracy: 0.8000 - model_2_accuracy: 0.7333 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.8000 - loss1: 8.4494 - loss2: 9.0197 - val_loss: 18.3203 - val_model_loss: 3.2471 - val_model_1_loss: 3.6829 - val_model_2_loss: 2.5349 - val_model_3_loss: 5.3821 - val_model_4_loss: 3.4732 - val_model_accuracy: 0.2917 - val_model_1_accuracy: 0.1778 - val_model_2_accuracy: 0.2833 - val_model_3_accuracy: 0.1972 - val_model_4_accuracy: 0.2306 - val_loss1: 8.7625 - val_loss2: 9.5012\n","Epoch 21/300\n","3/3 [==============================] - 6s 3s/step - loss: 4.9729 - model_loss: 1.0599 - model_1_loss: 0.9574 - model_2_loss: 0.9848 - model_3_loss: 0.9530 - model_4_loss: 1.0179 - model_accuracy: 0.6333 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.6000 - loss1: 8.3817 - loss2: 8.9311 - val_loss: 18.3328 - val_model_loss: 3.0066 - val_model_1_loss: 3.8602 - val_model_2_loss: 2.3281 - val_model_3_loss: 5.7580 - val_model_4_loss: 3.3798 - val_model_accuracy: 0.3722 - val_model_1_accuracy: 0.2278 - val_model_2_accuracy: 0.2917 - val_model_3_accuracy: 0.1944 - val_model_4_accuracy: 0.2250 - val_loss1: 8.7277 - val_loss2: 9.5077\n","Epoch 22/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.7904 - model_loss: 0.3203 - model_1_loss: 0.3594 - model_2_loss: 0.3691 - model_3_loss: 0.3607 - model_4_loss: 0.3808 - model_accuracy: 0.9000 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.9000 - loss1: 8.3944 - loss2: 8.9159 - val_loss: 17.8713 - val_model_loss: 2.8253 - val_model_1_loss: 3.8141 - val_model_2_loss: 2.2843 - val_model_3_loss: 5.6716 - val_model_4_loss: 3.2760 - val_model_accuracy: 0.3500 - val_model_1_accuracy: 0.2444 - val_model_2_accuracy: 0.3167 - val_model_3_accuracy: 0.2028 - val_model_4_accuracy: 0.2250 - val_loss1: 8.6901 - val_loss2: 9.5053\n","Epoch 23/300\n","3/3 [==============================] - 6s 3s/step - loss: 3.4768 - model_loss: 0.6973 - model_1_loss: 0.6867 - model_2_loss: 0.6505 - model_3_loss: 0.7073 - model_4_loss: 0.7351 - model_accuracy: 0.7000 - model_1_accuracy: 0.7667 - model_2_accuracy: 0.7667 - model_3_accuracy: 0.7000 - model_4_accuracy: 0.7333 - loss1: 8.5428 - loss2: 8.9691 - val_loss: 16.9106 - val_model_loss: 2.6883 - val_model_1_loss: 3.5547 - val_model_2_loss: 2.2189 - val_model_3_loss: 5.1754 - val_model_4_loss: 3.2733 - val_model_accuracy: 0.4000 - val_model_1_accuracy: 0.2306 - val_model_2_accuracy: 0.2833 - val_model_3_accuracy: 0.1972 - val_model_4_accuracy: 0.2056 - val_loss1: 8.6465 - val_loss2: 9.4987\n","Epoch 24/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.8187 - model_loss: 0.5885 - model_1_loss: 0.5367 - model_2_loss: 0.5801 - model_3_loss: 0.5335 - model_4_loss: 0.5799 - model_accuracy: 0.7667 - model_1_accuracy: 0.7667 - model_2_accuracy: 0.7333 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.7333 - loss1: 8.6191 - loss2: 9.0139 - val_loss: 16.5310 - val_model_loss: 2.6516 - val_model_1_loss: 3.4542 - val_model_2_loss: 2.2970 - val_model_3_loss: 4.7512 - val_model_4_loss: 3.3771 - val_model_accuracy: 0.3500 - val_model_1_accuracy: 0.2278 - val_model_2_accuracy: 0.2556 - val_model_3_accuracy: 0.2111 - val_model_4_accuracy: 0.1917 - val_loss1: 8.6199 - val_loss2: 9.4881\n","Epoch 25/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.8651 - model_loss: 0.3782 - model_1_loss: 0.3597 - model_2_loss: 0.4050 - model_3_loss: 0.3508 - model_4_loss: 0.3714 - model_accuracy: 0.9000 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.8667 - loss1: 8.5322 - loss2: 8.9842 - val_loss: 16.1610 - val_model_loss: 2.6715 - val_model_1_loss: 3.4423 - val_model_2_loss: 2.3119 - val_model_3_loss: 4.3812 - val_model_4_loss: 3.3542 - val_model_accuracy: 0.3000 - val_model_1_accuracy: 0.2722 - val_model_2_accuracy: 0.3500 - val_model_3_accuracy: 0.2083 - val_model_4_accuracy: 0.2000 - val_loss1: 8.6090 - val_loss2: 9.4907\n","Epoch 26/300\n","3/3 [==============================] - 6s 3s/step - loss: 3.5129 - model_loss: 0.8262 - model_1_loss: 0.6492 - model_2_loss: 0.6748 - model_3_loss: 0.6656 - model_4_loss: 0.6971 - model_accuracy: 0.7000 - model_1_accuracy: 0.7667 - model_2_accuracy: 0.7333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.7333 - loss1: 8.3932 - loss2: 8.9063 - val_loss: 15.2344 - val_model_loss: 2.6247 - val_model_1_loss: 3.3092 - val_model_2_loss: 2.2867 - val_model_3_loss: 3.9296 - val_model_4_loss: 3.0842 - val_model_accuracy: 0.2944 - val_model_1_accuracy: 0.2667 - val_model_2_accuracy: 0.3833 - val_model_3_accuracy: 0.2083 - val_model_4_accuracy: 0.2111 - val_loss1: 8.5859 - val_loss2: 9.5164\n","Epoch 27/300\n","3/3 [==============================] - 6s 3s/step - loss: 4.2414 - model_loss: 0.8663 - model_1_loss: 0.8546 - model_2_loss: 0.8483 - model_3_loss: 0.8223 - model_4_loss: 0.8498 - model_accuracy: 0.7333 - model_1_accuracy: 0.7333 - model_2_accuracy: 0.7000 - model_3_accuracy: 0.7667 - model_4_accuracy: 0.7333 - loss1: 8.4674 - loss2: 8.9800 - val_loss: 13.9809 - val_model_loss: 2.3380 - val_model_1_loss: 3.0638 - val_model_2_loss: 2.2466 - val_model_3_loss: 3.7671 - val_model_4_loss: 2.5654 - val_model_accuracy: 0.4083 - val_model_1_accuracy: 0.2056 - val_model_2_accuracy: 0.3583 - val_model_3_accuracy: 0.2056 - val_model_4_accuracy: 0.2000 - val_loss1: 8.5920 - val_loss2: 9.5435\n","Epoch 28/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.7622 - model_loss: 0.5153 - model_1_loss: 0.6564 - model_2_loss: 0.4727 - model_3_loss: 0.6064 - model_4_loss: 0.5114 - model_accuracy: 0.8333 - model_1_accuracy: 0.7667 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.8667 - loss1: 8.4523 - loss2: 8.9837 - val_loss: 14.2791 - val_model_loss: 2.3753 - val_model_1_loss: 3.1142 - val_model_2_loss: 2.3068 - val_model_3_loss: 4.0410 - val_model_4_loss: 2.4419 - val_model_accuracy: 0.3444 - val_model_1_accuracy: 0.1194 - val_model_2_accuracy: 0.3472 - val_model_3_accuracy: 0.1972 - val_model_4_accuracy: 0.2556 - val_loss1: 8.6423 - val_loss2: 9.5578\n","Epoch 29/300\n","3/3 [==============================] - 5s 2s/step - loss: 3.5206 - model_loss: 0.7555 - model_1_loss: 0.7407 - model_2_loss: 0.7540 - model_3_loss: 0.7085 - model_4_loss: 0.5620 - model_accuracy: 0.7667 - model_1_accuracy: 0.8000 - model_2_accuracy: 0.7333 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.7667 - loss1: 8.3752 - loss2: 8.8321 - val_loss: 15.4737 - val_model_loss: 2.3650 - val_model_1_loss: 3.5031 - val_model_2_loss: 2.3330 - val_model_3_loss: 4.6365 - val_model_4_loss: 2.6361 - val_model_accuracy: 0.3389 - val_model_1_accuracy: 0.1361 - val_model_2_accuracy: 0.2611 - val_model_3_accuracy: 0.2028 - val_model_4_accuracy: 0.2361 - val_loss1: 8.7099 - val_loss2: 9.5691\n","Epoch 30/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.5053 - model_loss: 0.3307 - model_1_loss: 0.2648 - model_2_loss: 0.2431 - model_3_loss: 0.3407 - model_4_loss: 0.3261 - model_accuracy: 0.9333 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9667 - loss1: 8.2906 - loss2: 8.8828 - val_loss: 16.1542 - val_model_loss: 2.4097 - val_model_1_loss: 3.7184 - val_model_2_loss: 2.3871 - val_model_3_loss: 4.8774 - val_model_4_loss: 2.7616 - val_model_accuracy: 0.3361 - val_model_1_accuracy: 0.1444 - val_model_2_accuracy: 0.2722 - val_model_3_accuracy: 0.2028 - val_model_4_accuracy: 0.2222 - val_loss1: 8.7603 - val_loss2: 9.5774\n","Epoch 31/300\n","3/3 [==============================] - 5s 2s/step - loss: 3.1965 - model_loss: 0.6279 - model_1_loss: 0.6547 - model_2_loss: 0.6296 - model_3_loss: 0.6893 - model_4_loss: 0.5950 - model_accuracy: 0.7333 - model_1_accuracy: 0.7333 - model_2_accuracy: 0.7000 - model_3_accuracy: 0.7000 - model_4_accuracy: 0.7667 - loss1: 8.3642 - loss2: 8.8708 - val_loss: 15.1632 - val_model_loss: 2.2626 - val_model_1_loss: 3.3667 - val_model_2_loss: 2.3813 - val_model_3_loss: 4.4876 - val_model_4_loss: 2.6650 - val_model_accuracy: 0.3889 - val_model_1_accuracy: 0.1667 - val_model_2_accuracy: 0.2861 - val_model_3_accuracy: 0.2056 - val_model_4_accuracy: 0.1833 - val_loss1: 8.7490 - val_loss2: 9.5699\n","Epoch 32/300\n","3/3 [==============================] - 5s 3s/step - loss: 2.5691 - model_loss: 0.5491 - model_1_loss: 0.5203 - model_2_loss: 0.5045 - model_3_loss: 0.4830 - model_4_loss: 0.5122 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.8667 - loss1: 8.4421 - loss2: 8.8912 - val_loss: 14.3702 - val_model_loss: 2.1777 - val_model_1_loss: 3.0850 - val_model_2_loss: 2.3632 - val_model_3_loss: 4.1228 - val_model_4_loss: 2.6215 - val_model_accuracy: 0.4111 - val_model_1_accuracy: 0.2167 - val_model_2_accuracy: 0.3389 - val_model_3_accuracy: 0.2167 - val_model_4_accuracy: 0.2000 - val_loss1: 8.7207 - val_loss2: 9.5546\n","Epoch 33/300\n","3/3 [==============================] - 5s 2s/step - loss: 3.4349 - model_loss: 0.6688 - model_1_loss: 0.7589 - model_2_loss: 0.6864 - model_3_loss: 0.6539 - model_4_loss: 0.6670 - model_accuracy: 0.7000 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.7000 - model_4_accuracy: 0.7000 - loss1: 8.5828 - loss2: 9.0195 - val_loss: 14.3570 - val_model_loss: 2.1853 - val_model_1_loss: 3.0484 - val_model_2_loss: 2.3971 - val_model_3_loss: 4.0693 - val_model_4_loss: 2.6570 - val_model_accuracy: 0.4028 - val_model_1_accuracy: 0.2694 - val_model_2_accuracy: 0.2444 - val_model_3_accuracy: 0.2278 - val_model_4_accuracy: 0.2472 - val_loss1: 8.7204 - val_loss2: 9.5397\n","Epoch 34/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.7247 - model_loss: 0.4730 - model_1_loss: 0.5778 - model_2_loss: 0.5202 - model_3_loss: 0.5319 - model_4_loss: 0.6217 - model_accuracy: 0.8667 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8000 - loss1: 8.5060 - loss2: 8.9639 - val_loss: 14.4283 - val_model_loss: 2.2455 - val_model_1_loss: 3.0704 - val_model_2_loss: 2.5612 - val_model_3_loss: 3.9288 - val_model_4_loss: 2.6224 - val_model_accuracy: 0.3833 - val_model_1_accuracy: 0.2472 - val_model_2_accuracy: 0.2111 - val_model_3_accuracy: 0.2278 - val_model_4_accuracy: 0.2667 - val_loss1: 8.6953 - val_loss2: 9.5165\n","Epoch 35/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.9152 - model_loss: 0.3721 - model_1_loss: 0.3651 - model_2_loss: 0.3949 - model_3_loss: 0.4184 - model_4_loss: 0.3648 - model_accuracy: 0.9000 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9000 - loss1: 8.4883 - loss2: 8.9208 - val_loss: 14.3293 - val_model_loss: 2.2651 - val_model_1_loss: 3.5796 - val_model_2_loss: 2.8013 - val_model_3_loss: 3.2930 - val_model_4_loss: 2.3902 - val_model_accuracy: 0.4333 - val_model_1_accuracy: 0.1722 - val_model_2_accuracy: 0.2028 - val_model_3_accuracy: 0.2667 - val_model_4_accuracy: 0.3000 - val_loss1: 8.6529 - val_loss2: 9.4991\n","Epoch 36/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.2354 - model_loss: 0.4295 - model_1_loss: 0.5189 - model_2_loss: 0.4352 - model_3_loss: 0.4274 - model_4_loss: 0.4245 - model_accuracy: 0.7667 - model_1_accuracy: 0.7667 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8667 - loss1: 8.4602 - loss2: 8.9079 - val_loss: 14.0535 - val_model_loss: 2.2671 - val_model_1_loss: 3.5500 - val_model_2_loss: 2.9732 - val_model_3_loss: 3.0294 - val_model_4_loss: 2.2338 - val_model_accuracy: 0.4361 - val_model_1_accuracy: 0.1750 - val_model_2_accuracy: 0.2083 - val_model_3_accuracy: 0.3000 - val_model_4_accuracy: 0.4083 - val_loss1: 8.6569 - val_loss2: 9.4833\n","Epoch 37/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.8472 - model_loss: 0.5444 - model_1_loss: 0.6744 - model_2_loss: 0.5192 - model_3_loss: 0.5447 - model_4_loss: 0.5645 - model_accuracy: 0.8333 - model_1_accuracy: 0.8000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.7667 - model_4_accuracy: 0.8000 - loss1: 8.5303 - loss2: 8.9481 - val_loss: 13.5786 - val_model_loss: 2.1760 - val_model_1_loss: 2.9062 - val_model_2_loss: 2.7373 - val_model_3_loss: 3.4923 - val_model_4_loss: 2.2667 - val_model_accuracy: 0.4389 - val_model_1_accuracy: 0.2611 - val_model_2_accuracy: 0.2472 - val_model_3_accuracy: 0.3222 - val_model_4_accuracy: 0.3167 - val_loss1: 8.6875 - val_loss2: 9.4849\n","Epoch 38/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.4774 - model_loss: 0.4394 - model_1_loss: 0.6092 - model_2_loss: 0.4175 - model_3_loss: 0.5377 - model_4_loss: 0.4736 - model_accuracy: 0.8667 - model_1_accuracy: 0.8000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9000 - loss1: 8.6004 - loss2: 8.9824 - val_loss: 15.8116 - val_model_loss: 2.7366 - val_model_1_loss: 3.2799 - val_model_2_loss: 2.7596 - val_model_3_loss: 4.1188 - val_model_4_loss: 2.9167 - val_model_accuracy: 0.3444 - val_model_1_accuracy: 0.3028 - val_model_2_accuracy: 0.2361 - val_model_3_accuracy: 0.3111 - val_model_4_accuracy: 0.3167 - val_loss1: 8.6954 - val_loss2: 9.4816\n","Epoch 39/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.8615 - model_loss: 0.4135 - model_1_loss: 0.3540 - model_2_loss: 0.3473 - model_3_loss: 0.3755 - model_4_loss: 0.3712 - model_accuracy: 0.8000 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.7667 - loss1: 8.6322 - loss2: 8.9858 - val_loss: 18.0203 - val_model_loss: 3.1430 - val_model_1_loss: 3.8257 - val_model_2_loss: 2.9772 - val_model_3_loss: 4.6597 - val_model_4_loss: 3.4147 - val_model_accuracy: 0.3028 - val_model_1_accuracy: 0.2917 - val_model_2_accuracy: 0.2222 - val_model_3_accuracy: 0.2667 - val_model_4_accuracy: 0.3028 - val_loss1: 8.7297 - val_loss2: 9.4838\n","Epoch 40/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.6520 - model_loss: 0.3675 - model_1_loss: 0.2879 - model_2_loss: 0.3501 - model_3_loss: 0.2993 - model_4_loss: 0.3472 - model_accuracy: 0.8667 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9000 - loss1: 8.5839 - loss2: 8.9595 - val_loss: 18.5482 - val_model_loss: 2.6767 - val_model_1_loss: 3.9757 - val_model_2_loss: 3.4870 - val_model_3_loss: 4.9721 - val_model_4_loss: 3.4367 - val_model_accuracy: 0.2944 - val_model_1_accuracy: 0.2778 - val_model_2_accuracy: 0.1917 - val_model_3_accuracy: 0.2556 - val_model_4_accuracy: 0.2750 - val_loss1: 8.7357 - val_loss2: 9.4656\n","Epoch 41/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.7997 - model_loss: 0.3964 - model_1_loss: 0.3404 - model_2_loss: 0.3776 - model_3_loss: 0.3226 - model_4_loss: 0.3627 - model_accuracy: 0.9000 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.8667 - loss1: 8.6818 - loss2: 9.0055 - val_loss: 19.2203 - val_model_loss: 2.7061 - val_model_1_loss: 3.9711 - val_model_2_loss: 3.9166 - val_model_3_loss: 5.2266 - val_model_4_loss: 3.3999 - val_model_accuracy: 0.2556 - val_model_1_accuracy: 0.2694 - val_model_2_accuracy: 0.1889 - val_model_3_accuracy: 0.2583 - val_model_4_accuracy: 0.2722 - val_loss1: 8.6912 - val_loss2: 9.4289\n","Epoch 42/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.9238 - model_loss: 0.4705 - model_1_loss: 0.6394 - model_2_loss: 0.5896 - model_3_loss: 0.4947 - model_4_loss: 0.7295 - model_accuracy: 0.8667 - model_1_accuracy: 0.7667 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.7667 - loss1: 8.4916 - loss2: 8.9158 - val_loss: 18.1720 - val_model_loss: 2.6742 - val_model_1_loss: 3.6989 - val_model_2_loss: 4.0567 - val_model_3_loss: 4.9357 - val_model_4_loss: 2.8066 - val_model_accuracy: 0.2806 - val_model_1_accuracy: 0.2611 - val_model_2_accuracy: 0.2056 - val_model_3_accuracy: 0.3583 - val_model_4_accuracy: 0.2833 - val_loss1: 8.6121 - val_loss2: 9.3874\n","Epoch 43/300\n","3/3 [==============================] - 5s 3s/step - loss: 1.4606 - model_loss: 0.2930 - model_1_loss: 0.2571 - model_2_loss: 0.2942 - model_3_loss: 0.3224 - model_4_loss: 0.2940 - model_accuracy: 0.8667 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8667 - loss1: 8.4863 - loss2: 8.8788 - val_loss: 16.7700 - val_model_loss: 2.5162 - val_model_1_loss: 3.3816 - val_model_2_loss: 4.1181 - val_model_3_loss: 4.4979 - val_model_4_loss: 2.2563 - val_model_accuracy: 0.3417 - val_model_1_accuracy: 0.2444 - val_model_2_accuracy: 0.2722 - val_model_3_accuracy: 0.3889 - val_model_4_accuracy: 0.2889 - val_loss1: 8.4916 - val_loss2: 9.3521\n","Epoch 44/300\n","3/3 [==============================] - 6s 3s/step - loss: 2.2248 - model_loss: 0.4393 - model_1_loss: 0.4287 - model_2_loss: 0.4608 - model_3_loss: 0.4512 - model_4_loss: 0.4448 - model_accuracy: 0.8667 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.8667 - loss1: 8.4903 - loss2: 8.9177 - val_loss: 15.5754 - val_model_loss: 2.4317 - val_model_1_loss: 2.9946 - val_model_2_loss: 4.2315 - val_model_3_loss: 4.0463 - val_model_4_loss: 1.8712 - val_model_accuracy: 0.4472 - val_model_1_accuracy: 0.2972 - val_model_2_accuracy: 0.3250 - val_model_3_accuracy: 0.3611 - val_model_4_accuracy: 0.3611 - val_loss1: 8.3780 - val_loss2: 9.3155\n","Epoch 45/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.6793 - model_loss: 0.3436 - model_1_loss: 0.3075 - model_2_loss: 0.2988 - model_3_loss: 0.3430 - model_4_loss: 0.3865 - model_accuracy: 0.8667 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9000 - loss1: 8.5148 - loss2: 8.8723 - val_loss: 15.4977 - val_model_loss: 2.5688 - val_model_1_loss: 2.7684 - val_model_2_loss: 4.3929 - val_model_3_loss: 4.0194 - val_model_4_loss: 1.7482 - val_model_accuracy: 0.4083 - val_model_1_accuracy: 0.3194 - val_model_2_accuracy: 0.3583 - val_model_3_accuracy: 0.3556 - val_model_4_accuracy: 0.4556 - val_loss1: 8.3059 - val_loss2: 9.2815\n","Epoch 46/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.4929 - model_loss: 0.3201 - model_1_loss: 0.2733 - model_2_loss: 0.2957 - model_3_loss: 0.3506 - model_4_loss: 0.2533 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.4566 - loss2: 8.8213 - val_loss: 15.8433 - val_model_loss: 2.6897 - val_model_1_loss: 2.6070 - val_model_2_loss: 4.3835 - val_model_3_loss: 4.3195 - val_model_4_loss: 1.8436 - val_model_accuracy: 0.4083 - val_model_1_accuracy: 0.3389 - val_model_2_accuracy: 0.3528 - val_model_3_accuracy: 0.3472 - val_model_4_accuracy: 0.4306 - val_loss1: 8.3389 - val_loss2: 9.3028\n","Epoch 47/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.9526 - model_loss: 0.5853 - model_1_loss: 0.6321 - model_2_loss: 0.5373 - model_3_loss: 0.5511 - model_4_loss: 0.6468 - model_accuracy: 0.8667 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 8.4747 - loss2: 8.7795 - val_loss: 16.5899 - val_model_loss: 2.7114 - val_model_1_loss: 2.6665 - val_model_2_loss: 4.4926 - val_model_3_loss: 4.7966 - val_model_4_loss: 1.9229 - val_model_accuracy: 0.3972 - val_model_1_accuracy: 0.3333 - val_model_2_accuracy: 0.3333 - val_model_3_accuracy: 0.3500 - val_model_4_accuracy: 0.4083 - val_loss1: 8.3689 - val_loss2: 9.3074\n","Epoch 48/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.3083 - model_loss: 0.2618 - model_1_loss: 0.2556 - model_2_loss: 0.2264 - model_3_loss: 0.2716 - model_4_loss: 0.2928 - model_accuracy: 0.9000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9000 - loss1: 8.5748 - loss2: 8.9405 - val_loss: 16.8063 - val_model_loss: 2.6776 - val_model_1_loss: 2.8159 - val_model_2_loss: 4.3756 - val_model_3_loss: 4.9470 - val_model_4_loss: 1.9904 - val_model_accuracy: 0.4056 - val_model_1_accuracy: 0.3639 - val_model_2_accuracy: 0.3472 - val_model_3_accuracy: 0.3611 - val_model_4_accuracy: 0.4528 - val_loss1: 8.4085 - val_loss2: 9.3202\n","Epoch 49/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.1384 - model_loss: 0.2118 - model_1_loss: 0.2503 - model_2_loss: 0.2146 - model_3_loss: 0.2603 - model_4_loss: 0.2014 - model_accuracy: 0.9000 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.5225 - loss2: 8.8947 - val_loss: 16.9138 - val_model_loss: 2.7507 - val_model_1_loss: 2.9667 - val_model_2_loss: 4.0734 - val_model_3_loss: 4.9293 - val_model_4_loss: 2.1937 - val_model_accuracy: 0.4889 - val_model_1_accuracy: 0.3972 - val_model_2_accuracy: 0.3583 - val_model_3_accuracy: 0.3889 - val_model_4_accuracy: 0.4000 - val_loss1: 8.4274 - val_loss2: 9.3202\n","Epoch 50/300\n","3/3 [==============================] - 6s 3s/step - loss: 2.0270 - model_loss: 0.4398 - model_1_loss: 0.3060 - model_2_loss: 0.4775 - model_3_loss: 0.4246 - model_4_loss: 0.3791 - model_accuracy: 0.8333 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.7333 - model_4_accuracy: 0.8667 - loss1: 8.4716 - loss2: 8.8801 - val_loss: 17.4289 - val_model_loss: 2.9395 - val_model_1_loss: 3.2004 - val_model_2_loss: 3.7433 - val_model_3_loss: 5.1528 - val_model_4_loss: 2.3930 - val_model_accuracy: 0.5028 - val_model_1_accuracy: 0.4250 - val_model_2_accuracy: 0.3528 - val_model_3_accuracy: 0.3889 - val_model_4_accuracy: 0.3417 - val_loss1: 8.4325 - val_loss2: 9.3120\n","Epoch 51/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6218 - model_loss: 0.1327 - model_1_loss: 0.1166 - model_2_loss: 0.1366 - model_3_loss: 0.1212 - model_4_loss: 0.1147 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4423 - loss2: 8.8411 - val_loss: 17.6273 - val_model_loss: 3.0098 - val_model_1_loss: 3.3783 - val_model_2_loss: 3.3034 - val_model_3_loss: 5.5002 - val_model_4_loss: 2.4356 - val_model_accuracy: 0.4750 - val_model_1_accuracy: 0.4389 - val_model_2_accuracy: 0.3583 - val_model_3_accuracy: 0.3306 - val_model_4_accuracy: 0.3222 - val_loss1: 8.4000 - val_loss2: 9.2702\n","Epoch 52/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.8504 - model_loss: 0.3530 - model_1_loss: 0.3599 - model_2_loss: 0.3587 - model_3_loss: 0.4048 - model_4_loss: 0.3740 - model_accuracy: 0.9333 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.8667 - loss1: 8.3754 - loss2: 8.8152 - val_loss: 17.0736 - val_model_loss: 2.9447 - val_model_1_loss: 3.0981 - val_model_2_loss: 3.3276 - val_model_3_loss: 5.3383 - val_model_4_loss: 2.3649 - val_model_accuracy: 0.4639 - val_model_1_accuracy: 0.4472 - val_model_2_accuracy: 0.3556 - val_model_3_accuracy: 0.3306 - val_model_4_accuracy: 0.3500 - val_loss1: 8.3949 - val_loss2: 9.2582\n","Epoch 53/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.2165 - model_loss: 0.2921 - model_1_loss: 0.2098 - model_2_loss: 0.2476 - model_3_loss: 0.2769 - model_4_loss: 0.1900 - model_accuracy: 0.9667 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.4698 - loss2: 8.8804 - val_loss: 16.2737 - val_model_loss: 2.5234 - val_model_1_loss: 2.7686 - val_model_2_loss: 3.9887 - val_model_3_loss: 4.7224 - val_model_4_loss: 2.2707 - val_model_accuracy: 0.4583 - val_model_1_accuracy: 0.4361 - val_model_2_accuracy: 0.2972 - val_model_3_accuracy: 0.3611 - val_model_4_accuracy: 0.4528 - val_loss1: 8.3359 - val_loss2: 9.2605\n","Epoch 54/300\n","3/3 [==============================] - 5s 3s/step - loss: 1.9449 - model_loss: 0.5003 - model_1_loss: 0.3607 - model_2_loss: 0.3705 - model_3_loss: 0.3290 - model_4_loss: 0.3844 - model_accuracy: 0.8000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.8333 - loss1: 8.5610 - loss2: 8.9357 - val_loss: 16.4762 - val_model_loss: 2.2597 - val_model_1_loss: 2.5377 - val_model_2_loss: 4.9855 - val_model_3_loss: 4.5919 - val_model_4_loss: 2.1014 - val_model_accuracy: 0.4972 - val_model_1_accuracy: 0.4556 - val_model_2_accuracy: 0.3083 - val_model_3_accuracy: 0.4000 - val_model_4_accuracy: 0.4694 - val_loss1: 8.3351 - val_loss2: 9.2415\n","Epoch 55/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.7770 - model_loss: 0.3660 - model_1_loss: 0.2954 - model_2_loss: 0.3755 - model_3_loss: 0.3867 - model_4_loss: 0.3533 - model_accuracy: 0.8667 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.8667 - loss1: 8.6292 - loss2: 8.9448 - val_loss: 17.1360 - val_model_loss: 2.2266 - val_model_1_loss: 2.5595 - val_model_2_loss: 5.2981 - val_model_3_loss: 5.0459 - val_model_4_loss: 2.0059 - val_model_accuracy: 0.5333 - val_model_1_accuracy: 0.4528 - val_model_2_accuracy: 0.3111 - val_model_3_accuracy: 0.4139 - val_model_4_accuracy: 0.4889 - val_loss1: 8.2892 - val_loss2: 9.2013\n","Epoch 56/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7689 - model_loss: 0.1598 - model_1_loss: 0.1416 - model_2_loss: 0.1530 - model_3_loss: 0.1625 - model_4_loss: 0.1520 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.4780 - loss2: 8.8787 - val_loss: 17.7963 - val_model_loss: 2.3496 - val_model_1_loss: 2.6375 - val_model_2_loss: 5.3492 - val_model_3_loss: 5.4384 - val_model_4_loss: 2.0216 - val_model_accuracy: 0.4306 - val_model_1_accuracy: 0.4333 - val_model_2_accuracy: 0.2833 - val_model_3_accuracy: 0.3639 - val_model_4_accuracy: 0.4694 - val_loss1: 8.2249 - val_loss2: 9.1622\n","Epoch 57/300\n","3/3 [==============================] - 5s 3s/step - loss: 2.3524 - model_loss: 0.4473 - model_1_loss: 0.4593 - model_2_loss: 0.5321 - model_3_loss: 0.4530 - model_4_loss: 0.4607 - model_accuracy: 0.8333 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 8.5057 - loss2: 8.8609 - val_loss: 18.0934 - val_model_loss: 2.5076 - val_model_1_loss: 2.7201 - val_model_2_loss: 5.4202 - val_model_3_loss: 5.3446 - val_model_4_loss: 2.1009 - val_model_accuracy: 0.4278 - val_model_1_accuracy: 0.4167 - val_model_2_accuracy: 0.2889 - val_model_3_accuracy: 0.3750 - val_model_4_accuracy: 0.4083 - val_loss1: 8.2604 - val_loss2: 9.1831\n","Epoch 58/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.9961 - model_loss: 0.4016 - model_1_loss: 0.3807 - model_2_loss: 0.3570 - model_3_loss: 0.3878 - model_4_loss: 0.4691 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 8.4547 - loss2: 8.8230 - val_loss: 18.9237 - val_model_loss: 2.7272 - val_model_1_loss: 2.8055 - val_model_2_loss: 5.5747 - val_model_3_loss: 5.3313 - val_model_4_loss: 2.4851 - val_model_accuracy: 0.4194 - val_model_1_accuracy: 0.3750 - val_model_2_accuracy: 0.2833 - val_model_3_accuracy: 0.3722 - val_model_4_accuracy: 0.3083 - val_loss1: 8.3680 - val_loss2: 9.2160\n","Epoch 59/300\n","3/3 [==============================] - 5s 3s/step - loss: 1.2647 - model_loss: 0.2586 - model_1_loss: 0.2455 - model_2_loss: 0.3086 - model_3_loss: 0.2337 - model_4_loss: 0.2183 - model_accuracy: 0.9000 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9000 - loss1: 8.5404 - loss2: 8.8687 - val_loss: 20.6453 - val_model_loss: 3.1017 - val_model_1_loss: 3.0162 - val_model_2_loss: 5.8181 - val_model_3_loss: 5.3987 - val_model_4_loss: 3.3106 - val_model_accuracy: 0.3972 - val_model_1_accuracy: 0.3389 - val_model_2_accuracy: 0.2944 - val_model_3_accuracy: 0.3556 - val_model_4_accuracy: 0.3167 - val_loss1: 8.4763 - val_loss2: 9.2520\n","Epoch 60/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.9004 - model_loss: 0.4287 - model_1_loss: 0.3205 - model_2_loss: 0.3593 - model_3_loss: 0.3512 - model_4_loss: 0.4408 - model_accuracy: 0.8667 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.8667 - loss1: 8.4358 - loss2: 8.8355 - val_loss: 20.5774 - val_model_loss: 3.3275 - val_model_1_loss: 2.9739 - val_model_2_loss: 5.5960 - val_model_3_loss: 5.2703 - val_model_4_loss: 3.4098 - val_model_accuracy: 0.4056 - val_model_1_accuracy: 0.4000 - val_model_2_accuracy: 0.2917 - val_model_3_accuracy: 0.3556 - val_model_4_accuracy: 0.3056 - val_loss1: 8.4597 - val_loss2: 9.2503\n","Epoch 61/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.2259 - model_loss: 0.2997 - model_1_loss: 0.2164 - model_2_loss: 0.2337 - model_3_loss: 0.1990 - model_4_loss: 0.2771 - model_accuracy: 0.8667 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9000 - loss1: 8.5242 - loss2: 8.8698 - val_loss: 18.0088 - val_model_loss: 2.7851 - val_model_1_loss: 2.6362 - val_model_2_loss: 4.8778 - val_model_3_loss: 5.2386 - val_model_4_loss: 2.4711 - val_model_accuracy: 0.4056 - val_model_1_accuracy: 0.4556 - val_model_2_accuracy: 0.3000 - val_model_3_accuracy: 0.3639 - val_model_4_accuracy: 0.3778 - val_loss1: 8.4442 - val_loss2: 9.2575\n","Epoch 62/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.8065 - model_loss: 0.1523 - model_1_loss: 0.1103 - model_2_loss: 0.2434 - model_3_loss: 0.1424 - model_4_loss: 0.1581 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.5442 - loss2: 8.8412 - val_loss: 16.5995 - val_model_loss: 2.4237 - val_model_1_loss: 2.3746 - val_model_2_loss: 4.4878 - val_model_3_loss: 5.2919 - val_model_4_loss: 2.0216 - val_model_accuracy: 0.5111 - val_model_1_accuracy: 0.4528 - val_model_2_accuracy: 0.3028 - val_model_3_accuracy: 0.3583 - val_model_4_accuracy: 0.4167 - val_loss1: 8.4260 - val_loss2: 9.2620\n","Epoch 63/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.0678 - model_loss: 0.3876 - model_1_loss: 0.4705 - model_2_loss: 0.3809 - model_3_loss: 0.3721 - model_4_loss: 0.4566 - model_accuracy: 0.9000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 8.3415 - loss2: 8.7689 - val_loss: 16.8725 - val_model_loss: 2.5716 - val_model_1_loss: 1.9850 - val_model_2_loss: 4.8992 - val_model_3_loss: 5.0341 - val_model_4_loss: 2.3825 - val_model_accuracy: 0.4917 - val_model_1_accuracy: 0.4222 - val_model_2_accuracy: 0.3028 - val_model_3_accuracy: 0.3639 - val_model_4_accuracy: 0.5056 - val_loss1: 8.2935 - val_loss2: 9.1963\n","Epoch 64/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.0404 - model_loss: 0.4539 - model_1_loss: 0.3553 - model_2_loss: 0.3003 - model_3_loss: 0.4260 - model_4_loss: 0.5049 - model_accuracy: 0.8667 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.8667 - loss1: 8.3820 - loss2: 8.8322 - val_loss: 17.7854 - val_model_loss: 2.6550 - val_model_1_loss: 1.9843 - val_model_2_loss: 5.1962 - val_model_3_loss: 5.0328 - val_model_4_loss: 2.9172 - val_model_accuracy: 0.4444 - val_model_1_accuracy: 0.3917 - val_model_2_accuracy: 0.2972 - val_model_3_accuracy: 0.3722 - val_model_4_accuracy: 0.4417 - val_loss1: 8.1927 - val_loss2: 9.1673\n","Epoch 65/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.7651 - model_loss: 0.6113 - model_1_loss: 0.5103 - model_2_loss: 0.4399 - model_3_loss: 0.5973 - model_4_loss: 0.6064 - model_accuracy: 0.7667 - model_1_accuracy: 0.8000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.8333 - loss1: 8.4015 - loss2: 8.8285 - val_loss: 17.1260 - val_model_loss: 2.2168 - val_model_1_loss: 2.0037 - val_model_2_loss: 4.9443 - val_model_3_loss: 5.2954 - val_model_4_loss: 2.6658 - val_model_accuracy: 0.4583 - val_model_1_accuracy: 0.4111 - val_model_2_accuracy: 0.2861 - val_model_3_accuracy: 0.3861 - val_model_4_accuracy: 0.4750 - val_loss1: 8.1724 - val_loss2: 9.1762\n","Epoch 66/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5303 - model_loss: 0.1127 - model_1_loss: 0.1193 - model_2_loss: 0.1081 - model_3_loss: 0.0771 - model_4_loss: 0.1132 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2339 - loss2: 8.7661 - val_loss: 16.6982 - val_model_loss: 2.3897 - val_model_1_loss: 2.0251 - val_model_2_loss: 4.2958 - val_model_3_loss: 5.4318 - val_model_4_loss: 2.5558 - val_model_accuracy: 0.4917 - val_model_1_accuracy: 0.3444 - val_model_2_accuracy: 0.2806 - val_model_3_accuracy: 0.3944 - val_model_4_accuracy: 0.4861 - val_loss1: 8.1654 - val_loss2: 9.1725\n","Epoch 67/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.9865 - model_loss: 0.4605 - model_1_loss: 0.3812 - model_2_loss: 0.3698 - model_3_loss: 0.3635 - model_4_loss: 0.4114 - model_accuracy: 0.8667 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.8667 - loss1: 8.1829 - loss2: 8.6051 - val_loss: 15.9466 - val_model_loss: 2.5671 - val_model_1_loss: 1.9273 - val_model_2_loss: 3.9778 - val_model_3_loss: 5.1345 - val_model_4_loss: 2.3399 - val_model_accuracy: 0.3972 - val_model_1_accuracy: 0.3389 - val_model_2_accuracy: 0.2806 - val_model_3_accuracy: 0.3944 - val_model_4_accuracy: 0.5222 - val_loss1: 8.2126 - val_loss2: 9.1862\n","Epoch 68/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.8842 - model_loss: 0.2160 - model_1_loss: 0.1897 - model_2_loss: 0.2085 - model_3_loss: 0.1174 - model_4_loss: 0.1526 - model_accuracy: 0.9000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9333 - loss1: 8.3434 - loss2: 8.7588 - val_loss: 16.1646 - val_model_loss: 2.5131 - val_model_1_loss: 2.1970 - val_model_2_loss: 4.4141 - val_model_3_loss: 4.8518 - val_model_4_loss: 2.1886 - val_model_accuracy: 0.4250 - val_model_1_accuracy: 0.2917 - val_model_2_accuracy: 0.2889 - val_model_3_accuracy: 0.3944 - val_model_4_accuracy: 0.5056 - val_loss1: 8.2439 - val_loss2: 9.1928\n","Epoch 69/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.1651 - model_loss: 0.2255 - model_1_loss: 0.1947 - model_2_loss: 0.2307 - model_3_loss: 0.2463 - model_4_loss: 0.2679 - model_accuracy: 0.9333 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.8667 - loss1: 8.2327 - loss2: 8.6984 - val_loss: 16.7512 - val_model_loss: 2.6052 - val_model_1_loss: 2.5697 - val_model_2_loss: 4.8680 - val_model_3_loss: 4.7028 - val_model_4_loss: 2.0054 - val_model_accuracy: 0.3528 - val_model_1_accuracy: 0.2778 - val_model_2_accuracy: 0.3083 - val_model_3_accuracy: 0.3944 - val_model_4_accuracy: 0.4972 - val_loss1: 8.2372 - val_loss2: 9.1686\n","Epoch 70/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7721 - model_loss: 0.1717 - model_1_loss: 0.1261 - model_2_loss: 0.1209 - model_3_loss: 0.2116 - model_4_loss: 0.1418 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9333 - loss1: 8.2678 - loss2: 8.6865 - val_loss: 17.7608 - val_model_loss: 3.1343 - val_model_1_loss: 2.9910 - val_model_2_loss: 5.2749 - val_model_3_loss: 4.5362 - val_model_4_loss: 1.8243 - val_model_accuracy: 0.2639 - val_model_1_accuracy: 0.2778 - val_model_2_accuracy: 0.3222 - val_model_3_accuracy: 0.3889 - val_model_4_accuracy: 0.5194 - val_loss1: 8.2020 - val_loss2: 9.1141\n","Epoch 71/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.8560 - model_loss: 0.4523 - model_1_loss: 0.3678 - model_2_loss: 0.3171 - model_3_loss: 0.3712 - model_4_loss: 0.3476 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.8667 - loss1: 8.3028 - loss2: 8.6996 - val_loss: 19.3510 - val_model_loss: 3.7213 - val_model_1_loss: 3.1010 - val_model_2_loss: 5.4598 - val_model_3_loss: 5.0701 - val_model_4_loss: 1.9988 - val_model_accuracy: 0.2806 - val_model_1_accuracy: 0.3389 - val_model_2_accuracy: 0.3111 - val_model_3_accuracy: 0.3778 - val_model_4_accuracy: 0.3944 - val_loss1: 8.2128 - val_loss2: 9.0621\n","Epoch 72/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6116 - model_loss: 0.1264 - model_1_loss: 0.1067 - model_2_loss: 0.1481 - model_3_loss: 0.1298 - model_4_loss: 0.1005 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4837 - loss2: 8.8382 - val_loss: 20.3616 - val_model_loss: 3.9810 - val_model_1_loss: 2.9504 - val_model_2_loss: 5.4445 - val_model_3_loss: 5.7541 - val_model_4_loss: 2.2317 - val_model_accuracy: 0.2944 - val_model_1_accuracy: 0.3306 - val_model_2_accuracy: 0.2944 - val_model_3_accuracy: 0.3750 - val_model_4_accuracy: 0.3556 - val_loss1: 8.1605 - val_loss2: 8.9821\n","Epoch 73/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5444 - model_loss: 0.1237 - model_1_loss: 0.0924 - model_2_loss: 0.0932 - model_3_loss: 0.1325 - model_4_loss: 0.1025 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.3112 - loss2: 8.6619 - val_loss: 20.8079 - val_model_loss: 4.1253 - val_model_1_loss: 2.7309 - val_model_2_loss: 5.5247 - val_model_3_loss: 5.9910 - val_model_4_loss: 2.4360 - val_model_accuracy: 0.3167 - val_model_1_accuracy: 0.3222 - val_model_2_accuracy: 0.2944 - val_model_3_accuracy: 0.3639 - val_model_4_accuracy: 0.3444 - val_loss1: 8.0776 - val_loss2: 8.9165\n","Epoch 74/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.6047 - model_loss: 0.7635 - model_1_loss: 0.4377 - model_2_loss: 0.4499 - model_3_loss: 0.4855 - model_4_loss: 0.4680 - model_accuracy: 0.8000 - model_1_accuracy: 0.8000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.8333 - loss1: 8.2708 - loss2: 8.7057 - val_loss: 18.8164 - val_model_loss: 3.2123 - val_model_1_loss: 2.1979 - val_model_2_loss: 4.9563 - val_model_3_loss: 6.1763 - val_model_4_loss: 2.2735 - val_model_accuracy: 0.3083 - val_model_1_accuracy: 0.3861 - val_model_2_accuracy: 0.2778 - val_model_3_accuracy: 0.3694 - val_model_4_accuracy: 0.3750 - val_loss1: 8.0297 - val_loss2: 8.8826\n","Epoch 75/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.4687 - model_loss: 0.6353 - model_1_loss: 0.4277 - model_2_loss: 0.4005 - model_3_loss: 0.4333 - model_4_loss: 0.5719 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8000 - loss1: 8.3706 - loss2: 8.7595 - val_loss: 19.6561 - val_model_loss: 3.7636 - val_model_1_loss: 3.0486 - val_model_2_loss: 3.4008 - val_model_3_loss: 6.8686 - val_model_4_loss: 2.5747 - val_model_accuracy: 0.3833 - val_model_1_accuracy: 0.3694 - val_model_2_accuracy: 0.2722 - val_model_3_accuracy: 0.3694 - val_model_4_accuracy: 0.4278 - val_loss1: 8.1268 - val_loss2: 8.8123\n","Epoch 76/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.8462 - model_loss: 0.3267 - model_1_loss: 0.3333 - model_2_loss: 0.4310 - model_3_loss: 0.4143 - model_4_loss: 0.3409 - model_accuracy: 0.9333 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9333 - loss1: 8.2535 - loss2: 8.7230 - val_loss: 21.5013 - val_model_loss: 5.2239 - val_model_1_loss: 3.6617 - val_model_2_loss: 2.7026 - val_model_3_loss: 6.9884 - val_model_4_loss: 2.9248 - val_model_accuracy: 0.3278 - val_model_1_accuracy: 0.3583 - val_model_2_accuracy: 0.2806 - val_model_3_accuracy: 0.3583 - val_model_4_accuracy: 0.4167 - val_loss1: 8.2418 - val_loss2: 8.7689\n","Epoch 77/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.6958 - model_loss: 0.5002 - model_1_loss: 0.3103 - model_2_loss: 0.2623 - model_3_loss: 0.3656 - model_4_loss: 0.2574 - model_accuracy: 0.8000 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.9000 - loss1: 8.2964 - loss2: 8.7151 - val_loss: 19.2397 - val_model_loss: 4.7509 - val_model_1_loss: 2.9047 - val_model_2_loss: 3.2664 - val_model_3_loss: 5.8709 - val_model_4_loss: 2.4470 - val_model_accuracy: 0.2833 - val_model_1_accuracy: 0.3528 - val_model_2_accuracy: 0.2722 - val_model_3_accuracy: 0.3667 - val_model_4_accuracy: 0.4389 - val_loss1: 8.2440 - val_loss2: 8.8606\n","Epoch 78/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5795 - model_loss: 0.1396 - model_1_loss: 0.0931 - model_2_loss: 0.1125 - model_3_loss: 0.1164 - model_4_loss: 0.1180 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.3492 - loss2: 8.7796 - val_loss: 18.2369 - val_model_loss: 4.5339 - val_model_1_loss: 2.6623 - val_model_2_loss: 3.7847 - val_model_3_loss: 5.1379 - val_model_4_loss: 2.1180 - val_model_accuracy: 0.2111 - val_model_1_accuracy: 0.3278 - val_model_2_accuracy: 0.2806 - val_model_3_accuracy: 0.3667 - val_model_4_accuracy: 0.4444 - val_loss1: 8.2257 - val_loss2: 8.9269\n","Epoch 79/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4944 - model_loss: 0.1885 - model_1_loss: 0.0479 - model_2_loss: 0.0681 - model_3_loss: 0.0979 - model_4_loss: 0.0919 - model_accuracy: 0.9333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.2777 - loss2: 8.6959 - val_loss: 18.1434 - val_model_loss: 4.3757 - val_model_1_loss: 2.7307 - val_model_2_loss: 4.2194 - val_model_3_loss: 4.8387 - val_model_4_loss: 1.9789 - val_model_accuracy: 0.1944 - val_model_1_accuracy: 0.2861 - val_model_2_accuracy: 0.2833 - val_model_3_accuracy: 0.3611 - val_model_4_accuracy: 0.4472 - val_loss1: 8.2203 - val_loss2: 8.9913\n","Epoch 80/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.1907 - model_loss: 0.4450 - model_1_loss: 0.3197 - model_2_loss: 0.5333 - model_3_loss: 0.4193 - model_4_loss: 0.4734 - model_accuracy: 0.8000 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8667 - loss1: 8.5148 - loss2: 8.8059 - val_loss: 17.8180 - val_model_loss: 4.1911 - val_model_1_loss: 2.7429 - val_model_2_loss: 4.3105 - val_model_3_loss: 4.5738 - val_model_4_loss: 1.9996 - val_model_accuracy: 0.2000 - val_model_1_accuracy: 0.2778 - val_model_2_accuracy: 0.2833 - val_model_3_accuracy: 0.3639 - val_model_4_accuracy: 0.4472 - val_loss1: 8.1928 - val_loss2: 9.0248\n","Epoch 81/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.1938 - model_loss: 0.3349 - model_1_loss: 0.1738 - model_2_loss: 0.2074 - model_3_loss: 0.2494 - model_4_loss: 0.2284 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9000 - loss1: 8.2199 - loss2: 8.6906 - val_loss: 17.0051 - val_model_loss: 3.8287 - val_model_1_loss: 2.6249 - val_model_2_loss: 3.9580 - val_model_3_loss: 4.6395 - val_model_4_loss: 1.9539 - val_model_accuracy: 0.2250 - val_model_1_accuracy: 0.2833 - val_model_2_accuracy: 0.2778 - val_model_3_accuracy: 0.3639 - val_model_4_accuracy: 0.4472 - val_loss1: 8.1672 - val_loss2: 9.0234\n","Epoch 82/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.9333 - model_loss: 0.2356 - model_1_loss: 0.1682 - model_2_loss: 0.2001 - model_3_loss: 0.1850 - model_4_loss: 0.1445 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.4050 - loss2: 8.7964 - val_loss: 16.4912 - val_model_loss: 3.4972 - val_model_1_loss: 2.6489 - val_model_2_loss: 3.6746 - val_model_3_loss: 4.6650 - val_model_4_loss: 2.0055 - val_model_accuracy: 0.2306 - val_model_1_accuracy: 0.2806 - val_model_2_accuracy: 0.2750 - val_model_3_accuracy: 0.3694 - val_model_4_accuracy: 0.4444 - val_loss1: 8.1593 - val_loss2: 9.0268\n","Epoch 83/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.5228 - model_loss: 0.2969 - model_1_loss: 0.2517 - model_2_loss: 0.3345 - model_3_loss: 0.3006 - model_4_loss: 0.3391 - model_accuracy: 0.8667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9000 - loss1: 8.1666 - loss2: 8.6037 - val_loss: 16.5035 - val_model_loss: 3.4226 - val_model_1_loss: 2.5848 - val_model_2_loss: 3.8566 - val_model_3_loss: 4.6618 - val_model_4_loss: 1.9777 - val_model_accuracy: 0.2333 - val_model_1_accuracy: 0.2806 - val_model_2_accuracy: 0.2889 - val_model_3_accuracy: 0.3778 - val_model_4_accuracy: 0.4583 - val_loss1: 8.2058 - val_loss2: 9.0352\n","Epoch 84/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7672 - model_loss: 0.2459 - model_1_loss: 0.1127 - model_2_loss: 0.1159 - model_3_loss: 0.1427 - model_4_loss: 0.1500 - model_accuracy: 0.9000 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.2700 - loss2: 8.7153 - val_loss: 16.6421 - val_model_loss: 3.5029 - val_model_1_loss: 2.5572 - val_model_2_loss: 3.9538 - val_model_3_loss: 4.6073 - val_model_4_loss: 2.0210 - val_model_accuracy: 0.2194 - val_model_1_accuracy: 0.2944 - val_model_2_accuracy: 0.2889 - val_model_3_accuracy: 0.3694 - val_model_4_accuracy: 0.4556 - val_loss1: 8.2502 - val_loss2: 9.0481\n","Epoch 85/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6168 - model_loss: 0.1158 - model_1_loss: 0.0863 - model_2_loss: 0.1158 - model_3_loss: 0.1367 - model_4_loss: 0.1622 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.3447 - loss2: 8.7323 - val_loss: 17.2148 - val_model_loss: 3.6457 - val_model_1_loss: 2.5874 - val_model_2_loss: 4.3355 - val_model_3_loss: 4.4764 - val_model_4_loss: 2.1698 - val_model_accuracy: 0.2278 - val_model_1_accuracy: 0.3194 - val_model_2_accuracy: 0.2944 - val_model_3_accuracy: 0.3667 - val_model_4_accuracy: 0.4750 - val_loss1: 8.2406 - val_loss2: 9.0462\n","Epoch 86/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6290 - model_loss: 0.1163 - model_1_loss: 0.0975 - model_2_loss: 0.1518 - model_3_loss: 0.1134 - model_4_loss: 0.1500 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.3422 - loss2: 8.7536 - val_loss: 17.0574 - val_model_loss: 3.7341 - val_model_1_loss: 2.6065 - val_model_2_loss: 4.1447 - val_model_3_loss: 4.3214 - val_model_4_loss: 2.2507 - val_model_accuracy: 0.2278 - val_model_1_accuracy: 0.3500 - val_model_2_accuracy: 0.2917 - val_model_3_accuracy: 0.3667 - val_model_4_accuracy: 0.4861 - val_loss1: 8.2658 - val_loss2: 9.0602\n","Epoch 87/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.9102 - model_loss: 0.1976 - model_1_loss: 0.1249 - model_2_loss: 0.1514 - model_3_loss: 0.2049 - model_4_loss: 0.2314 - model_accuracy: 0.9000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.3299 - loss2: 8.7444 - val_loss: 16.8170 - val_model_loss: 3.5785 - val_model_1_loss: 2.6987 - val_model_2_loss: 4.2347 - val_model_3_loss: 3.9844 - val_model_4_loss: 2.3207 - val_model_accuracy: 0.2444 - val_model_1_accuracy: 0.3611 - val_model_2_accuracy: 0.2833 - val_model_3_accuracy: 0.3722 - val_model_4_accuracy: 0.4722 - val_loss1: 8.2514 - val_loss2: 9.0836\n","Epoch 88/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.9408 - model_loss: 0.1982 - model_1_loss: 0.1474 - model_2_loss: 0.2166 - model_3_loss: 0.1762 - model_4_loss: 0.2025 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.4522 - loss2: 8.8262 - val_loss: 16.2586 - val_model_loss: 3.3140 - val_model_1_loss: 2.8069 - val_model_2_loss: 3.9070 - val_model_3_loss: 3.8449 - val_model_4_loss: 2.3858 - val_model_accuracy: 0.2667 - val_model_1_accuracy: 0.3722 - val_model_2_accuracy: 0.2889 - val_model_3_accuracy: 0.3722 - val_model_4_accuracy: 0.4556 - val_loss1: 8.2442 - val_loss2: 9.1027\n","Epoch 89/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4580 - model_loss: 0.1179 - model_1_loss: 0.0974 - model_2_loss: 0.0728 - model_3_loss: 0.0931 - model_4_loss: 0.0768 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.3073 - loss2: 8.7764 - val_loss: 15.0375 - val_model_loss: 2.9586 - val_model_1_loss: 2.6620 - val_model_2_loss: 3.1720 - val_model_3_loss: 3.8681 - val_model_4_loss: 2.3767 - val_model_accuracy: 0.3167 - val_model_1_accuracy: 0.3806 - val_model_2_accuracy: 0.2944 - val_model_3_accuracy: 0.3750 - val_model_4_accuracy: 0.5028 - val_loss1: 8.2675 - val_loss2: 9.1054\n","Epoch 90/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.3234 - model_loss: 0.2662 - model_1_loss: 0.2766 - model_2_loss: 0.2558 - model_3_loss: 0.2546 - model_4_loss: 0.2701 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.8667 - loss1: 8.2489 - loss2: 8.7808 - val_loss: 14.2595 - val_model_loss: 2.7728 - val_model_1_loss: 2.5066 - val_model_2_loss: 2.9342 - val_model_3_loss: 3.7620 - val_model_4_loss: 2.2840 - val_model_accuracy: 0.3389 - val_model_1_accuracy: 0.3889 - val_model_2_accuracy: 0.2861 - val_model_3_accuracy: 0.3806 - val_model_4_accuracy: 0.5472 - val_loss1: 8.2374 - val_loss2: 9.1051\n","Epoch 91/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.1751 - model_loss: 0.2703 - model_1_loss: 0.1649 - model_2_loss: 0.3338 - model_3_loss: 0.1718 - model_4_loss: 0.2343 - model_accuracy: 0.9000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.8667 - loss1: 8.2650 - loss2: 8.7439 - val_loss: 14.3536 - val_model_loss: 2.9471 - val_model_1_loss: 2.2732 - val_model_2_loss: 3.4681 - val_model_3_loss: 3.4637 - val_model_4_loss: 2.2015 - val_model_accuracy: 0.2944 - val_model_1_accuracy: 0.4000 - val_model_2_accuracy: 0.2750 - val_model_3_accuracy: 0.3944 - val_model_4_accuracy: 0.6056 - val_loss1: 8.1640 - val_loss2: 9.0923\n","Epoch 92/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5226 - model_loss: 0.1381 - model_1_loss: 0.0815 - model_2_loss: 0.0871 - model_3_loss: 0.1264 - model_4_loss: 0.0895 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1623 - loss2: 8.7030 - val_loss: 15.4071 - val_model_loss: 3.3121 - val_model_1_loss: 2.2255 - val_model_2_loss: 4.5090 - val_model_3_loss: 3.1111 - val_model_4_loss: 2.2494 - val_model_accuracy: 0.3083 - val_model_1_accuracy: 0.3944 - val_model_2_accuracy: 0.2833 - val_model_3_accuracy: 0.4083 - val_model_4_accuracy: 0.6000 - val_loss1: 8.0706 - val_loss2: 9.0630\n","Epoch 93/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.1278 - model_loss: 0.2140 - model_1_loss: 0.1321 - model_2_loss: 0.3395 - model_3_loss: 0.1874 - model_4_loss: 0.2549 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.2692 - loss2: 8.7013 - val_loss: 15.0680 - val_model_loss: 3.8805 - val_model_1_loss: 2.1627 - val_model_2_loss: 4.0703 - val_model_3_loss: 2.7734 - val_model_4_loss: 2.1812 - val_model_accuracy: 0.2806 - val_model_1_accuracy: 0.3944 - val_model_2_accuracy: 0.2778 - val_model_3_accuracy: 0.4389 - val_model_4_accuracy: 0.5806 - val_loss1: 8.0728 - val_loss2: 9.0648\n","Epoch 94/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.7573 - model_loss: 0.4946 - model_1_loss: 0.2795 - model_2_loss: 0.3673 - model_3_loss: 0.3404 - model_4_loss: 0.2756 - model_accuracy: 0.8333 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.8667 - loss1: 8.2191 - loss2: 8.6773 - val_loss: 14.4656 - val_model_loss: 3.9537 - val_model_1_loss: 2.2273 - val_model_2_loss: 3.7243 - val_model_3_loss: 2.4433 - val_model_4_loss: 2.1170 - val_model_accuracy: 0.2778 - val_model_1_accuracy: 0.3778 - val_model_2_accuracy: 0.2806 - val_model_3_accuracy: 0.4500 - val_model_4_accuracy: 0.5139 - val_loss1: 8.0876 - val_loss2: 9.0837\n","Epoch 95/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.0532 - model_loss: 0.2672 - model_1_loss: 0.2469 - model_2_loss: 0.1621 - model_3_loss: 0.1643 - model_4_loss: 0.2125 - model_accuracy: 0.9333 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.1894 - loss2: 8.6879 - val_loss: 13.3518 - val_model_loss: 3.4858 - val_model_1_loss: 2.0952 - val_model_2_loss: 3.5289 - val_model_3_loss: 2.1849 - val_model_4_loss: 2.0570 - val_model_accuracy: 0.2667 - val_model_1_accuracy: 0.3528 - val_model_2_accuracy: 0.2778 - val_model_3_accuracy: 0.4361 - val_model_4_accuracy: 0.4889 - val_loss1: 8.1100 - val_loss2: 9.1188\n","Epoch 96/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.0059 - model_loss: 0.4330 - model_1_loss: 0.3042 - model_2_loss: 0.4468 - model_3_loss: 0.3572 - model_4_loss: 0.4647 - model_accuracy: 0.8667 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.8333 - loss1: 8.2623 - loss2: 8.7870 - val_loss: 11.7174 - val_model_loss: 2.5603 - val_model_1_loss: 1.6326 - val_model_2_loss: 3.5310 - val_model_3_loss: 2.0512 - val_model_4_loss: 1.9424 - val_model_accuracy: 0.2889 - val_model_1_accuracy: 0.4389 - val_model_2_accuracy: 0.2611 - val_model_3_accuracy: 0.4611 - val_model_4_accuracy: 0.5611 - val_loss1: 8.0737 - val_loss2: 9.1185\n","Epoch 97/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7842 - model_loss: 0.1661 - model_1_loss: 0.1363 - model_2_loss: 0.1682 - model_3_loss: 0.1249 - model_4_loss: 0.1888 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.3005 - loss2: 8.7873 - val_loss: 11.2504 - val_model_loss: 2.2978 - val_model_1_loss: 1.4541 - val_model_2_loss: 3.6329 - val_model_3_loss: 2.0026 - val_model_4_loss: 1.8629 - val_model_accuracy: 0.3306 - val_model_1_accuracy: 0.4611 - val_model_2_accuracy: 0.2528 - val_model_3_accuracy: 0.4694 - val_model_4_accuracy: 0.5583 - val_loss1: 8.0213 - val_loss2: 9.0844\n","Epoch 98/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.2856 - model_loss: 0.1780 - model_1_loss: 0.1514 - model_2_loss: 0.3296 - model_3_loss: 0.2464 - model_4_loss: 0.3802 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9000 - loss1: 8.3319 - loss2: 8.8004 - val_loss: 10.5834 - val_model_loss: 2.2693 - val_model_1_loss: 1.4432 - val_model_2_loss: 2.6001 - val_model_3_loss: 2.2496 - val_model_4_loss: 2.0213 - val_model_accuracy: 0.3722 - val_model_1_accuracy: 0.5611 - val_model_2_accuracy: 0.2611 - val_model_3_accuracy: 0.4111 - val_model_4_accuracy: 0.6139 - val_loss1: 7.9332 - val_loss2: 9.0126\n","Epoch 99/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.5695 - model_loss: 0.3000 - model_1_loss: 0.2889 - model_2_loss: 0.3913 - model_3_loss: 0.2994 - model_4_loss: 0.2899 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.2411 - loss2: 8.6837 - val_loss: 11.4254 - val_model_loss: 2.5636 - val_model_1_loss: 1.5733 - val_model_2_loss: 2.6706 - val_model_3_loss: 2.3818 - val_model_4_loss: 2.2360 - val_model_accuracy: 0.3194 - val_model_1_accuracy: 0.5417 - val_model_2_accuracy: 0.2528 - val_model_3_accuracy: 0.4222 - val_model_4_accuracy: 0.5944 - val_loss1: 7.9017 - val_loss2: 8.9658\n","Epoch 100/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.8597 - model_loss: 0.1495 - model_1_loss: 0.1024 - model_2_loss: 0.1953 - model_3_loss: 0.1251 - model_4_loss: 0.2875 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.8667 - loss1: 8.2314 - loss2: 8.7612 - val_loss: 12.6574 - val_model_loss: 3.1602 - val_model_1_loss: 1.7090 - val_model_2_loss: 3.2611 - val_model_3_loss: 2.3073 - val_model_4_loss: 2.2199 - val_model_accuracy: 0.2306 - val_model_1_accuracy: 0.5028 - val_model_2_accuracy: 0.2500 - val_model_3_accuracy: 0.4917 - val_model_4_accuracy: 0.6056 - val_loss1: 7.9285 - val_loss2: 8.9483\n","Epoch 101/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.8665 - model_loss: 0.3778 - model_1_loss: 0.3302 - model_2_loss: 0.3350 - model_3_loss: 0.4476 - model_4_loss: 0.3759 - model_accuracy: 0.8667 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.8667 - loss1: 8.2070 - loss2: 8.7360 - val_loss: 14.2564 - val_model_loss: 3.9285 - val_model_1_loss: 1.8240 - val_model_2_loss: 3.9694 - val_model_3_loss: 2.3573 - val_model_4_loss: 2.1772 - val_model_accuracy: 0.2278 - val_model_1_accuracy: 0.4889 - val_model_2_accuracy: 0.2639 - val_model_3_accuracy: 0.4472 - val_model_4_accuracy: 0.5944 - val_loss1: 7.9699 - val_loss2: 8.9406\n","Epoch 102/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5572 - model_loss: 0.1169 - model_1_loss: 0.0918 - model_2_loss: 0.1252 - model_3_loss: 0.1075 - model_4_loss: 0.1158 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.2537 - loss2: 8.7788 - val_loss: 15.2514 - val_model_loss: 4.4893 - val_model_1_loss: 1.8465 - val_model_2_loss: 3.9764 - val_model_3_loss: 2.6027 - val_model_4_loss: 2.3365 - val_model_accuracy: 0.2250 - val_model_1_accuracy: 0.4889 - val_model_2_accuracy: 0.2694 - val_model_3_accuracy: 0.4222 - val_model_4_accuracy: 0.4778 - val_loss1: 8.0031 - val_loss2: 8.9346\n","Epoch 103/300\n","3/3 [==============================] - 5s 3s/step - loss: 1.1575 - model_loss: 0.3170 - model_1_loss: 0.1792 - model_2_loss: 0.2293 - model_3_loss: 0.1638 - model_4_loss: 0.2682 - model_accuracy: 0.8333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.4453 - loss2: 8.8371 - val_loss: 14.5781 - val_model_loss: 3.8339 - val_model_1_loss: 1.8749 - val_model_2_loss: 3.4160 - val_model_3_loss: 2.8950 - val_model_4_loss: 2.5583 - val_model_accuracy: 0.2056 - val_model_1_accuracy: 0.4667 - val_model_2_accuracy: 0.2889 - val_model_3_accuracy: 0.4194 - val_model_4_accuracy: 0.4250 - val_loss1: 8.0440 - val_loss2: 8.9596\n","Epoch 104/300\n","3/3 [==============================] - 5s 3s/step - loss: 1.1418 - model_loss: 0.2762 - model_1_loss: 0.2640 - model_2_loss: 0.2158 - model_3_loss: 0.1891 - model_4_loss: 0.1968 - model_accuracy: 0.9000 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.3175 - loss2: 8.7872 - val_loss: 13.9544 - val_model_loss: 3.2302 - val_model_1_loss: 1.9988 - val_model_2_loss: 2.6738 - val_model_3_loss: 3.3783 - val_model_4_loss: 2.6733 - val_model_accuracy: 0.2889 - val_model_1_accuracy: 0.4444 - val_model_2_accuracy: 0.4139 - val_model_3_accuracy: 0.4083 - val_model_4_accuracy: 0.4556 - val_loss1: 8.0954 - val_loss2: 8.9612\n","Epoch 105/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.0920 - model_loss: 0.2488 - model_1_loss: 0.1937 - model_2_loss: 0.1761 - model_3_loss: 0.2230 - model_4_loss: 0.2505 - model_accuracy: 0.9000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.5084 - loss2: 8.9010 - val_loss: 13.9549 - val_model_loss: 3.0355 - val_model_1_loss: 2.0469 - val_model_2_loss: 2.5886 - val_model_3_loss: 3.5941 - val_model_4_loss: 2.6899 - val_model_accuracy: 0.4139 - val_model_1_accuracy: 0.5028 - val_model_2_accuracy: 0.5139 - val_model_3_accuracy: 0.4083 - val_model_4_accuracy: 0.5139 - val_loss1: 8.1452 - val_loss2: 8.9630\n","Epoch 106/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.0688 - model_loss: 0.1929 - model_1_loss: 0.2486 - model_2_loss: 0.2758 - model_3_loss: 0.1450 - model_4_loss: 0.2066 - model_accuracy: 0.9333 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.3178 - loss2: 8.8354 - val_loss: 13.6202 - val_model_loss: 2.8932 - val_model_1_loss: 2.0124 - val_model_2_loss: 2.7219 - val_model_3_loss: 3.3693 - val_model_4_loss: 2.6234 - val_model_accuracy: 0.4194 - val_model_1_accuracy: 0.4944 - val_model_2_accuracy: 0.4833 - val_model_3_accuracy: 0.4194 - val_model_4_accuracy: 0.5083 - val_loss1: 8.1693 - val_loss2: 8.9954\n","Epoch 107/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.4119 - model_loss: 0.2773 - model_1_loss: 0.2781 - model_2_loss: 0.2928 - model_3_loss: 0.2784 - model_4_loss: 0.2853 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.3492 - loss2: 8.8496 - val_loss: 13.6083 - val_model_loss: 2.7721 - val_model_1_loss: 2.1939 - val_model_2_loss: 2.8182 - val_model_3_loss: 3.2743 - val_model_4_loss: 2.5499 - val_model_accuracy: 0.4250 - val_model_1_accuracy: 0.5000 - val_model_2_accuracy: 0.4444 - val_model_3_accuracy: 0.4500 - val_model_4_accuracy: 0.5028 - val_loss1: 8.1982 - val_loss2: 9.0190\n","Epoch 108/300\n","3/3 [==============================] - 6s 3s/step - loss: 0.8066 - model_loss: 0.1647 - model_1_loss: 0.1170 - model_2_loss: 0.2013 - model_3_loss: 0.1773 - model_4_loss: 0.1463 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9333 - loss1: 8.3227 - loss2: 8.7497 - val_loss: 13.1633 - val_model_loss: 2.6385 - val_model_1_loss: 2.0141 - val_model_2_loss: 2.7244 - val_model_3_loss: 3.3412 - val_model_4_loss: 2.4450 - val_model_accuracy: 0.4389 - val_model_1_accuracy: 0.5139 - val_model_2_accuracy: 0.5444 - val_model_3_accuracy: 0.4361 - val_model_4_accuracy: 0.5111 - val_loss1: 8.3154 - val_loss2: 9.0468\n","Epoch 109/300\n","3/3 [==============================] - 6s 3s/step - loss: 0.4023 - model_loss: 0.1090 - model_1_loss: 0.0823 - model_2_loss: 0.0509 - model_3_loss: 0.0671 - model_4_loss: 0.0930 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.5440 - loss2: 8.8918 - val_loss: 12.3794 - val_model_loss: 2.4831 - val_model_1_loss: 1.8241 - val_model_2_loss: 2.5570 - val_model_3_loss: 3.2886 - val_model_4_loss: 2.2265 - val_model_accuracy: 0.4917 - val_model_1_accuracy: 0.6194 - val_model_2_accuracy: 0.5639 - val_model_3_accuracy: 0.4361 - val_model_4_accuracy: 0.5472 - val_loss1: 8.4243 - val_loss2: 9.0462\n","Epoch 110/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.2231 - model_loss: 0.2432 - model_1_loss: 0.2149 - model_2_loss: 0.2450 - model_3_loss: 0.2297 - model_4_loss: 0.2902 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9000 - loss1: 8.3367 - loss2: 8.8096 - val_loss: 12.6596 - val_model_loss: 2.4866 - val_model_1_loss: 2.0480 - val_model_2_loss: 2.5217 - val_model_3_loss: 3.4648 - val_model_4_loss: 2.1385 - val_model_accuracy: 0.5361 - val_model_1_accuracy: 0.5917 - val_model_2_accuracy: 0.5472 - val_model_3_accuracy: 0.4278 - val_model_4_accuracy: 0.5528 - val_loss1: 8.4890 - val_loss2: 9.0234\n","Epoch 111/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2417 - model_loss: 0.0502 - model_1_loss: 0.0372 - model_2_loss: 0.0598 - model_3_loss: 0.0440 - model_4_loss: 0.0506 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3949 - loss2: 8.8686 - val_loss: 14.1116 - val_model_loss: 2.8063 - val_model_1_loss: 2.5145 - val_model_2_loss: 2.5918 - val_model_3_loss: 3.9808 - val_model_4_loss: 2.2182 - val_model_accuracy: 0.4750 - val_model_1_accuracy: 0.5167 - val_model_2_accuracy: 0.4944 - val_model_3_accuracy: 0.4444 - val_model_4_accuracy: 0.4917 - val_loss1: 8.4958 - val_loss2: 8.9878\n","Epoch 112/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4248 - model_loss: 0.1146 - model_1_loss: 0.0651 - model_2_loss: 0.0929 - model_3_loss: 0.0768 - model_4_loss: 0.0754 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6198 - loss2: 8.9057 - val_loss: 15.0596 - val_model_loss: 2.9127 - val_model_1_loss: 2.8412 - val_model_2_loss: 2.5853 - val_model_3_loss: 4.3744 - val_model_4_loss: 2.3461 - val_model_accuracy: 0.4611 - val_model_1_accuracy: 0.5167 - val_model_2_accuracy: 0.4944 - val_model_3_accuracy: 0.4472 - val_model_4_accuracy: 0.4833 - val_loss1: 8.4790 - val_loss2: 8.9587\n","Epoch 113/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.0156 - model_loss: 0.2344 - model_1_loss: 0.2066 - model_2_loss: 0.1643 - model_3_loss: 0.1981 - model_4_loss: 0.2123 - model_accuracy: 0.9333 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.8667 - loss1: 8.6864 - loss2: 8.9826 - val_loss: 13.8322 - val_model_loss: 2.5846 - val_model_1_loss: 2.2976 - val_model_2_loss: 2.5651 - val_model_3_loss: 4.2768 - val_model_4_loss: 2.1080 - val_model_accuracy: 0.5389 - val_model_1_accuracy: 0.5167 - val_model_2_accuracy: 0.4417 - val_model_3_accuracy: 0.4361 - val_model_4_accuracy: 0.5861 - val_loss1: 8.4193 - val_loss2: 9.0165\n","Epoch 114/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.8924 - model_loss: 0.2790 - model_1_loss: 0.1074 - model_2_loss: 0.1710 - model_3_loss: 0.1770 - model_4_loss: 0.1580 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.3140 - loss2: 8.7945 - val_loss: 13.3299 - val_model_loss: 2.4102 - val_model_1_loss: 1.8829 - val_model_2_loss: 2.7460 - val_model_3_loss: 4.1563 - val_model_4_loss: 2.1345 - val_model_accuracy: 0.5500 - val_model_1_accuracy: 0.5167 - val_model_2_accuracy: 0.3361 - val_model_3_accuracy: 0.4056 - val_model_4_accuracy: 0.5111 - val_loss1: 8.3228 - val_loss2: 9.0369\n","Epoch 115/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6861 - model_loss: 0.1700 - model_1_loss: 0.1117 - model_2_loss: 0.1362 - model_3_loss: 0.1093 - model_4_loss: 0.1590 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.4395 - loss2: 8.8906 - val_loss: 13.7984 - val_model_loss: 2.3906 - val_model_1_loss: 1.9035 - val_model_2_loss: 3.0208 - val_model_3_loss: 4.2665 - val_model_4_loss: 2.2169 - val_model_accuracy: 0.5528 - val_model_1_accuracy: 0.5000 - val_model_2_accuracy: 0.3389 - val_model_3_accuracy: 0.3750 - val_model_4_accuracy: 0.4833 - val_loss1: 8.2943 - val_loss2: 9.0639\n","Epoch 116/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.4470 - model_loss: 0.2575 - model_1_loss: 0.2733 - model_2_loss: 0.3054 - model_3_loss: 0.3149 - model_4_loss: 0.2959 - model_accuracy: 0.9000 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9000 - loss1: 8.5202 - loss2: 8.9269 - val_loss: 13.7267 - val_model_loss: 2.5493 - val_model_1_loss: 2.2168 - val_model_2_loss: 2.8041 - val_model_3_loss: 3.8122 - val_model_4_loss: 2.3443 - val_model_accuracy: 0.5056 - val_model_1_accuracy: 0.4611 - val_model_2_accuracy: 0.3583 - val_model_3_accuracy: 0.3361 - val_model_4_accuracy: 0.5028 - val_loss1: 8.2401 - val_loss2: 9.0744\n","Epoch 117/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7627 - model_loss: 0.1678 - model_1_loss: 0.1588 - model_2_loss: 0.1630 - model_3_loss: 0.1268 - model_4_loss: 0.1463 - model_accuracy: 0.9000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.5695 - loss2: 8.9170 - val_loss: 13.6430 - val_model_loss: 2.8194 - val_model_1_loss: 2.2453 - val_model_2_loss: 2.5713 - val_model_3_loss: 3.6547 - val_model_4_loss: 2.3522 - val_model_accuracy: 0.3639 - val_model_1_accuracy: 0.4972 - val_model_2_accuracy: 0.4722 - val_model_3_accuracy: 0.3250 - val_model_4_accuracy: 0.5222 - val_loss1: 8.1067 - val_loss2: 9.0453\n","Epoch 118/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4472 - model_loss: 0.1267 - model_1_loss: 0.0953 - model_2_loss: 0.0830 - model_3_loss: 0.0688 - model_4_loss: 0.0734 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4041 - loss2: 8.8197 - val_loss: 13.5587 - val_model_loss: 2.9575 - val_model_1_loss: 1.9503 - val_model_2_loss: 2.7225 - val_model_3_loss: 3.5283 - val_model_4_loss: 2.4000 - val_model_accuracy: 0.3028 - val_model_1_accuracy: 0.5694 - val_model_2_accuracy: 0.4056 - val_model_3_accuracy: 0.3222 - val_model_4_accuracy: 0.5389 - val_loss1: 8.0398 - val_loss2: 9.0382\n","Epoch 119/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.3537 - model_loss: 0.2820 - model_1_loss: 0.2144 - model_2_loss: 0.2557 - model_3_loss: 0.2857 - model_4_loss: 0.3159 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.3466 - loss2: 8.7631 - val_loss: 14.1046 - val_model_loss: 2.9941 - val_model_1_loss: 1.8587 - val_model_2_loss: 2.9870 - val_model_3_loss: 3.7773 - val_model_4_loss: 2.4875 - val_model_accuracy: 0.2806 - val_model_1_accuracy: 0.5861 - val_model_2_accuracy: 0.3500 - val_model_3_accuracy: 0.3167 - val_model_4_accuracy: 0.5389 - val_loss1: 8.0005 - val_loss2: 8.9998\n","Epoch 120/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.8986 - model_loss: 0.2161 - model_1_loss: 0.2082 - model_2_loss: 0.1618 - model_3_loss: 0.1486 - model_4_loss: 0.1638 - model_accuracy: 0.9000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.3538 - loss2: 8.8252 - val_loss: 13.8308 - val_model_loss: 2.9448 - val_model_1_loss: 1.8325 - val_model_2_loss: 3.3923 - val_model_3_loss: 3.1921 - val_model_4_loss: 2.4691 - val_model_accuracy: 0.2861 - val_model_1_accuracy: 0.6083 - val_model_2_accuracy: 0.3167 - val_model_3_accuracy: 0.3361 - val_model_4_accuracy: 0.5500 - val_loss1: 8.0233 - val_loss2: 9.0073\n","Epoch 121/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.7022 - model_loss: 0.1846 - model_1_loss: 0.0793 - model_2_loss: 0.1281 - model_3_loss: 0.1461 - model_4_loss: 0.1641 - model_accuracy: 0.9333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.3400 - loss2: 8.7602 - val_loss: 13.4130 - val_model_loss: 2.5999 - val_model_1_loss: 1.8769 - val_model_2_loss: 2.9068 - val_model_3_loss: 3.6423 - val_model_4_loss: 2.3871 - val_model_accuracy: 0.4000 - val_model_1_accuracy: 0.6167 - val_model_2_accuracy: 0.3611 - val_model_3_accuracy: 0.3167 - val_model_4_accuracy: 0.6000 - val_loss1: 8.0971 - val_loss2: 8.9900\n","Epoch 122/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2518 - model_loss: 0.0516 - model_1_loss: 0.0476 - model_2_loss: 0.0544 - model_3_loss: 0.0495 - model_4_loss: 0.0488 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3223 - loss2: 8.7700 - val_loss: 13.5247 - val_model_loss: 2.7881 - val_model_1_loss: 1.9404 - val_model_2_loss: 2.5208 - val_model_3_loss: 3.9157 - val_model_4_loss: 2.3596 - val_model_accuracy: 0.4222 - val_model_1_accuracy: 0.6333 - val_model_2_accuracy: 0.5361 - val_model_3_accuracy: 0.3111 - val_model_4_accuracy: 0.6111 - val_loss1: 8.1974 - val_loss2: 8.9876\n","Epoch 123/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6402 - model_loss: 0.1547 - model_1_loss: 0.1017 - model_2_loss: 0.1479 - model_3_loss: 0.1136 - model_4_loss: 0.1224 - model_accuracy: 0.9000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9333 - loss1: 8.2928 - loss2: 8.8248 - val_loss: 13.6695 - val_model_loss: 2.9281 - val_model_1_loss: 1.9906 - val_model_2_loss: 2.7408 - val_model_3_loss: 3.6477 - val_model_4_loss: 2.3622 - val_model_accuracy: 0.4278 - val_model_1_accuracy: 0.6278 - val_model_2_accuracy: 0.4889 - val_model_3_accuracy: 0.3111 - val_model_4_accuracy: 0.6111 - val_loss1: 8.2716 - val_loss2: 8.9989\n","Epoch 124/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7271 - model_loss: 0.1444 - model_1_loss: 0.1364 - model_2_loss: 0.1538 - model_3_loss: 0.1556 - model_4_loss: 0.1369 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.3449 - loss2: 8.7718 - val_loss: 13.5392 - val_model_loss: 2.9054 - val_model_1_loss: 2.0259 - val_model_2_loss: 2.9307 - val_model_3_loss: 3.3007 - val_model_4_loss: 2.3765 - val_model_accuracy: 0.4444 - val_model_1_accuracy: 0.6278 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.3556 - val_model_4_accuracy: 0.6056 - val_loss1: 8.3079 - val_loss2: 9.0067\n","Epoch 125/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5862 - model_loss: 0.1357 - model_1_loss: 0.0915 - model_2_loss: 0.1321 - model_3_loss: 0.1185 - model_4_loss: 0.1085 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.2550 - loss2: 8.7455 - val_loss: 12.8616 - val_model_loss: 2.7868 - val_model_1_loss: 1.9987 - val_model_2_loss: 2.8517 - val_model_3_loss: 2.9103 - val_model_4_loss: 2.3142 - val_model_accuracy: 0.4944 - val_model_1_accuracy: 0.6417 - val_model_2_accuracy: 0.4472 - val_model_3_accuracy: 0.3806 - val_model_4_accuracy: 0.6000 - val_loss1: 8.2973 - val_loss2: 9.0171\n","Epoch 126/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7164 - model_loss: 0.1328 - model_1_loss: 0.1465 - model_2_loss: 0.1189 - model_3_loss: 0.1520 - model_4_loss: 0.1662 - model_accuracy: 0.9667 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.4171 - loss2: 8.8111 - val_loss: 11.8437 - val_model_loss: 2.6749 - val_model_1_loss: 1.9349 - val_model_2_loss: 2.5227 - val_model_3_loss: 2.5318 - val_model_4_loss: 2.1794 - val_model_accuracy: 0.5139 - val_model_1_accuracy: 0.6583 - val_model_2_accuracy: 0.4556 - val_model_3_accuracy: 0.4278 - val_model_4_accuracy: 0.6306 - val_loss1: 8.2388 - val_loss2: 8.9968\n","Epoch 127/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1153 - model_loss: 0.0226 - model_1_loss: 0.0187 - model_2_loss: 0.0258 - model_3_loss: 0.0199 - model_4_loss: 0.0284 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2450 - loss2: 8.7575 - val_loss: 11.1093 - val_model_loss: 2.5780 - val_model_1_loss: 1.8636 - val_model_2_loss: 2.2255 - val_model_3_loss: 2.3826 - val_model_4_loss: 2.0597 - val_model_accuracy: 0.5417 - val_model_1_accuracy: 0.6528 - val_model_2_accuracy: 0.4667 - val_model_3_accuracy: 0.4583 - val_model_4_accuracy: 0.6472 - val_loss1: 8.1223 - val_loss2: 8.9502\n","Epoch 128/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.9102 - model_loss: 0.1755 - model_1_loss: 0.1427 - model_2_loss: 0.2335 - model_3_loss: 0.2131 - model_4_loss: 0.1453 - model_accuracy: 0.9333 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.1926 - loss2: 8.6971 - val_loss: 11.3845 - val_model_loss: 2.5837 - val_model_1_loss: 1.8401 - val_model_2_loss: 2.5288 - val_model_3_loss: 2.3866 - val_model_4_loss: 2.0453 - val_model_accuracy: 0.5667 - val_model_1_accuracy: 0.6167 - val_model_2_accuracy: 0.4167 - val_model_3_accuracy: 0.4611 - val_model_4_accuracy: 0.6472 - val_loss1: 8.0776 - val_loss2: 8.9384\n","Epoch 129/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.1403 - model_loss: 0.2343 - model_1_loss: 0.2057 - model_2_loss: 0.2427 - model_3_loss: 0.2264 - model_4_loss: 0.2313 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.8667 - loss1: 8.2537 - loss2: 8.7639 - val_loss: 11.3454 - val_model_loss: 2.5876 - val_model_1_loss: 1.8112 - val_model_2_loss: 2.5995 - val_model_3_loss: 2.3956 - val_model_4_loss: 1.9515 - val_model_accuracy: 0.5611 - val_model_1_accuracy: 0.6167 - val_model_2_accuracy: 0.4194 - val_model_3_accuracy: 0.4750 - val_model_4_accuracy: 0.6528 - val_loss1: 8.0819 - val_loss2: 8.9533\n","Epoch 130/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2208 - model_loss: 0.0493 - model_1_loss: 0.0235 - model_2_loss: 0.0516 - model_3_loss: 0.0525 - model_4_loss: 0.0439 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3345 - loss2: 8.8644 - val_loss: 11.6011 - val_model_loss: 2.7341 - val_model_1_loss: 1.9483 - val_model_2_loss: 2.6276 - val_model_3_loss: 2.3186 - val_model_4_loss: 1.9726 - val_model_accuracy: 0.5250 - val_model_1_accuracy: 0.5528 - val_model_2_accuracy: 0.4472 - val_model_3_accuracy: 0.5111 - val_model_4_accuracy: 0.6444 - val_loss1: 8.1206 - val_loss2: 8.9569\n","Epoch 131/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.6231 - model_loss: 0.3205 - model_1_loss: 0.3027 - model_2_loss: 0.2865 - model_3_loss: 0.3619 - model_4_loss: 0.3516 - model_accuracy: 0.8667 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.8667 - loss1: 8.2200 - loss2: 8.7409 - val_loss: 11.3244 - val_model_loss: 3.0472 - val_model_1_loss: 1.8475 - val_model_2_loss: 2.4696 - val_model_3_loss: 1.8947 - val_model_4_loss: 2.0653 - val_model_accuracy: 0.5278 - val_model_1_accuracy: 0.6250 - val_model_2_accuracy: 0.4611 - val_model_3_accuracy: 0.5972 - val_model_4_accuracy: 0.6139 - val_loss1: 8.3119 - val_loss2: 8.9756\n","Epoch 132/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6741 - model_loss: 0.1095 - model_1_loss: 0.1303 - model_2_loss: 0.1399 - model_3_loss: 0.1597 - model_4_loss: 0.1347 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.4405 - loss2: 8.8843 - val_loss: 12.9312 - val_model_loss: 3.5135 - val_model_1_loss: 2.1472 - val_model_2_loss: 2.5005 - val_model_3_loss: 2.2828 - val_model_4_loss: 2.4872 - val_model_accuracy: 0.4639 - val_model_1_accuracy: 0.5806 - val_model_2_accuracy: 0.5139 - val_model_3_accuracy: 0.5306 - val_model_4_accuracy: 0.5500 - val_loss1: 8.3846 - val_loss2: 8.9025\n","Epoch 133/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.8689 - model_loss: 0.1772 - model_1_loss: 0.1448 - model_2_loss: 0.2112 - model_3_loss: 0.2004 - model_4_loss: 0.1353 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.2214 - loss2: 8.6977 - val_loss: 14.3494 - val_model_loss: 3.6674 - val_model_1_loss: 2.4469 - val_model_2_loss: 2.5133 - val_model_3_loss: 2.7830 - val_model_4_loss: 2.9388 - val_model_accuracy: 0.3944 - val_model_1_accuracy: 0.5333 - val_model_2_accuracy: 0.5000 - val_model_3_accuracy: 0.4194 - val_model_4_accuracy: 0.4806 - val_loss1: 8.4075 - val_loss2: 8.8375\n","Epoch 134/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6558 - model_loss: 0.0932 - model_1_loss: 0.1426 - model_2_loss: 0.1269 - model_3_loss: 0.1451 - model_4_loss: 0.1480 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.4883 - loss2: 8.8860 - val_loss: 14.3372 - val_model_loss: 3.3846 - val_model_1_loss: 2.4932 - val_model_2_loss: 2.3868 - val_model_3_loss: 3.0207 - val_model_4_loss: 3.0519 - val_model_accuracy: 0.3972 - val_model_1_accuracy: 0.5083 - val_model_2_accuracy: 0.4750 - val_model_3_accuracy: 0.3583 - val_model_4_accuracy: 0.4250 - val_loss1: 8.3662 - val_loss2: 8.7833\n","Epoch 135/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1862 - model_loss: 0.0401 - model_1_loss: 0.0347 - model_2_loss: 0.0360 - model_3_loss: 0.0433 - model_4_loss: 0.0321 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5108 - loss2: 8.8647 - val_loss: 13.6683 - val_model_loss: 3.0897 - val_model_1_loss: 2.3440 - val_model_2_loss: 2.3047 - val_model_3_loss: 2.9546 - val_model_4_loss: 2.9754 - val_model_accuracy: 0.4278 - val_model_1_accuracy: 0.5139 - val_model_2_accuracy: 0.4556 - val_model_3_accuracy: 0.3361 - val_model_4_accuracy: 0.4111 - val_loss1: 8.3355 - val_loss2: 8.7665\n","Epoch 136/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6183 - model_loss: 0.0921 - model_1_loss: 0.1637 - model_2_loss: 0.1027 - model_3_loss: 0.1405 - model_4_loss: 0.1193 - model_accuracy: 1.0000 - model_1_accuracy: 0.9333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.5576 - loss2: 8.9046 - val_loss: 12.2158 - val_model_loss: 2.7015 - val_model_1_loss: 2.0800 - val_model_2_loss: 2.0918 - val_model_3_loss: 2.5864 - val_model_4_loss: 2.7561 - val_model_accuracy: 0.5083 - val_model_1_accuracy: 0.5389 - val_model_2_accuracy: 0.4639 - val_model_3_accuracy: 0.4472 - val_model_4_accuracy: 0.3750 - val_loss1: 8.2985 - val_loss2: 8.8011\n","Epoch 137/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.2544 - model_loss: 0.2168 - model_1_loss: 0.3234 - model_2_loss: 0.1464 - model_3_loss: 0.2516 - model_4_loss: 0.3163 - model_accuracy: 0.9333 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.8667 - loss1: 8.5032 - loss2: 8.8793 - val_loss: 11.3671 - val_model_loss: 2.3149 - val_model_1_loss: 1.8312 - val_model_2_loss: 1.8930 - val_model_3_loss: 2.4716 - val_model_4_loss: 2.8565 - val_model_accuracy: 0.4889 - val_model_1_accuracy: 0.5528 - val_model_2_accuracy: 0.4944 - val_model_3_accuracy: 0.4778 - val_model_4_accuracy: 0.3500 - val_loss1: 8.2448 - val_loss2: 8.8258\n","Epoch 138/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6018 - model_loss: 0.1433 - model_1_loss: 0.1044 - model_2_loss: 0.1253 - model_3_loss: 0.1043 - model_4_loss: 0.1245 - model_accuracy: 0.9000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.4049 - loss2: 8.8205 - val_loss: 10.9297 - val_model_loss: 2.1778 - val_model_1_loss: 1.9575 - val_model_2_loss: 1.8031 - val_model_3_loss: 2.2311 - val_model_4_loss: 2.7602 - val_model_accuracy: 0.4861 - val_model_1_accuracy: 0.5056 - val_model_2_accuracy: 0.5167 - val_model_3_accuracy: 0.5000 - val_model_4_accuracy: 0.4139 - val_loss1: 8.2340 - val_loss2: 8.8379\n","Epoch 139/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2863 - model_loss: 0.0674 - model_1_loss: 0.0638 - model_2_loss: 0.0479 - model_3_loss: 0.0536 - model_4_loss: 0.0537 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.4877 - loss2: 8.9035 - val_loss: 10.6142 - val_model_loss: 2.1594 - val_model_1_loss: 1.9618 - val_model_2_loss: 1.7967 - val_model_3_loss: 2.0222 - val_model_4_loss: 2.6740 - val_model_accuracy: 0.5306 - val_model_1_accuracy: 0.5167 - val_model_2_accuracy: 0.5500 - val_model_3_accuracy: 0.5278 - val_model_4_accuracy: 0.4917 - val_loss1: 8.2305 - val_loss2: 8.8417\n","Epoch 140/300\n","3/3 [==============================] - 6s 3s/step - loss: 0.3317 - model_loss: 0.0767 - model_1_loss: 0.0526 - model_2_loss: 0.0488 - model_3_loss: 0.0680 - model_4_loss: 0.0855 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.3125 - loss2: 8.7875 - val_loss: 10.1098 - val_model_loss: 2.1719 - val_model_1_loss: 1.7261 - val_model_2_loss: 1.8182 - val_model_3_loss: 1.8464 - val_model_4_loss: 2.5471 - val_model_accuracy: 0.6250 - val_model_1_accuracy: 0.6000 - val_model_2_accuracy: 0.5500 - val_model_3_accuracy: 0.5750 - val_model_4_accuracy: 0.5917 - val_loss1: 8.2175 - val_loss2: 8.8557\n","Epoch 141/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.2156 - model_loss: 0.2260 - model_1_loss: 0.2031 - model_2_loss: 0.2990 - model_3_loss: 0.2849 - model_4_loss: 0.2026 - model_accuracy: 0.8667 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.9333 - loss1: 8.2588 - loss2: 8.7293 - val_loss: 10.4053 - val_model_loss: 2.3186 - val_model_1_loss: 1.6306 - val_model_2_loss: 1.9809 - val_model_3_loss: 1.8807 - val_model_4_loss: 2.5945 - val_model_accuracy: 0.6139 - val_model_1_accuracy: 0.6556 - val_model_2_accuracy: 0.5361 - val_model_3_accuracy: 0.6083 - val_model_4_accuracy: 0.6556 - val_loss1: 8.2375 - val_loss2: 8.8630\n","Epoch 142/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7685 - model_loss: 0.1704 - model_1_loss: 0.1560 - model_2_loss: 0.1196 - model_3_loss: 0.1605 - model_4_loss: 0.1621 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.3660 - loss2: 8.8113 - val_loss: 10.8713 - val_model_loss: 2.3394 - val_model_1_loss: 1.5759 - val_model_2_loss: 2.5505 - val_model_3_loss: 1.6957 - val_model_4_loss: 2.7098 - val_model_accuracy: 0.5917 - val_model_1_accuracy: 0.6917 - val_model_2_accuracy: 0.4167 - val_model_3_accuracy: 0.6389 - val_model_4_accuracy: 0.6639 - val_loss1: 8.2240 - val_loss2: 8.8588\n","Epoch 143/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.8892 - model_loss: 0.1204 - model_1_loss: 0.1704 - model_2_loss: 0.1495 - model_3_loss: 0.1760 - model_4_loss: 0.2729 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.8667 - loss1: 8.3274 - loss2: 8.7842 - val_loss: 11.5227 - val_model_loss: 2.3682 - val_model_1_loss: 1.6865 - val_model_2_loss: 2.9099 - val_model_3_loss: 1.6778 - val_model_4_loss: 2.8803 - val_model_accuracy: 0.5722 - val_model_1_accuracy: 0.6333 - val_model_2_accuracy: 0.4111 - val_model_3_accuracy: 0.6389 - val_model_4_accuracy: 0.6250 - val_loss1: 8.1932 - val_loss2: 8.8613\n","Epoch 144/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7132 - model_loss: 0.1178 - model_1_loss: 0.0842 - model_2_loss: 0.2530 - model_3_loss: 0.1723 - model_4_loss: 0.0860 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 1.0000 - loss1: 8.4509 - loss2: 8.8660 - val_loss: 10.9870 - val_model_loss: 2.4195 - val_model_1_loss: 1.7544 - val_model_2_loss: 2.0672 - val_model_3_loss: 1.8826 - val_model_4_loss: 2.8632 - val_model_accuracy: 0.5750 - val_model_1_accuracy: 0.6250 - val_model_2_accuracy: 0.5222 - val_model_3_accuracy: 0.6583 - val_model_4_accuracy: 0.6472 - val_loss1: 8.2607 - val_loss2: 8.8928\n","Epoch 145/300\n","3/3 [==============================] - 6s 3s/step - loss: 0.2954 - model_loss: 0.0656 - model_1_loss: 0.0590 - model_2_loss: 0.0662 - model_3_loss: 0.0494 - model_4_loss: 0.0553 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3356 - loss2: 8.7872 - val_loss: 11.0287 - val_model_loss: 2.4063 - val_model_1_loss: 1.8192 - val_model_2_loss: 1.8287 - val_model_3_loss: 2.1300 - val_model_4_loss: 2.8445 - val_model_accuracy: 0.6056 - val_model_1_accuracy: 0.6278 - val_model_2_accuracy: 0.6361 - val_model_3_accuracy: 0.6667 - val_model_4_accuracy: 0.6500 - val_loss1: 8.3091 - val_loss2: 8.9038\n","Epoch 146/300\n","3/3 [==============================] - 6s 3s/step - loss: 0.9067 - model_loss: 0.1554 - model_1_loss: 0.1245 - model_2_loss: 0.1979 - model_3_loss: 0.2581 - model_4_loss: 0.1708 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.9333 - loss1: 8.4652 - loss2: 8.9008 - val_loss: 11.0232 - val_model_loss: 2.2644 - val_model_1_loss: 1.8676 - val_model_2_loss: 1.9108 - val_model_3_loss: 2.2494 - val_model_4_loss: 2.7311 - val_model_accuracy: 0.6194 - val_model_1_accuracy: 0.6500 - val_model_2_accuracy: 0.6583 - val_model_3_accuracy: 0.6639 - val_model_4_accuracy: 0.6556 - val_loss1: 8.3161 - val_loss2: 8.9200\n","Epoch 147/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.0528 - model_loss: 0.1830 - model_1_loss: 0.2015 - model_2_loss: 0.1784 - model_3_loss: 0.3102 - model_4_loss: 0.1796 - model_accuracy: 0.9000 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.9000 - loss1: 8.3765 - loss2: 8.7924 - val_loss: 10.3701 - val_model_loss: 2.0384 - val_model_1_loss: 1.7562 - val_model_2_loss: 1.8834 - val_model_3_loss: 2.1259 - val_model_4_loss: 2.5662 - val_model_accuracy: 0.6528 - val_model_1_accuracy: 0.6528 - val_model_2_accuracy: 0.6778 - val_model_3_accuracy: 0.6750 - val_model_4_accuracy: 0.6639 - val_loss1: 8.2917 - val_loss2: 8.9404\n","Epoch 148/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1104 - model_loss: 0.0183 - model_1_loss: 0.0205 - model_2_loss: 0.0367 - model_3_loss: 0.0186 - model_4_loss: 0.0163 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4283 - loss2: 8.8874 - val_loss: 9.6741 - val_model_loss: 1.8270 - val_model_1_loss: 1.6245 - val_model_2_loss: 1.8189 - val_model_3_loss: 2.0575 - val_model_4_loss: 2.3462 - val_model_accuracy: 0.6500 - val_model_1_accuracy: 0.6306 - val_model_2_accuracy: 0.7000 - val_model_3_accuracy: 0.6750 - val_model_4_accuracy: 0.6833 - val_loss1: 8.2527 - val_loss2: 8.9495\n","Epoch 149/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3767 - model_loss: 0.0655 - model_1_loss: 0.0441 - model_2_loss: 0.0893 - model_3_loss: 0.1000 - model_4_loss: 0.0777 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4118 - loss2: 8.8420 - val_loss: 9.2663 - val_model_loss: 1.7054 - val_model_1_loss: 1.7443 - val_model_2_loss: 1.6889 - val_model_3_loss: 1.9985 - val_model_4_loss: 2.1292 - val_model_accuracy: 0.6472 - val_model_1_accuracy: 0.5583 - val_model_2_accuracy: 0.7167 - val_model_3_accuracy: 0.6417 - val_model_4_accuracy: 0.6861 - val_loss1: 8.2129 - val_loss2: 8.9757\n","Epoch 150/300\n","3/3 [==============================] - 6s 3s/step - loss: 1.2088 - model_loss: 0.2217 - model_1_loss: 0.3268 - model_2_loss: 0.1294 - model_3_loss: 0.2578 - model_4_loss: 0.2731 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.4303 - loss2: 8.8345 - val_loss: 9.2411 - val_model_loss: 1.7567 - val_model_1_loss: 1.4510 - val_model_2_loss: 1.7255 - val_model_3_loss: 2.2415 - val_model_4_loss: 2.0664 - val_model_accuracy: 0.6972 - val_model_1_accuracy: 0.7111 - val_model_2_accuracy: 0.7083 - val_model_3_accuracy: 0.6000 - val_model_4_accuracy: 0.6972 - val_loss1: 8.2057 - val_loss2: 8.9144\n","Epoch 151/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5212 - model_loss: 0.0864 - model_1_loss: 0.0886 - model_2_loss: 0.1500 - model_3_loss: 0.1270 - model_4_loss: 0.0691 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9667 - loss1: 8.5287 - loss2: 8.9120 - val_loss: 10.5863 - val_model_loss: 2.2754 - val_model_1_loss: 1.7079 - val_model_2_loss: 1.8237 - val_model_3_loss: 2.7312 - val_model_4_loss: 2.0481 - val_model_accuracy: 0.6167 - val_model_1_accuracy: 0.6694 - val_model_2_accuracy: 0.6583 - val_model_3_accuracy: 0.4972 - val_model_4_accuracy: 0.7056 - val_loss1: 8.2462 - val_loss2: 8.8358\n","Epoch 152/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7739 - model_loss: 0.1402 - model_1_loss: 0.1500 - model_2_loss: 0.1451 - model_3_loss: 0.1727 - model_4_loss: 0.1659 - model_accuracy: 0.9667 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.4721 - loss2: 8.8904 - val_loss: 12.5037 - val_model_loss: 3.0535 - val_model_1_loss: 2.2281 - val_model_2_loss: 1.9268 - val_model_3_loss: 3.2001 - val_model_4_loss: 2.0951 - val_model_accuracy: 0.5333 - val_model_1_accuracy: 0.5917 - val_model_2_accuracy: 0.6083 - val_model_3_accuracy: 0.4611 - val_model_4_accuracy: 0.6778 - val_loss1: 8.2521 - val_loss2: 8.7419\n","Epoch 153/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.2704 - model_loss: 0.2627 - model_1_loss: 0.2614 - model_2_loss: 0.3137 - model_3_loss: 0.2047 - model_4_loss: 0.2279 - model_accuracy: 0.9333 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9000 - loss1: 8.4811 - loss2: 8.8880 - val_loss: 14.0984 - val_model_loss: 3.6940 - val_model_1_loss: 2.6465 - val_model_2_loss: 1.9062 - val_model_3_loss: 3.5690 - val_model_4_loss: 2.2827 - val_model_accuracy: 0.5028 - val_model_1_accuracy: 0.5806 - val_model_2_accuracy: 0.5944 - val_model_3_accuracy: 0.4250 - val_model_4_accuracy: 0.5972 - val_loss1: 8.2568 - val_loss2: 8.6894\n","Epoch 154/300\n","3/3 [==============================] - 5s 2s/step - loss: 2.3882 - model_loss: 0.6153 - model_1_loss: 0.4115 - model_2_loss: 0.5239 - model_3_loss: 0.4570 - model_4_loss: 0.3805 - model_accuracy: 0.8000 - model_1_accuracy: 0.8000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.7667 - model_4_accuracy: 0.7667 - loss1: 8.3450 - loss2: 8.8302 - val_loss: 12.9487 - val_model_loss: 3.1338 - val_model_1_loss: 2.5403 - val_model_2_loss: 1.6383 - val_model_3_loss: 3.3656 - val_model_4_loss: 2.2706 - val_model_accuracy: 0.5417 - val_model_1_accuracy: 0.5694 - val_model_2_accuracy: 0.6028 - val_model_3_accuracy: 0.4750 - val_model_4_accuracy: 0.5944 - val_loss1: 8.2034 - val_loss2: 8.6900\n","Epoch 155/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4544 - model_loss: 0.0825 - model_1_loss: 0.0848 - model_2_loss: 0.0875 - model_3_loss: 0.1226 - model_4_loss: 0.0770 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.4394 - loss2: 8.8512 - val_loss: 12.1291 - val_model_loss: 2.6212 - val_model_1_loss: 2.4656 - val_model_2_loss: 1.5941 - val_model_3_loss: 3.0516 - val_model_4_loss: 2.3966 - val_model_accuracy: 0.6361 - val_model_1_accuracy: 0.5583 - val_model_2_accuracy: 0.5583 - val_model_3_accuracy: 0.5222 - val_model_4_accuracy: 0.6444 - val_loss1: 8.1248 - val_loss2: 8.6952\n","Epoch 156/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6168 - model_loss: 0.1122 - model_1_loss: 0.1322 - model_2_loss: 0.0524 - model_3_loss: 0.2123 - model_4_loss: 0.1076 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.5188 - loss2: 8.9141 - val_loss: 11.6278 - val_model_loss: 2.5411 - val_model_1_loss: 2.2456 - val_model_2_loss: 1.6854 - val_model_3_loss: 2.5903 - val_model_4_loss: 2.5654 - val_model_accuracy: 0.6722 - val_model_1_accuracy: 0.5806 - val_model_2_accuracy: 0.5278 - val_model_3_accuracy: 0.5500 - val_model_4_accuracy: 0.6750 - val_loss1: 8.0346 - val_loss2: 8.6858\n","Epoch 157/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.2199 - model_loss: 0.2573 - model_1_loss: 0.2073 - model_2_loss: 0.3148 - model_3_loss: 0.2143 - model_4_loss: 0.2262 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.4769 - loss2: 8.8389 - val_loss: 11.8239 - val_model_loss: 2.6838 - val_model_1_loss: 2.2419 - val_model_2_loss: 1.6438 - val_model_3_loss: 2.4080 - val_model_4_loss: 2.8464 - val_model_accuracy: 0.6528 - val_model_1_accuracy: 0.6361 - val_model_2_accuracy: 0.6417 - val_model_3_accuracy: 0.5833 - val_model_4_accuracy: 0.6722 - val_loss1: 8.0399 - val_loss2: 8.6967\n","Epoch 158/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.0364 - model_loss: 0.4057 - model_1_loss: 0.0964 - model_2_loss: 0.1287 - model_3_loss: 0.1892 - model_4_loss: 0.2163 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.3609 - loss2: 8.7667 - val_loss: 12.6568 - val_model_loss: 2.8582 - val_model_1_loss: 2.5091 - val_model_2_loss: 2.0078 - val_model_3_loss: 2.3785 - val_model_4_loss: 2.9031 - val_model_accuracy: 0.6472 - val_model_1_accuracy: 0.6500 - val_model_2_accuracy: 0.6250 - val_model_3_accuracy: 0.5917 - val_model_4_accuracy: 0.6694 - val_loss1: 8.0610 - val_loss2: 8.6339\n","Epoch 159/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.9407 - model_loss: 0.2134 - model_1_loss: 0.1735 - model_2_loss: 0.2065 - model_3_loss: 0.1776 - model_4_loss: 0.1697 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9333 - loss1: 8.3553 - loss2: 8.8015 - val_loss: 12.8654 - val_model_loss: 2.8193 - val_model_1_loss: 2.5769 - val_model_2_loss: 2.2183 - val_model_3_loss: 2.3839 - val_model_4_loss: 2.8671 - val_model_accuracy: 0.6722 - val_model_1_accuracy: 0.6444 - val_model_2_accuracy: 0.6333 - val_model_3_accuracy: 0.6167 - val_model_4_accuracy: 0.6583 - val_loss1: 8.0696 - val_loss2: 8.5332\n","Epoch 160/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4247 - model_loss: 0.0797 - model_1_loss: 0.0553 - model_2_loss: 0.0781 - model_3_loss: 0.0739 - model_4_loss: 0.1377 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.3281 - loss2: 8.7998 - val_loss: 13.2086 - val_model_loss: 2.8095 - val_model_1_loss: 2.5902 - val_model_2_loss: 2.3844 - val_model_3_loss: 2.4962 - val_model_4_loss: 2.9283 - val_model_accuracy: 0.6583 - val_model_1_accuracy: 0.6333 - val_model_2_accuracy: 0.6194 - val_model_3_accuracy: 0.6306 - val_model_4_accuracy: 0.6472 - val_loss1: 8.0599 - val_loss2: 8.4340\n","Epoch 161/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7503 - model_loss: 0.1699 - model_1_loss: 0.1007 - model_2_loss: 0.2314 - model_3_loss: 0.1263 - model_4_loss: 0.1220 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.4549 - loss2: 8.8545 - val_loss: 13.1047 - val_model_loss: 2.7192 - val_model_1_loss: 2.4687 - val_model_2_loss: 2.4371 - val_model_3_loss: 2.5428 - val_model_4_loss: 2.9369 - val_model_accuracy: 0.6722 - val_model_1_accuracy: 0.6306 - val_model_2_accuracy: 0.6222 - val_model_3_accuracy: 0.6306 - val_model_4_accuracy: 0.6444 - val_loss1: 8.0640 - val_loss2: 8.4653\n","Epoch 162/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.2952 - model_loss: 0.0632 - model_1_loss: 0.0257 - model_2_loss: 0.1039 - model_3_loss: 0.0612 - model_4_loss: 0.0412 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.3838 - loss2: 8.8080 - val_loss: 12.8225 - val_model_loss: 2.5969 - val_model_1_loss: 2.3127 - val_model_2_loss: 2.4174 - val_model_3_loss: 2.5775 - val_model_4_loss: 2.9181 - val_model_accuracy: 0.6500 - val_model_1_accuracy: 0.6417 - val_model_2_accuracy: 0.6222 - val_model_3_accuracy: 0.5667 - val_model_4_accuracy: 0.6389 - val_loss1: 8.0919 - val_loss2: 8.5819\n","Epoch 163/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5673 - model_loss: 0.1237 - model_1_loss: 0.1015 - model_2_loss: 0.1141 - model_3_loss: 0.1104 - model_4_loss: 0.1177 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.3887 - loss2: 8.7904 - val_loss: 12.4082 - val_model_loss: 2.4742 - val_model_1_loss: 2.0636 - val_model_2_loss: 2.3266 - val_model_3_loss: 2.6103 - val_model_4_loss: 2.9335 - val_model_accuracy: 0.6472 - val_model_1_accuracy: 0.6722 - val_model_2_accuracy: 0.6278 - val_model_3_accuracy: 0.5222 - val_model_4_accuracy: 0.6417 - val_loss1: 8.1406 - val_loss2: 8.6920\n","Epoch 164/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.1548 - model_loss: 0.3282 - model_1_loss: 0.2006 - model_2_loss: 0.2080 - model_3_loss: 0.2088 - model_4_loss: 0.2093 - model_accuracy: 0.9000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.3172 - loss2: 8.7721 - val_loss: 12.6031 - val_model_loss: 2.5572 - val_model_1_loss: 1.9470 - val_model_2_loss: 2.2700 - val_model_3_loss: 2.7076 - val_model_4_loss: 3.1213 - val_model_accuracy: 0.6278 - val_model_1_accuracy: 0.6806 - val_model_2_accuracy: 0.6333 - val_model_3_accuracy: 0.5333 - val_model_4_accuracy: 0.6333 - val_loss1: 8.1880 - val_loss2: 8.7460\n","Epoch 165/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7445 - model_loss: 0.1726 - model_1_loss: 0.1089 - model_2_loss: 0.1889 - model_3_loss: 0.1131 - model_4_loss: 0.1610 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9000 - loss1: 8.5223 - loss2: 8.8375 - val_loss: 13.3546 - val_model_loss: 2.7849 - val_model_1_loss: 1.9273 - val_model_2_loss: 2.3520 - val_model_3_loss: 2.7798 - val_model_4_loss: 3.5107 - val_model_accuracy: 0.6111 - val_model_1_accuracy: 0.6917 - val_model_2_accuracy: 0.5889 - val_model_3_accuracy: 0.5694 - val_model_4_accuracy: 0.6222 - val_loss1: 8.2123 - val_loss2: 8.7122\n","Epoch 166/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5049 - model_loss: 0.1186 - model_1_loss: 0.0839 - model_2_loss: 0.0970 - model_3_loss: 0.1086 - model_4_loss: 0.0968 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.4269 - loss2: 8.8364 - val_loss: 13.6392 - val_model_loss: 2.8638 - val_model_1_loss: 1.8509 - val_model_2_loss: 2.3909 - val_model_3_loss: 2.7876 - val_model_4_loss: 3.7458 - val_model_accuracy: 0.6333 - val_model_1_accuracy: 0.7028 - val_model_2_accuracy: 0.5667 - val_model_3_accuracy: 0.5806 - val_model_4_accuracy: 0.5944 - val_loss1: 8.2598 - val_loss2: 8.7158\n","Epoch 167/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1838 - model_loss: 0.0241 - model_1_loss: 0.0119 - model_2_loss: 0.0550 - model_3_loss: 0.0313 - model_4_loss: 0.0614 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.5974 - loss2: 8.9650 - val_loss: 14.0143 - val_model_loss: 3.0164 - val_model_1_loss: 1.7969 - val_model_2_loss: 2.3332 - val_model_3_loss: 2.8153 - val_model_4_loss: 4.0526 - val_model_accuracy: 0.6278 - val_model_1_accuracy: 0.7111 - val_model_2_accuracy: 0.6000 - val_model_3_accuracy: 0.5778 - val_model_4_accuracy: 0.5556 - val_loss1: 8.2961 - val_loss2: 8.7268\n","Epoch 168/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3780 - model_loss: 0.0902 - model_1_loss: 0.0469 - model_2_loss: 0.1259 - model_3_loss: 0.0550 - model_4_loss: 0.0601 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4810 - loss2: 8.8707 - val_loss: 13.9886 - val_model_loss: 3.0474 - val_model_1_loss: 1.6881 - val_model_2_loss: 2.2559 - val_model_3_loss: 2.7555 - val_model_4_loss: 4.2417 - val_model_accuracy: 0.6194 - val_model_1_accuracy: 0.7111 - val_model_2_accuracy: 0.6306 - val_model_3_accuracy: 0.5778 - val_model_4_accuracy: 0.5250 - val_loss1: 8.3023 - val_loss2: 8.7327\n","Epoch 169/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.8180 - model_loss: 0.1381 - model_1_loss: 0.1878 - model_2_loss: 0.0925 - model_3_loss: 0.1893 - model_4_loss: 0.2103 - model_accuracy: 0.9333 - model_1_accuracy: 0.9000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.5801 - loss2: 8.8709 - val_loss: 13.5655 - val_model_loss: 2.9971 - val_model_1_loss: 1.5672 - val_model_2_loss: 2.1355 - val_model_3_loss: 2.7154 - val_model_4_loss: 4.1504 - val_model_accuracy: 0.6222 - val_model_1_accuracy: 0.7250 - val_model_2_accuracy: 0.6333 - val_model_3_accuracy: 0.5750 - val_model_4_accuracy: 0.5806 - val_loss1: 8.2738 - val_loss2: 8.7303\n","Epoch 170/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1117 - model_loss: 0.0185 - model_1_loss: 0.0122 - model_2_loss: 0.0413 - model_3_loss: 0.0187 - model_4_loss: 0.0211 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4418 - loss2: 8.8677 - val_loss: 13.0018 - val_model_loss: 2.8507 - val_model_1_loss: 1.4728 - val_model_2_loss: 1.9888 - val_model_3_loss: 2.5937 - val_model_4_loss: 4.0958 - val_model_accuracy: 0.6278 - val_model_1_accuracy: 0.7306 - val_model_2_accuracy: 0.6389 - val_model_3_accuracy: 0.5750 - val_model_4_accuracy: 0.5944 - val_loss1: 8.2364 - val_loss2: 8.7134\n","Epoch 171/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3682 - model_loss: 0.0436 - model_1_loss: 0.0253 - model_2_loss: 0.0842 - model_3_loss: 0.0820 - model_4_loss: 0.1331 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.5942 - loss2: 8.9366 - val_loss: 12.8476 - val_model_loss: 2.7430 - val_model_1_loss: 1.4281 - val_model_2_loss: 2.0914 - val_model_3_loss: 2.5655 - val_model_4_loss: 4.0196 - val_model_accuracy: 0.6306 - val_model_1_accuracy: 0.7333 - val_model_2_accuracy: 0.6389 - val_model_3_accuracy: 0.5917 - val_model_4_accuracy: 0.5889 - val_loss1: 8.2204 - val_loss2: 8.6940\n","Epoch 172/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4832 - model_loss: 0.1181 - model_1_loss: 0.1256 - model_2_loss: 0.0835 - model_3_loss: 0.0410 - model_4_loss: 0.1151 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9333 - loss1: 8.4359 - loss2: 8.8442 - val_loss: 12.8768 - val_model_loss: 2.7291 - val_model_1_loss: 1.4700 - val_model_2_loss: 2.1875 - val_model_3_loss: 2.5807 - val_model_4_loss: 3.9095 - val_model_accuracy: 0.6361 - val_model_1_accuracy: 0.7278 - val_model_2_accuracy: 0.6139 - val_model_3_accuracy: 0.5861 - val_model_4_accuracy: 0.5667 - val_loss1: 8.2237 - val_loss2: 8.6974\n","Epoch 173/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2070 - model_loss: 0.0384 - model_1_loss: 0.0184 - model_2_loss: 0.0728 - model_3_loss: 0.0445 - model_4_loss: 0.0328 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4370 - loss2: 8.8328 - val_loss: 13.0582 - val_model_loss: 2.8162 - val_model_1_loss: 1.6311 - val_model_2_loss: 2.2538 - val_model_3_loss: 2.5680 - val_model_4_loss: 3.7891 - val_model_accuracy: 0.6194 - val_model_1_accuracy: 0.6972 - val_model_2_accuracy: 0.6167 - val_model_3_accuracy: 0.5861 - val_model_4_accuracy: 0.5611 - val_loss1: 8.2325 - val_loss2: 8.7148\n","Epoch 174/300\n","3/3 [==============================] - 6s 3s/step - loss: 0.4066 - model_loss: 0.0569 - model_1_loss: 0.0498 - model_2_loss: 0.1291 - model_3_loss: 0.0842 - model_4_loss: 0.0866 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.5071 - loss2: 8.8934 - val_loss: 12.8705 - val_model_loss: 2.8381 - val_model_1_loss: 1.7074 - val_model_2_loss: 2.2705 - val_model_3_loss: 2.5011 - val_model_4_loss: 3.5534 - val_model_accuracy: 0.5944 - val_model_1_accuracy: 0.6778 - val_model_2_accuracy: 0.6028 - val_model_3_accuracy: 0.5917 - val_model_4_accuracy: 0.5694 - val_loss1: 8.2354 - val_loss2: 8.7553\n","Epoch 175/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.7793 - model_loss: 0.0839 - model_1_loss: 0.0286 - model_2_loss: 0.1465 - model_3_loss: 0.2520 - model_4_loss: 0.2684 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.5033 - loss2: 8.8590 - val_loss: 11.9855 - val_model_loss: 2.6381 - val_model_1_loss: 1.7056 - val_model_2_loss: 2.0744 - val_model_3_loss: 2.2638 - val_model_4_loss: 3.3036 - val_model_accuracy: 0.6028 - val_model_1_accuracy: 0.6750 - val_model_2_accuracy: 0.6056 - val_model_3_accuracy: 0.6000 - val_model_4_accuracy: 0.6111 - val_loss1: 8.2295 - val_loss2: 8.8188\n","Epoch 176/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2696 - model_loss: 0.0722 - model_1_loss: 0.0417 - model_2_loss: 0.0540 - model_3_loss: 0.0366 - model_4_loss: 0.0651 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5043 - loss2: 8.8994 - val_loss: 11.1391 - val_model_loss: 2.4861 - val_model_1_loss: 1.7294 - val_model_2_loss: 1.9954 - val_model_3_loss: 2.0397 - val_model_4_loss: 2.8886 - val_model_accuracy: 0.6333 - val_model_1_accuracy: 0.6583 - val_model_2_accuracy: 0.5639 - val_model_3_accuracy: 0.6083 - val_model_4_accuracy: 0.6111 - val_loss1: 8.2289 - val_loss2: 8.8737\n","Epoch 177/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.7260 - model_loss: 0.1326 - model_1_loss: 0.1055 - model_2_loss: 0.1827 - model_3_loss: 0.1714 - model_4_loss: 0.1338 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.5964 - loss2: 8.9767 - val_loss: 11.0722 - val_model_loss: 2.5463 - val_model_1_loss: 1.7289 - val_model_2_loss: 2.1312 - val_model_3_loss: 2.0075 - val_model_4_loss: 2.6584 - val_model_accuracy: 0.6417 - val_model_1_accuracy: 0.6722 - val_model_2_accuracy: 0.5167 - val_model_3_accuracy: 0.6167 - val_model_4_accuracy: 0.6000 - val_loss1: 8.2587 - val_loss2: 8.9070\n","Epoch 178/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4824 - model_loss: 0.0755 - model_1_loss: 0.1290 - model_2_loss: 0.1219 - model_3_loss: 0.0713 - model_4_loss: 0.0848 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.6326 - loss2: 8.9578 - val_loss: 10.7856 - val_model_loss: 2.6474 - val_model_1_loss: 1.6831 - val_model_2_loss: 1.8655 - val_model_3_loss: 2.1229 - val_model_4_loss: 2.4668 - val_model_accuracy: 0.6528 - val_model_1_accuracy: 0.6778 - val_model_2_accuracy: 0.6389 - val_model_3_accuracy: 0.6194 - val_model_4_accuracy: 0.6444 - val_loss1: 8.2875 - val_loss2: 8.9172\n","Epoch 179/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2620 - model_loss: 0.0476 - model_1_loss: 0.0276 - model_2_loss: 0.0741 - model_3_loss: 0.0714 - model_4_loss: 0.0413 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.4276 - loss2: 8.9042 - val_loss: 10.9707 - val_model_loss: 2.5946 - val_model_1_loss: 1.6872 - val_model_2_loss: 1.7834 - val_model_3_loss: 2.4922 - val_model_4_loss: 2.4133 - val_model_accuracy: 0.6444 - val_model_1_accuracy: 0.6833 - val_model_2_accuracy: 0.6778 - val_model_3_accuracy: 0.5250 - val_model_4_accuracy: 0.6722 - val_loss1: 8.2960 - val_loss2: 8.9027\n","Epoch 180/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6417 - model_loss: 0.1260 - model_1_loss: 0.0944 - model_2_loss: 0.1309 - model_3_loss: 0.1271 - model_4_loss: 0.1633 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.3771 - loss2: 8.8274 - val_loss: 11.4969 - val_model_loss: 2.5608 - val_model_1_loss: 1.7728 - val_model_2_loss: 1.7787 - val_model_3_loss: 2.9216 - val_model_4_loss: 2.4631 - val_model_accuracy: 0.6083 - val_model_1_accuracy: 0.6500 - val_model_2_accuracy: 0.7056 - val_model_3_accuracy: 0.5056 - val_model_4_accuracy: 0.6389 - val_loss1: 8.2950 - val_loss2: 8.9079\n","Epoch 181/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1483 - model_loss: 0.0253 - model_1_loss: 0.0395 - model_2_loss: 0.0258 - model_3_loss: 0.0358 - model_4_loss: 0.0218 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5147 - loss2: 8.8957 - val_loss: 11.6848 - val_model_loss: 2.6054 - val_model_1_loss: 1.8170 - val_model_2_loss: 1.7961 - val_model_3_loss: 2.9354 - val_model_4_loss: 2.5308 - val_model_accuracy: 0.5889 - val_model_1_accuracy: 0.6667 - val_model_2_accuracy: 0.7167 - val_model_3_accuracy: 0.5306 - val_model_4_accuracy: 0.6278 - val_loss1: 8.2672 - val_loss2: 8.9006\n","Epoch 182/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.0807 - model_loss: 0.1773 - model_1_loss: 0.2792 - model_2_loss: 0.2791 - model_3_loss: 0.0610 - model_4_loss: 0.2841 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.4592 - loss2: 8.8564 - val_loss: 11.7304 - val_model_loss: 2.4288 - val_model_1_loss: 1.9012 - val_model_2_loss: 1.9371 - val_model_3_loss: 2.6995 - val_model_4_loss: 2.7638 - val_model_accuracy: 0.6556 - val_model_1_accuracy: 0.6361 - val_model_2_accuracy: 0.6972 - val_model_3_accuracy: 0.5500 - val_model_4_accuracy: 0.6000 - val_loss1: 8.2542 - val_loss2: 8.8821\n","Epoch 183/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5742 - model_loss: 0.0954 - model_1_loss: 0.1076 - model_2_loss: 0.0992 - model_3_loss: 0.1633 - model_4_loss: 0.1087 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.4255 - loss2: 8.8842 - val_loss: 11.6942 - val_model_loss: 2.4258 - val_model_1_loss: 1.9424 - val_model_2_loss: 2.0854 - val_model_3_loss: 2.3421 - val_model_4_loss: 2.8985 - val_model_accuracy: 0.6639 - val_model_1_accuracy: 0.6417 - val_model_2_accuracy: 0.6639 - val_model_3_accuracy: 0.6278 - val_model_4_accuracy: 0.6111 - val_loss1: 8.2100 - val_loss2: 8.8593\n","Epoch 184/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.9534 - model_loss: 0.2083 - model_1_loss: 0.1668 - model_2_loss: 0.1726 - model_3_loss: 0.1878 - model_4_loss: 0.2178 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.3949 - loss2: 8.8536 - val_loss: 11.6769 - val_model_loss: 2.4334 - val_model_1_loss: 1.9923 - val_model_2_loss: 2.0909 - val_model_3_loss: 2.1275 - val_model_4_loss: 3.0328 - val_model_accuracy: 0.6583 - val_model_1_accuracy: 0.6361 - val_model_2_accuracy: 0.6444 - val_model_3_accuracy: 0.6222 - val_model_4_accuracy: 0.6306 - val_loss1: 8.1345 - val_loss2: 8.8180\n","Epoch 185/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6089 - model_loss: 0.1193 - model_1_loss: 0.0971 - model_2_loss: 0.1302 - model_3_loss: 0.1315 - model_4_loss: 0.1309 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.3879 - loss2: 8.8600 - val_loss: 10.7342 - val_model_loss: 2.1705 - val_model_1_loss: 1.9355 - val_model_2_loss: 1.8772 - val_model_3_loss: 1.8515 - val_model_4_loss: 2.8995 - val_model_accuracy: 0.6611 - val_model_1_accuracy: 0.6306 - val_model_2_accuracy: 0.6444 - val_model_3_accuracy: 0.6278 - val_model_4_accuracy: 0.6333 - val_loss1: 8.0942 - val_loss2: 8.8108\n","Epoch 186/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3568 - model_loss: 0.0714 - model_1_loss: 0.0618 - model_2_loss: 0.0756 - model_3_loss: 0.0793 - model_4_loss: 0.0687 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3225 - loss2: 8.8845 - val_loss: 10.1492 - val_model_loss: 1.9948 - val_model_1_loss: 1.9237 - val_model_2_loss: 1.7255 - val_model_3_loss: 1.6869 - val_model_4_loss: 2.8182 - val_model_accuracy: 0.6611 - val_model_1_accuracy: 0.6306 - val_model_2_accuracy: 0.6139 - val_model_3_accuracy: 0.6361 - val_model_4_accuracy: 0.6333 - val_loss1: 8.0552 - val_loss2: 8.8044\n","Epoch 187/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.5491 - model_loss: 0.0584 - model_1_loss: 0.1034 - model_2_loss: 0.0547 - model_3_loss: 0.2578 - model_4_loss: 0.0749 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9333 - model_4_accuracy: 1.0000 - loss1: 8.3362 - loss2: 8.7623 - val_loss: 10.3536 - val_model_loss: 1.9590 - val_model_1_loss: 2.0364 - val_model_2_loss: 1.6621 - val_model_3_loss: 1.9333 - val_model_4_loss: 2.7628 - val_model_accuracy: 0.6667 - val_model_1_accuracy: 0.6611 - val_model_2_accuracy: 0.5833 - val_model_3_accuracy: 0.6000 - val_model_4_accuracy: 0.6389 - val_loss1: 8.0688 - val_loss2: 8.8207\n","Epoch 188/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4970 - model_loss: 0.0897 - model_1_loss: 0.0909 - model_2_loss: 0.1032 - model_3_loss: 0.1142 - model_4_loss: 0.0989 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.3437 - loss2: 8.8492 - val_loss: 10.8621 - val_model_loss: 1.9920 - val_model_1_loss: 2.2230 - val_model_2_loss: 1.6589 - val_model_3_loss: 2.2116 - val_model_4_loss: 2.7766 - val_model_accuracy: 0.6667 - val_model_1_accuracy: 0.6833 - val_model_2_accuracy: 0.5750 - val_model_3_accuracy: 0.5833 - val_model_4_accuracy: 0.6361 - val_loss1: 8.0945 - val_loss2: 8.8423\n","Epoch 189/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2339 - model_loss: 0.0259 - model_1_loss: 0.0178 - model_2_loss: 0.0560 - model_3_loss: 0.0810 - model_4_loss: 0.0532 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4858 - loss2: 8.8723 - val_loss: 11.1643 - val_model_loss: 2.0811 - val_model_1_loss: 2.4151 - val_model_2_loss: 1.5500 - val_model_3_loss: 2.3870 - val_model_4_loss: 2.7310 - val_model_accuracy: 0.6861 - val_model_1_accuracy: 0.6861 - val_model_2_accuracy: 0.6139 - val_model_3_accuracy: 0.5694 - val_model_4_accuracy: 0.6361 - val_loss1: 8.1227 - val_loss2: 8.8477\n","Epoch 190/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6613 - model_loss: 0.0939 - model_1_loss: 0.0766 - model_2_loss: 0.1090 - model_3_loss: 0.2082 - model_4_loss: 0.1735 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9000 - loss1: 8.3848 - loss2: 8.8283 - val_loss: 11.0492 - val_model_loss: 2.1468 - val_model_1_loss: 2.4187 - val_model_2_loss: 1.4836 - val_model_3_loss: 2.3685 - val_model_4_loss: 2.6316 - val_model_accuracy: 0.6972 - val_model_1_accuracy: 0.6917 - val_model_2_accuracy: 0.6500 - val_model_3_accuracy: 0.5722 - val_model_4_accuracy: 0.6444 - val_loss1: 8.1406 - val_loss2: 8.8631\n","Epoch 191/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1779 - model_loss: 0.0241 - model_1_loss: 0.0356 - model_2_loss: 0.0260 - model_3_loss: 0.0598 - model_4_loss: 0.0325 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.5326 - loss2: 8.8965 - val_loss: 10.8549 - val_model_loss: 2.2090 - val_model_1_loss: 2.3837 - val_model_2_loss: 1.4870 - val_model_3_loss: 2.2535 - val_model_4_loss: 2.5217 - val_model_accuracy: 0.6917 - val_model_1_accuracy: 0.6833 - val_model_2_accuracy: 0.6528 - val_model_3_accuracy: 0.5750 - val_model_4_accuracy: 0.6583 - val_loss1: 8.1523 - val_loss2: 8.8926\n","Epoch 192/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.7887 - model_loss: 0.1501 - model_1_loss: 0.1772 - model_2_loss: 0.1971 - model_3_loss: 0.1500 - model_4_loss: 0.1143 - model_accuracy: 0.9667 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.5165 - loss2: 8.8252 - val_loss: 10.6806 - val_model_loss: 2.3361 - val_model_1_loss: 2.2527 - val_model_2_loss: 1.5184 - val_model_3_loss: 2.1988 - val_model_4_loss: 2.3747 - val_model_accuracy: 0.6750 - val_model_1_accuracy: 0.6444 - val_model_2_accuracy: 0.6639 - val_model_3_accuracy: 0.5917 - val_model_4_accuracy: 0.6528 - val_loss1: 8.1848 - val_loss2: 8.9218\n","Epoch 193/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3883 - model_loss: 0.1202 - model_1_loss: 0.1076 - model_2_loss: 0.0487 - model_3_loss: 0.0626 - model_4_loss: 0.0492 - model_accuracy: 0.9667 - model_1_accuracy: 0.9333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.4817 - loss2: 8.8610 - val_loss: 9.8754 - val_model_loss: 2.3267 - val_model_1_loss: 1.9322 - val_model_2_loss: 1.4935 - val_model_3_loss: 2.0287 - val_model_4_loss: 2.0942 - val_model_accuracy: 0.6056 - val_model_1_accuracy: 0.5972 - val_model_2_accuracy: 0.6750 - val_model_3_accuracy: 0.5944 - val_model_4_accuracy: 0.6472 - val_loss1: 8.2215 - val_loss2: 8.9645\n","Epoch 194/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.3077 - model_loss: 0.0553 - model_1_loss: 0.0455 - model_2_loss: 0.0729 - model_3_loss: 0.0834 - model_4_loss: 0.0505 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.4831 - loss2: 8.8945 - val_loss: 9.6083 - val_model_loss: 2.4260 - val_model_1_loss: 1.7119 - val_model_2_loss: 1.5980 - val_model_3_loss: 1.9335 - val_model_4_loss: 1.9389 - val_model_accuracy: 0.5611 - val_model_1_accuracy: 0.6472 - val_model_2_accuracy: 0.6722 - val_model_3_accuracy: 0.5889 - val_model_4_accuracy: 0.6667 - val_loss1: 8.2480 - val_loss2: 8.9896\n","Epoch 195/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.4851 - model_loss: 0.1037 - model_1_loss: 0.1134 - model_2_loss: 0.0899 - model_3_loss: 0.1011 - model_4_loss: 0.0769 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.3873 - loss2: 8.8486 - val_loss: 9.8609 - val_model_loss: 2.5459 - val_model_1_loss: 1.7036 - val_model_2_loss: 1.7601 - val_model_3_loss: 1.9723 - val_model_4_loss: 1.8790 - val_model_accuracy: 0.6250 - val_model_1_accuracy: 0.6833 - val_model_2_accuracy: 0.6500 - val_model_3_accuracy: 0.5917 - val_model_4_accuracy: 0.6694 - val_loss1: 8.2887 - val_loss2: 8.9895\n","Epoch 196/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5392 - model_loss: 0.0954 - model_1_loss: 0.0704 - model_2_loss: 0.1404 - model_3_loss: 0.1332 - model_4_loss: 0.0997 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.5709 - loss2: 8.9290 - val_loss: 10.1366 - val_model_loss: 2.7230 - val_model_1_loss: 1.8078 - val_model_2_loss: 1.8163 - val_model_3_loss: 1.9640 - val_model_4_loss: 1.8254 - val_model_accuracy: 0.6306 - val_model_1_accuracy: 0.6944 - val_model_2_accuracy: 0.6583 - val_model_3_accuracy: 0.6056 - val_model_4_accuracy: 0.6750 - val_loss1: 8.3262 - val_loss2: 8.9839\n","Epoch 197/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4877 - model_loss: 0.1028 - model_1_loss: 0.0878 - model_2_loss: 0.0744 - model_3_loss: 0.1457 - model_4_loss: 0.0769 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9667 - loss1: 8.6575 - loss2: 8.9991 - val_loss: 10.4585 - val_model_loss: 2.8595 - val_model_1_loss: 1.9380 - val_model_2_loss: 1.8689 - val_model_3_loss: 1.9694 - val_model_4_loss: 1.8226 - val_model_accuracy: 0.6361 - val_model_1_accuracy: 0.6722 - val_model_2_accuracy: 0.6583 - val_model_3_accuracy: 0.5972 - val_model_4_accuracy: 0.6806 - val_loss1: 8.3445 - val_loss2: 8.9726\n","Epoch 198/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1826 - model_loss: 0.0166 - model_1_loss: 0.1138 - model_2_loss: 0.0207 - model_3_loss: 0.0175 - model_4_loss: 0.0139 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4904 - loss2: 8.9136 - val_loss: 10.7257 - val_model_loss: 2.9622 - val_model_1_loss: 2.0043 - val_model_2_loss: 1.9422 - val_model_3_loss: 1.9989 - val_model_4_loss: 1.8181 - val_model_accuracy: 0.6333 - val_model_1_accuracy: 0.6861 - val_model_2_accuracy: 0.6528 - val_model_3_accuracy: 0.5806 - val_model_4_accuracy: 0.6806 - val_loss1: 8.3466 - val_loss2: 8.9659\n","Epoch 199/300\n","3/3 [==============================] - 5s 3s/step - loss: 1.0915 - model_loss: 0.2375 - model_1_loss: 0.2412 - model_2_loss: 0.2296 - model_3_loss: 0.1976 - model_4_loss: 0.1857 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.5257 - loss2: 8.8493 - val_loss: 10.5306 - val_model_loss: 2.8571 - val_model_1_loss: 2.0438 - val_model_2_loss: 1.9684 - val_model_3_loss: 1.9464 - val_model_4_loss: 1.7148 - val_model_accuracy: 0.6278 - val_model_1_accuracy: 0.6889 - val_model_2_accuracy: 0.6167 - val_model_3_accuracy: 0.5722 - val_model_4_accuracy: 0.6833 - val_loss1: 8.3337 - val_loss2: 8.9841\n","Epoch 200/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.2017 - model_loss: 0.0414 - model_1_loss: 0.0474 - model_2_loss: 0.0341 - model_3_loss: 0.0555 - model_4_loss: 0.0233 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3337 - loss2: 8.7900 - val_loss: 10.1718 - val_model_loss: 2.6790 - val_model_1_loss: 2.0295 - val_model_2_loss: 1.9205 - val_model_3_loss: 1.8493 - val_model_4_loss: 1.6934 - val_model_accuracy: 0.6056 - val_model_1_accuracy: 0.6722 - val_model_2_accuracy: 0.6000 - val_model_3_accuracy: 0.5750 - val_model_4_accuracy: 0.6722 - val_loss1: 8.3183 - val_loss2: 8.9998\n","Epoch 201/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2704 - model_loss: 0.0483 - model_1_loss: 0.0485 - model_2_loss: 0.0563 - model_3_loss: 0.0716 - model_4_loss: 0.0456 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.6431 - loss2: 8.9308 - val_loss: 10.3960 - val_model_loss: 2.7427 - val_model_1_loss: 2.0361 - val_model_2_loss: 1.9230 - val_model_3_loss: 1.8114 - val_model_4_loss: 1.8828 - val_model_accuracy: 0.5167 - val_model_1_accuracy: 0.6444 - val_model_2_accuracy: 0.5972 - val_model_3_accuracy: 0.5750 - val_model_4_accuracy: 0.5833 - val_loss1: 8.3092 - val_loss2: 9.0139\n","Epoch 202/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3538 - model_loss: 0.0721 - model_1_loss: 0.0594 - model_2_loss: 0.0683 - model_3_loss: 0.0761 - model_4_loss: 0.0779 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.3843 - loss2: 8.8067 - val_loss: 11.0522 - val_model_loss: 2.8443 - val_model_1_loss: 2.2059 - val_model_2_loss: 2.0007 - val_model_3_loss: 1.8355 - val_model_4_loss: 2.1658 - val_model_accuracy: 0.4861 - val_model_1_accuracy: 0.5750 - val_model_2_accuracy: 0.6111 - val_model_3_accuracy: 0.5833 - val_model_4_accuracy: 0.5556 - val_loss1: 8.2962 - val_loss2: 9.0022\n","Epoch 203/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3387 - model_loss: 0.0278 - model_1_loss: 0.1505 - model_2_loss: 0.0696 - model_3_loss: 0.0610 - model_4_loss: 0.0298 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.5011 - loss2: 8.8685 - val_loss: 12.2103 - val_model_loss: 3.0544 - val_model_1_loss: 2.6611 - val_model_2_loss: 2.0718 - val_model_3_loss: 1.8454 - val_model_4_loss: 2.5776 - val_model_accuracy: 0.4500 - val_model_1_accuracy: 0.5472 - val_model_2_accuracy: 0.6111 - val_model_3_accuracy: 0.6111 - val_model_4_accuracy: 0.5500 - val_loss1: 8.2538 - val_loss2: 8.9473\n","Epoch 204/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1365 - model_loss: 0.0165 - model_1_loss: 0.0219 - model_2_loss: 0.0245 - model_3_loss: 0.0408 - model_4_loss: 0.0328 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5355 - loss2: 8.9256 - val_loss: 13.0621 - val_model_loss: 3.2869 - val_model_1_loss: 3.0777 - val_model_2_loss: 2.0749 - val_model_3_loss: 1.7972 - val_model_4_loss: 2.8254 - val_model_accuracy: 0.4417 - val_model_1_accuracy: 0.5167 - val_model_2_accuracy: 0.5889 - val_model_3_accuracy: 0.6194 - val_model_4_accuracy: 0.5694 - val_loss1: 8.2035 - val_loss2: 8.8947\n","Epoch 205/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7867 - model_loss: 0.1550 - model_1_loss: 0.1342 - model_2_loss: 0.1595 - model_3_loss: 0.1583 - model_4_loss: 0.1797 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.4718 - loss2: 8.8735 - val_loss: 13.4966 - val_model_loss: 3.1846 - val_model_1_loss: 3.3514 - val_model_2_loss: 2.0840 - val_model_3_loss: 1.8528 - val_model_4_loss: 3.0239 - val_model_accuracy: 0.4778 - val_model_1_accuracy: 0.4917 - val_model_2_accuracy: 0.5833 - val_model_3_accuracy: 0.6250 - val_model_4_accuracy: 0.5694 - val_loss1: 8.1797 - val_loss2: 8.8578\n","Epoch 206/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.4864 - model_loss: 0.0135 - model_1_loss: 0.2900 - model_2_loss: 0.0546 - model_3_loss: 0.1106 - model_4_loss: 0.0177 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.6204 - loss2: 8.9296 - val_loss: 13.8923 - val_model_loss: 3.0499 - val_model_1_loss: 3.3336 - val_model_2_loss: 2.1697 - val_model_3_loss: 2.1559 - val_model_4_loss: 3.1831 - val_model_accuracy: 0.5806 - val_model_1_accuracy: 0.5222 - val_model_2_accuracy: 0.6056 - val_model_3_accuracy: 0.6083 - val_model_4_accuracy: 0.6028 - val_loss1: 8.2211 - val_loss2: 8.8738\n","Epoch 207/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1298 - model_loss: 0.0154 - model_1_loss: 0.0185 - model_2_loss: 0.0280 - model_3_loss: 0.0349 - model_4_loss: 0.0330 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5464 - loss2: 8.9208 - val_loss: 14.5608 - val_model_loss: 3.1558 - val_model_1_loss: 3.3029 - val_model_2_loss: 2.3309 - val_model_3_loss: 2.5605 - val_model_4_loss: 3.2107 - val_model_accuracy: 0.6250 - val_model_1_accuracy: 0.5583 - val_model_2_accuracy: 0.6111 - val_model_3_accuracy: 0.5111 - val_model_4_accuracy: 0.6278 - val_loss1: 8.2395 - val_loss2: 8.8536\n","Epoch 208/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1916 - model_loss: 0.0419 - model_1_loss: 0.0323 - model_2_loss: 0.0350 - model_3_loss: 0.0589 - model_4_loss: 0.0235 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.5262 - loss2: 8.8900 - val_loss: 15.1096 - val_model_loss: 3.3127 - val_model_1_loss: 3.3113 - val_model_2_loss: 2.4510 - val_model_3_loss: 2.8486 - val_model_4_loss: 3.1859 - val_model_accuracy: 0.6278 - val_model_1_accuracy: 0.5611 - val_model_2_accuracy: 0.6056 - val_model_3_accuracy: 0.4667 - val_model_4_accuracy: 0.6333 - val_loss1: 8.2520 - val_loss2: 8.8319\n","Epoch 209/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3669 - model_loss: 0.0523 - model_1_loss: 0.0766 - model_2_loss: 0.0628 - model_3_loss: 0.1085 - model_4_loss: 0.0668 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.5686 - loss2: 8.9334 - val_loss: 15.3737 - val_model_loss: 3.4437 - val_model_1_loss: 3.2909 - val_model_2_loss: 2.5603 - val_model_3_loss: 2.8995 - val_model_4_loss: 3.1794 - val_model_accuracy: 0.6278 - val_model_1_accuracy: 0.5722 - val_model_2_accuracy: 0.5861 - val_model_3_accuracy: 0.4694 - val_model_4_accuracy: 0.6417 - val_loss1: 8.2609 - val_loss2: 8.8097\n","Epoch 210/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2660 - model_loss: 0.0249 - model_1_loss: 0.0525 - model_2_loss: 0.1347 - model_3_loss: 0.0116 - model_4_loss: 0.0424 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5930 - loss2: 8.9310 - val_loss: 15.4308 - val_model_loss: 3.5247 - val_model_1_loss: 3.1764 - val_model_2_loss: 2.6527 - val_model_3_loss: 2.9080 - val_model_4_loss: 3.1689 - val_model_accuracy: 0.6306 - val_model_1_accuracy: 0.5722 - val_model_2_accuracy: 0.5861 - val_model_3_accuracy: 0.4806 - val_model_4_accuracy: 0.6444 - val_loss1: 8.2917 - val_loss2: 8.8441\n","Epoch 211/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4278 - model_loss: 0.0664 - model_1_loss: 0.0872 - model_2_loss: 0.1070 - model_3_loss: 0.0850 - model_4_loss: 0.0821 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.5462 - loss2: 8.9392 - val_loss: 15.4297 - val_model_loss: 3.5848 - val_model_1_loss: 3.0981 - val_model_2_loss: 2.7219 - val_model_3_loss: 2.8781 - val_model_4_loss: 3.1469 - val_model_accuracy: 0.6278 - val_model_1_accuracy: 0.5806 - val_model_2_accuracy: 0.6111 - val_model_3_accuracy: 0.5306 - val_model_4_accuracy: 0.6417 - val_loss1: 8.2971 - val_loss2: 8.8775\n","Epoch 212/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.6109 - model_loss: 0.0925 - model_1_loss: 0.1200 - model_2_loss: 0.1571 - model_3_loss: 0.1621 - model_4_loss: 0.0792 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.3479 - loss2: 8.7795 - val_loss: 15.6608 - val_model_loss: 3.7794 - val_model_1_loss: 3.0225 - val_model_2_loss: 2.8142 - val_model_3_loss: 2.9656 - val_model_4_loss: 3.0791 - val_model_accuracy: 0.6250 - val_model_1_accuracy: 0.5833 - val_model_2_accuracy: 0.6083 - val_model_3_accuracy: 0.5667 - val_model_4_accuracy: 0.6417 - val_loss1: 8.3334 - val_loss2: 8.8888\n","Epoch 213/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3889 - model_loss: 0.0724 - model_1_loss: 0.1011 - model_2_loss: 0.0930 - model_3_loss: 0.0641 - model_4_loss: 0.0583 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3538 - loss2: 8.8221 - val_loss: 15.7608 - val_model_loss: 3.8171 - val_model_1_loss: 2.9867 - val_model_2_loss: 2.8467 - val_model_3_loss: 3.1138 - val_model_4_loss: 2.9965 - val_model_accuracy: 0.6278 - val_model_1_accuracy: 0.5917 - val_model_2_accuracy: 0.6194 - val_model_3_accuracy: 0.5806 - val_model_4_accuracy: 0.6444 - val_loss1: 8.3367 - val_loss2: 8.8757\n","Epoch 214/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2357 - model_loss: 0.0310 - model_1_loss: 0.0496 - model_2_loss: 0.0809 - model_3_loss: 0.0430 - model_4_loss: 0.0312 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.5967 - loss2: 8.9425 - val_loss: 15.5074 - val_model_loss: 3.7447 - val_model_1_loss: 2.9568 - val_model_2_loss: 2.7211 - val_model_3_loss: 3.1859 - val_model_4_loss: 2.8989 - val_model_accuracy: 0.6250 - val_model_1_accuracy: 0.6028 - val_model_2_accuracy: 0.6361 - val_model_3_accuracy: 0.5778 - val_model_4_accuracy: 0.6417 - val_loss1: 8.3177 - val_loss2: 8.8656\n","Epoch 215/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.0930 - model_loss: 0.0112 - model_1_loss: 0.0214 - model_2_loss: 0.0136 - model_3_loss: 0.0366 - model_4_loss: 0.0103 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5501 - loss2: 8.9625 - val_loss: 14.8543 - val_model_loss: 3.5853 - val_model_1_loss: 2.8626 - val_model_2_loss: 2.4915 - val_model_3_loss: 3.1369 - val_model_4_loss: 2.7780 - val_model_accuracy: 0.6222 - val_model_1_accuracy: 0.6167 - val_model_2_accuracy: 0.6417 - val_model_3_accuracy: 0.5833 - val_model_4_accuracy: 0.6444 - val_loss1: 8.2831 - val_loss2: 8.8592\n","Epoch 216/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3953 - model_loss: 0.0661 - model_1_loss: 0.0753 - model_2_loss: 0.0747 - model_3_loss: 0.0899 - model_4_loss: 0.0892 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.6616 - loss2: 9.0239 - val_loss: 14.4412 - val_model_loss: 3.4854 - val_model_1_loss: 2.7741 - val_model_2_loss: 2.3374 - val_model_3_loss: 3.1270 - val_model_4_loss: 2.7173 - val_model_accuracy: 0.6194 - val_model_1_accuracy: 0.6139 - val_model_2_accuracy: 0.6528 - val_model_3_accuracy: 0.5833 - val_model_4_accuracy: 0.6444 - val_loss1: 8.2659 - val_loss2: 8.8672\n","Epoch 217/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6114 - model_loss: 0.1221 - model_1_loss: 0.0546 - model_2_loss: 0.1316 - model_3_loss: 0.1237 - model_4_loss: 0.1794 - model_accuracy: 0.9333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.6486 - loss2: 8.9828 - val_loss: 13.9156 - val_model_loss: 3.3979 - val_model_1_loss: 2.6433 - val_model_2_loss: 2.1225 - val_model_3_loss: 3.0870 - val_model_4_loss: 2.6649 - val_model_accuracy: 0.6000 - val_model_1_accuracy: 0.6194 - val_model_2_accuracy: 0.6500 - val_model_3_accuracy: 0.5833 - val_model_4_accuracy: 0.6389 - val_loss1: 8.2755 - val_loss2: 8.9001\n","Epoch 218/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7059 - model_loss: 0.1583 - model_1_loss: 0.1085 - model_2_loss: 0.1014 - model_3_loss: 0.1659 - model_4_loss: 0.1718 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9333 - loss1: 8.5820 - loss2: 8.9239 - val_loss: 12.6358 - val_model_loss: 3.1258 - val_model_1_loss: 2.3823 - val_model_2_loss: 1.9588 - val_model_3_loss: 2.6509 - val_model_4_loss: 2.5180 - val_model_accuracy: 0.5889 - val_model_1_accuracy: 0.6306 - val_model_2_accuracy: 0.6444 - val_model_3_accuracy: 0.6167 - val_model_4_accuracy: 0.6167 - val_loss1: 8.2926 - val_loss2: 8.9108\n","Epoch 219/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6592 - model_loss: 0.1582 - model_1_loss: 0.0956 - model_2_loss: 0.1205 - model_3_loss: 0.1361 - model_4_loss: 0.1489 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.5333 - loss2: 8.8640 - val_loss: 12.0286 - val_model_loss: 3.0346 - val_model_1_loss: 2.1834 - val_model_2_loss: 2.0344 - val_model_3_loss: 2.3227 - val_model_4_loss: 2.4536 - val_model_accuracy: 0.5889 - val_model_1_accuracy: 0.6306 - val_model_2_accuracy: 0.6056 - val_model_3_accuracy: 0.6417 - val_model_4_accuracy: 0.5611 - val_loss1: 8.2627 - val_loss2: 8.8639\n","Epoch 220/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3793 - model_loss: 0.0647 - model_1_loss: 0.0775 - model_2_loss: 0.0891 - model_3_loss: 0.0805 - model_4_loss: 0.0676 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.4652 - loss2: 8.8411 - val_loss: 12.2047 - val_model_loss: 2.9823 - val_model_1_loss: 2.1759 - val_model_2_loss: 2.3850 - val_model_3_loss: 2.2411 - val_model_4_loss: 2.4204 - val_model_accuracy: 0.6250 - val_model_1_accuracy: 0.6167 - val_model_2_accuracy: 0.5583 - val_model_3_accuracy: 0.6222 - val_model_4_accuracy: 0.5778 - val_loss1: 8.2579 - val_loss2: 8.8165\n","Epoch 221/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1070 - model_loss: 0.0096 - model_1_loss: 0.0258 - model_2_loss: 0.0338 - model_3_loss: 0.0190 - model_4_loss: 0.0188 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4892 - loss2: 8.8608 - val_loss: 12.7930 - val_model_loss: 3.0362 - val_model_1_loss: 2.2153 - val_model_2_loss: 2.7000 - val_model_3_loss: 2.2847 - val_model_4_loss: 2.5569 - val_model_accuracy: 0.6361 - val_model_1_accuracy: 0.6333 - val_model_2_accuracy: 0.5556 - val_model_3_accuracy: 0.6083 - val_model_4_accuracy: 0.6056 - val_loss1: 8.2504 - val_loss2: 8.7898\n","Epoch 222/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1829 - model_loss: 0.0235 - model_1_loss: 0.0227 - model_2_loss: 0.0745 - model_3_loss: 0.0335 - model_4_loss: 0.0288 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5626 - loss2: 8.9119 - val_loss: 12.8833 - val_model_loss: 3.0394 - val_model_1_loss: 2.2307 - val_model_2_loss: 2.7424 - val_model_3_loss: 2.2163 - val_model_4_loss: 2.6546 - val_model_accuracy: 0.6667 - val_model_1_accuracy: 0.6417 - val_model_2_accuracy: 0.5861 - val_model_3_accuracy: 0.6222 - val_model_4_accuracy: 0.6528 - val_loss1: 8.2542 - val_loss2: 8.7948\n","Epoch 223/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4109 - model_loss: 0.0794 - model_1_loss: 0.0566 - model_2_loss: 0.1022 - model_3_loss: 0.0938 - model_4_loss: 0.0790 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.4315 - loss2: 8.8613 - val_loss: 12.7820 - val_model_loss: 3.0186 - val_model_1_loss: 2.2132 - val_model_2_loss: 2.6825 - val_model_3_loss: 2.1356 - val_model_4_loss: 2.7321 - val_model_accuracy: 0.6806 - val_model_1_accuracy: 0.6694 - val_model_2_accuracy: 0.6333 - val_model_3_accuracy: 0.6222 - val_model_4_accuracy: 0.6444 - val_loss1: 8.2684 - val_loss2: 8.8282\n","Epoch 224/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6520 - model_loss: 0.1167 - model_1_loss: 0.1012 - model_2_loss: 0.2256 - model_3_loss: 0.0999 - model_4_loss: 0.1086 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.5836 - loss2: 8.9063 - val_loss: 12.5353 - val_model_loss: 2.7654 - val_model_1_loss: 2.0540 - val_model_2_loss: 2.5816 - val_model_3_loss: 2.1233 - val_model_4_loss: 3.0110 - val_model_accuracy: 0.6139 - val_model_1_accuracy: 0.6778 - val_model_2_accuracy: 0.6222 - val_model_3_accuracy: 0.5889 - val_model_4_accuracy: 0.5778 - val_loss1: 8.2499 - val_loss2: 8.8874\n","Epoch 225/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.2876 - model_loss: 0.0403 - model_1_loss: 0.0536 - model_2_loss: 0.0463 - model_3_loss: 0.0843 - model_4_loss: 0.0632 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.5524 - loss2: 8.8544 - val_loss: 11.6092 - val_model_loss: 2.6879 - val_model_1_loss: 1.8641 - val_model_2_loss: 2.4838 - val_model_3_loss: 1.6469 - val_model_4_loss: 2.9265 - val_model_accuracy: 0.6028 - val_model_1_accuracy: 0.7028 - val_model_2_accuracy: 0.6167 - val_model_3_accuracy: 0.6750 - val_model_4_accuracy: 0.5889 - val_loss1: 8.2784 - val_loss2: 8.9515\n","Epoch 226/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.0748 - model_loss: 0.0194 - model_1_loss: 0.0141 - model_2_loss: 0.0117 - model_3_loss: 0.0202 - model_4_loss: 0.0094 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5269 - loss2: 8.8583 - val_loss: 11.6327 - val_model_loss: 2.5962 - val_model_1_loss: 1.8348 - val_model_2_loss: 2.4715 - val_model_3_loss: 1.8401 - val_model_4_loss: 2.8903 - val_model_accuracy: 0.6028 - val_model_1_accuracy: 0.6750 - val_model_2_accuracy: 0.5806 - val_model_3_accuracy: 0.5806 - val_model_4_accuracy: 0.5917 - val_loss1: 8.2527 - val_loss2: 8.9453\n","Epoch 227/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4555 - model_loss: 0.0415 - model_1_loss: 0.0230 - model_2_loss: 0.0568 - model_3_loss: 0.3185 - model_4_loss: 0.0157 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 1.0000 - loss1: 8.4575 - loss2: 8.8297 - val_loss: 11.4946 - val_model_loss: 2.4280 - val_model_1_loss: 1.8199 - val_model_2_loss: 2.5178 - val_model_3_loss: 1.9006 - val_model_4_loss: 2.8284 - val_model_accuracy: 0.6639 - val_model_1_accuracy: 0.6750 - val_model_2_accuracy: 0.5361 - val_model_3_accuracy: 0.6222 - val_model_4_accuracy: 0.6000 - val_loss1: 8.3208 - val_loss2: 8.9953\n","Epoch 228/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2302 - model_loss: 0.0595 - model_1_loss: 0.0359 - model_2_loss: 0.0552 - model_3_loss: 0.0332 - model_4_loss: 0.0464 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5787 - loss2: 8.9220 - val_loss: 11.8731 - val_model_loss: 2.5185 - val_model_1_loss: 1.7823 - val_model_2_loss: 2.6085 - val_model_3_loss: 2.3268 - val_model_4_loss: 2.6369 - val_model_accuracy: 0.6889 - val_model_1_accuracy: 0.6750 - val_model_2_accuracy: 0.5861 - val_model_3_accuracy: 0.6250 - val_model_4_accuracy: 0.6833 - val_loss1: 8.3910 - val_loss2: 8.9863\n","Epoch 229/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3012 - model_loss: 0.0785 - model_1_loss: 0.0394 - model_2_loss: 0.0465 - model_3_loss: 0.0848 - model_4_loss: 0.0519 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.4637 - loss2: 8.8426 - val_loss: 12.2604 - val_model_loss: 2.6978 - val_model_1_loss: 1.7337 - val_model_2_loss: 2.6789 - val_model_3_loss: 2.6553 - val_model_4_loss: 2.4948 - val_model_accuracy: 0.6639 - val_model_1_accuracy: 0.6861 - val_model_2_accuracy: 0.5833 - val_model_3_accuracy: 0.6194 - val_model_4_accuracy: 0.6889 - val_loss1: 8.3917 - val_loss2: 8.9268\n","Epoch 230/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3671 - model_loss: 0.0627 - model_1_loss: 0.0665 - model_2_loss: 0.0787 - model_3_loss: 0.1003 - model_4_loss: 0.0590 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 1.0000 - loss1: 8.5219 - loss2: 8.8623 - val_loss: 12.9284 - val_model_loss: 2.9729 - val_model_1_loss: 1.7760 - val_model_2_loss: 2.8100 - val_model_3_loss: 2.9267 - val_model_4_loss: 2.4428 - val_model_accuracy: 0.6556 - val_model_1_accuracy: 0.6944 - val_model_2_accuracy: 0.5972 - val_model_3_accuracy: 0.6333 - val_model_4_accuracy: 0.7000 - val_loss1: 8.3971 - val_loss2: 8.8557\n","Epoch 231/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7790 - model_loss: 0.1586 - model_1_loss: 0.1305 - model_2_loss: 0.1944 - model_3_loss: 0.1457 - model_4_loss: 0.1497 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.5042 - loss2: 8.8639 - val_loss: 13.0017 - val_model_loss: 3.1654 - val_model_1_loss: 1.7770 - val_model_2_loss: 2.4303 - val_model_3_loss: 3.1901 - val_model_4_loss: 2.4388 - val_model_accuracy: 0.6083 - val_model_1_accuracy: 0.6917 - val_model_2_accuracy: 0.6222 - val_model_3_accuracy: 0.6417 - val_model_4_accuracy: 0.6806 - val_loss1: 8.3611 - val_loss2: 8.7995\n","Epoch 232/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4351 - model_loss: 0.0864 - model_1_loss: 0.0563 - model_2_loss: 0.1156 - model_3_loss: 0.0923 - model_4_loss: 0.0845 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.7772 - loss2: 9.0210 - val_loss: 12.9869 - val_model_loss: 3.2915 - val_model_1_loss: 1.7272 - val_model_2_loss: 2.2054 - val_model_3_loss: 3.2834 - val_model_4_loss: 2.4793 - val_model_accuracy: 0.6250 - val_model_1_accuracy: 0.7056 - val_model_2_accuracy: 0.6389 - val_model_3_accuracy: 0.6472 - val_model_4_accuracy: 0.6722 - val_loss1: 8.3384 - val_loss2: 8.7716\n","Epoch 233/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1091 - model_loss: 0.0210 - model_1_loss: 0.0156 - model_2_loss: 0.0159 - model_3_loss: 0.0236 - model_4_loss: 0.0329 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5588 - loss2: 8.9517 - val_loss: 13.0401 - val_model_loss: 3.3407 - val_model_1_loss: 1.7267 - val_model_2_loss: 2.2412 - val_model_3_loss: 3.2637 - val_model_4_loss: 2.4678 - val_model_accuracy: 0.6361 - val_model_1_accuracy: 0.7056 - val_model_2_accuracy: 0.6444 - val_model_3_accuracy: 0.6500 - val_model_4_accuracy: 0.6722 - val_loss1: 8.3489 - val_loss2: 8.7671\n","Epoch 234/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7234 - model_loss: 0.1282 - model_1_loss: 0.1113 - model_2_loss: 0.1840 - model_3_loss: 0.1966 - model_4_loss: 0.1034 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.5602 - loss2: 8.9742 - val_loss: 12.2568 - val_model_loss: 3.0400 - val_model_1_loss: 1.6915 - val_model_2_loss: 2.3158 - val_model_3_loss: 2.8607 - val_model_4_loss: 2.3489 - val_model_accuracy: 0.6250 - val_model_1_accuracy: 0.6806 - val_model_2_accuracy: 0.6167 - val_model_3_accuracy: 0.6472 - val_model_4_accuracy: 0.6639 - val_loss1: 8.3855 - val_loss2: 8.8099\n","Epoch 235/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2770 - model_loss: 0.1178 - model_1_loss: 0.0331 - model_2_loss: 0.0496 - model_3_loss: 0.0370 - model_4_loss: 0.0396 - model_accuracy: 0.9333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5112 - loss2: 8.8891 - val_loss: 11.3412 - val_model_loss: 2.5364 - val_model_1_loss: 1.7411 - val_model_2_loss: 2.3022 - val_model_3_loss: 2.5394 - val_model_4_loss: 2.2221 - val_model_accuracy: 0.6056 - val_model_1_accuracy: 0.6944 - val_model_2_accuracy: 0.6028 - val_model_3_accuracy: 0.6417 - val_model_4_accuracy: 0.6528 - val_loss1: 8.4121 - val_loss2: 8.8745\n","Epoch 236/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3049 - model_loss: 0.1078 - model_1_loss: 0.0273 - model_2_loss: 0.0494 - model_3_loss: 0.0702 - model_4_loss: 0.0501 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.6954 - loss2: 9.0237 - val_loss: 10.8872 - val_model_loss: 2.2240 - val_model_1_loss: 1.8259 - val_model_2_loss: 2.2302 - val_model_3_loss: 2.4563 - val_model_4_loss: 2.1507 - val_model_accuracy: 0.6167 - val_model_1_accuracy: 0.6917 - val_model_2_accuracy: 0.6417 - val_model_3_accuracy: 0.6472 - val_model_4_accuracy: 0.6611 - val_loss1: 8.4088 - val_loss2: 8.8925\n","Epoch 237/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5740 - model_loss: 0.1964 - model_1_loss: 0.0482 - model_2_loss: 0.1414 - model_3_loss: 0.1381 - model_4_loss: 0.0500 - model_accuracy: 0.9333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9000 - model_4_accuracy: 1.0000 - loss1: 8.5224 - loss2: 8.8845 - val_loss: 10.8041 - val_model_loss: 2.3689 - val_model_1_loss: 1.9130 - val_model_2_loss: 2.1074 - val_model_3_loss: 2.2799 - val_model_4_loss: 2.1348 - val_model_accuracy: 0.6083 - val_model_1_accuracy: 0.6667 - val_model_2_accuracy: 0.6472 - val_model_3_accuracy: 0.6500 - val_model_4_accuracy: 0.6611 - val_loss1: 8.4372 - val_loss2: 8.9460\n","Epoch 238/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.6766 - model_loss: 0.1186 - model_1_loss: 0.0684 - model_2_loss: 0.1166 - model_3_loss: 0.1091 - model_4_loss: 0.2639 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.5100 - loss2: 8.8885 - val_loss: 11.1484 - val_model_loss: 2.5962 - val_model_1_loss: 1.9996 - val_model_2_loss: 2.0457 - val_model_3_loss: 2.1900 - val_model_4_loss: 2.3169 - val_model_accuracy: 0.5889 - val_model_1_accuracy: 0.6639 - val_model_2_accuracy: 0.6417 - val_model_3_accuracy: 0.6417 - val_model_4_accuracy: 0.6417 - val_loss1: 8.3944 - val_loss2: 8.9277\n","Epoch 239/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.6233 - model_loss: 0.2333 - model_1_loss: 0.0504 - model_2_loss: 0.0450 - model_3_loss: 0.1432 - model_4_loss: 0.1513 - model_accuracy: 0.9333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9667 - loss1: 8.5915 - loss2: 8.9565 - val_loss: 11.1364 - val_model_loss: 2.5215 - val_model_1_loss: 2.0585 - val_model_2_loss: 1.9958 - val_model_3_loss: 2.1505 - val_model_4_loss: 2.4101 - val_model_accuracy: 0.6389 - val_model_1_accuracy: 0.6556 - val_model_2_accuracy: 0.6250 - val_model_3_accuracy: 0.6278 - val_model_4_accuracy: 0.6250 - val_loss1: 8.3584 - val_loss2: 8.9119\n","Epoch 240/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5959 - model_loss: 0.1651 - model_1_loss: 0.0637 - model_2_loss: 0.0798 - model_3_loss: 0.1696 - model_4_loss: 0.1177 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9667 - loss1: 8.5053 - loss2: 8.9023 - val_loss: 10.6158 - val_model_loss: 2.2765 - val_model_1_loss: 2.0341 - val_model_2_loss: 1.8894 - val_model_3_loss: 1.9277 - val_model_4_loss: 2.4880 - val_model_accuracy: 0.6861 - val_model_1_accuracy: 0.6472 - val_model_2_accuracy: 0.6722 - val_model_3_accuracy: 0.6611 - val_model_4_accuracy: 0.6083 - val_loss1: 8.3253 - val_loss2: 8.8963\n","Epoch 241/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.2148 - model_loss: 0.0502 - model_1_loss: 0.0136 - model_2_loss: 0.0278 - model_3_loss: 0.0488 - model_4_loss: 0.0745 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.4856 - loss2: 8.8451 - val_loss: 10.9694 - val_model_loss: 2.1684 - val_model_1_loss: 1.9857 - val_model_2_loss: 1.8522 - val_model_3_loss: 1.7832 - val_model_4_loss: 3.1799 - val_model_accuracy: 0.6778 - val_model_1_accuracy: 0.6361 - val_model_2_accuracy: 0.6778 - val_model_3_accuracy: 0.6611 - val_model_4_accuracy: 0.5083 - val_loss1: 8.2567 - val_loss2: 8.8533\n","Epoch 242/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7300 - model_loss: 0.1949 - model_1_loss: 0.1147 - model_2_loss: 0.1912 - model_3_loss: 0.1380 - model_4_loss: 0.0911 - model_accuracy: 0.9000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.5091 - loss2: 8.8832 - val_loss: 10.9509 - val_model_loss: 2.3559 - val_model_1_loss: 1.8301 - val_model_2_loss: 1.7926 - val_model_3_loss: 1.7361 - val_model_4_loss: 3.2362 - val_model_accuracy: 0.6528 - val_model_1_accuracy: 0.6889 - val_model_2_accuracy: 0.6639 - val_model_3_accuracy: 0.6306 - val_model_4_accuracy: 0.5167 - val_loss1: 8.1797 - val_loss2: 8.7996\n","Epoch 243/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1772 - model_loss: 0.0856 - model_1_loss: 0.0084 - model_2_loss: 0.0144 - model_3_loss: 0.0392 - model_4_loss: 0.0296 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5191 - loss2: 8.8560 - val_loss: 12.1761 - val_model_loss: 3.5292 - val_model_1_loss: 2.1060 - val_model_2_loss: 2.1490 - val_model_3_loss: 1.8068 - val_model_4_loss: 2.5850 - val_model_accuracy: 0.6361 - val_model_1_accuracy: 0.6667 - val_model_2_accuracy: 0.6500 - val_model_3_accuracy: 0.6250 - val_model_4_accuracy: 0.5667 - val_loss1: 8.1272 - val_loss2: 8.7741\n","Epoch 244/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4850 - model_loss: 0.0662 - model_1_loss: 0.0519 - model_2_loss: 0.1039 - model_3_loss: 0.1386 - model_4_loss: 0.1244 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.3758 - loss2: 8.7850 - val_loss: 14.3149 - val_model_loss: 4.5182 - val_model_1_loss: 2.8336 - val_model_2_loss: 2.6194 - val_model_3_loss: 2.0286 - val_model_4_loss: 2.3151 - val_model_accuracy: 0.6194 - val_model_1_accuracy: 0.6500 - val_model_2_accuracy: 0.6528 - val_model_3_accuracy: 0.6417 - val_model_4_accuracy: 0.6222 - val_loss1: 8.0796 - val_loss2: 8.7129\n","Epoch 245/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.7458 - model_loss: 0.2201 - model_1_loss: 0.0678 - model_2_loss: 0.2169 - model_3_loss: 0.0797 - model_4_loss: 0.1613 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.4232 - loss2: 8.8392 - val_loss: 14.3296 - val_model_loss: 4.4121 - val_model_1_loss: 2.9574 - val_model_2_loss: 2.7771 - val_model_3_loss: 2.1710 - val_model_4_loss: 2.0119 - val_model_accuracy: 0.6222 - val_model_1_accuracy: 0.6500 - val_model_2_accuracy: 0.6417 - val_model_3_accuracy: 0.6583 - val_model_4_accuracy: 0.6472 - val_loss1: 8.1112 - val_loss2: 8.7640\n","Epoch 246/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.9512 - model_loss: 0.3466 - model_1_loss: 0.1146 - model_2_loss: 0.2406 - model_3_loss: 0.1313 - model_4_loss: 0.1181 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.4431 - loss2: 8.8251 - val_loss: 15.9711 - val_model_loss: 3.2923 - val_model_1_loss: 2.5456 - val_model_2_loss: 3.5792 - val_model_3_loss: 2.4037 - val_model_4_loss: 4.1503 - val_model_accuracy: 0.6000 - val_model_1_accuracy: 0.6028 - val_model_2_accuracy: 0.4750 - val_model_3_accuracy: 0.6417 - val_model_4_accuracy: 0.4222 - val_loss1: 8.1216 - val_loss2: 8.7172\n","Epoch 247/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.5186 - model_loss: 0.1170 - model_1_loss: 0.0487 - model_2_loss: 0.1071 - model_3_loss: 0.0569 - model_4_loss: 0.1889 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.4236 - loss2: 8.8013 - val_loss: 17.7231 - val_model_loss: 3.1589 - val_model_1_loss: 2.5418 - val_model_2_loss: 4.2464 - val_model_3_loss: 2.6726 - val_model_4_loss: 5.1034 - val_model_accuracy: 0.5917 - val_model_1_accuracy: 0.6472 - val_model_2_accuracy: 0.4667 - val_model_3_accuracy: 0.6333 - val_model_4_accuracy: 0.3889 - val_loss1: 8.1265 - val_loss2: 8.5769\n","Epoch 248/300\n","3/3 [==============================] - 5s 2s/step - loss: 1.2051 - model_loss: 0.2295 - model_1_loss: 0.1783 - model_2_loss: 0.2635 - model_3_loss: 0.1929 - model_4_loss: 0.3409 - model_accuracy: 0.9000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9000 - loss1: 8.4169 - loss2: 8.8160 - val_loss: 17.3927 - val_model_loss: 3.3560 - val_model_1_loss: 2.3467 - val_model_2_loss: 4.2581 - val_model_3_loss: 2.7869 - val_model_4_loss: 4.6450 - val_model_accuracy: 0.5861 - val_model_1_accuracy: 0.6778 - val_model_2_accuracy: 0.4972 - val_model_3_accuracy: 0.6194 - val_model_4_accuracy: 0.4639 - val_loss1: 8.1985 - val_loss2: 8.5431\n","Epoch 249/300\n","3/3 [==============================] - 5s 3s/step - loss: 2.2251 - model_loss: 0.4026 - model_1_loss: 0.3322 - model_2_loss: 0.4674 - model_3_loss: 0.4543 - model_4_loss: 0.5686 - model_accuracy: 0.8000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8000 - model_3_accuracy: 0.8000 - model_4_accuracy: 0.8333 - loss1: 8.3684 - loss2: 8.7744 - val_loss: 16.1876 - val_model_loss: 3.7147 - val_model_1_loss: 2.0275 - val_model_2_loss: 3.7571 - val_model_3_loss: 2.9415 - val_model_4_loss: 3.7468 - val_model_accuracy: 0.5278 - val_model_1_accuracy: 0.6778 - val_model_2_accuracy: 0.5167 - val_model_3_accuracy: 0.6139 - val_model_4_accuracy: 0.5250 - val_loss1: 8.2261 - val_loss2: 8.6196\n","Epoch 250/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.3882 - model_loss: 0.0805 - model_1_loss: 0.0294 - model_2_loss: 0.0845 - model_3_loss: 0.0196 - model_4_loss: 0.1742 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9000 - loss1: 8.3902 - loss2: 8.8090 - val_loss: 16.2784 - val_model_loss: 3.8270 - val_model_1_loss: 1.9529 - val_model_2_loss: 3.7203 - val_model_3_loss: 3.2701 - val_model_4_loss: 3.5080 - val_model_accuracy: 0.4778 - val_model_1_accuracy: 0.6444 - val_model_2_accuracy: 0.5472 - val_model_3_accuracy: 0.6111 - val_model_4_accuracy: 0.5528 - val_loss1: 8.2264 - val_loss2: 8.6778\n","Epoch 251/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.2279 - model_loss: 0.0743 - model_1_loss: 0.0351 - model_2_loss: 0.0460 - model_3_loss: 0.0246 - model_4_loss: 0.0479 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4839 - loss2: 8.8526 - val_loss: 17.4260 - val_model_loss: 3.7408 - val_model_1_loss: 2.1293 - val_model_2_loss: 4.0469 - val_model_3_loss: 3.4923 - val_model_4_loss: 4.0167 - val_model_accuracy: 0.4694 - val_model_1_accuracy: 0.6472 - val_model_2_accuracy: 0.4972 - val_model_3_accuracy: 0.6028 - val_model_4_accuracy: 0.6028 - val_loss1: 8.1569 - val_loss2: 8.5790\n","Epoch 252/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.8964 - model_loss: 0.3641 - model_1_loss: 0.0778 - model_2_loss: 0.1352 - model_3_loss: 0.1571 - model_4_loss: 0.1623 - model_accuracy: 0.8667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.5744 - loss2: 8.8894 - val_loss: 17.7784 - val_model_loss: 3.2074 - val_model_1_loss: 2.5315 - val_model_2_loss: 4.2067 - val_model_3_loss: 3.5634 - val_model_4_loss: 4.2694 - val_model_accuracy: 0.5389 - val_model_1_accuracy: 0.6111 - val_model_2_accuracy: 0.4722 - val_model_3_accuracy: 0.6056 - val_model_4_accuracy: 0.6389 - val_loss1: 8.1197 - val_loss2: 8.4150\n","Epoch 253/300\n","3/3 [==============================] - 5s 3s/step - loss: 1.1498 - model_loss: 0.2140 - model_1_loss: 0.1289 - model_2_loss: 0.2558 - model_3_loss: 0.1458 - model_4_loss: 0.4053 - model_accuracy: 0.9333 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.8333 - loss1: 8.5604 - loss2: 8.8338 - val_loss: 18.3593 - val_model_loss: 3.2119 - val_model_1_loss: 2.8790 - val_model_2_loss: 4.0672 - val_model_3_loss: 3.5492 - val_model_4_loss: 4.6520 - val_model_accuracy: 0.5583 - val_model_1_accuracy: 0.6111 - val_model_2_accuracy: 0.4611 - val_model_3_accuracy: 0.6167 - val_model_4_accuracy: 0.5639 - val_loss1: 8.0844 - val_loss2: 8.2587\n","Epoch 254/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.9918 - model_loss: 0.1218 - model_1_loss: 0.1174 - model_2_loss: 0.2603 - model_3_loss: 0.2632 - model_4_loss: 0.2290 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9000 - loss1: 8.4010 - loss2: 8.7505 - val_loss: 18.8973 - val_model_loss: 3.2152 - val_model_1_loss: 3.3751 - val_model_2_loss: 3.5505 - val_model_3_loss: 3.6361 - val_model_4_loss: 5.1205 - val_model_accuracy: 0.5222 - val_model_1_accuracy: 0.6667 - val_model_2_accuracy: 0.5111 - val_model_3_accuracy: 0.6278 - val_model_4_accuracy: 0.4611 - val_loss1: 8.0362 - val_loss2: 8.1305\n","Epoch 255/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.4404 - model_loss: 0.0531 - model_1_loss: 0.1045 - model_2_loss: 0.0870 - model_3_loss: 0.0712 - model_4_loss: 0.1246 - model_accuracy: 1.0000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.3772 - loss2: 8.7746 - val_loss: 18.6480 - val_model_loss: 3.2043 - val_model_1_loss: 3.2260 - val_model_2_loss: 3.3295 - val_model_3_loss: 3.4762 - val_model_4_loss: 5.4120 - val_model_accuracy: 0.5222 - val_model_1_accuracy: 0.6806 - val_model_2_accuracy: 0.4861 - val_model_3_accuracy: 0.6306 - val_model_4_accuracy: 0.4306 - val_loss1: 8.0420 - val_loss2: 8.0964\n","Epoch 256/300\n","3/3 [==============================] - 6s 3s/step - loss: 0.3180 - model_loss: 0.1136 - model_1_loss: 0.0292 - model_2_loss: 0.0613 - model_3_loss: 0.0330 - model_4_loss: 0.0809 - model_accuracy: 0.9333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4541 - loss2: 8.7609 - val_loss: 15.2991 - val_model_loss: 2.7270 - val_model_1_loss: 2.4756 - val_model_2_loss: 2.6950 - val_model_3_loss: 3.2287 - val_model_4_loss: 4.1728 - val_model_accuracy: 0.6083 - val_model_1_accuracy: 0.6833 - val_model_2_accuracy: 0.5722 - val_model_3_accuracy: 0.6417 - val_model_4_accuracy: 0.4944 - val_loss1: 8.0629 - val_loss2: 8.1819\n","Epoch 257/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2189 - model_loss: 0.0689 - model_1_loss: 0.0154 - model_2_loss: 0.0481 - model_3_loss: 0.0416 - model_4_loss: 0.0450 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4524 - loss2: 8.8187 - val_loss: 13.5871 - val_model_loss: 2.4597 - val_model_1_loss: 2.0263 - val_model_2_loss: 2.3994 - val_model_3_loss: 3.0105 - val_model_4_loss: 3.6912 - val_model_accuracy: 0.6444 - val_model_1_accuracy: 0.6889 - val_model_2_accuracy: 0.6472 - val_model_3_accuracy: 0.6556 - val_model_4_accuracy: 0.5500 - val_loss1: 8.0562 - val_loss2: 8.2440\n","Epoch 258/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1354 - model_loss: 0.0284 - model_1_loss: 0.0083 - model_2_loss: 0.0191 - model_3_loss: 0.0219 - model_4_loss: 0.0578 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.4449 - loss2: 8.7934 - val_loss: 12.6303 - val_model_loss: 2.2920 - val_model_1_loss: 1.7791 - val_model_2_loss: 2.2908 - val_model_3_loss: 2.8181 - val_model_4_loss: 3.4503 - val_model_accuracy: 0.6500 - val_model_1_accuracy: 0.6833 - val_model_2_accuracy: 0.6639 - val_model_3_accuracy: 0.6556 - val_model_4_accuracy: 0.5528 - val_loss1: 8.0625 - val_loss2: 8.3276\n","Epoch 259/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1856 - model_loss: 0.0251 - model_1_loss: 0.0126 - model_2_loss: 0.0193 - model_3_loss: 0.0545 - model_4_loss: 0.0742 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.5898 - loss2: 8.8935 - val_loss: 11.9917 - val_model_loss: 2.2367 - val_model_1_loss: 1.6506 - val_model_2_loss: 2.2635 - val_model_3_loss: 2.7017 - val_model_4_loss: 3.1393 - val_model_accuracy: 0.6528 - val_model_1_accuracy: 0.6833 - val_model_2_accuracy: 0.6694 - val_model_3_accuracy: 0.6694 - val_model_4_accuracy: 0.5778 - val_loss1: 8.1246 - val_loss2: 8.4139\n","Epoch 260/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.9056 - model_loss: 0.1143 - model_1_loss: 0.2575 - model_2_loss: 0.2069 - model_3_loss: 0.1031 - model_4_loss: 0.2239 - model_accuracy: 0.9667 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9667 - loss1: 8.4494 - loss2: 8.7959 - val_loss: 11.2699 - val_model_loss: 2.2072 - val_model_1_loss: 1.6339 - val_model_2_loss: 2.1575 - val_model_3_loss: 2.5497 - val_model_4_loss: 2.7216 - val_model_accuracy: 0.6583 - val_model_1_accuracy: 0.6639 - val_model_2_accuracy: 0.6667 - val_model_3_accuracy: 0.6861 - val_model_4_accuracy: 0.6000 - val_loss1: 8.2281 - val_loss2: 8.5622\n","Epoch 261/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4201 - model_loss: 0.0709 - model_1_loss: 0.0552 - model_2_loss: 0.1323 - model_3_loss: 0.0579 - model_4_loss: 0.1038 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.4922 - loss2: 8.8600 - val_loss: 11.0830 - val_model_loss: 2.1243 - val_model_1_loss: 2.0062 - val_model_2_loss: 2.0355 - val_model_3_loss: 2.4882 - val_model_4_loss: 2.4287 - val_model_accuracy: 0.6556 - val_model_1_accuracy: 0.5722 - val_model_2_accuracy: 0.6806 - val_model_3_accuracy: 0.6944 - val_model_4_accuracy: 0.6306 - val_loss1: 8.2403 - val_loss2: 8.5901\n","Epoch 262/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2869 - model_loss: 0.0463 - model_1_loss: 0.1003 - model_2_loss: 0.0631 - model_3_loss: 0.0344 - model_4_loss: 0.0427 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6145 - loss2: 8.9000 - val_loss: 10.8587 - val_model_loss: 2.2069 - val_model_1_loss: 1.9801 - val_model_2_loss: 2.0004 - val_model_3_loss: 2.4215 - val_model_4_loss: 2.2499 - val_model_accuracy: 0.5778 - val_model_1_accuracy: 0.6056 - val_model_2_accuracy: 0.6833 - val_model_3_accuracy: 0.6778 - val_model_4_accuracy: 0.6444 - val_loss1: 8.2410 - val_loss2: 8.5901\n","Epoch 263/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6573 - model_loss: 0.0617 - model_1_loss: 0.1305 - model_2_loss: 0.1026 - model_3_loss: 0.0646 - model_4_loss: 0.2979 - model_accuracy: 1.0000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9333 - loss1: 8.4982 - loss2: 8.8549 - val_loss: 11.1343 - val_model_loss: 2.2163 - val_model_1_loss: 1.9626 - val_model_2_loss: 2.0912 - val_model_3_loss: 2.4431 - val_model_4_loss: 2.4212 - val_model_accuracy: 0.5750 - val_model_1_accuracy: 0.6889 - val_model_2_accuracy: 0.6722 - val_model_3_accuracy: 0.6667 - val_model_4_accuracy: 0.6500 - val_loss1: 8.2235 - val_loss2: 8.5952\n","Epoch 264/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.7652 - model_loss: 0.0916 - model_1_loss: 0.0600 - model_2_loss: 0.2587 - model_3_loss: 0.1012 - model_4_loss: 0.2537 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.8667 - loss1: 8.5006 - loss2: 8.8126 - val_loss: 11.6284 - val_model_loss: 2.1863 - val_model_1_loss: 2.1639 - val_model_2_loss: 2.1829 - val_model_3_loss: 2.3865 - val_model_4_loss: 2.7087 - val_model_accuracy: 0.5778 - val_model_1_accuracy: 0.6556 - val_model_2_accuracy: 0.6667 - val_model_3_accuracy: 0.6528 - val_model_4_accuracy: 0.6472 - val_loss1: 8.2200 - val_loss2: 8.5686\n","Epoch 265/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.1970 - model_loss: 0.0289 - model_1_loss: 0.0308 - model_2_loss: 0.0584 - model_3_loss: 0.0403 - model_4_loss: 0.0387 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6008 - loss2: 8.8563 - val_loss: 12.2337 - val_model_loss: 2.0902 - val_model_1_loss: 2.3722 - val_model_2_loss: 2.2449 - val_model_3_loss: 2.3827 - val_model_4_loss: 3.1437 - val_model_accuracy: 0.6250 - val_model_1_accuracy: 0.6139 - val_model_2_accuracy: 0.6444 - val_model_3_accuracy: 0.6444 - val_model_4_accuracy: 0.5722 - val_loss1: 8.1956 - val_loss2: 8.5315\n","Epoch 266/300\n","3/3 [==============================] - 6s 3s/step - loss: 0.1225 - model_loss: 0.0159 - model_1_loss: 0.0395 - model_2_loss: 0.0230 - model_3_loss: 0.0207 - model_4_loss: 0.0234 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6004 - loss2: 8.8560 - val_loss: 13.0119 - val_model_loss: 2.0177 - val_model_1_loss: 2.5339 - val_model_2_loss: 2.3183 - val_model_3_loss: 2.3933 - val_model_4_loss: 3.7487 - val_model_accuracy: 0.6444 - val_model_1_accuracy: 0.5778 - val_model_2_accuracy: 0.6139 - val_model_3_accuracy: 0.6472 - val_model_4_accuracy: 0.5111 - val_loss1: 8.1556 - val_loss2: 8.5042\n","Epoch 267/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.6930 - model_loss: 0.0925 - model_1_loss: 0.1637 - model_2_loss: 0.1093 - model_3_loss: 0.1300 - model_4_loss: 0.1974 - model_accuracy: 0.9667 - model_1_accuracy: 0.9333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.5341 - loss2: 8.8512 - val_loss: 12.5055 - val_model_loss: 1.9096 - val_model_1_loss: 2.5027 - val_model_2_loss: 2.2725 - val_model_3_loss: 2.1934 - val_model_4_loss: 3.6274 - val_model_accuracy: 0.6472 - val_model_1_accuracy: 0.5806 - val_model_2_accuracy: 0.6194 - val_model_3_accuracy: 0.6556 - val_model_4_accuracy: 0.5028 - val_loss1: 8.1154 - val_loss2: 8.5508\n","Epoch 268/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.2217 - model_loss: 0.0450 - model_1_loss: 0.0289 - model_2_loss: 0.0655 - model_3_loss: 0.0324 - model_4_loss: 0.0498 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5724 - loss2: 8.8446 - val_loss: 12.2314 - val_model_loss: 1.8328 - val_model_1_loss: 2.7402 - val_model_2_loss: 2.2415 - val_model_3_loss: 2.0579 - val_model_4_loss: 3.3590 - val_model_accuracy: 0.6528 - val_model_1_accuracy: 0.6083 - val_model_2_accuracy: 0.6278 - val_model_3_accuracy: 0.6583 - val_model_4_accuracy: 0.5111 - val_loss1: 8.0658 - val_loss2: 8.5887\n","Epoch 269/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.4004 - model_loss: 0.0544 - model_1_loss: 0.0379 - model_2_loss: 0.0868 - model_3_loss: 0.0897 - model_4_loss: 0.1315 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 8.5742 - loss2: 8.8841 - val_loss: 13.4674 - val_model_loss: 1.9993 - val_model_1_loss: 3.0088 - val_model_2_loss: 2.5447 - val_model_3_loss: 2.3109 - val_model_4_loss: 3.6037 - val_model_accuracy: 0.6556 - val_model_1_accuracy: 0.6333 - val_model_2_accuracy: 0.6028 - val_model_3_accuracy: 0.6694 - val_model_4_accuracy: 0.5056 - val_loss1: 8.0940 - val_loss2: 8.5619\n","Epoch 270/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.8626 - model_loss: 0.1565 - model_1_loss: 0.2433 - model_2_loss: 0.1259 - model_3_loss: 0.1707 - model_4_loss: 0.1661 - model_accuracy: 0.9333 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9333 - loss1: 8.4643 - loss2: 8.8233 - val_loss: 13.9881 - val_model_loss: 2.2643 - val_model_1_loss: 2.4428 - val_model_2_loss: 2.9554 - val_model_3_loss: 2.7077 - val_model_4_loss: 3.6179 - val_model_accuracy: 0.6556 - val_model_1_accuracy: 0.6444 - val_model_2_accuracy: 0.5944 - val_model_3_accuracy: 0.6250 - val_model_4_accuracy: 0.5861 - val_loss1: 8.1665 - val_loss2: 8.6064\n","Epoch 271/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.4446 - model_loss: 0.0844 - model_1_loss: 0.1064 - model_2_loss: 0.0974 - model_3_loss: 0.0598 - model_4_loss: 0.0966 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.5170 - loss2: 8.8446 - val_loss: 13.6600 - val_model_loss: 2.2945 - val_model_1_loss: 2.2472 - val_model_2_loss: 2.9706 - val_model_3_loss: 2.9313 - val_model_4_loss: 3.2164 - val_model_accuracy: 0.6583 - val_model_1_accuracy: 0.6167 - val_model_2_accuracy: 0.6000 - val_model_3_accuracy: 0.6139 - val_model_4_accuracy: 0.6056 - val_loss1: 8.2061 - val_loss2: 8.6552\n","Epoch 272/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2854 - model_loss: 0.0641 - model_1_loss: 0.0447 - model_2_loss: 0.0723 - model_3_loss: 0.0433 - model_4_loss: 0.0610 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4565 - loss2: 8.8230 - val_loss: 13.3633 - val_model_loss: 2.2522 - val_model_1_loss: 2.2988 - val_model_2_loss: 2.8324 - val_model_3_loss: 3.0025 - val_model_4_loss: 2.9773 - val_model_accuracy: 0.6583 - val_model_1_accuracy: 0.5972 - val_model_2_accuracy: 0.6222 - val_model_3_accuracy: 0.6167 - val_model_4_accuracy: 0.6083 - val_loss1: 8.2074 - val_loss2: 8.6353\n","Epoch 273/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.0904 - model_loss: 0.0081 - model_1_loss: 0.0435 - model_2_loss: 0.0138 - model_3_loss: 0.0139 - model_4_loss: 0.0111 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6111 - loss2: 8.8610 - val_loss: 13.1274 - val_model_loss: 2.1630 - val_model_1_loss: 2.3880 - val_model_2_loss: 2.6883 - val_model_3_loss: 3.0196 - val_model_4_loss: 2.8684 - val_model_accuracy: 0.6639 - val_model_1_accuracy: 0.6000 - val_model_2_accuracy: 0.6194 - val_model_3_accuracy: 0.6222 - val_model_4_accuracy: 0.6111 - val_loss1: 8.2021 - val_loss2: 8.6095\n","Epoch 274/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.1187 - model_loss: 0.0288 - model_1_loss: 0.0176 - model_2_loss: 0.0253 - model_3_loss: 0.0294 - model_4_loss: 0.0176 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5106 - loss2: 8.8787 - val_loss: 13.0004 - val_model_loss: 2.0221 - val_model_1_loss: 2.5097 - val_model_2_loss: 2.5933 - val_model_3_loss: 3.0187 - val_model_4_loss: 2.8566 - val_model_accuracy: 0.6694 - val_model_1_accuracy: 0.6056 - val_model_2_accuracy: 0.6250 - val_model_3_accuracy: 0.6278 - val_model_4_accuracy: 0.6111 - val_loss1: 8.1841 - val_loss2: 8.5875\n","Epoch 275/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3228 - model_loss: 0.0740 - model_1_loss: 0.0748 - model_2_loss: 0.0345 - model_3_loss: 0.0892 - model_4_loss: 0.0504 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.6269 - loss2: 8.9128 - val_loss: 12.6476 - val_model_loss: 1.8506 - val_model_1_loss: 2.5975 - val_model_2_loss: 2.5014 - val_model_3_loss: 2.9020 - val_model_4_loss: 2.7960 - val_model_accuracy: 0.6694 - val_model_1_accuracy: 0.6111 - val_model_2_accuracy: 0.6139 - val_model_3_accuracy: 0.6333 - val_model_4_accuracy: 0.6111 - val_loss1: 8.1830 - val_loss2: 8.6000\n","Epoch 276/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2972 - model_loss: 0.0284 - model_1_loss: 0.0563 - model_2_loss: 0.0904 - model_3_loss: 0.0618 - model_4_loss: 0.0602 - model_accuracy: 1.0000 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.5777 - loss2: 8.8663 - val_loss: 12.4433 - val_model_loss: 1.7762 - val_model_1_loss: 2.6016 - val_model_2_loss: 2.5036 - val_model_3_loss: 2.7794 - val_model_4_loss: 2.7825 - val_model_accuracy: 0.6722 - val_model_1_accuracy: 0.6222 - val_model_2_accuracy: 0.6111 - val_model_3_accuracy: 0.6361 - val_model_4_accuracy: 0.6167 - val_loss1: 8.1954 - val_loss2: 8.6285\n","Epoch 277/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1192 - model_loss: 0.0134 - model_1_loss: 0.0168 - model_2_loss: 0.0244 - model_3_loss: 0.0203 - model_4_loss: 0.0444 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5619 - loss2: 8.8870 - val_loss: 12.1256 - val_model_loss: 1.7545 - val_model_1_loss: 2.5550 - val_model_2_loss: 2.4879 - val_model_3_loss: 2.7045 - val_model_4_loss: 2.6237 - val_model_accuracy: 0.6722 - val_model_1_accuracy: 0.6194 - val_model_2_accuracy: 0.6139 - val_model_3_accuracy: 0.6472 - val_model_4_accuracy: 0.6250 - val_loss1: 8.2199 - val_loss2: 8.6628\n","Epoch 278/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1116 - model_loss: 0.0157 - model_1_loss: 0.0244 - model_2_loss: 0.0214 - model_3_loss: 0.0221 - model_4_loss: 0.0281 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5707 - loss2: 8.8344 - val_loss: 11.8568 - val_model_loss: 1.7620 - val_model_1_loss: 2.5079 - val_model_2_loss: 2.4561 - val_model_3_loss: 2.6559 - val_model_4_loss: 2.4748 - val_model_accuracy: 0.6694 - val_model_1_accuracy: 0.6306 - val_model_2_accuracy: 0.6194 - val_model_3_accuracy: 0.6472 - val_model_4_accuracy: 0.6583 - val_loss1: 8.2350 - val_loss2: 8.6938\n","Epoch 279/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.2813 - model_loss: 0.0332 - model_1_loss: 0.0528 - model_2_loss: 0.0744 - model_3_loss: 0.0515 - model_4_loss: 0.0695 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.5376 - loss2: 8.8539 - val_loss: 11.7605 - val_model_loss: 1.7818 - val_model_1_loss: 2.4271 - val_model_2_loss: 2.4208 - val_model_3_loss: 2.6372 - val_model_4_loss: 2.4936 - val_model_accuracy: 0.6750 - val_model_1_accuracy: 0.6583 - val_model_2_accuracy: 0.6556 - val_model_3_accuracy: 0.6583 - val_model_4_accuracy: 0.6944 - val_loss1: 8.2455 - val_loss2: 8.7177\n","Epoch 280/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2271 - model_loss: 0.0242 - model_1_loss: 0.0407 - model_2_loss: 0.0468 - model_3_loss: 0.0313 - model_4_loss: 0.0842 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.5244 - loss2: 8.8664 - val_loss: 11.9062 - val_model_loss: 1.8384 - val_model_1_loss: 2.3154 - val_model_2_loss: 2.4529 - val_model_3_loss: 2.6605 - val_model_4_loss: 2.6389 - val_model_accuracy: 0.6750 - val_model_1_accuracy: 0.6722 - val_model_2_accuracy: 0.6611 - val_model_3_accuracy: 0.6639 - val_model_4_accuracy: 0.6694 - val_loss1: 8.2611 - val_loss2: 8.7207\n","Epoch 281/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2248 - model_loss: 0.0162 - model_1_loss: 0.0163 - model_2_loss: 0.0883 - model_3_loss: 0.0225 - model_4_loss: 0.0815 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5144 - loss2: 8.9434 - val_loss: 12.1598 - val_model_loss: 1.8900 - val_model_1_loss: 2.2735 - val_model_2_loss: 2.4844 - val_model_3_loss: 2.7115 - val_model_4_loss: 2.8004 - val_model_accuracy: 0.6639 - val_model_1_accuracy: 0.6806 - val_model_2_accuracy: 0.6639 - val_model_3_accuracy: 0.6556 - val_model_4_accuracy: 0.6361 - val_loss1: 8.2537 - val_loss2: 8.7298\n","Epoch 282/300\n","3/3 [==============================] - 5s 3s/step - loss: 0.1405 - model_loss: 0.0199 - model_1_loss: 0.0366 - model_2_loss: 0.0326 - model_3_loss: 0.0192 - model_4_loss: 0.0321 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4976 - loss2: 8.8521 - val_loss: 12.1174 - val_model_loss: 1.8616 - val_model_1_loss: 2.1760 - val_model_2_loss: 2.4146 - val_model_3_loss: 2.7473 - val_model_4_loss: 2.9179 - val_model_accuracy: 0.6694 - val_model_1_accuracy: 0.6806 - val_model_2_accuracy: 0.6556 - val_model_3_accuracy: 0.6472 - val_model_4_accuracy: 0.6361 - val_loss1: 8.2379 - val_loss2: 8.7491\n","Epoch 283/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.0678 - model_loss: 0.0146 - model_1_loss: 0.0173 - model_2_loss: 0.0116 - model_3_loss: 0.0081 - model_4_loss: 0.0162 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4800 - loss2: 8.8481 - val_loss: 12.2132 - val_model_loss: 1.8229 - val_model_1_loss: 2.0631 - val_model_2_loss: 2.3287 - val_model_3_loss: 2.7912 - val_model_4_loss: 3.2073 - val_model_accuracy: 0.6694 - val_model_1_accuracy: 0.6833 - val_model_2_accuracy: 0.6500 - val_model_3_accuracy: 0.6444 - val_model_4_accuracy: 0.6389 - val_loss1: 8.2078 - val_loss2: 8.7419\n","Epoch 284/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1730 - model_loss: 0.0351 - model_1_loss: 0.0356 - model_2_loss: 0.0494 - model_3_loss: 0.0325 - model_4_loss: 0.0203 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6287 - loss2: 8.9242 - val_loss: 12.1199 - val_model_loss: 1.7610 - val_model_1_loss: 1.9680 - val_model_2_loss: 2.2124 - val_model_3_loss: 2.7876 - val_model_4_loss: 3.3910 - val_model_accuracy: 0.6722 - val_model_1_accuracy: 0.6889 - val_model_2_accuracy: 0.6333 - val_model_3_accuracy: 0.6500 - val_model_4_accuracy: 0.6417 - val_loss1: 8.1722 - val_loss2: 8.7433\n","Epoch 285/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2546 - model_loss: 0.0497 - model_1_loss: 0.0358 - model_2_loss: 0.0495 - model_3_loss: 0.0410 - model_4_loss: 0.0787 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6064 - loss2: 8.9371 - val_loss: 12.5640 - val_model_loss: 1.7936 - val_model_1_loss: 2.0663 - val_model_2_loss: 2.3821 - val_model_3_loss: 2.8184 - val_model_4_loss: 3.5036 - val_model_accuracy: 0.6667 - val_model_1_accuracy: 0.6806 - val_model_2_accuracy: 0.5472 - val_model_3_accuracy: 0.6500 - val_model_4_accuracy: 0.6083 - val_loss1: 8.1716 - val_loss2: 8.7624\n","Epoch 286/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.0394 - model_loss: 0.0065 - model_1_loss: 0.0072 - model_2_loss: 0.0107 - model_3_loss: 0.0066 - model_4_loss: 0.0083 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5638 - loss2: 8.8580 - val_loss: 13.3301 - val_model_loss: 1.8285 - val_model_1_loss: 2.1980 - val_model_2_loss: 2.6945 - val_model_3_loss: 2.8372 - val_model_4_loss: 3.7718 - val_model_accuracy: 0.6667 - val_model_1_accuracy: 0.6583 - val_model_2_accuracy: 0.5361 - val_model_3_accuracy: 0.6361 - val_model_4_accuracy: 0.5500 - val_loss1: 8.1658 - val_loss2: 8.7719\n","Epoch 287/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4351 - model_loss: 0.0870 - model_1_loss: 0.0617 - model_2_loss: 0.0772 - model_3_loss: 0.0932 - model_4_loss: 0.1159 - model_accuracy: 0.9667 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.4707 - loss2: 8.8138 - val_loss: 14.1834 - val_model_loss: 2.0620 - val_model_1_loss: 2.4197 - val_model_2_loss: 2.9159 - val_model_3_loss: 2.8979 - val_model_4_loss: 3.8880 - val_model_accuracy: 0.6333 - val_model_1_accuracy: 0.5944 - val_model_2_accuracy: 0.5333 - val_model_3_accuracy: 0.6333 - val_model_4_accuracy: 0.5306 - val_loss1: 8.1768 - val_loss2: 8.7813\n","Epoch 288/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1014 - model_loss: 0.0168 - model_1_loss: 0.0136 - model_2_loss: 0.0355 - model_3_loss: 0.0159 - model_4_loss: 0.0196 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5228 - loss2: 8.8649 - val_loss: 14.5519 - val_model_loss: 2.2748 - val_model_1_loss: 2.6344 - val_model_2_loss: 2.9340 - val_model_3_loss: 2.9113 - val_model_4_loss: 3.7974 - val_model_accuracy: 0.5889 - val_model_1_accuracy: 0.5806 - val_model_2_accuracy: 0.5306 - val_model_3_accuracy: 0.6222 - val_model_4_accuracy: 0.5306 - val_loss1: 8.1998 - val_loss2: 8.8002\n","Epoch 289/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.0497 - model_loss: 0.0039 - model_1_loss: 0.0083 - model_2_loss: 0.0144 - model_3_loss: 0.0051 - model_4_loss: 0.0181 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6834 - loss2: 8.9764 - val_loss: 14.5421 - val_model_loss: 2.4671 - val_model_1_loss: 2.7566 - val_model_2_loss: 2.8171 - val_model_3_loss: 2.9065 - val_model_4_loss: 3.5947 - val_model_accuracy: 0.5750 - val_model_1_accuracy: 0.5639 - val_model_2_accuracy: 0.5306 - val_model_3_accuracy: 0.6222 - val_model_4_accuracy: 0.5333 - val_loss1: 8.2203 - val_loss2: 8.8208\n","Epoch 290/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.5254 - model_loss: 0.1145 - model_1_loss: 0.0452 - model_2_loss: 0.1963 - model_3_loss: 0.0485 - model_4_loss: 0.1208 - model_accuracy: 0.9333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.5917 - loss2: 8.9355 - val_loss: 13.3717 - val_model_loss: 2.5259 - val_model_1_loss: 2.3840 - val_model_2_loss: 2.4250 - val_model_3_loss: 2.8088 - val_model_4_loss: 3.2280 - val_model_accuracy: 0.6417 - val_model_1_accuracy: 0.6278 - val_model_2_accuracy: 0.5361 - val_model_3_accuracy: 0.6250 - val_model_4_accuracy: 0.5389 - val_loss1: 8.3016 - val_loss2: 8.8653\n","Epoch 291/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1691 - model_loss: 0.0442 - model_1_loss: 0.0171 - model_2_loss: 0.0548 - model_3_loss: 0.0343 - model_4_loss: 0.0187 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.7392 - loss2: 9.0125 - val_loss: 12.8579 - val_model_loss: 2.6600 - val_model_1_loss: 2.3062 - val_model_2_loss: 2.2493 - val_model_3_loss: 2.7032 - val_model_4_loss: 2.9392 - val_model_accuracy: 0.6389 - val_model_1_accuracy: 0.6417 - val_model_2_accuracy: 0.6222 - val_model_3_accuracy: 0.6306 - val_model_4_accuracy: 0.5889 - val_loss1: 8.3421 - val_loss2: 8.8676\n","Epoch 292/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6470 - model_loss: 0.1647 - model_1_loss: 0.0920 - model_2_loss: 0.1334 - model_3_loss: 0.0710 - model_4_loss: 0.1859 - model_accuracy: 0.9333 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9333 - loss1: 8.5460 - loss2: 8.9053 - val_loss: 11.7855 - val_model_loss: 2.6711 - val_model_1_loss: 2.1305 - val_model_2_loss: 2.0516 - val_model_3_loss: 2.5095 - val_model_4_loss: 2.4229 - val_model_accuracy: 0.5528 - val_model_1_accuracy: 0.6583 - val_model_2_accuracy: 0.6611 - val_model_3_accuracy: 0.6500 - val_model_4_accuracy: 0.6500 - val_loss1: 8.3746 - val_loss2: 8.8800\n","Epoch 293/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.3137 - model_loss: 0.1311 - model_1_loss: 0.0437 - model_2_loss: 0.0514 - model_3_loss: 0.0562 - model_4_loss: 0.0313 - model_accuracy: 0.9333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.6706 - loss2: 8.9636 - val_loss: 10.6604 - val_model_loss: 2.6251 - val_model_1_loss: 1.8498 - val_model_2_loss: 1.8562 - val_model_3_loss: 2.2693 - val_model_4_loss: 2.0599 - val_model_accuracy: 0.5556 - val_model_1_accuracy: 0.6778 - val_model_2_accuracy: 0.6750 - val_model_3_accuracy: 0.6611 - val_model_4_accuracy: 0.6889 - val_loss1: 8.4070 - val_loss2: 8.9176\n","Epoch 294/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1516 - model_loss: 0.0133 - model_1_loss: 0.0133 - model_2_loss: 0.0505 - model_3_loss: 0.0088 - model_4_loss: 0.0655 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 8.6829 - loss2: 8.9593 - val_loss: 10.0818 - val_model_loss: 2.5757 - val_model_1_loss: 1.6879 - val_model_2_loss: 1.7075 - val_model_3_loss: 2.1775 - val_model_4_loss: 1.9332 - val_model_accuracy: 0.5667 - val_model_1_accuracy: 0.6639 - val_model_2_accuracy: 0.6639 - val_model_3_accuracy: 0.6639 - val_model_4_accuracy: 0.6444 - val_loss1: 8.4149 - val_loss2: 8.9386\n","Epoch 295/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1366 - model_loss: 0.0100 - model_1_loss: 0.0135 - model_2_loss: 0.0632 - model_3_loss: 0.0120 - model_4_loss: 0.0380 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6233 - loss2: 8.9349 - val_loss: 9.6671 - val_model_loss: 2.4595 - val_model_1_loss: 1.5742 - val_model_2_loss: 1.6292 - val_model_3_loss: 2.0956 - val_model_4_loss: 1.9086 - val_model_accuracy: 0.5861 - val_model_1_accuracy: 0.6833 - val_model_2_accuracy: 0.6667 - val_model_3_accuracy: 0.6694 - val_model_4_accuracy: 0.6111 - val_loss1: 8.4149 - val_loss2: 8.9473\n","Epoch 296/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.4861 - model_loss: 0.2082 - model_1_loss: 0.0419 - model_2_loss: 0.1060 - model_3_loss: 0.0483 - model_4_loss: 0.0817 - model_accuracy: 0.8667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.7011 - loss2: 8.9740 - val_loss: 8.5251 - val_model_loss: 1.7364 - val_model_1_loss: 1.4104 - val_model_2_loss: 1.6453 - val_model_3_loss: 1.9916 - val_model_4_loss: 1.7414 - val_model_accuracy: 0.6861 - val_model_1_accuracy: 0.7139 - val_model_2_accuracy: 0.6778 - val_model_3_accuracy: 0.6722 - val_model_4_accuracy: 0.6083 - val_loss1: 8.4115 - val_loss2: 9.0001\n","Epoch 297/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.0648 - model_loss: 0.0112 - model_1_loss: 0.0050 - model_2_loss: 0.0231 - model_3_loss: 0.0052 - model_4_loss: 0.0203 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5824 - loss2: 8.9075 - val_loss: 8.2009 - val_model_loss: 1.6303 - val_model_1_loss: 1.3438 - val_model_2_loss: 1.7288 - val_model_3_loss: 1.9156 - val_model_4_loss: 1.5824 - val_model_accuracy: 0.6972 - val_model_1_accuracy: 0.7361 - val_model_2_accuracy: 0.6667 - val_model_3_accuracy: 0.6750 - val_model_4_accuracy: 0.6278 - val_loss1: 8.3936 - val_loss2: 9.0282\n","Epoch 298/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.6766 - model_loss: 0.1906 - model_1_loss: 0.1059 - model_2_loss: 0.1605 - model_3_loss: 0.0999 - model_4_loss: 0.1196 - model_accuracy: 0.9000 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9667 - loss1: 8.5180 - loss2: 8.8299 - val_loss: 7.9254 - val_model_loss: 1.5822 - val_model_1_loss: 1.3297 - val_model_2_loss: 1.7567 - val_model_3_loss: 1.8067 - val_model_4_loss: 1.4501 - val_model_accuracy: 0.7000 - val_model_1_accuracy: 0.7417 - val_model_2_accuracy: 0.6667 - val_model_3_accuracy: 0.6778 - val_model_4_accuracy: 0.6944 - val_loss1: 8.3870 - val_loss2: 9.0507\n","Epoch 299/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.1418 - model_loss: 0.0604 - model_1_loss: 0.0124 - model_2_loss: 0.0395 - model_3_loss: 0.0135 - model_4_loss: 0.0161 - model_accuracy: 0.9667 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6360 - loss2: 8.9194 - val_loss: 7.9777 - val_model_loss: 1.6121 - val_model_1_loss: 1.3880 - val_model_2_loss: 1.8346 - val_model_3_loss: 1.7388 - val_model_4_loss: 1.4042 - val_model_accuracy: 0.6972 - val_model_1_accuracy: 0.7111 - val_model_2_accuracy: 0.6528 - val_model_3_accuracy: 0.6583 - val_model_4_accuracy: 0.7306 - val_loss1: 8.3667 - val_loss2: 9.0593\n","Epoch 300/300\n","3/3 [==============================] - 5s 2s/step - loss: 0.2735 - model_loss: 0.0481 - model_1_loss: 0.0218 - model_2_loss: 0.1268 - model_3_loss: 0.0545 - model_4_loss: 0.0224 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9667 - model_4_accuracy: 1.0000 - loss1: 8.5897 - loss2: 8.8673 - val_loss: 8.1060 - val_model_loss: 1.6275 - val_model_1_loss: 1.3999 - val_model_2_loss: 1.8720 - val_model_3_loss: 1.7753 - val_model_4_loss: 1.4312 - val_model_accuracy: 0.6944 - val_model_1_accuracy: 0.7139 - val_model_2_accuracy: 0.6528 - val_model_3_accuracy: 0.6389 - val_model_4_accuracy: 0.7333 - val_loss1: 8.3566 - val_loss2: 9.0599\n","Epoch 00150: early stopping and save the model\n"]}],"source":["#construct joint training for the five base models\n","input_size = (200, 200, 3)\n","model0 = create_ResNet(input_shape=input_size, num_classes=6, num_filters = 64, random_seed=1)\n","model1 = create_ResNet(input_shape=input_size, num_classes=6, num_filters = 64, random_seed=2)\n","model2 = create_ResNet(input_shape=input_size, num_classes=6, num_filters = 64, random_seed=3)\n","model3 = create_ResNet(input_shape=input_size, num_classes=6, num_filters = 64, random_seed=4)\n","model4 = create_ResNet(input_shape=input_size, num_classes=6, num_filters = 64, random_seed=5)\n","allinputs = keras.Input(shape=input_size)\n","output0, feature_maps0 = model0(allinputs)\n","output1, feature_maps1 = model1(allinputs)\n","output2, feature_maps2 = model2(allinputs)\n","output3, feature_maps3 = model3(allinputs)\n","output4, feature_maps4 = model4(allinputs)\n","model_train = keras.Model(\n","    inputs=allinputs, outputs=[output0, output1, output2, output3, output4])\n","\n","#implement distance loss\n","loss1, loss2, loss = cosine_euclidean_sum_loss(x=[feature_maps0, feature_maps1, feature_maps2, feature_maps3, feature_maps4], \n","                                      cosine_weight=1, euclidean_weight=10, mask=True, max_norm=False)\n","\n","model_train.add_loss(loss)\n","model_train.add_metric(loss1, name=\"loss1\", aggregation='mean')\n","model_train.add_metric(loss2, name=\"loss2\", aggregation='mean')\n","\n","model_train.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                    loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'],\n","                    metrics=['accuracy'])\n","\n","#construct training and validation samples\n","train_sequence = NEUdata(x_train, y_train, batch_size=10, train=True)\n","validation_sequence = NEUdata(x_val, y_val, batch_size=10, train=False)\n","\n","#training \n","history = model_train.fit(\n","    train_sequence,\n","    epochs=300,\n","    validation_data=validation_sequence,\n","    #validation_steps=36,\n","    callbacks=CustomEarlyStoppingAndSave(\n","        save_path='100_samples_seed_fix.h5',\n","        patience=10))\n","frame = pd.DataFrame({\n","    'loss':\n","    history.history['loss'],\n","    'loss1':\n","    history.history['loss1'],\n","    'loss2':\n","    history.history['loss2'],\n","    'model_0_loss':\n","    history.history['model_loss'],\n","    'model_1_loss':\n","    history.history['model_1_loss'],\n","    'model_2_loss':\n","    history.history['model_2_loss'],\n","    'model_3_loss':\n","    history.history['model_3_loss'],\n","    'model_4_loss':\n","    history.history['model_4_loss'],\n","    'model_0_accuracy':\n","    history.history['model_accuracy'],\n","    'model_1_accuracy':\n","    history.history['model_1_accuracy'],\n","    'model_2_accuracy':\n","    history.history['model_2_accuracy'],\n","    'model_3_accuracy':\n","    history.history['model_3_accuracy'],\n","    'model_4_accuracy':\n","    history.history['model_4_accuracy'],\n","    'val_loss':\n","    history.history['val_loss'],\n","    'val_loss1':\n","    history.history['val_loss1'],\n","    'val_loss2':\n","    history.history['val_loss2'],\n","    'val_model_0_loss':\n","    history.history['val_model_loss'],\n","    'val_model_1_loss':\n","    history.history['val_model_1_loss'],\n","    'val_model_2_loss':\n","    history.history['val_model_2_loss'],\n","    'val_model_3_loss':\n","    history.history['val_model_3_loss'],\n","    'val_model_4_loss':\n","    history.history['val_model_4_loss'],\n","    'val_model_0_accuracy':\n","    history.history['val_model_accuracy'],\n","    'val_model_1_accuracy':\n","    history.history['val_model_1_accuracy'],\n","    'val_model_2_accuracy':\n","    history.history['val_model_2_accuracy'],\n","    'val_model_3_accuracy':\n","    history.history['val_model_3_accuracy'],\n","    'val_model_4_accuracy':\n","    history.history['val_model_4_accuracy'],\n","})\n","#frame.to_excel('table_{numsample}_samples_seed_{numseed}.xlsx'.format(numsample=100, numseed='fix'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8Q68bw0VAfd","executionInfo":{"status":"ok","timestamp":1650577567317,"user_tz":-120,"elapsed":7305,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"3075c824-eb89-4138-d5a1-57deccc2fc46"},"outputs":[{"output_type":"stream","name":"stdout","text":["36/36 [==============================] - 7s 121ms/step - loss: 13.5281 - model_loss: 2.3241 - model_1_loss: 2.2965 - model_2_loss: 2.5084 - model_3_loss: 3.3708 - model_4_loss: 3.0284 - model_accuracy: 0.5889 - model_1_accuracy: 0.5722 - model_2_accuracy: 0.5667 - model_3_accuracy: 0.4028 - model_4_accuracy: 0.5889 - loss1: 8.0744 - loss2: 8.8353\n"]}],"source":["#evaluation of the five base models\n","evaluate = model_train.evaluate(x_test,[keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test)],batch_size=10)\n","evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mW1xEi9mVP08","executionInfo":{"status":"ok","timestamp":1650577574921,"user_tz":-120,"elapsed":7605,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"cc4599e5-7625-4f4c-f861-9268546f2c74"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5805555555555556"]},"metadata":{},"execution_count":12}],"source":["#hard voting ensemble\n","class HardVotingEnsemble:\n","    def __init__(self, model, testdata ,batch_size):\n","        self.ensemble_model = model\n","        self.testdata = testdata\n","        self.batch_size = batch_size\n","        self.data_size = testdata[1].shape[0]\n","    def prediction(self):\n","        predictions =[]\n","        for i in range(int(self.data_size/self.batch_size)):\n","            batch_predictions = np.argmax(self.ensemble_model.predict(self.testdata[0][i*self.batch_size:(i+1)*self.batch_size]),axis=2) \n","            batch_predictions = np.stack(batch_predictions, axis=1)\n","            batch_predictions = [np.argmax(np.bincount(pre)) for pre in batch_predictions]\n","            predictions = predictions+batch_predictions\n","        return np.array(predictions)\n","\n","    def evaluate(self):\n","        predictions = self.prediction()\n","        accuracy = np.sum(\n","            predictions == self.testdata[1]) / self.data_size\n","        return accuracy\n","HEnsemble = HardVotingEnsemble(model = model_train,testdata = (x_test, y_test),batch_size=10)\n","HEnsemble.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p79zKgdTxTgO","executionInfo":{"status":"ok","timestamp":1650577580069,"user_tz":-120,"elapsed":5150,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"67743e81-7640-46be-dcad-d53809b6758e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5722222222222222"]},"metadata":{},"execution_count":13}],"source":["#soft voting ensemble\n","def SoftVotingEnsemble(model, x, y):\n","  data_size = x.shape[0]\n","  predictions = tf.argmax(tf.reduce_mean(model.predict(x), axis = 0),axis=1)\n","  accuracy = np.sum(\n","     predictions == y) / data_size\n","  return accuracy\n","SoftVotingEnsemble(model_train, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ML_FZOLCe79"},"outputs":[],"source":["class eCustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(eCustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_accuracy') \n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        #self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXwnG-CQCfbJ"},"outputs":[],"source":["class eNEUdata(keras.utils.Sequence):\n","    def __init__(self, data_x, data_y, batch_size, train):\n","      self.data_x = data_x\n","      self.data_y = data_y\n","      self.train = train\n","      self.batch_size = batch_size\n","\n","    def __len__(self):\n","      return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","      batch_x = self.data_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n","                            \n","      batch_y = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n","      if self.train == True:\n","          batch_x = Data_Aug(batch_x)\n","\n","      batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","      batch_y = keras.utils.to_categorical(batch_y, 6)\n","      return batch_x, batch_y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oql4eIoXC5mF","executionInfo":{"status":"ok","timestamp":1650578974939,"user_tz":-120,"elapsed":260569,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"1897566f-a0bb-469a-dd11-6531c5b81a1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","3/3 [==============================] - 10s 3s/step - loss: 1.5645 - accuracy: 0.4000 - val_loss: 4.0553 - val_accuracy: 0.3111\n","Epoch 2/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.6118 - accuracy: 0.8000 - val_loss: 3.8166 - val_accuracy: 0.4222\n","Epoch 3/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.6643 - accuracy: 0.8000 - val_loss: 3.5200 - val_accuracy: 0.4639\n","Epoch 4/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.8118 - accuracy: 0.7000 - val_loss: 3.4091 - val_accuracy: 0.4722\n","Epoch 5/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.6714 - accuracy: 0.8000 - val_loss: 3.3559 - val_accuracy: 0.4861\n","Epoch 6/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.4617 - accuracy: 0.9000 - val_loss: 3.0584 - val_accuracy: 0.4944\n","Epoch 7/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.3431 - accuracy: 0.9667 - val_loss: 2.8566 - val_accuracy: 0.4944\n","Epoch 8/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.4097 - accuracy: 0.9000 - val_loss: 2.7821 - val_accuracy: 0.4889\n","Epoch 9/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2677 - accuracy: 0.9000 - val_loss: 2.6997 - val_accuracy: 0.4889\n","Epoch 10/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2029 - accuracy: 0.9667 - val_loss: 2.5756 - val_accuracy: 0.4972\n","Epoch 11/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.4046 - accuracy: 0.8333 - val_loss: 2.4653 - val_accuracy: 0.5139\n","Epoch 12/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1810 - accuracy: 1.0000 - val_loss: 2.3707 - val_accuracy: 0.5194\n","Epoch 13/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2283 - accuracy: 0.9667 - val_loss: 2.2717 - val_accuracy: 0.5278\n","Epoch 14/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.3910 - accuracy: 0.8667 - val_loss: 2.1917 - val_accuracy: 0.5250\n","Epoch 15/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 2.1107 - val_accuracy: 0.5306\n","Epoch 16/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 2.0812 - val_accuracy: 0.5278\n","Epoch 17/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1421 - accuracy: 0.9667 - val_loss: 2.0405 - val_accuracy: 0.5222\n","Epoch 18/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.3018 - accuracy: 0.9333 - val_loss: 2.0072 - val_accuracy: 0.5306\n","Epoch 19/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.3096 - accuracy: 0.9000 - val_loss: 1.9444 - val_accuracy: 0.5389\n","Epoch 20/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2560 - accuracy: 0.9333 - val_loss: 1.8916 - val_accuracy: 0.5389\n","Epoch 21/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2182 - accuracy: 0.9667 - val_loss: 1.8484 - val_accuracy: 0.5417\n","Epoch 22/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.4095 - accuracy: 0.8667 - val_loss: 1.7887 - val_accuracy: 0.5528\n","Epoch 23/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2816 - accuracy: 0.9333 - val_loss: 1.7280 - val_accuracy: 0.5639\n","Epoch 24/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 1.6742 - val_accuracy: 0.5861\n","Epoch 25/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2687 - accuracy: 0.8667 - val_loss: 1.6310 - val_accuracy: 0.5972\n","Epoch 26/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2085 - accuracy: 0.9667 - val_loss: 1.6045 - val_accuracy: 0.6000\n","Epoch 27/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.3071 - accuracy: 0.9667 - val_loss: 1.5949 - val_accuracy: 0.5972\n","Epoch 28/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1525 - accuracy: 1.0000 - val_loss: 1.5848 - val_accuracy: 0.6083\n","Epoch 29/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2680 - accuracy: 0.9000 - val_loss: 1.5709 - val_accuracy: 0.6139\n","Epoch 30/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 1.5489 - val_accuracy: 0.6167\n","Epoch 31/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1724 - accuracy: 0.9667 - val_loss: 1.5280 - val_accuracy: 0.6250\n","Epoch 32/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.3054 - accuracy: 0.9000 - val_loss: 1.5015 - val_accuracy: 0.6194\n","Epoch 33/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 1.4681 - val_accuracy: 0.6194\n","Epoch 34/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2664 - accuracy: 0.9333 - val_loss: 1.4685 - val_accuracy: 0.6139\n","Epoch 35/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2278 - accuracy: 0.9667 - val_loss: 1.4792 - val_accuracy: 0.5917\n","Epoch 36/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 1.4879 - val_accuracy: 0.5861\n","Epoch 37/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2268 - accuracy: 0.9667 - val_loss: 1.4952 - val_accuracy: 0.5750\n","Epoch 38/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1285 - accuracy: 1.0000 - val_loss: 1.4868 - val_accuracy: 0.5639\n","Epoch 39/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1283 - accuracy: 0.9667 - val_loss: 1.4644 - val_accuracy: 0.5694\n","Epoch 40/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1480 - accuracy: 0.9667 - val_loss: 1.4503 - val_accuracy: 0.5833\n","Epoch 41/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1140 - accuracy: 0.9667 - val_loss: 1.4217 - val_accuracy: 0.5861\n","Epoch 42/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1111 - accuracy: 0.9667 - val_loss: 1.4024 - val_accuracy: 0.5889\n","Epoch 43/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.2766 - accuracy: 0.9333 - val_loss: 1.3778 - val_accuracy: 0.5833\n","Epoch 44/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1518 - accuracy: 0.9333 - val_loss: 1.3428 - val_accuracy: 0.5889\n","Epoch 45/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.3785 - accuracy: 0.8333 - val_loss: 1.3205 - val_accuracy: 0.6028\n","Epoch 46/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1944 - accuracy: 0.9333 - val_loss: 1.3035 - val_accuracy: 0.6139\n","Epoch 47/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1727 - accuracy: 0.9667 - val_loss: 1.2883 - val_accuracy: 0.6389\n","Epoch 48/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1267 - accuracy: 0.9333 - val_loss: 1.2826 - val_accuracy: 0.6472\n","Epoch 49/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.0913 - accuracy: 1.0000 - val_loss: 1.2790 - val_accuracy: 0.6556\n","Epoch 50/50\n","3/3 [==============================] - 5s 2s/step - loss: 0.1237 - accuracy: 0.9667 - val_loss: 1.2748 - val_accuracy: 0.6611\n","Epoch 00050: early stopping and save the model\n","12/12 [==============================] - 5s 288ms/step - loss: 1.6132 - accuracy: 0.6028\n"]}],"source":["#feature fusion model\n","input_size = (200, 200, 3)\n","model_path = '100_samples_seed_fix.h5'\n","model = keras.models.load_model(model_path)\n","extractor_1 = keras.models.Model(inputs=model.layers[1].inputs,outputs=model.layers[1].layers[56].output)\n","extractor_2 = keras.models.Model(inputs=model.layers[2].inputs,outputs=model.layers[2].layers[56].output)\n","extractor_3 = keras.models.Model(inputs=model.layers[3].inputs,outputs=model.layers[3].layers[56].output)\n","extractor_4 = keras.models.Model(inputs=model.layers[4].inputs,outputs=model.layers[4].layers[56].output)\n","extractor_5 = keras.models.Model(inputs=model.layers[5].inputs,outputs=model.layers[5].layers[56].output)\n","extractor_1.trainable = False\n","extractor_2.trainable = False\n","extractor_3.trainable = False\n","extractor_4.trainable = False\n","extractor_5.trainable = False\n","inputs = keras.Input(shape = input_size)\n","features_1 = extractor_1(inputs, training = False)\n","features_2 = extractor_2(inputs, training = False)\n","features_3 = extractor_3(inputs, training = False)\n","features_4 = extractor_4(inputs, training = False)\n","features_5 = extractor_5(inputs, training = False)\n","\n","x = keras.layers.Concatenate(axis=-1)([features_1,features_2,features_3,features_4,features_5])\n","\n","x = keras.layers.Flatten()(x)\n","x = keras.layers.Dense(128,  name='dense_100')(x)\n","x = keras.layers.BatchNormalization()(x)\n","x = keras.layers.Activation('relu')(x)\n","x = keras.layers.Dropout(0.5)(x)\n","outputs = keras.layers.Dense(6, activation='softmax', name='dense_101')(x)\n","ensemble = keras.Model(inputs = inputs, outputs = outputs)\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","train_sequence = eNEUdata(x_train, y_train, batch_size=10, train=True)\n","validation_sequence = eNEUdata(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=50,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FH_Ry7tpC_G_","executionInfo":{"status":"ok","timestamp":1650579114523,"user_tz":-120,"elapsed":139593,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"672b9f9e-4f4b-42e8-bbdc-7ccaa95973f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","3/3 [==============================] - 16s 3s/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 1.3566 - val_accuracy: 0.6167\n","Epoch 2/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.1557 - accuracy: 0.9333 - val_loss: 1.4233 - val_accuracy: 0.6139\n","Epoch 3/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.1191 - accuracy: 1.0000 - val_loss: 1.4578 - val_accuracy: 0.6000\n","Epoch 4/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.0782 - accuracy: 1.0000 - val_loss: 1.5336 - val_accuracy: 0.5806\n","Epoch 5/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.1001 - accuracy: 0.9667 - val_loss: 1.6580 - val_accuracy: 0.5639\n","Epoch 6/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.5778\n","Epoch 7/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.3156 - accuracy: 0.9333 - val_loss: 1.5342 - val_accuracy: 0.5972\n","Epoch 8/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.4219 - accuracy: 0.8667 - val_loss: 1.4512 - val_accuracy: 0.6083\n","Epoch 9/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.1779 - accuracy: 0.9667 - val_loss: 1.4219 - val_accuracy: 0.6056\n","Epoch 10/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.2577 - accuracy: 0.9333 - val_loss: 1.3769 - val_accuracy: 0.6028\n","Epoch 11/20\n","3/3 [==============================] - 6s 3s/step - loss: 0.2749 - accuracy: 0.9000 - val_loss: 1.3298 - val_accuracy: 0.6361\n","Epoch 12/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.1592 - accuracy: 0.9667 - val_loss: 1.3110 - val_accuracy: 0.6333\n","Epoch 13/20\n","3/3 [==============================] - 6s 3s/step - loss: 0.2774 - accuracy: 0.8333 - val_loss: 1.2849 - val_accuracy: 0.6417\n","Epoch 14/20\n","3/3 [==============================] - 6s 3s/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 1.2648 - val_accuracy: 0.6528\n","Epoch 15/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.1226 - accuracy: 0.9667 - val_loss: 1.2647 - val_accuracy: 0.6500\n","Epoch 16/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.1962 - accuracy: 0.9667 - val_loss: 1.2664 - val_accuracy: 0.6250\n","Epoch 17/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.1420 - accuracy: 0.9667 - val_loss: 1.2750 - val_accuracy: 0.6111\n","Epoch 18/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.1403 - accuracy: 0.9333 - val_loss: 1.2916 - val_accuracy: 0.6194\n","Epoch 19/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.1249 - accuracy: 0.9667 - val_loss: 1.2928 - val_accuracy: 0.6222\n","Epoch 20/20\n","3/3 [==============================] - 5s 2s/step - loss: 0.2129 - accuracy: 0.9333 - val_loss: 1.2818 - val_accuracy: 0.6222\n","Epoch 00014: early stopping and save the model\n","12/12 [==============================] - 5s 288ms/step - loss: 1.5699 - accuracy: 0.5722\n"]}],"source":["#finetuning\n","extractor_1.trainable = True\n","extractor_2.trainable = True\n","extractor_3.trainable = True\n","extractor_4.trainable = True\n","extractor_5.trainable = True\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","#train_sequence = ecifar10data(sampled_x_train, sampled_y_train, batch_size=10, train=False)\n","#validation_sequence = ecifar10data(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=20,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"y1W3vPZQppO3","executionInfo":{"status":"ok","timestamp":1650579119382,"user_tz":-120,"elapsed":4868,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"5e45b72e-488e-424d-cef3-7a09653d0dc7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'              precision    recall  f1-score   support\\n\\n           0     0.8594    0.9167    0.8871        60\\n           1     0.5797    0.6667    0.6202        60\\n           2     0.7143    0.9167    0.8029        60\\n           3     0.4348    0.5000    0.4651        60\\n           4     0.0000    0.0000    0.0000        60\\n           5     0.3467    0.4333    0.3852        60\\n\\n    accuracy                         0.5722       360\\n   macro avg     0.4891    0.5722    0.5267       360\\nweighted avg     0.4891    0.5722    0.5267       360\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["#f1 score\n","predict = tf.argmax(ensemble.predict(x_test),axis=-1)\n","classification_report(y_test, predict,digits=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHRllqV9hlkE"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"NEUResNetEX.ipynb","provenance":[],"mount_file_id":"1-BcMYRjD7ldPJsFalD51ZILiIPJvd93s","authorship_tag":"ABX9TyO3CTscGqbmW9t6/4Mf8CBP"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}