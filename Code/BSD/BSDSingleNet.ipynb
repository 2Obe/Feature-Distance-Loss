{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BSDSingleNet.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1h0FfWBsyivwz6AtVff3ecsw-bS0YTQay","authorship_tag":"ABX9TyMyxg6P39IenO4swqDR1j2G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#unzip BSD datasets\n","!unzip '/content/drive/MyDrive/KGT/KGT_validation.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/KGT_test.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/100_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/50_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/20_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/10_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/5_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/3_samples.zip' -d '/content'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"NbJcqk0QOrS0","executionInfo":{"status":"ok","timestamp":1651009608299,"user_tz":-120,"elapsed":4,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"d3db25f8-85a4-4659-aa6b-cb59ff8d2fd3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n!unzip '/content/drive/MyDrive/KGT/KGT_validation.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/KGT_test.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/100_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/50_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/20_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/10_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/5_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/3_samples.zip' -d '/content'\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","from tensorflow import keras\n","from sklearn import model_selection\n","import imgaug.augmenters as iaa\n","import imgaug as ia\n","import os"],"metadata":{"id":"BH3qEOZzOsLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ia.seed(1)\n","def Data_Aug(samples):\n","    randomaug = iaa.Sometimes(\n","        0.5,\n","        iaa.OneOf([\n","            iaa.Sequential([\n","                iaa.AllChannelsCLAHE(clip_limit=(1, 10)),\n","                iaa.Affine(rotate=(-5, 5))\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(translate_percent={\n","                    \"x\": (-0.2, 0.2),\n","                    \"y\": (-0.2, 0.2)\n","                }),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(rotate=(-10, 10)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.PerspectiveTransform(scale=(0, 0.15)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ])\n","        ]))\n","\n","\n","    return randomaug.augment_images(samples)\n","\n","def resize_images(imgs, hight, width):\n","    seq = iaa.Resize({\"height\": hight, \"width\": width})\n","    aug = seq.augment_images(imgs)\n","    return aug"],"metadata":{"id":"gaUmcnZwK5Z5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RJ3uDY9FgNZ"},"outputs":[],"source":["#load BSD images\n","def load_data(dir_path, labels_dict):\n","  all_names = os.listdir(dir_path)\n","  data_x = []\n","  data_y = []\n","  for name in all_names:\n","    img = keras.preprocessing.image.load_img(os.path.join(dir_path, name), target_size=(100,100))\n","    img = keras.preprocessing.image.img_to_array(img,dtype='uint8')\n","    data_x.append(img)\n","    lab = labels_dict[name[:1]]\n","    data_y.append(lab)\n","  data_x = np.array(data_x)\n","  data_y = np.array(data_y)\n","  return data_x, data_y\n","class BSDdata(keras.utils.Sequence):\n","    def __init__(self, data_x, data_y, batch_size, train):\n","      self.data_x = data_x\n","      self.data_y = data_y\n","      self.train = train\n","      self.batch_size = batch_size\n","\n","    def __len__(self):\n","      return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","      batch_x = self.data_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n","                            \n","      batch_y = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n","      if self.train == True:\n","          batch_x = Data_Aug(batch_x)\n","\n","      batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","      batch_y = keras.utils.to_categorical(batch_y, 2)\n","      return batch_x, batch_y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unA7GJ9ofGEv"},"outputs":[],"source":["#save the best model during training\n","class CustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(CustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_accuracy') \n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","source":["def create_AlexNet(input_shape, num_classes=6, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  x = keras.layers.Conv2D(96, (3,3), strides=(2,2), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","  \n","  x = keras.layers.Conv2D(256, (3,3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x) \n","  x = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n"," \n","  x = keras.layers.Conv2D(384, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x) \n","  x = keras.layers.Conv2D(384, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x) \n","  x = keras.layers.Conv2D(256, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  feature_maps = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","  \n","  x = keras.layers.Flatten()(feature_maps)\n","  #x = keras.layers.Dense(256,activation='relu')(x)\n","  #x = keras.layers.Dropout(0.5)(x)\n","  x = keras.layers.Dense(128,activation='relu')(x)\n","  x = keras.layers.Dropout(0.5)(x)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n","  model = keras.Model(inputs=inputs, outputs=outputs)\n","  return model"],"metadata":{"id":"57au-gFlNLBl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_VGGNet(input_shape, num_classes,  random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  x = keras.layers.Conv2D(64, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(64, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.2)(x)\n","\n","  x = keras.layers.Conv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.3)(x)\n","  \n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.4)(x)\n","\n","\n","    \n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  p3 = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.5)(p3)\n","\n","\n"," \n","   \n","  '''  \n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.5)(x) \n","  '''\n","  \n"," \n","\n","  #x = keras.layers.GlobalAveragePooling2D()(x)\n","  x = keras.layers.Flatten()(x)\n","  x = keras.layers.Dense(128,  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Dropout(0.5)(x)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n","  return keras.Model(inputs=inputs, outputs=outputs)"],"metadata":{"id":"jKtv_83j2p9e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_ResNet(input_shape, num_classes=6, num_filters = 64, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x)\n","\n","  \n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(2*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x) \n","\n","    \n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(4*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x) \n","\n","   \n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(8*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x) \n","  \n","  \n","  x = keras.layers.GlobalAveragePooling2D()(x)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  model = keras.Model(inputs=inputs, outputs=outputs)\n","  return model"],"metadata":{"id":"qwlaT__OP9vM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load training, validation and testing images\n","training_data_path = '50_samples'\n","validation_data_path = 'KGT_validation'\n","test_data_path = 'KGT_test'\n","labels_dict = {'N': 0, 'P': 1}\n","x_train, y_train = load_data(training_data_path, labels_dict)\n","x_val, y_val = load_data(validation_data_path, labels_dict)\n","x_test, y_test = load_data(test_data_path, labels_dict)\n","_, x_val, _, y_val = model_selection.train_test_split(\n","    x_val,\n","    y_val,\n","    test_size=2000,\n","    random_state=0,\n","    stratify=y_val)\n","x_test = x_test/255.0"],"metadata":{"id":"uByuscclPUZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#construct model\n","input_size = (100, 100, 3)\n","\n","model = create_AlexNet(input_shape=input_size, num_classes=2, random_seed=None)\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                    loss=['categorical_crossentropy'],\n","                    metrics=['accuracy'])\n","\n","train_sequence = BSDdata(x_train, y_train, batch_size=10, train=True)\n","validation_sequence = BSDdata(x_val, y_val, batch_size=10, train=False)\n","\n","#training\n","history = model.fit(\n","    train_sequence,\n","    epochs=300,\n","    validation_data=validation_sequence,\n","    #validation_steps=12,\n","    callbacks=CustomEarlyStoppingAndSave(\n","        save_path='100_samples_seed_fix.h5',\n","        patience=10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4a5P5V5OKw8","outputId":"f151ffc8-38d2-45ae-f4c9-2a162ab06f60","executionInfo":{"status":"ok","timestamp":1651010046977,"user_tz":-120,"elapsed":420734,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","10/10 [==============================] - 4s 164ms/step - loss: 0.7718 - accuracy: 0.7500 - val_loss: 1.9635 - val_accuracy: 0.5040\n","Epoch 2/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.6683 - accuracy: 0.8100 - val_loss: 0.9249 - val_accuracy: 0.4840\n","Epoch 3/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.3701 - accuracy: 0.8500 - val_loss: 0.8616 - val_accuracy: 0.4785\n","Epoch 4/300\n","10/10 [==============================] - 1s 154ms/step - loss: 0.2396 - accuracy: 0.9000 - val_loss: 0.9748 - val_accuracy: 0.4880\n","Epoch 5/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.1177 - accuracy: 0.9600 - val_loss: 0.8165 - val_accuracy: 0.4110\n","Epoch 6/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.1997 - accuracy: 0.9100 - val_loss: 0.7994 - val_accuracy: 0.4560\n","Epoch 7/300\n","10/10 [==============================] - 1s 136ms/step - loss: 0.1449 - accuracy: 0.9500 - val_loss: 0.8412 - val_accuracy: 0.4250\n","Epoch 8/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0857 - accuracy: 0.9800 - val_loss: 0.9184 - val_accuracy: 0.4595\n","Epoch 9/300\n","10/10 [==============================] - 2s 174ms/step - loss: 0.2688 - accuracy: 0.9100 - val_loss: 0.9000 - val_accuracy: 0.4960\n","Epoch 10/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.1473 - accuracy: 0.9600 - val_loss: 0.8896 - val_accuracy: 0.4865\n","Epoch 11/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.1815 - accuracy: 0.9300 - val_loss: 1.1041 - val_accuracy: 0.4960\n","Epoch 12/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0983 - accuracy: 0.9600 - val_loss: 1.3919 - val_accuracy: 0.4960\n","Epoch 13/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.1078 - accuracy: 0.9600 - val_loss: 1.2931 - val_accuracy: 0.4895\n","Epoch 14/300\n","10/10 [==============================] - 1s 135ms/step - loss: 0.0496 - accuracy: 0.9800 - val_loss: 1.1918 - val_accuracy: 0.4815\n","Epoch 15/300\n","10/10 [==============================] - 1s 135ms/step - loss: 0.0803 - accuracy: 0.9700 - val_loss: 1.3529 - val_accuracy: 0.4945\n","Epoch 16/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.1205 - accuracy: 0.9600 - val_loss: 1.4733 - val_accuracy: 0.4955\n","Epoch 17/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.3161 - accuracy: 0.9100 - val_loss: 0.8437 - val_accuracy: 0.5500\n","Epoch 18/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0813 - accuracy: 0.9600 - val_loss: 1.4446 - val_accuracy: 0.4955\n","Epoch 19/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.1203 - accuracy: 0.9600 - val_loss: 0.9418 - val_accuracy: 0.5290\n","Epoch 20/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.1941 - accuracy: 0.9500 - val_loss: 1.3089 - val_accuracy: 0.4915\n","Epoch 21/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0645 - accuracy: 0.9600 - val_loss: 0.8827 - val_accuracy: 0.5470\n","Epoch 22/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.1146 - accuracy: 0.9600 - val_loss: 1.2131 - val_accuracy: 0.4815\n","Epoch 23/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.0346 - accuracy: 0.9900 - val_loss: 1.6866 - val_accuracy: 0.4825\n","Epoch 24/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0502 - accuracy: 0.9800 - val_loss: 1.2906 - val_accuracy: 0.5150\n","Epoch 25/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 1.4755 - val_accuracy: 0.5085\n","Epoch 26/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0957 - accuracy: 0.9800 - val_loss: 1.8446 - val_accuracy: 0.4975\n","Epoch 27/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.1160 - accuracy: 0.9500 - val_loss: 0.9030 - val_accuracy: 0.6255\n","Epoch 28/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.1462 - accuracy: 0.9600 - val_loss: 1.0835 - val_accuracy: 0.5115\n","Epoch 29/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0559 - accuracy: 0.9800 - val_loss: 1.1220 - val_accuracy: 0.5265\n","Epoch 30/300\n","10/10 [==============================] - 1s 148ms/step - loss: 0.0542 - accuracy: 0.9700 - val_loss: 1.4055 - val_accuracy: 0.5125\n","Epoch 31/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.1120 - accuracy: 0.9500 - val_loss: 1.0684 - val_accuracy: 0.5340\n","Epoch 32/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 1.3011 - val_accuracy: 0.5030\n","Epoch 33/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.1269 - accuracy: 0.9800 - val_loss: 0.7139 - val_accuracy: 0.7315\n","Epoch 34/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0986 - accuracy: 0.9700 - val_loss: 0.8267 - val_accuracy: 0.6650\n","Epoch 35/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.8801 - val_accuracy: 0.6555\n","Epoch 36/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0358 - accuracy: 0.9900 - val_loss: 0.7323 - val_accuracy: 0.7470\n","Epoch 37/300\n","10/10 [==============================] - 1s 136ms/step - loss: 0.1106 - accuracy: 0.9800 - val_loss: 0.7303 - val_accuracy: 0.7005\n","Epoch 38/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0273 - accuracy: 0.9900 - val_loss: 0.7393 - val_accuracy: 0.6925\n","Epoch 39/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0938 - accuracy: 0.9600 - val_loss: 0.7982 - val_accuracy: 0.7450\n","Epoch 40/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0823 - accuracy: 0.9700 - val_loss: 0.8605 - val_accuracy: 0.7560\n","Epoch 41/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.6800\n","Epoch 42/300\n","10/10 [==============================] - 1s 133ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0675 - val_accuracy: 0.6785\n","Epoch 43/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.1250 - accuracy: 0.9700 - val_loss: 0.7426 - val_accuracy: 0.8185\n","Epoch 44/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0798 - accuracy: 0.9800 - val_loss: 0.6836 - val_accuracy: 0.7655\n","Epoch 45/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0534 - accuracy: 0.9900 - val_loss: 0.6949 - val_accuracy: 0.7610\n","Epoch 46/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0758 - accuracy: 0.9800 - val_loss: 0.7686 - val_accuracy: 0.7620\n","Epoch 47/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0576 - accuracy: 0.9800 - val_loss: 0.8504 - val_accuracy: 0.7155\n","Epoch 48/300\n","10/10 [==============================] - 2s 163ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.8834 - val_accuracy: 0.7125\n","Epoch 49/300\n","10/10 [==============================] - 2s 153ms/step - loss: 0.0226 - accuracy: 0.9900 - val_loss: 0.8391 - val_accuracy: 0.7505\n","Epoch 50/300\n","10/10 [==============================] - 1s 134ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3397 - val_accuracy: 0.6405\n","Epoch 51/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.1090 - accuracy: 0.9700 - val_loss: 0.7540 - val_accuracy: 0.7925\n","Epoch 52/300\n","10/10 [==============================] - 1s 135ms/step - loss: 0.0497 - accuracy: 0.9800 - val_loss: 0.7813 - val_accuracy: 0.8075\n","Epoch 53/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0227 - accuracy: 0.9900 - val_loss: 0.9100 - val_accuracy: 0.7440\n","Epoch 54/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.1526 - accuracy: 0.9300 - val_loss: 1.1809 - val_accuracy: 0.7575\n","Epoch 55/300\n","10/10 [==============================] - 1s 135ms/step - loss: 0.0416 - accuracy: 0.9800 - val_loss: 0.9227 - val_accuracy: 0.7880\n","Epoch 56/300\n","10/10 [==============================] - 1s 136ms/step - loss: 0.0806 - accuracy: 0.9700 - val_loss: 0.9584 - val_accuracy: 0.7890\n","Epoch 57/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0498 - accuracy: 0.9800 - val_loss: 0.7985 - val_accuracy: 0.7855\n","Epoch 58/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.1191 - accuracy: 0.9600 - val_loss: 0.9721 - val_accuracy: 0.8070\n","Epoch 59/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.7895 - val_accuracy: 0.8005\n","Epoch 60/300\n","10/10 [==============================] - 1s 151ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.0879 - val_accuracy: 0.7235\n","Epoch 61/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.2200 - val_accuracy: 0.7280\n","Epoch 62/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0487 - accuracy: 0.9900 - val_loss: 1.0539 - val_accuracy: 0.7975\n","Epoch 63/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0537 - accuracy: 0.9800 - val_loss: 1.2151 - val_accuracy: 0.7845\n","Epoch 64/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0569 - accuracy: 0.9900 - val_loss: 0.9551 - val_accuracy: 0.7790\n","Epoch 65/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9359 - val_accuracy: 0.7585\n","Epoch 66/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.8969 - val_accuracy: 0.7685\n","Epoch 67/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0461 - accuracy: 0.9900 - val_loss: 1.2004 - val_accuracy: 0.7725\n","Epoch 68/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0837 - accuracy: 0.9600 - val_loss: 1.1306 - val_accuracy: 0.7400\n","Epoch 69/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0504 - accuracy: 0.9600 - val_loss: 0.9099 - val_accuracy: 0.7980\n","Epoch 70/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0499 - accuracy: 0.9800 - val_loss: 1.0032 - val_accuracy: 0.7885\n","Epoch 71/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.1161 - accuracy: 0.9700 - val_loss: 1.2768 - val_accuracy: 0.8065\n","Epoch 72/300\n","10/10 [==============================] - 1s 135ms/step - loss: 0.0526 - accuracy: 0.9900 - val_loss: 2.0868 - val_accuracy: 0.7075\n","Epoch 73/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0345 - accuracy: 0.9800 - val_loss: 1.6400 - val_accuracy: 0.7180\n","Epoch 74/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.1281 - accuracy: 0.9600 - val_loss: 1.0349 - val_accuracy: 0.7850\n","Epoch 75/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0687 - accuracy: 0.9800 - val_loss: 0.7057 - val_accuracy: 0.7925\n","Epoch 76/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.1129 - accuracy: 0.9800 - val_loss: 0.6550 - val_accuracy: 0.7950\n","Epoch 77/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0531 - accuracy: 0.9800 - val_loss: 0.6504 - val_accuracy: 0.7975\n","Epoch 78/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0679 - accuracy: 0.9800 - val_loss: 1.1294 - val_accuracy: 0.7480\n","Epoch 79/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.0288 - val_accuracy: 0.7875\n","Epoch 80/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0218 - accuracy: 0.9900 - val_loss: 0.9640 - val_accuracy: 0.8060\n","Epoch 81/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.0122 - val_accuracy: 0.8035\n","Epoch 82/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.1224 - accuracy: 0.9900 - val_loss: 0.9782 - val_accuracy: 0.8035\n","Epoch 83/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0225 - accuracy: 0.9900 - val_loss: 0.8993 - val_accuracy: 0.8105\n","Epoch 84/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.9659 - val_accuracy: 0.7890\n","Epoch 85/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.0032 - val_accuracy: 0.7960\n","Epoch 86/300\n","10/10 [==============================] - 1s 132ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0286 - val_accuracy: 0.7965\n","Epoch 87/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0542 - val_accuracy: 0.7980\n","Epoch 88/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1254 - val_accuracy: 0.8035\n","Epoch 89/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2587 - val_accuracy: 0.8150\n","Epoch 90/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0346 - accuracy: 0.9900 - val_loss: 1.4907 - val_accuracy: 0.7445\n","Epoch 91/300\n","10/10 [==============================] - 1s 148ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4444 - val_accuracy: 0.7655\n","Epoch 92/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0872 - accuracy: 0.9800 - val_loss: 0.8126 - val_accuracy: 0.7675\n","Epoch 93/300\n","10/10 [==============================] - 1s 151ms/step - loss: 0.0640 - accuracy: 0.9700 - val_loss: 0.7524 - val_accuracy: 0.7555\n","Epoch 94/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0320 - accuracy: 0.9900 - val_loss: 0.8346 - val_accuracy: 0.7295\n","Epoch 95/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.9418 - val_accuracy: 0.7470\n","Epoch 96/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.1185 - accuracy: 0.9900 - val_loss: 1.0781 - val_accuracy: 0.7455\n","Epoch 97/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0373 - accuracy: 0.9800 - val_loss: 0.7969 - val_accuracy: 0.8060\n","Epoch 98/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.0288 - val_accuracy: 0.7645\n","Epoch 99/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.0363 - val_accuracy: 0.8140\n","Epoch 100/300\n","10/10 [==============================] - 1s 136ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.1067 - val_accuracy: 0.8165\n","Epoch 101/300\n","10/10 [==============================] - 1s 134ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.1204 - val_accuracy: 0.8020\n","Epoch 102/300\n","10/10 [==============================] - 1s 138ms/step - loss: 9.6186e-04 - accuracy: 1.0000 - val_loss: 1.2632 - val_accuracy: 0.7850\n","Epoch 103/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.2004 - accuracy: 0.9700 - val_loss: 1.1056 - val_accuracy: 0.8125\n","Epoch 104/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0929 - accuracy: 0.9600 - val_loss: 0.8040 - val_accuracy: 0.7070\n","Epoch 105/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.1113 - accuracy: 0.9500 - val_loss: 0.7704 - val_accuracy: 0.7955\n","Epoch 106/300\n","10/10 [==============================] - 1s 136ms/step - loss: 0.0609 - accuracy: 0.9800 - val_loss: 1.2191 - val_accuracy: 0.7345\n","Epoch 107/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.7793 - val_accuracy: 0.8070\n","Epoch 108/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0650 - accuracy: 0.9800 - val_loss: 0.7652 - val_accuracy: 0.8185\n","Epoch 109/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.8167 - val_accuracy: 0.8195\n","Epoch 110/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0277 - accuracy: 0.9800 - val_loss: 0.8233 - val_accuracy: 0.8155\n","Epoch 111/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0860 - accuracy: 0.9800 - val_loss: 0.8662 - val_accuracy: 0.7980\n","Epoch 112/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0189 - accuracy: 0.9900 - val_loss: 0.9014 - val_accuracy: 0.8180\n","Epoch 113/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0516 - accuracy: 0.9700 - val_loss: 0.7506 - val_accuracy: 0.7860\n","Epoch 114/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0403 - accuracy: 0.9900 - val_loss: 0.8828 - val_accuracy: 0.7820\n","Epoch 115/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.0387 - val_accuracy: 0.7860\n","Epoch 116/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0475 - accuracy: 0.9900 - val_loss: 1.3976 - val_accuracy: 0.7690\n","Epoch 117/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.6371 - val_accuracy: 0.7525\n","Epoch 118/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0342 - accuracy: 0.9800 - val_loss: 1.2946 - val_accuracy: 0.7750\n","Epoch 119/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.2709 - accuracy: 0.9500 - val_loss: 1.6586 - val_accuracy: 0.7865\n","Epoch 120/300\n","10/10 [==============================] - 1s 136ms/step - loss: 0.0806 - accuracy: 0.9600 - val_loss: 0.8363 - val_accuracy: 0.8035\n","Epoch 121/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0422 - accuracy: 0.9800 - val_loss: 0.8121 - val_accuracy: 0.7810\n","Epoch 122/300\n","10/10 [==============================] - 1s 135ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.1395 - val_accuracy: 0.7525\n","Epoch 123/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0264 - accuracy: 0.9900 - val_loss: 1.1295 - val_accuracy: 0.7815\n","Epoch 124/300\n","10/10 [==============================] - 1s 135ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0836 - val_accuracy: 0.7980\n","Epoch 125/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0219 - accuracy: 0.9900 - val_loss: 1.5800 - val_accuracy: 0.7360\n","Epoch 126/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.9733 - val_accuracy: 0.7045\n","Epoch 127/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0250 - accuracy: 0.9900 - val_loss: 1.3945 - val_accuracy: 0.7185\n","Epoch 128/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0282 - accuracy: 0.9900 - val_loss: 1.2263 - val_accuracy: 0.7795\n","Epoch 129/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 1.1604 - val_accuracy: 0.7970\n","Epoch 130/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3142 - val_accuracy: 0.7895\n","Epoch 131/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0400 - accuracy: 0.9700 - val_loss: 1.2573 - val_accuracy: 0.8145\n","Epoch 132/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0178 - accuracy: 0.9900 - val_loss: 1.5011 - val_accuracy: 0.7310\n","Epoch 133/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0719 - accuracy: 0.9800 - val_loss: 2.2626 - val_accuracy: 0.7785\n","Epoch 134/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.4435 - val_accuracy: 0.7830\n","Epoch 135/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0431 - accuracy: 0.9800 - val_loss: 1.0421 - val_accuracy: 0.7795\n","Epoch 136/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0875 - accuracy: 0.9800 - val_loss: 1.0159 - val_accuracy: 0.7340\n","Epoch 137/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.8410\n","Epoch 138/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.8711 - val_accuracy: 0.8390\n","Epoch 139/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.8270\n","Epoch 140/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0415 - accuracy: 0.9900 - val_loss: 1.7191 - val_accuracy: 0.6920\n","Epoch 141/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0719 - accuracy: 0.9900 - val_loss: 0.9720 - val_accuracy: 0.7930\n","Epoch 142/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 0.9431 - val_accuracy: 0.8400\n","Epoch 143/300\n","10/10 [==============================] - 1s 148ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.9446 - val_accuracy: 0.8355\n","Epoch 144/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0478 - accuracy: 0.9900 - val_loss: 0.9343 - val_accuracy: 0.8105\n","Epoch 145/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.9895 - val_accuracy: 0.8015\n","Epoch 146/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0301 - accuracy: 0.9900 - val_loss: 1.0676 - val_accuracy: 0.8145\n","Epoch 147/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0341 - accuracy: 0.9800 - val_loss: 1.2660 - val_accuracy: 0.8440\n","Epoch 148/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.0356 - accuracy: 0.9900 - val_loss: 1.1667 - val_accuracy: 0.7630\n","Epoch 149/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0330 - accuracy: 0.9800 - val_loss: 1.8544 - val_accuracy: 0.7420\n","Epoch 150/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.1508 - accuracy: 0.9600 - val_loss: 1.4371 - val_accuracy: 0.7660\n","Epoch 151/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.1018 - accuracy: 0.9700 - val_loss: 0.7443 - val_accuracy: 0.8105\n","Epoch 152/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8105\n","Epoch 153/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0630 - accuracy: 0.9800 - val_loss: 0.8946 - val_accuracy: 0.8140\n","Epoch 154/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.7815\n","Epoch 155/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2306 - val_accuracy: 0.7685\n","Epoch 156/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0699 - accuracy: 0.9900 - val_loss: 1.2131 - val_accuracy: 0.7715\n","Epoch 157/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0354 - accuracy: 0.9800 - val_loss: 1.0746 - val_accuracy: 0.7850\n","Epoch 158/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.2176 - val_accuracy: 0.7905\n","Epoch 159/300\n","10/10 [==============================] - 1s 148ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.5699 - val_accuracy: 0.7585\n","Epoch 160/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.9455 - val_accuracy: 0.7275\n","Epoch 161/300\n","10/10 [==============================] - 1s 137ms/step - loss: 1.5079e-04 - accuracy: 1.0000 - val_loss: 2.0775 - val_accuracy: 0.7185\n","Epoch 162/300\n","10/10 [==============================] - 1s 135ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.9201 - val_accuracy: 0.7390\n","Epoch 163/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.6607 - val_accuracy: 0.7560\n","Epoch 164/300\n","10/10 [==============================] - 1s 142ms/step - loss: 4.5108e-04 - accuracy: 1.0000 - val_loss: 1.6169 - val_accuracy: 0.7630\n","Epoch 165/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6486 - val_accuracy: 0.7660\n","Epoch 166/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.7532 - val_accuracy: 0.7585\n","Epoch 167/300\n","10/10 [==============================] - 1s 144ms/step - loss: 6.3762e-04 - accuracy: 1.0000 - val_loss: 1.8257 - val_accuracy: 0.7540\n","Epoch 168/300\n","10/10 [==============================] - 1s 139ms/step - loss: 3.7742e-04 - accuracy: 1.0000 - val_loss: 1.9396 - val_accuracy: 0.7525\n","Epoch 169/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 1.9075 - val_accuracy: 0.7550\n","Epoch 170/300\n","10/10 [==============================] - 1s 139ms/step - loss: 2.5345e-04 - accuracy: 1.0000 - val_loss: 1.5935 - val_accuracy: 0.8075\n","Epoch 171/300\n","10/10 [==============================] - 1s 143ms/step - loss: 3.9248e-04 - accuracy: 1.0000 - val_loss: 1.6232 - val_accuracy: 0.8140\n","Epoch 172/300\n","10/10 [==============================] - 1s 148ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.6404 - val_accuracy: 0.8170\n","Epoch 173/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0140 - accuracy: 0.9900 - val_loss: 1.6364 - val_accuracy: 0.7835\n","Epoch 174/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.9430 - val_accuracy: 0.7420\n","Epoch 175/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.1623 - accuracy: 0.9800 - val_loss: 1.1948 - val_accuracy: 0.8290\n","Epoch 176/300\n","10/10 [==============================] - 1s 148ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.0438 - val_accuracy: 0.8145\n","Epoch 177/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0281 - accuracy: 0.9800 - val_loss: 1.3868 - val_accuracy: 0.7170\n","Epoch 178/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2823 - val_accuracy: 0.7900\n","Epoch 179/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0256 - accuracy: 0.9900 - val_loss: 1.2606 - val_accuracy: 0.8135\n","Epoch 180/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2571 - val_accuracy: 0.7930\n","Epoch 181/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.3688 - val_accuracy: 0.8215\n","Epoch 182/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.4387 - val_accuracy: 0.8175\n","Epoch 183/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6816 - val_accuracy: 0.7770\n","Epoch 184/300\n","10/10 [==============================] - 1s 135ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.6156 - val_accuracy: 0.7870\n","Epoch 185/300\n","10/10 [==============================] - 1s 135ms/step - loss: 3.4701e-04 - accuracy: 1.0000 - val_loss: 1.5256 - val_accuracy: 0.8255\n","Epoch 186/300\n","10/10 [==============================] - 1s 149ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.7281 - val_accuracy: 0.8275\n","Epoch 187/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.7526 - val_accuracy: 0.8275\n","Epoch 188/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.0508 - accuracy: 0.9800 - val_loss: 1.6826 - val_accuracy: 0.8235\n","Epoch 189/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0199 - accuracy: 0.9900 - val_loss: 2.8354 - val_accuracy: 0.6395\n","Epoch 190/300\n","10/10 [==============================] - 1s 151ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.6229 - val_accuracy: 0.7800\n","Epoch 191/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0263 - accuracy: 0.9900 - val_loss: 1.4911 - val_accuracy: 0.8295\n","Epoch 192/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 1.2038 - val_accuracy: 0.7935\n","Epoch 193/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4601 - val_accuracy: 0.7560\n","Epoch 194/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0161 - accuracy: 0.9900 - val_loss: 1.2662 - val_accuracy: 0.8160\n","Epoch 195/300\n","10/10 [==============================] - 1s 150ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.3387 - val_accuracy: 0.8160\n","Epoch 196/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.3969 - val_accuracy: 0.8170\n","Epoch 197/300\n","10/10 [==============================] - 1s 138ms/step - loss: 5.6690e-04 - accuracy: 1.0000 - val_loss: 1.4670 - val_accuracy: 0.8295\n","Epoch 198/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5435 - val_accuracy: 0.8260\n","Epoch 199/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0225 - accuracy: 0.9800 - val_loss: 1.5312 - val_accuracy: 0.8285\n","Epoch 200/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0116 - accuracy: 0.9900 - val_loss: 2.1717 - val_accuracy: 0.7225\n","Epoch 201/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.1036 - accuracy: 0.9900 - val_loss: 1.4344 - val_accuracy: 0.7815\n","Epoch 202/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0229 - accuracy: 0.9900 - val_loss: 1.2614 - val_accuracy: 0.8120\n","Epoch 203/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0263 - accuracy: 0.9900 - val_loss: 1.0907 - val_accuracy: 0.8205\n","Epoch 204/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0138 - accuracy: 0.9900 - val_loss: 1.0732 - val_accuracy: 0.8165\n","Epoch 205/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2426 - val_accuracy: 0.8170\n","Epoch 206/300\n","10/10 [==============================] - 1s 147ms/step - loss: 9.8228e-04 - accuracy: 1.0000 - val_loss: 1.3352 - val_accuracy: 0.8155\n","Epoch 207/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.4027 - val_accuracy: 0.8120\n","Epoch 208/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6115 - val_accuracy: 0.8010\n","Epoch 209/300\n","10/10 [==============================] - 1s 147ms/step - loss: 1.1461e-04 - accuracy: 1.0000 - val_loss: 1.7460 - val_accuracy: 0.7910\n","Epoch 210/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7544 - val_accuracy: 0.7950\n","Epoch 211/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7178 - val_accuracy: 0.8080\n","Epoch 212/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7265 - val_accuracy: 0.8130\n","Epoch 213/300\n","10/10 [==============================] - 1s 143ms/step - loss: 5.0300e-04 - accuracy: 1.0000 - val_loss: 1.7461 - val_accuracy: 0.8110\n","Epoch 214/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.7654 - val_accuracy: 0.8080\n","Epoch 215/300\n","10/10 [==============================] - 1s 142ms/step - loss: 7.1367e-05 - accuracy: 1.0000 - val_loss: 1.8151 - val_accuracy: 0.8005\n","Epoch 216/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0639 - accuracy: 0.9900 - val_loss: 1.7470 - val_accuracy: 0.8015\n","Epoch 217/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.7650 - val_accuracy: 0.7940\n","Epoch 218/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.7551 - val_accuracy: 0.8000\n","Epoch 219/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6516 - val_accuracy: 0.7980\n","Epoch 220/300\n","10/10 [==============================] - 1s 135ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6578 - val_accuracy: 0.8145\n","Epoch 221/300\n","10/10 [==============================] - 1s 134ms/step - loss: 5.0937e-05 - accuracy: 1.0000 - val_loss: 1.6960 - val_accuracy: 0.8170\n","Epoch 222/300\n","10/10 [==============================] - 1s 135ms/step - loss: 4.3238e-04 - accuracy: 1.0000 - val_loss: 1.7107 - val_accuracy: 0.8195\n","Epoch 223/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.7644 - val_accuracy: 0.8215\n","Epoch 224/300\n","10/10 [==============================] - 1s 136ms/step - loss: 0.0149 - accuracy: 0.9900 - val_loss: 1.6878 - val_accuracy: 0.8010\n","Epoch 225/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0094 - accuracy: 0.9900 - val_loss: 2.0111 - val_accuracy: 0.8110\n","Epoch 226/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 2.0840 - val_accuracy: 0.7765\n","Epoch 227/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.9331 - val_accuracy: 0.8145\n","Epoch 228/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4090 - val_accuracy: 0.8180\n","Epoch 229/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.1174 - accuracy: 0.9800 - val_loss: 1.7779 - val_accuracy: 0.8070\n","Epoch 230/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.3914 - val_accuracy: 0.7585\n","Epoch 231/300\n","10/10 [==============================] - 1s 148ms/step - loss: 0.1806 - accuracy: 0.9700 - val_loss: 1.2160 - val_accuracy: 0.7675\n","Epoch 232/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0388 - accuracy: 0.9800 - val_loss: 0.8412 - val_accuracy: 0.7600\n","Epoch 233/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0870 - accuracy: 0.9700 - val_loss: 1.6057 - val_accuracy: 0.7810\n","Epoch 234/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0422 - accuracy: 0.9700 - val_loss: 1.4835 - val_accuracy: 0.8130\n","Epoch 235/300\n","10/10 [==============================] - 1s 151ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.5345 - val_accuracy: 0.8140\n","Epoch 236/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5773 - val_accuracy: 0.8160\n","Epoch 237/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4877 - val_accuracy: 0.7965\n","Epoch 238/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.5540 - val_accuracy: 0.8120\n","Epoch 239/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0178 - accuracy: 0.9900 - val_loss: 1.2983 - val_accuracy: 0.8090\n","Epoch 240/300\n","10/10 [==============================] - 1s 148ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.4489 - val_accuracy: 0.7295\n","Epoch 241/300\n","10/10 [==============================] - 1s 150ms/step - loss: 0.1116 - accuracy: 0.9900 - val_loss: 1.3165 - val_accuracy: 0.8080\n","Epoch 242/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.5291 - val_accuracy: 0.8125\n","Epoch 243/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0236 - accuracy: 0.9900 - val_loss: 1.2924 - val_accuracy: 0.8010\n","Epoch 244/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0410 - accuracy: 0.9800 - val_loss: 1.3315 - val_accuracy: 0.8045\n","Epoch 245/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.3248 - val_accuracy: 0.8155\n","Epoch 246/300\n","10/10 [==============================] - 1s 145ms/step - loss: 6.5660e-04 - accuracy: 1.0000 - val_loss: 1.3540 - val_accuracy: 0.8160\n","Epoch 247/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0148 - accuracy: 0.9900 - val_loss: 1.3354 - val_accuracy: 0.7975\n","Epoch 248/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.2154 - val_accuracy: 0.8205\n","Epoch 249/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0872 - accuracy: 0.9900 - val_loss: 1.1405 - val_accuracy: 0.7660\n","Epoch 250/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0816 - accuracy: 0.9800 - val_loss: 1.4373 - val_accuracy: 0.8030\n","Epoch 251/300\n","10/10 [==============================] - 1s 150ms/step - loss: 0.0165 - accuracy: 0.9900 - val_loss: 0.9602 - val_accuracy: 0.8210\n","Epoch 252/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.9692 - val_accuracy: 0.8285\n","Epoch 253/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.8280\n","Epoch 254/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.2312 - val_accuracy: 0.8325\n","Epoch 255/300\n","10/10 [==============================] - 1s 139ms/step - loss: 6.3550e-04 - accuracy: 1.0000 - val_loss: 1.5097 - val_accuracy: 0.8280\n","Epoch 256/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.4652 - val_accuracy: 0.8285\n","Epoch 257/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0165 - accuracy: 0.9900 - val_loss: 1.4531 - val_accuracy: 0.8285\n","Epoch 258/300\n","10/10 [==============================] - 1s 150ms/step - loss: 0.0212 - accuracy: 0.9800 - val_loss: 1.4332 - val_accuracy: 0.8275\n","Epoch 259/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.5001 - val_accuracy: 0.7980\n","Epoch 260/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.4544 - val_accuracy: 0.8015\n","Epoch 261/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0152 - accuracy: 0.9900 - val_loss: 1.5885 - val_accuracy: 0.8145\n","Epoch 262/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.7874 - val_accuracy: 0.8180\n","Epoch 263/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.0167 - accuracy: 0.9900 - val_loss: 1.9521 - val_accuracy: 0.8110\n","Epoch 264/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0128 - accuracy: 0.9900 - val_loss: 2.1704 - val_accuracy: 0.7700\n","Epoch 265/300\n","10/10 [==============================] - 1s 150ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.3061 - val_accuracy: 0.7720\n","Epoch 266/300\n","10/10 [==============================] - 1s 145ms/step - loss: 0.1262 - accuracy: 0.9900 - val_loss: 1.8856 - val_accuracy: 0.8335\n","Epoch 267/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 1.5527 - val_accuracy: 0.8410\n","Epoch 268/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1795 - val_accuracy: 0.8435\n","Epoch 269/300\n","10/10 [==============================] - 1s 140ms/step - loss: 7.3604e-04 - accuracy: 1.0000 - val_loss: 1.1427 - val_accuracy: 0.8295\n","Epoch 270/300\n","10/10 [==============================] - 1s 142ms/step - loss: 4.1498e-04 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.8255\n","Epoch 271/300\n","10/10 [==============================] - 1s 142ms/step - loss: 6.0050e-04 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.8260\n","Epoch 272/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2177 - val_accuracy: 0.8250\n","Epoch 273/300\n","10/10 [==============================] - 1s 139ms/step - loss: 1.6182e-04 - accuracy: 1.0000 - val_loss: 1.2384 - val_accuracy: 0.8270\n","Epoch 274/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.8340\n","Epoch 275/300\n","10/10 [==============================] - 1s 142ms/step - loss: 7.5821e-04 - accuracy: 1.0000 - val_loss: 1.4256 - val_accuracy: 0.8425\n","Epoch 276/300\n","10/10 [==============================] - 1s 141ms/step - loss: 1.9494e-04 - accuracy: 1.0000 - val_loss: 1.4910 - val_accuracy: 0.8435\n","Epoch 277/300\n","10/10 [==============================] - 1s 142ms/step - loss: 1.5983e-04 - accuracy: 1.0000 - val_loss: 1.5132 - val_accuracy: 0.8440\n","Epoch 278/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4796 - val_accuracy: 0.8385\n","Epoch 279/300\n","10/10 [==============================] - 1s 136ms/step - loss: 5.0373e-04 - accuracy: 1.0000 - val_loss: 1.4636 - val_accuracy: 0.8210\n","Epoch 280/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5237 - val_accuracy: 0.8280\n","Epoch 281/300\n","10/10 [==============================] - 1s 142ms/step - loss: 6.9114e-05 - accuracy: 1.0000 - val_loss: 1.5479 - val_accuracy: 0.8295\n","Epoch 282/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0628 - accuracy: 0.9900 - val_loss: 1.9284 - val_accuracy: 0.8380\n","Epoch 283/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.6291 - val_accuracy: 0.8490\n","Epoch 284/300\n","10/10 [==============================] - 1s 147ms/step - loss: 1.2409e-04 - accuracy: 1.0000 - val_loss: 1.5742 - val_accuracy: 0.8285\n","Epoch 285/300\n","10/10 [==============================] - 1s 140ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6537 - val_accuracy: 0.8225\n","Epoch 286/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.1887 - accuracy: 0.9700 - val_loss: 1.3588 - val_accuracy: 0.8225\n","Epoch 287/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.2330 - accuracy: 0.9700 - val_loss: 1.3438 - val_accuracy: 0.8055\n","Epoch 288/300\n","10/10 [==============================] - 1s 137ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2773 - val_accuracy: 0.8005\n","Epoch 289/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0443 - accuracy: 0.9900 - val_loss: 1.2572 - val_accuracy: 0.8000\n","Epoch 290/300\n","10/10 [==============================] - 1s 146ms/step - loss: 0.0305 - accuracy: 0.9900 - val_loss: 0.8869 - val_accuracy: 0.7900\n","Epoch 291/300\n","10/10 [==============================] - 1s 141ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.0061 - val_accuracy: 0.7815\n","Epoch 292/300\n","10/10 [==============================] - 2s 181ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1843 - val_accuracy: 0.7830\n","Epoch 293/300\n","10/10 [==============================] - 1s 152ms/step - loss: 6.9777e-04 - accuracy: 1.0000 - val_loss: 1.3350 - val_accuracy: 0.7920\n","Epoch 294/300\n","10/10 [==============================] - 1s 152ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.4435 - val_accuracy: 0.7950\n","Epoch 295/300\n","10/10 [==============================] - 1s 143ms/step - loss: 0.0145 - accuracy: 0.9900 - val_loss: 1.6091 - val_accuracy: 0.8220\n","Epoch 296/300\n","10/10 [==============================] - 1s 147ms/step - loss: 0.0700 - accuracy: 0.9900 - val_loss: 1.8932 - val_accuracy: 0.6945\n","Epoch 297/300\n","10/10 [==============================] - 1s 144ms/step - loss: 0.1676 - accuracy: 0.9700 - val_loss: 2.2398 - val_accuracy: 0.7865\n","Epoch 298/300\n","10/10 [==============================] - 1s 139ms/step - loss: 0.0865 - accuracy: 0.9800 - val_loss: 2.0383 - val_accuracy: 0.8035\n","Epoch 299/300\n","10/10 [==============================] - 1s 138ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 1.8652 - val_accuracy: 0.7610\n","Epoch 300/300\n","10/10 [==============================] - 1s 142ms/step - loss: 0.0352 - accuracy: 0.9900 - val_loss: 1.6058 - val_accuracy: 0.8305\n","Epoch 00283: early stopping and save the model\n"]}]},{"cell_type":"code","source":["evaluate1 = model.evaluate(x_test, keras.utils.to_categorical(y_test,2))\n","evaluate1"],"metadata":{"id":"F_LxZ8TyPmMN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651010049240,"user_tz":-120,"elapsed":2267,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"6524e109-d78f-489b-e8d5-12a9386ba454"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["128/128 [==============================] - 1s 8ms/step - loss: 0.7292 - accuracy: 0.9013\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7291783094406128, 0.9012770056724548]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["model_train = keras.models.load_model('100_samples_seed_fix.h5')\n","evaluate2 = model_train.evaluate(x_test, keras.utils.to_categorical(y_test,2))\n","evaluate2"],"metadata":{"id":"Jawc89TTOjoy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651010051444,"user_tz":-120,"elapsed":2205,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"643ef93e-cf2c-4268-abd2-2d92af65a4c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["128/128 [==============================] - 1s 7ms/step - loss: 0.7292 - accuracy: 0.9013\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7291783094406128, 0.9012770056724548]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[""],"metadata":{"id":"hUCt20IyRYzz"},"execution_count":null,"outputs":[]}]}