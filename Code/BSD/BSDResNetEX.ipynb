{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1651061444994,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"},"user_tz":-120},"id":"tt00VOZ_d5dq","outputId":"b00f5a2f-b130-42a7-c26e-c98920b32342"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n!unzip '/content/drive/MyDrive/KGT/KGT_validation.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/KGT_test.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/100_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/50_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/20_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/10_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/5_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/3_samples.zip' -d '/content'\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["#unzip NEU dataset\n","!unzip '/content/drive/MyDrive/KGT/KGT_validation.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/KGT_test.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/100_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/50_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/20_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/10_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/5_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/3_samples.zip' -d '/content'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlirJGkod7y0"},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","from tensorflow import keras\n","from sklearn import model_selection\n","from sklearn.metrics import classification_report\n","import imgaug.augmenters as iaa\n","import imgaug as ia\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TGGKlSyFBJn"},"outputs":[],"source":["ia.seed(1)\n","def Data_Aug(samples):\n","    randomaug = iaa.Sometimes(\n","        0.5,\n","        iaa.OneOf([\n","            iaa.Sequential([\n","                iaa.AllChannelsCLAHE(clip_limit=(1, 10)),\n","                iaa.Affine(rotate=(-5, 5))\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(translate_percent={\n","                    \"x\": (-0.2, 0.2),\n","                    \"y\": (-0.2, 0.2)\n","                }),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(rotate=(-10, 10)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.PerspectiveTransform(scale=(0, 0.15)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ])\n","        ]))\n","\n","\n","    return randomaug.augment_images(samples)\n","\n","def resize_images(imgs, hight, width):\n","    seq = iaa.Resize({\"height\": hight, \"width\": width})\n","    aug = seq.augment_images(imgs)\n","    return aug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RJ3uDY9FgNZ"},"outputs":[],"source":["#load NEU dataset\n","def load_data(dir_path, labels_dict):\n","  all_names = os.listdir(dir_path)\n","  data_x = []\n","  data_y = []\n","  for name in all_names:\n","    img = keras.preprocessing.image.load_img(os.path.join(dir_path, name), target_size=(100,100))\n","    img = keras.preprocessing.image.img_to_array(img,dtype='uint8')\n","    data_x.append(img)\n","    lab = labels_dict[name[:1]]\n","    data_y.append(lab)\n","  data_x = np.array(data_x)\n","  data_y = np.array(data_y)\n","  return data_x, data_y\n","class KGTdata(keras.utils.Sequence):\n","    def __init__(self, data_x, data_y, batch_size, train):\n","      self.data_x = data_x\n","      self.data_y = data_y\n","      self.train = train\n","      self.batch_size = batch_size\n","\n","    def __len__(self):\n","      return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","      batch_x = self.data_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n","                            \n","      batch_y = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n","      if self.train == True:\n","          batch_x = Data_Aug(batch_x)\n","\n","      batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","      batch_y = keras.utils.to_categorical(batch_y, 2)\n","      return batch_x, [batch_y, batch_y, batch_y, batch_y, batch_y]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4U_n_3bce9u4"},"outputs":[],"source":["#save the best model during training \n","class CustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(CustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_model_accuracy') + logs.get(\n","            'val_model_1_accuracy') + logs.get(\n","                'val_model_2_accuracy') \n","                #+ logs.get(\n","                 #   'val_model_3_accuracy') + logs.get('val_model_4_accuracy')\n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1BPrwTrBVE2"},"outputs":[],"source":["#Cosine&Euclidean distance loss\n","def descriptor(X, mask = False, max_norm = False):\n","  X = tf.reduce_mean(X, axis=3)\n","  if mask:\n","    mean_X = tf.reduce_mean(X, axis = [1,2], keepdims= True)\n","    X = tf.where(X > mean_X, X , tf.zeros_like(X, dtype=tf.float32))\n","  if max_norm:\n","    max_X=tf.reduce_max(X, axis = [1,2], keepdims= True)\n","    X = tf.math.divide_no_nan(X, max_X)\n","  return X \n","  \n","def compute_euclidean_sum(X, Y):\n","  L2_distance = tf.reduce_mean(tf.exp(-(X - Y)**2), axis= [1,2])\n","  return tf.reduce_mean(L2_distance)\n","\n","def compute_cosine_sum(X, Y):\n","  X = tf.reshape(X, [tf.shape(X)[0], -1])\n","  Y = tf.reshape(Y, [tf.shape(Y)[0], -1])\n","  loss = -keras.losses.cosine_similarity(X,Y,axis=-1)\n","  return tf.reduce_mean(loss)\n","\n","def cosine_euclidean_sum_loss(x, cosine_weight, euclidean_weight, mask, max_norm):\n","  descriptor0 = descriptor(x[0], mask=mask, max_norm=max_norm)\n","  descriptor1 = descriptor(x[1], mask=mask, max_norm=max_norm)\n","  descriptor2 = descriptor(x[2], mask=mask, max_norm=max_norm)\n","  descriptor3 = descriptor(x[3], mask=mask, max_norm=max_norm)\n","  descriptor4 = descriptor(x[4], mask=mask, max_norm=max_norm)\n","  cosine_sum = compute_cosine_sum(descriptor0, descriptor1)+compute_cosine_sum(descriptor0, descriptor2)+compute_cosine_sum(descriptor0, descriptor3)+compute_cosine_sum(descriptor0, descriptor4)+compute_cosine_sum(descriptor1, descriptor2)+compute_cosine_sum(descriptor1, descriptor3)+compute_cosine_sum(descriptor1, descriptor4)+compute_cosine_sum(descriptor2, descriptor3)+compute_cosine_sum(descriptor2, descriptor4)+compute_cosine_sum(descriptor3, descriptor4)\n","  euclidean_sum = compute_euclidean_sum(descriptor0, descriptor1)+compute_euclidean_sum(descriptor0, descriptor2)+compute_euclidean_sum(descriptor0, descriptor3)+compute_euclidean_sum(descriptor0, descriptor4)+compute_euclidean_sum(descriptor1, descriptor2)+compute_euclidean_sum(descriptor1, descriptor3)+compute_euclidean_sum(descriptor1, descriptor4)+compute_euclidean_sum(descriptor2, descriptor3)+compute_euclidean_sum(descriptor2, descriptor4)+compute_euclidean_sum(descriptor3, descriptor4)\n","  return cosine_sum, euclidean_sum, cosine_weight*cosine_sum+euclidean_weight*euclidean_sum  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMRptakCHOr_"},"outputs":[],"source":["#create single ResNet model\n","def create_ResNet(input_shape, num_classes=6, num_filters = 64, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x)\n","\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(2*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(4*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(8*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  last_acti = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  x = keras.layers.GlobalAveragePooling2D()(last_acti)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  model = keras.Model(inputs=inputs, outputs=[outputs,last_acti])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8mni5GQeq_2"},"outputs":[],"source":["#load training, validation and testing images\n","training_data_path = '3_samples'\n","validation_data_path = 'KGT_validation'\n","test_data_path = 'KGT_test'\n","labels_dict = {'N': 0, 'P': 1}\n","x_train, y_train = load_data(training_data_path, labels_dict)\n","x_val, y_val = load_data(validation_data_path, labels_dict)\n","x_test, y_test = load_data(test_data_path, labels_dict)\n","_, x_val, _, y_val = model_selection.train_test_split(\n","    x_val,\n","    y_val,\n","    test_size=2000,\n","    random_state=0,\n","    stratify=y_val)\n","x_test = x_test/255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nf634qPVt_Mq","executionInfo":{"status":"ok","timestamp":1651064121875,"user_tz":-120,"elapsed":2654349,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"62024434-e664-4968-c389-18d53ecd06d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","1/1 [==============================] - 26s 26s/step - loss: 23.8329 - model_loss: 1.7621 - model_1_loss: 0.7249 - model_2_loss: 0.6890 - model_3_loss: 1.5302 - model_4_loss: 1.7580 - model_accuracy: 0.5000 - model_1_accuracy: 0.5000 - model_2_accuracy: 0.5000 - model_3_accuracy: 0.5000 - model_4_accuracy: 0.5000 - loss1: 8.6365 - loss2: 8.7323 - val_loss: 40.5235 - val_model_loss: 9.4741 - val_model_1_loss: 1.8720 - val_model_2_loss: 5.6306 - val_model_3_loss: 0.8188 - val_model_4_loss: 5.2187 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.5040 - val_model_3_accuracy: 0.5065 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6561 - val_loss2: 7.8531\n","Epoch 2/300\n","1/1 [==============================] - 8s 8s/step - loss: 19.9612 - model_loss: 0.8735 - model_1_loss: 0.2070 - model_2_loss: 0.2874 - model_3_loss: 0.4836 - model_4_loss: 1.1320 - model_accuracy: 0.6667 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.6667 - loss1: 8.4071 - loss2: 8.5706 - val_loss: 42.7241 - val_model_loss: 10.2913 - val_model_1_loss: 2.4673 - val_model_2_loss: 5.4796 - val_model_3_loss: 1.2069 - val_model_4_loss: 5.7867 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.5040 - val_model_3_accuracy: 0.5040 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6612 - val_loss2: 7.8312\n","Epoch 3/300\n","1/1 [==============================] - 8s 8s/step - loss: 19.8864 - model_loss: 0.7649 - model_1_loss: 0.2955 - model_2_loss: 0.6029 - model_3_loss: 0.5764 - model_4_loss: 0.8639 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.8333 - loss1: 8.2629 - loss2: 8.5198 - val_loss: 38.6591 - val_model_loss: 9.7183 - val_model_1_loss: 1.9291 - val_model_2_loss: 3.4903 - val_model_3_loss: 0.8054 - val_model_4_loss: 5.2492 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.5040 - val_model_3_accuracy: 0.4500 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6620 - val_loss2: 7.8049\n","Epoch 4/300\n","1/1 [==============================] - 8s 8s/step - loss: 17.4974 - model_loss: 0.2448 - model_1_loss: 0.0819 - model_2_loss: 0.0500 - model_3_loss: 0.1670 - model_4_loss: 0.1598 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.3778 - loss2: 8.4161 - val_loss: 33.3846 - val_model_loss: 8.4834 - val_model_1_loss: 1.1456 - val_model_2_loss: 1.2094 - val_model_3_loss: 1.2688 - val_model_4_loss: 3.8847 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.5040 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6540 - val_loss2: 7.7387\n","Epoch 5/300\n","1/1 [==============================] - 8s 8s/step - loss: 16.2187 - model_loss: 0.0521 - model_1_loss: 0.0033 - model_2_loss: 0.0091 - model_3_loss: 0.0022 - model_4_loss: 0.0755 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9785 - loss2: 8.0980 - val_loss: 32.5133 - val_model_loss: 7.6802 - val_model_1_loss: 0.7788 - val_model_2_loss: 1.4708 - val_model_3_loss: 2.1958 - val_model_4_loss: 3.1288 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4070 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6380 - val_loss2: 7.6209\n","Epoch 6/300\n","1/1 [==============================] - 8s 8s/step - loss: 15.8780 - model_loss: 0.0220 - model_1_loss: 0.0025 - model_2_loss: 0.0145 - model_3_loss: 2.6538e-04 - model_4_loss: 0.0435 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.6702 - loss2: 8.1250 - val_loss: 33.9823 - val_model_loss: 6.9199 - val_model_1_loss: 1.0235 - val_model_2_loss: 3.2911 - val_model_3_loss: 2.9906 - val_model_4_loss: 2.6498 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5045 - val_loss1: 9.6168 - val_loss2: 7.4906\n","Epoch 7/300\n","1/1 [==============================] - 8s 8s/step - loss: 15.9209 - model_loss: 0.0310 - model_1_loss: 0.0795 - model_2_loss: 0.2779 - model_3_loss: 0.0120 - model_4_loss: 0.0282 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.6291 - loss2: 7.8632 - val_loss: 32.0811 - val_model_loss: 6.6057 - val_model_1_loss: 0.8081 - val_model_2_loss: 1.6832 - val_model_3_loss: 3.4383 - val_model_4_loss: 2.5244 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.3995 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5060 - val_loss1: 9.5910 - val_loss2: 7.4304\n","Epoch 8/300\n","1/1 [==============================] - 8s 8s/step - loss: 15.1995 - model_loss: 0.0164 - model_1_loss: 0.0041 - model_2_loss: 0.0189 - model_3_loss: 2.0183e-04 - model_4_loss: 0.0070 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.4101 - loss2: 7.7428 - val_loss: 31.2547 - val_model_loss: 6.3916 - val_model_1_loss: 0.9085 - val_model_2_loss: 0.8498 - val_model_3_loss: 3.7552 - val_model_4_loss: 2.4226 - val_model_accuracy: 0.5070 - val_model_1_accuracy: 0.4740 - val_model_2_accuracy: 0.2965 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5010 - val_loss1: 9.5615 - val_loss2: 7.3656\n","Epoch 9/300\n","1/1 [==============================] - 8s 8s/step - loss: 14.8475 - model_loss: 0.0013 - model_1_loss: 0.0677 - model_2_loss: 0.0146 - model_3_loss: 0.0252 - model_4_loss: 0.0013 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.9947 - loss2: 7.7427 - val_loss: 32.4263 - val_model_loss: 6.0543 - val_model_1_loss: 2.0134 - val_model_2_loss: 1.6166 - val_model_3_loss: 3.6753 - val_model_4_loss: 2.2422 - val_model_accuracy: 0.5090 - val_model_1_accuracy: 0.4945 - val_model_2_accuracy: 0.5050 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4815 - val_loss1: 9.5289 - val_loss2: 7.2955\n","Epoch 10/300\n","1/1 [==============================] - 9s 9s/step - loss: 13.5048 - model_loss: 0.0058 - model_1_loss: 8.4060e-04 - model_2_loss: 0.0062 - model_3_loss: 2.3158e-04 - model_4_loss: 0.0013 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.4055 - loss2: 7.0850 - val_loss: 33.9445 - val_model_loss: 5.7151 - val_model_1_loss: 3.1432 - val_model_2_loss: 2.6877 - val_model_3_loss: 3.5930 - val_model_4_loss: 2.0765 - val_model_accuracy: 0.5030 - val_model_1_accuracy: 0.5090 - val_model_2_accuracy: 0.5055 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4840 - val_loss1: 9.4966 - val_loss2: 7.2324\n","Epoch 11/300\n","1/1 [==============================] - 8s 8s/step - loss: 12.8554 - model_loss: 0.0022 - model_1_loss: 6.2708e-04 - model_2_loss: 0.0029 - model_3_loss: 2.0134e-04 - model_4_loss: 8.4744e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.8664 - loss2: 6.9822 - val_loss: 35.3314 - val_model_loss: 5.4073 - val_model_1_loss: 4.0986 - val_model_2_loss: 3.7616 - val_model_3_loss: 3.4412 - val_model_4_loss: 1.9732 - val_model_accuracy: 0.4955 - val_model_1_accuracy: 0.5080 - val_model_2_accuracy: 0.5050 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4815 - val_loss1: 9.4618 - val_loss2: 7.1877\n","Epoch 12/300\n","1/1 [==============================] - 8s 8s/step - loss: 11.9036 - model_loss: 7.9388e-05 - model_1_loss: 8.1560e-04 - model_2_loss: 0.0084 - model_3_loss: 5.3688e-04 - model_4_loss: 6.1210e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.3986 - loss2: 6.4951 - val_loss: 36.1991 - val_model_loss: 5.0263 - val_model_1_loss: 4.8428 - val_model_2_loss: 4.6379 - val_model_3_loss: 3.3179 - val_model_4_loss: 1.8133 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.5080 - val_model_2_accuracy: 0.5050 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4870 - val_loss1: 9.4173 - val_loss2: 7.1436\n","Epoch 13/300\n","1/1 [==============================] - 8s 8s/step - loss: 11.9449 - model_loss: 0.0023 - model_1_loss: 0.0140 - model_2_loss: 0.0116 - model_3_loss: 0.0023 - model_4_loss: 3.5229e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.2551 - loss2: 6.6592 - val_loss: 36.3513 - val_model_loss: 4.4957 - val_model_1_loss: 5.3115 - val_model_2_loss: 5.2542 - val_model_3_loss: 3.1939 - val_model_4_loss: 1.6123 - val_model_accuracy: 0.4990 - val_model_1_accuracy: 0.5085 - val_model_2_accuracy: 0.5065 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4930 - val_loss1: 9.3653 - val_loss2: 7.1183\n","Epoch 14/300\n","1/1 [==============================] - 8s 8s/step - loss: 10.4870 - model_loss: 3.0059e-05 - model_1_loss: 1.0333e-04 - model_2_loss: 4.4478e-04 - model_3_loss: 5.3048e-06 - model_4_loss: 2.5233e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.4266 - loss2: 6.0598 - val_loss: 36.6429 - val_model_loss: 4.0986 - val_model_1_loss: 5.7220 - val_model_2_loss: 5.8597 - val_model_3_loss: 3.0638 - val_model_4_loss: 1.5033 - val_model_accuracy: 0.5010 - val_model_1_accuracy: 0.5095 - val_model_2_accuracy: 0.5070 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4935 - val_loss1: 9.3039 - val_loss2: 7.0915\n","Epoch 15/300\n","1/1 [==============================] - 8s 8s/step - loss: 11.0076 - model_loss: 1.8313e-04 - model_1_loss: 1.7437e-04 - model_2_loss: 2.5782e-04 - model_3_loss: 2.3565e-04 - model_4_loss: 8.6037e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.8044 - loss2: 6.2023 - val_loss: 36.4475 - val_model_loss: 3.6196 - val_model_1_loss: 5.8969 - val_model_2_loss: 6.2987 - val_model_3_loss: 2.9604 - val_model_4_loss: 1.3608 - val_model_accuracy: 0.5120 - val_model_1_accuracy: 0.5060 - val_model_2_accuracy: 0.5080 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4910 - val_loss1: 9.2311 - val_loss2: 7.0801\n","Epoch 16/300\n","1/1 [==============================] - 8s 8s/step - loss: 9.8998 - model_loss: 0.0743 - model_1_loss: 0.0167 - model_2_loss: 0.1631 - model_3_loss: 0.0043 - model_4_loss: 0.0223 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.9344 - loss2: 5.6845 - val_loss: 37.3154 - val_model_loss: 4.1008 - val_model_1_loss: 5.9009 - val_model_2_loss: 6.9056 - val_model_3_loss: 2.8528 - val_model_4_loss: 1.3367 - val_model_accuracy: 0.5085 - val_model_1_accuracy: 0.5010 - val_model_2_accuracy: 0.5075 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4870 - val_loss1: 9.1507 - val_loss2: 7.0679\n","Epoch 17/300\n","1/1 [==============================] - 8s 8s/step - loss: 9.1692 - model_loss: 0.0721 - model_1_loss: 0.0085 - model_2_loss: 0.0483 - model_3_loss: 0.0308 - model_4_loss: 0.0072 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.4962 - loss2: 5.5062 - val_loss: 38.1203 - val_model_loss: 4.8781 - val_model_1_loss: 5.8251 - val_model_2_loss: 7.2464 - val_model_3_loss: 2.7309 - val_model_4_loss: 1.3267 - val_model_accuracy: 0.5010 - val_model_1_accuracy: 0.4950 - val_model_2_accuracy: 0.5075 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4855 - val_loss1: 9.0519 - val_loss2: 7.0611\n","Epoch 18/300\n","1/1 [==============================] - 8s 8s/step - loss: 10.2927 - model_loss: 0.1957 - model_1_loss: 0.6481 - model_2_loss: 0.0070 - model_3_loss: 0.0197 - model_4_loss: 0.0527 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.6474 - loss2: 5.7220 - val_loss: 38.2392 - val_model_loss: 5.2407 - val_model_1_loss: 5.5170 - val_model_2_loss: 7.5560 - val_model_3_loss: 2.6620 - val_model_4_loss: 1.2633 - val_model_accuracy: 0.4995 - val_model_1_accuracy: 0.4930 - val_model_2_accuracy: 0.5055 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4815 - val_loss1: 8.9449 - val_loss2: 7.0554\n","Epoch 19/300\n","1/1 [==============================] - 8s 8s/step - loss: 9.7619 - model_loss: 4.7586e-04 - model_1_loss: 0.0401 - model_2_loss: 0.0313 - model_3_loss: 0.0013 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.9500 - loss2: 5.7375 - val_loss: 37.6369 - val_model_loss: 5.5259 - val_model_1_loss: 5.1202 - val_model_2_loss: 7.3027 - val_model_3_loss: 2.5896 - val_model_4_loss: 1.2273 - val_model_accuracy: 0.4995 - val_model_1_accuracy: 0.4950 - val_model_2_accuracy: 0.5030 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4830 - val_loss1: 8.8154 - val_loss2: 7.0559\n","Epoch 20/300\n","1/1 [==============================] - 8s 8s/step - loss: 9.2917 - model_loss: 2.7107e-04 - model_1_loss: 0.0060 - model_2_loss: 0.0204 - model_3_loss: 9.1846e-04 - model_4_loss: 0.0013 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.6721 - loss2: 5.5907 - val_loss: 36.7630 - val_model_loss: 5.5886 - val_model_1_loss: 4.6753 - val_model_2_loss: 7.0410 - val_model_3_loss: 2.5239 - val_model_4_loss: 1.1901 - val_model_accuracy: 0.4990 - val_model_1_accuracy: 0.4955 - val_model_2_accuracy: 0.5005 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4785 - val_loss1: 8.6702 - val_loss2: 7.0740\n","Epoch 21/300\n","1/1 [==============================] - 8s 8s/step - loss: 8.6190 - model_loss: 4.2178e-05 - model_1_loss: 2.8171e-05 - model_2_loss: 0.0012 - model_3_loss: 1.5772e-04 - model_4_loss: 9.2187e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.1930 - loss2: 5.4246 - val_loss: 35.8931 - val_model_loss: 5.5475 - val_model_1_loss: 4.2943 - val_model_2_loss: 6.8069 - val_model_3_loss: 2.4789 - val_model_4_loss: 1.1625 - val_model_accuracy: 0.4985 - val_model_1_accuracy: 0.4990 - val_model_2_accuracy: 0.5000 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4695 - val_loss1: 8.5144 - val_loss2: 7.0886\n","Epoch 22/300\n","1/1 [==============================] - 8s 8s/step - loss: 8.5390 - model_loss: 0.0038 - model_1_loss: 0.1023 - model_2_loss: 0.0014 - model_3_loss: 6.9174e-05 - model_4_loss: 1.4323e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.1058 - loss2: 5.3255 - val_loss: 34.5160 - val_model_loss: 5.3947 - val_model_1_loss: 3.5296 - val_model_2_loss: 6.5917 - val_model_3_loss: 2.4226 - val_model_4_loss: 1.1531 - val_model_accuracy: 0.5030 - val_model_1_accuracy: 0.5015 - val_model_2_accuracy: 0.4995 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4490 - val_loss1: 8.3199 - val_loss2: 7.1044\n","Epoch 23/300\n","1/1 [==============================] - 8s 8s/step - loss: 8.5917 - model_loss: 5.1375e-05 - model_1_loss: 2.4932e-04 - model_2_loss: 0.0053 - model_3_loss: 1.6523e-04 - model_4_loss: 0.0019 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.0209 - loss2: 5.5631 - val_loss: 33.2489 - val_model_loss: 5.1674 - val_model_1_loss: 2.9116 - val_model_2_loss: 6.4047 - val_model_3_loss: 2.3826 - val_model_4_loss: 1.1513 - val_model_accuracy: 0.5060 - val_model_1_accuracy: 0.5070 - val_model_2_accuracy: 0.4970 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4285 - val_loss1: 8.1081 - val_loss2: 7.1232\n","Epoch 24/300\n","1/1 [==============================] - 8s 8s/step - loss: 8.1782 - model_loss: 1.4146e-05 - model_1_loss: 1.7941e-05 - model_2_loss: 0.0016 - model_3_loss: 4.3471e-04 - model_4_loss: 1.2656e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.8602 - loss2: 5.3159 - val_loss: 31.9856 - val_model_loss: 4.8806 - val_model_1_loss: 2.4070 - val_model_2_loss: 6.1824 - val_model_3_loss: 2.3407 - val_model_4_loss: 1.1529 - val_model_accuracy: 0.5095 - val_model_1_accuracy: 0.5060 - val_model_2_accuracy: 0.4955 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4060 - val_loss1: 7.8761 - val_loss2: 7.1459\n","Epoch 25/300\n","1/1 [==============================] - 8s 8s/step - loss: 9.5661 - model_loss: 0.0059 - model_1_loss: 0.4603 - model_2_loss: 0.7196 - model_3_loss: 0.0811 - model_4_loss: 0.0049 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.6667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.1509 - loss2: 5.1434 - val_loss: 29.1091 - val_model_loss: 4.5910 - val_model_1_loss: 1.8268 - val_model_2_loss: 4.3047 - val_model_3_loss: 2.4373 - val_model_4_loss: 1.1658 - val_model_accuracy: 0.5160 - val_model_1_accuracy: 0.5115 - val_model_2_accuracy: 0.4755 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3920 - val_loss1: 7.6216 - val_loss2: 7.1618\n","Epoch 26/300\n","1/1 [==============================] - 8s 8s/step - loss: 8.3121 - model_loss: 3.9880e-04 - model_1_loss: 4.9952e-04 - model_2_loss: 5.7431e-04 - model_3_loss: 0.0020 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.0171 - loss2: 5.2905 - val_loss: 26.6098 - val_model_loss: 4.2382 - val_model_1_loss: 1.4146 - val_model_2_loss: 2.6874 - val_model_3_loss: 2.5405 - val_model_4_loss: 1.1762 - val_model_accuracy: 0.5230 - val_model_1_accuracy: 0.4970 - val_model_2_accuracy: 0.4935 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3860 - val_loss1: 7.3765 - val_loss2: 7.1763\n","Epoch 27/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.9127 - model_loss: 3.7785e-04 - model_1_loss: 5.7424e-04 - model_2_loss: 0.0104 - model_3_loss: 7.3259e-04 - model_4_loss: 7.9372e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7282 - loss2: 5.1716 - val_loss: 24.8692 - val_model_loss: 3.9183 - val_model_1_loss: 1.2375 - val_model_2_loss: 1.5783 - val_model_3_loss: 2.6298 - val_model_4_loss: 1.1911 - val_model_accuracy: 0.5295 - val_model_1_accuracy: 0.4495 - val_model_2_accuracy: 0.4680 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3855 - val_loss1: 7.1283 - val_loss2: 7.1860\n","Epoch 28/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.6967 - model_loss: 2.3119e-04 - model_1_loss: 0.0278 - model_2_loss: 0.0759 - model_3_loss: 0.0017 - model_4_loss: 1.8891e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4765 - loss2: 5.1145 - val_loss: 24.1097 - val_model_loss: 3.5923 - val_model_1_loss: 1.2453 - val_model_2_loss: 1.2789 - val_model_3_loss: 2.6919 - val_model_4_loss: 1.2100 - val_model_accuracy: 0.5285 - val_model_1_accuracy: 0.4140 - val_model_2_accuracy: 0.3835 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3830 - val_loss1: 6.8837 - val_loss2: 7.2075\n","Epoch 29/300\n","1/1 [==============================] - 8s 8s/step - loss: 8.8981 - model_loss: 0.9601 - model_1_loss: 0.0018 - model_2_loss: 0.1531 - model_3_loss: 0.0086 - model_4_loss: 0.0059 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4926 - loss2: 5.2761 - val_loss: 23.0606 - val_model_loss: 2.4032 - val_model_1_loss: 1.3607 - val_model_2_loss: 1.3862 - val_model_3_loss: 2.7370 - val_model_4_loss: 1.2361 - val_model_accuracy: 0.5475 - val_model_1_accuracy: 0.4145 - val_model_2_accuracy: 0.4690 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3750 - val_loss1: 6.6571 - val_loss2: 7.2803\n","Epoch 30/300\n","1/1 [==============================] - 8s 8s/step - loss: 8.2988 - model_loss: 0.0011 - model_1_loss: 0.0026 - model_2_loss: 0.0171 - model_3_loss: 0.0279 - model_4_loss: 0.0015 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7744 - loss2: 5.4742 - val_loss: 22.5803 - val_model_loss: 1.6228 - val_model_1_loss: 1.5236 - val_model_2_loss: 1.6632 - val_model_3_loss: 2.7195 - val_model_4_loss: 1.2641 - val_model_accuracy: 0.5335 - val_model_1_accuracy: 0.4530 - val_model_2_accuracy: 0.5135 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3700 - val_loss1: 6.4453 - val_loss2: 7.3418\n","Epoch 31/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.4480 - model_loss: 5.2069e-05 - model_1_loss: 0.0027 - model_2_loss: 0.0080 - model_3_loss: 0.0013 - model_4_loss: 1.0808e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2309 - loss2: 5.2051 - val_loss: 22.6302 - val_model_loss: 1.3225 - val_model_1_loss: 1.6930 - val_model_2_loss: 1.9845 - val_model_3_loss: 2.6939 - val_model_4_loss: 1.2953 - val_model_accuracy: 0.4495 - val_model_1_accuracy: 0.4805 - val_model_2_accuracy: 0.5160 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3655 - val_loss1: 6.2472 - val_loss2: 7.3937\n","Epoch 32/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.3730 - model_loss: 3.7908e-04 - model_1_loss: 0.0029 - model_2_loss: 0.0149 - model_3_loss: 7.8296e-04 - model_4_loss: 2.4616e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2119 - loss2: 5.1421 - val_loss: 23.0918 - val_model_loss: 1.4962 - val_model_1_loss: 1.8647 - val_model_2_loss: 2.2257 - val_model_3_loss: 2.6798 - val_model_4_loss: 1.3352 - val_model_accuracy: 0.4480 - val_model_1_accuracy: 0.4945 - val_model_2_accuracy: 0.5200 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3800 - val_loss1: 6.0514 - val_loss2: 7.4387\n","Epoch 33/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.5894 - model_loss: 9.8247e-04 - model_1_loss: 0.0104 - model_2_loss: 0.0101 - model_3_loss: 0.0014 - model_4_loss: 4.0767e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4624 - loss2: 5.1041 - val_loss: 23.7433 - val_model_loss: 1.9464 - val_model_1_loss: 2.0024 - val_model_2_loss: 2.4144 - val_model_3_loss: 2.6748 - val_model_4_loss: 1.3852 - val_model_accuracy: 0.4900 - val_model_1_accuracy: 0.4955 - val_model_2_accuracy: 0.5235 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3915 - val_loss1: 5.8505 - val_loss2: 7.4697\n","Epoch 34/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.8465 - model_loss: 0.0058 - model_1_loss: 0.0071 - model_2_loss: 0.0052 - model_3_loss: 0.0075 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.5716 - loss2: 5.2477 - val_loss: 24.3297 - val_model_loss: 2.4014 - val_model_1_loss: 2.1068 - val_model_2_loss: 2.5783 - val_model_3_loss: 2.6598 - val_model_4_loss: 1.4298 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.5300 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3930 - val_loss1: 5.6640 - val_loss2: 7.4897\n","Epoch 35/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.3365 - model_loss: 1.6892e-04 - model_1_loss: 5.1851e-04 - model_2_loss: 0.0032 - model_3_loss: 0.0011 - model_4_loss: 8.9661e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0748 - loss2: 5.2566 - val_loss: 24.7564 - val_model_loss: 2.7744 - val_model_1_loss: 2.1811 - val_model_2_loss: 2.6916 - val_model_3_loss: 2.6433 - val_model_4_loss: 1.4721 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.5325 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4000 - val_loss1: 5.4874 - val_loss2: 7.5066\n","Epoch 36/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.6777 - model_loss: 0.0201 - model_1_loss: 0.0132 - model_2_loss: 0.0324 - model_3_loss: 0.0131 - model_4_loss: 0.0017 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3769 - loss2: 5.2201 - val_loss: 24.9717 - val_model_loss: 2.9929 - val_model_1_loss: 2.2098 - val_model_2_loss: 2.7850 - val_model_3_loss: 2.6177 - val_model_4_loss: 1.5197 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.5315 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4095 - val_loss1: 5.3228 - val_loss2: 7.5238\n","Epoch 37/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.0016 - model_loss: 0.0011 - model_1_loss: 7.5442e-04 - model_2_loss: 0.0051 - model_3_loss: 3.8302e-04 - model_4_loss: 7.3208e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8563 - loss2: 5.1379 - val_loss: 25.0551 - val_model_loss: 3.1468 - val_model_1_loss: 2.2199 - val_model_2_loss: 2.8402 - val_model_3_loss: 2.5892 - val_model_4_loss: 1.5614 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.5330 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4260 - val_loss1: 5.1613 - val_loss2: 7.5362\n","Epoch 38/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.5863 - model_loss: 3.6281e-04 - model_1_loss: 0.0016 - model_2_loss: 0.0133 - model_3_loss: 0.0015 - model_4_loss: 2.4038e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3554 - loss2: 5.2140 - val_loss: 25.0704 - val_model_loss: 3.2447 - val_model_1_loss: 2.2356 - val_model_2_loss: 2.8489 - val_model_3_loss: 2.5750 - val_model_4_loss: 1.5979 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.5355 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4355 - val_loss1: 5.0217 - val_loss2: 7.5465\n","Epoch 39/300\n","1/1 [==============================] - 8s 8s/step - loss: 8.3426 - model_loss: 0.0157 - model_1_loss: 0.7085 - model_2_loss: 0.1340 - model_3_loss: 0.0337 - model_4_loss: 0.0447 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2800 - loss2: 5.1260 - val_loss: 24.0764 - val_model_loss: 3.2889 - val_model_1_loss: 1.7510 - val_model_2_loss: 2.5681 - val_model_3_loss: 2.4548 - val_model_4_loss: 1.5301 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4950 - val_model_2_accuracy: 0.5325 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4090 - val_loss1: 4.9140 - val_loss2: 7.5695\n","Epoch 40/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.1695 - model_loss: 4.4892e-04 - model_1_loss: 0.0060 - model_2_loss: 0.0083 - model_3_loss: 0.0023 - model_4_loss: 0.0010 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9453 - loss2: 5.2061 - val_loss: 23.2145 - val_model_loss: 3.2790 - val_model_1_loss: 1.3810 - val_model_2_loss: 2.3198 - val_model_3_loss: 2.3438 - val_model_4_loss: 1.4691 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4710 - val_model_2_accuracy: 0.5345 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3980 - val_loss1: 4.8291 - val_loss2: 7.5928\n","Epoch 41/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.0863 - model_loss: 0.0106 - model_1_loss: 8.1197e-04 - model_2_loss: 0.0082 - model_3_loss: 8.8179e-04 - model_4_loss: 2.2986e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9004 - loss2: 5.1651 - val_loss: 22.5089 - val_model_loss: 3.2426 - val_model_1_loss: 1.1473 - val_model_2_loss: 2.0825 - val_model_3_loss: 2.2512 - val_model_4_loss: 1.4294 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4135 - val_model_2_accuracy: 0.5425 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3845 - val_loss1: 4.7438 - val_loss2: 7.6120\n","Epoch 42/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.1911 - model_loss: 0.0111 - model_1_loss: 7.8008e-04 - model_2_loss: 0.0013 - model_3_loss: 0.0068 - model_4_loss: 4.6992e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0897 - loss2: 5.0809 - val_loss: 21.9956 - val_model_loss: 3.2153 - val_model_1_loss: 1.0330 - val_model_2_loss: 1.9057 - val_model_3_loss: 2.1734 - val_model_4_loss: 1.4076 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.3930 - val_model_2_accuracy: 0.5360 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3825 - val_loss1: 4.6509 - val_loss2: 7.6096\n","Epoch 43/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.2726 - model_loss: 0.0017 - model_1_loss: 0.0057 - model_2_loss: 0.0080 - model_3_loss: 0.0042 - model_4_loss: 0.0022 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1078 - loss2: 5.1430 - val_loss: 21.6078 - val_model_loss: 3.1699 - val_model_1_loss: 1.0051 - val_model_2_loss: 1.7607 - val_model_3_loss: 2.1136 - val_model_4_loss: 1.3905 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4235 - val_model_2_accuracy: 0.5080 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3830 - val_loss1: 4.5628 - val_loss2: 7.6051\n","Epoch 44/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.9749 - model_loss: 0.0015 - model_1_loss: 0.0047 - model_2_loss: 0.0095 - model_3_loss: 0.0028 - model_4_loss: 9.6427e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8157 - loss2: 5.1397 - val_loss: 21.3058 - val_model_loss: 3.1229 - val_model_1_loss: 1.0328 - val_model_2_loss: 1.6286 - val_model_3_loss: 2.0630 - val_model_4_loss: 1.3780 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4585 - val_model_2_accuracy: 0.5000 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3855 - val_loss1: 4.4792 - val_loss2: 7.6013\n","Epoch 45/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.6260 - model_loss: 0.1833 - model_1_loss: 5.2296e-04 - model_2_loss: 1.7773e-04 - model_3_loss: 5.9979e-05 - model_4_loss: 3.4173e-06 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2546 - loss2: 5.1873 - val_loss: 20.6889 - val_model_loss: 2.6821 - val_model_1_loss: 1.0930 - val_model_2_loss: 1.5366 - val_model_3_loss: 2.0168 - val_model_4_loss: 1.3662 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4750 - val_model_2_accuracy: 0.4655 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3850 - val_loss1: 4.4036 - val_loss2: 7.5907\n","Epoch 46/300\n","1/1 [==============================] - 8s 8s/step - loss: 9.8756 - model_loss: 0.6115 - model_1_loss: 0.0309 - model_2_loss: 0.6666 - model_3_loss: 0.6176 - model_4_loss: 0.8796 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 2.0223 - loss2: 5.0470 - val_loss: 19.6406 - val_model_loss: 2.0314 - val_model_1_loss: 1.1597 - val_model_2_loss: 1.5987 - val_model_3_loss: 1.6151 - val_model_4_loss: 1.2537 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.4850 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4245 - val_loss1: 4.3795 - val_loss2: 7.6025\n","Epoch 47/300\n","1/1 [==============================] - 8s 8s/step - loss: 9.0113 - model_loss: 0.5240 - model_1_loss: 0.0023 - model_2_loss: 0.4631 - model_3_loss: 0.2248 - model_4_loss: 0.5798 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 2.0847 - loss2: 5.1326 - val_loss: 19.0707 - val_model_loss: 1.4030 - val_model_1_loss: 1.2339 - val_model_2_loss: 1.8543 - val_model_3_loss: 1.1503 - val_model_4_loss: 1.4181 - val_model_accuracy: 0.4840 - val_model_1_accuracy: 0.4840 - val_model_2_accuracy: 0.5380 - val_model_3_accuracy: 0.4775 - val_model_4_accuracy: 0.4980 - val_loss1: 4.3820 - val_loss2: 7.6291\n","Epoch 48/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.2327 - model_loss: 0.0023 - model_1_loss: 0.0276 - model_2_loss: 0.0064 - model_3_loss: 0.0871 - model_4_loss: 0.0353 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9361 - loss2: 5.1380 - val_loss: 19.2158 - val_model_loss: 1.0793 - val_model_1_loss: 1.2809 - val_model_2_loss: 2.1616 - val_model_3_loss: 0.9433 - val_model_4_loss: 1.7441 - val_model_accuracy: 0.4730 - val_model_1_accuracy: 0.4840 - val_model_2_accuracy: 0.5395 - val_model_3_accuracy: 0.3280 - val_model_4_accuracy: 0.5060 - val_loss1: 4.3641 - val_loss2: 7.6426\n","Epoch 49/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.8667 - model_loss: 3.0262e-04 - model_1_loss: 0.0092 - model_2_loss: 0.0021 - model_3_loss: 0.0031 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7269 - loss2: 5.1236 - val_loss: 19.8552 - val_model_loss: 1.0216 - val_model_1_loss: 1.3325 - val_model_2_loss: 2.4647 - val_model_3_loss: 0.8911 - val_model_4_loss: 2.1639 - val_model_accuracy: 0.4685 - val_model_1_accuracy: 0.4850 - val_model_2_accuracy: 0.5395 - val_model_3_accuracy: 0.3635 - val_model_4_accuracy: 0.5085 - val_loss1: 4.3388 - val_loss2: 7.6424\n","Epoch 50/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.6543 - model_loss: 0.1636 - model_1_loss: 0.0092 - model_2_loss: 0.0526 - model_3_loss: 0.1210 - model_4_loss: 0.2225 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 2.0145 - loss2: 5.0708 - val_loss: 20.4399 - val_model_loss: 1.1001 - val_model_1_loss: 1.3786 - val_model_2_loss: 2.6812 - val_model_3_loss: 0.9138 - val_model_4_loss: 2.4389 - val_model_accuracy: 0.4720 - val_model_1_accuracy: 0.4865 - val_model_2_accuracy: 0.5420 - val_model_3_accuracy: 0.4580 - val_model_4_accuracy: 0.4940 - val_loss1: 4.2945 - val_loss2: 7.6329\n","Epoch 51/300\n","1/1 [==============================] - 9s 9s/step - loss: 6.8229 - model_loss: 5.8823e-04 - model_1_loss: 0.0017 - model_2_loss: 0.0022 - model_3_loss: 0.0028 - model_4_loss: 1.1037e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6037 - loss2: 5.2117 - val_loss: 21.0523 - val_model_loss: 1.2287 - val_model_1_loss: 1.4225 - val_model_2_loss: 2.8420 - val_model_3_loss: 0.9880 - val_model_4_loss: 2.7010 - val_model_accuracy: 0.5045 - val_model_1_accuracy: 0.4860 - val_model_2_accuracy: 0.5435 - val_model_3_accuracy: 0.5045 - val_model_4_accuracy: 0.4865 - val_loss1: 4.2490 - val_loss2: 7.6210\n","Epoch 52/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.4524 - model_loss: 0.0623 - model_1_loss: 0.0150 - model_2_loss: 0.0155 - model_3_loss: 0.3969 - model_4_loss: 0.1323 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 1.8274 - loss2: 5.0029 - val_loss: 21.2138 - val_model_loss: 1.3283 - val_model_1_loss: 1.4613 - val_model_2_loss: 2.9506 - val_model_3_loss: 0.9808 - val_model_4_loss: 2.6977 - val_model_accuracy: 0.5150 - val_model_1_accuracy: 0.4865 - val_model_2_accuracy: 0.5410 - val_model_3_accuracy: 0.5200 - val_model_4_accuracy: 0.4820 - val_loss1: 4.1883 - val_loss2: 7.6068\n","Epoch 53/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.8184 - model_loss: 0.0013 - model_1_loss: 0.0016 - model_2_loss: 7.2553e-04 - model_3_loss: 0.0011 - model_4_loss: 3.6603e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6864 - loss2: 5.1269 - val_loss: 21.2995 - val_model_loss: 1.4138 - val_model_1_loss: 1.4902 - val_model_2_loss: 3.0202 - val_model_3_loss: 0.9761 - val_model_4_loss: 2.6769 - val_model_accuracy: 0.5195 - val_model_1_accuracy: 0.4875 - val_model_2_accuracy: 0.5400 - val_model_3_accuracy: 0.5210 - val_model_4_accuracy: 0.4975 - val_loss1: 4.1291 - val_loss2: 7.5932\n","Epoch 54/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.2896 - model_loss: 0.1741 - model_1_loss: 0.0143 - model_2_loss: 0.2862 - model_3_loss: 0.0171 - model_4_loss: 0.0708 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6557 - loss2: 5.0716 - val_loss: 20.3639 - val_model_loss: 1.2866 - val_model_1_loss: 1.4994 - val_model_2_loss: 2.5205 - val_model_3_loss: 0.9720 - val_model_4_loss: 2.4403 - val_model_accuracy: 0.5160 - val_model_1_accuracy: 0.4870 - val_model_2_accuracy: 0.5430 - val_model_3_accuracy: 0.5160 - val_model_4_accuracy: 0.5040 - val_loss1: 4.0548 - val_loss2: 7.5903\n","Epoch 55/300\n","1/1 [==============================] - 8s 8s/step - loss: 8.4111 - model_loss: 0.0062 - model_1_loss: 0.0019 - model_2_loss: 0.0179 - model_3_loss: 0.7809 - model_4_loss: 0.0047 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.5000 - model_4_accuracy: 1.0000 - loss1: 2.3884 - loss2: 5.2111 - val_loss: 19.4513 - val_model_loss: 1.1757 - val_model_1_loss: 1.5086 - val_model_2_loss: 2.0937 - val_model_3_loss: 0.8573 - val_model_4_loss: 2.2707 - val_model_accuracy: 0.5140 - val_model_1_accuracy: 0.4860 - val_model_2_accuracy: 0.5385 - val_model_3_accuracy: 0.5015 - val_model_4_accuracy: 0.5040 - val_loss1: 3.9743 - val_loss2: 7.5710\n","Epoch 56/300\n","1/1 [==============================] - 8s 8s/step - loss: 8.0047 - model_loss: 0.1195 - model_1_loss: 0.1060 - model_2_loss: 0.1071 - model_3_loss: 0.4416 - model_4_loss: 0.0436 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.1140 - loss2: 5.0729 - val_loss: 18.3100 - val_model_loss: 1.0195 - val_model_1_loss: 1.4014 - val_model_2_loss: 1.6184 - val_model_3_loss: 0.8084 - val_model_4_loss: 2.0439 - val_model_accuracy: 0.4925 - val_model_1_accuracy: 0.4860 - val_model_2_accuracy: 0.5345 - val_model_3_accuracy: 0.3835 - val_model_4_accuracy: 0.5040 - val_loss1: 3.8835 - val_loss2: 7.5349\n","Epoch 57/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.3900 - model_loss: 0.0698 - model_1_loss: 0.0030 - model_2_loss: 0.0512 - model_3_loss: 0.0796 - model_4_loss: 0.0487 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0576 - loss2: 5.0800 - val_loss: 17.5679 - val_model_loss: 0.9211 - val_model_1_loss: 1.3051 - val_model_2_loss: 1.2574 - val_model_3_loss: 0.9683 - val_model_4_loss: 1.8158 - val_model_accuracy: 0.4995 - val_model_1_accuracy: 0.4840 - val_model_2_accuracy: 0.4905 - val_model_3_accuracy: 0.4650 - val_model_4_accuracy: 0.5040 - val_loss1: 3.8096 - val_loss2: 7.4905\n","Epoch 58/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.5435 - model_loss: 0.0041 - model_1_loss: 0.0251 - model_2_loss: 0.0126 - model_3_loss: 0.0410 - model_4_loss: 0.0115 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2827 - loss2: 5.1665 - val_loss: 17.3184 - val_model_loss: 0.8807 - val_model_1_loss: 1.2445 - val_model_2_loss: 1.0730 - val_model_3_loss: 1.3014 - val_model_4_loss: 1.6462 - val_model_accuracy: 0.5085 - val_model_1_accuracy: 0.4820 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5040 - val_loss1: 3.7393 - val_loss2: 7.4333\n","Epoch 59/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.9513 - model_loss: 5.6782e-04 - model_1_loss: 0.0083 - model_2_loss: 0.0279 - model_3_loss: 0.0011 - model_4_loss: 0.0046 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7225 - loss2: 5.1863 - val_loss: 17.4135 - val_model_loss: 0.8796 - val_model_1_loss: 1.1817 - val_model_2_loss: 1.0753 - val_model_3_loss: 1.7165 - val_model_4_loss: 1.5000 - val_model_accuracy: 0.4985 - val_model_1_accuracy: 0.4700 - val_model_2_accuracy: 0.4525 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5040 - val_loss1: 3.6808 - val_loss2: 7.3795\n","Epoch 60/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.9915 - model_loss: 9.6653e-04 - model_1_loss: 1.7471e-04 - model_2_loss: 0.0031 - model_3_loss: 5.4249e-04 - model_4_loss: 0.0103 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8528 - loss2: 5.1237 - val_loss: 17.7536 - val_model_loss: 0.9015 - val_model_1_loss: 1.1324 - val_model_2_loss: 1.2264 - val_model_3_loss: 2.1522 - val_model_4_loss: 1.3926 - val_model_accuracy: 0.4980 - val_model_1_accuracy: 0.4540 - val_model_2_accuracy: 0.4760 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5040 - val_loss1: 3.6331 - val_loss2: 7.3154\n","Epoch 61/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.9743 - model_loss: 0.0034 - model_1_loss: 0.0015 - model_2_loss: 0.0014 - model_3_loss: 0.0012 - model_4_loss: 0.0034 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7979 - loss2: 5.1656 - val_loss: 18.2062 - val_model_loss: 0.9386 - val_model_1_loss: 1.0918 - val_model_2_loss: 1.4461 - val_model_3_loss: 2.5815 - val_model_4_loss: 1.3087 - val_model_accuracy: 0.5035 - val_model_1_accuracy: 0.4245 - val_model_2_accuracy: 0.4945 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5040 - val_loss1: 3.5885 - val_loss2: 7.2510\n","Epoch 62/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.8401 - model_loss: 0.0064 - model_1_loss: 8.9104e-04 - model_2_loss: 0.0013 - model_3_loss: 0.0011 - model_4_loss: 0.0093 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7212 - loss2: 5.1000 - val_loss: 18.6845 - val_model_loss: 0.9817 - val_model_1_loss: 1.0628 - val_model_2_loss: 1.6700 - val_model_3_loss: 2.9857 - val_model_4_loss: 1.2438 - val_model_accuracy: 0.4985 - val_model_1_accuracy: 0.3905 - val_model_2_accuracy: 0.4955 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5085 - val_loss1: 3.5530 - val_loss2: 7.1875\n","Epoch 63/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.1338 - model_loss: 9.6281e-04 - model_1_loss: 0.0335 - model_2_loss: 0.2833 - model_3_loss: 0.0016 - model_4_loss: 0.0620 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7191 - loss2: 5.0334 - val_loss: 18.9582 - val_model_loss: 1.0288 - val_model_1_loss: 1.0534 - val_model_2_loss: 1.6653 - val_model_3_loss: 3.3613 - val_model_4_loss: 1.1840 - val_model_accuracy: 0.5035 - val_model_1_accuracy: 0.3520 - val_model_2_accuracy: 0.4950 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5215 - val_loss1: 3.5215 - val_loss2: 7.1439\n","Epoch 64/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.9280 - model_loss: 0.0312 - model_1_loss: 0.0763 - model_2_loss: 0.0438 - model_3_loss: 0.0805 - model_4_loss: 0.0019 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6925 - loss2: 5.0017 - val_loss: 19.2292 - val_model_loss: 1.0756 - val_model_1_loss: 1.0644 - val_model_2_loss: 1.6834 - val_model_3_loss: 3.6834 - val_model_4_loss: 1.1231 - val_model_accuracy: 0.4970 - val_model_1_accuracy: 0.3310 - val_model_2_accuracy: 0.4950 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5435 - val_loss1: 3.4941 - val_loss2: 7.1053\n","Epoch 65/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.8626 - model_loss: 6.3463e-04 - model_1_loss: 0.0014 - model_2_loss: 3.6941e-04 - model_3_loss: 0.0040 - model_4_loss: 7.3593e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7873 - loss2: 5.0683 - val_loss: 19.4758 - val_model_loss: 1.1158 - val_model_1_loss: 1.0781 - val_model_2_loss: 1.6995 - val_model_3_loss: 3.9606 - val_model_4_loss: 1.0749 - val_model_accuracy: 0.4950 - val_model_1_accuracy: 0.3120 - val_model_2_accuracy: 0.4945 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5645 - val_loss1: 3.4749 - val_loss2: 7.0719\n","Epoch 66/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.7875 - model_loss: 3.1119e-04 - model_1_loss: 0.0039 - model_2_loss: 0.0013 - model_3_loss: 0.0016 - model_4_loss: 0.0231 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7532 - loss2: 5.0041 - val_loss: 19.6995 - val_model_loss: 1.1536 - val_model_1_loss: 1.0947 - val_model_2_loss: 1.7233 - val_model_3_loss: 4.1968 - val_model_4_loss: 1.0385 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.2975 - val_model_2_accuracy: 0.4935 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5890 - val_loss1: 3.4504 - val_loss2: 7.0422\n","Epoch 67/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.0801 - model_loss: 0.0065 - model_1_loss: 0.0012 - model_2_loss: 0.0011 - model_3_loss: 0.0115 - model_4_loss: 0.0558 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8958 - loss2: 5.1082 - val_loss: 19.8957 - val_model_loss: 1.1924 - val_model_1_loss: 1.1103 - val_model_2_loss: 1.7613 - val_model_3_loss: 4.3924 - val_model_4_loss: 0.9797 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.2800 - val_model_2_accuracy: 0.4920 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.6370 - val_loss1: 3.4319 - val_loss2: 7.0277\n","Epoch 68/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.9235 - model_loss: 3.4330e-05 - model_1_loss: 0.0028 - model_2_loss: 0.0013 - model_3_loss: 5.8483e-05 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8003 - loss2: 5.1172 - val_loss: 20.0893 - val_model_loss: 1.2322 - val_model_1_loss: 1.1258 - val_model_2_loss: 1.8053 - val_model_3_loss: 4.5631 - val_model_4_loss: 0.9400 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.2695 - val_model_2_accuracy: 0.4910 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.6560 - val_loss1: 3.4140 - val_loss2: 7.0089\n","Epoch 69/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4909 - model_loss: 7.4897e-05 - model_1_loss: 3.5077e-04 - model_2_loss: 2.3949e-04 - model_3_loss: 8.0485e-04 - model_4_loss: 5.4362e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.4547 - loss2: 5.0342 - val_loss: 20.2554 - val_model_loss: 1.2632 - val_model_1_loss: 1.1427 - val_model_2_loss: 1.8480 - val_model_3_loss: 4.6928 - val_model_4_loss: 0.9125 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.2555 - val_model_2_accuracy: 0.4885 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.6300 - val_loss1: 3.3986 - val_loss2: 6.9975\n","Epoch 70/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.7206 - model_loss: 2.3523e-05 - model_1_loss: 0.0018 - model_2_loss: 0.0059 - model_3_loss: 0.0012 - model_4_loss: 0.0037 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6087 - loss2: 5.0992 - val_loss: 20.4131 - val_model_loss: 1.2943 - val_model_1_loss: 1.1600 - val_model_2_loss: 1.8890 - val_model_3_loss: 4.7999 - val_model_4_loss: 0.8993 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.2445 - val_model_2_accuracy: 0.4860 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5900 - val_loss1: 3.3842 - val_loss2: 6.9865\n","Epoch 71/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.6636 - model_loss: 5.4293e-05 - model_1_loss: 0.0020 - model_2_loss: 4.7805e-04 - model_3_loss: 7.4447e-04 - model_4_loss: 8.0138e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.5049 - loss2: 5.1553 - val_loss: 20.5567 - val_model_loss: 1.3223 - val_model_1_loss: 1.1797 - val_model_2_loss: 1.9341 - val_model_3_loss: 4.8748 - val_model_4_loss: 0.8966 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.2400 - val_model_2_accuracy: 0.4845 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5460 - val_loss1: 3.3702 - val_loss2: 6.9791\n","Epoch 72/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.6641 - model_loss: 0.3340 - model_1_loss: 0.0850 - model_2_loss: 0.0340 - model_3_loss: 0.4844 - model_4_loss: 0.0196 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 1.7254 - loss2: 4.9817 - val_loss: 20.4937 - val_model_loss: 1.3761 - val_model_1_loss: 1.1946 - val_model_2_loss: 1.9674 - val_model_3_loss: 4.7096 - val_model_4_loss: 0.9028 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.2590 - val_model_2_accuracy: 0.4850 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4980 - val_loss1: 3.3399 - val_loss2: 7.0033\n","Epoch 73/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.7012 - model_loss: 9.4092e-05 - model_1_loss: 0.0551 - model_2_loss: 0.0026 - model_3_loss: 0.0025 - model_4_loss: 7.8432e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.5491 - loss2: 5.0918 - val_loss: 20.4607 - val_model_loss: 1.4227 - val_model_1_loss: 1.2288 - val_model_2_loss: 2.0012 - val_model_3_loss: 4.5405 - val_model_4_loss: 0.9152 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.2720 - val_model_2_accuracy: 0.4820 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4695 - val_loss1: 3.3221 - val_loss2: 7.0303\n","Epoch 74/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.8316 - model_loss: 0.0144 - model_1_loss: 0.0012 - model_2_loss: 0.0019 - model_3_loss: 0.0082 - model_4_loss: 0.1577 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 1.4016 - loss2: 5.2465 - val_loss: 20.4959 - val_model_loss: 1.4654 - val_model_1_loss: 1.2673 - val_model_2_loss: 2.0581 - val_model_3_loss: 4.4128 - val_model_4_loss: 0.9334 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.2875 - val_model_2_accuracy: 0.4830 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4430 - val_loss1: 3.3098 - val_loss2: 7.0492\n","Epoch 75/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.8441 - model_loss: 9.1366e-05 - model_1_loss: 0.0406 - model_2_loss: 3.8488e-04 - model_3_loss: 0.0204 - model_4_loss: 0.0024 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.5886 - loss2: 5.1916 - val_loss: 20.5241 - val_model_loss: 1.5049 - val_model_1_loss: 1.2814 - val_model_2_loss: 2.1022 - val_model_3_loss: 4.2966 - val_model_4_loss: 0.9646 - val_model_accuracy: 0.4955 - val_model_1_accuracy: 0.3060 - val_model_2_accuracy: 0.4845 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4465 - val_loss1: 3.3025 - val_loss2: 7.0719\n","Epoch 76/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.5641 - model_loss: 5.0800e-05 - model_1_loss: 4.8748e-04 - model_2_loss: 0.0033 - model_3_loss: 4.3782e-04 - model_4_loss: 6.4938e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.4283 - loss2: 5.1309 - val_loss: 20.5697 - val_model_loss: 1.5423 - val_model_1_loss: 1.2940 - val_model_2_loss: 2.1488 - val_model_3_loss: 4.1854 - val_model_4_loss: 1.0042 - val_model_accuracy: 0.4955 - val_model_1_accuracy: 0.3155 - val_model_2_accuracy: 0.4845 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4450 - val_loss1: 3.2974 - val_loss2: 7.0976\n","Epoch 77/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.7670 - model_loss: 1.1345e-05 - model_1_loss: 4.2548e-04 - model_2_loss: 4.8139e-04 - model_3_loss: 5.7668e-05 - model_4_loss: 1.3263e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7265 - loss2: 5.0395 - val_loss: 20.6335 - val_model_loss: 1.5771 - val_model_1_loss: 1.3100 - val_model_2_loss: 2.1850 - val_model_3_loss: 4.0991 - val_model_4_loss: 1.0515 - val_model_accuracy: 0.4955 - val_model_1_accuracy: 0.3220 - val_model_2_accuracy: 0.4855 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4530 - val_loss1: 3.2919 - val_loss2: 7.1188\n","Epoch 78/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.7523 - model_loss: 0.0014 - model_1_loss: 4.3081e-04 - model_2_loss: 3.7309e-04 - model_3_loss: 2.1358e-05 - model_4_loss: 2.3762e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6003 - loss2: 5.1498 - val_loss: 20.6906 - val_model_loss: 1.6044 - val_model_1_loss: 1.3246 - val_model_2_loss: 2.2199 - val_model_3_loss: 4.0053 - val_model_4_loss: 1.1002 - val_model_accuracy: 0.4950 - val_model_1_accuracy: 0.3300 - val_model_2_accuracy: 0.4875 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4625 - val_loss1: 3.2888 - val_loss2: 7.1475\n","Epoch 79/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.5228 - model_loss: 1.1823e-04 - model_1_loss: 5.0575e-04 - model_2_loss: 0.0049 - model_3_loss: 6.5216e-04 - model_4_loss: 0.0047 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2973 - loss2: 5.2146 - val_loss: 20.7685 - val_model_loss: 1.6336 - val_model_1_loss: 1.3377 - val_model_2_loss: 2.2594 - val_model_3_loss: 3.9272 - val_model_4_loss: 1.1518 - val_model_accuracy: 0.4950 - val_model_1_accuracy: 0.3405 - val_model_2_accuracy: 0.4875 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4675 - val_loss1: 3.2858 - val_loss2: 7.1730\n","Epoch 80/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.5906 - model_loss: 1.9096e-04 - model_1_loss: 0.0015 - model_2_loss: 0.0014 - model_3_loss: 7.0994e-04 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.4338 - loss2: 5.1512 - val_loss: 20.8658 - val_model_loss: 1.6607 - val_model_1_loss: 1.3520 - val_model_2_loss: 2.3059 - val_model_3_loss: 3.8654 - val_model_4_loss: 1.2035 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3445 - val_model_2_accuracy: 0.4875 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4800 - val_loss1: 3.2841 - val_loss2: 7.1941\n","Epoch 81/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.9414 - model_loss: 0.0280 - model_1_loss: 0.2165 - model_2_loss: 0.3433 - model_3_loss: 0.3821 - model_4_loss: 0.2198 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 1.7693 - loss2: 4.9825 - val_loss: 20.6436 - val_model_loss: 1.6856 - val_model_1_loss: 1.3430 - val_model_2_loss: 2.2315 - val_model_3_loss: 3.6695 - val_model_4_loss: 1.2394 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3395 - val_model_2_accuracy: 0.4870 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4785 - val_loss1: 3.2864 - val_loss2: 7.1883\n","Epoch 82/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.6540 - model_loss: 1.5815e-05 - model_1_loss: 3.3601e-04 - model_2_loss: 7.7478e-04 - model_3_loss: 4.0191e-05 - model_4_loss: 1.5083e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6011 - loss2: 5.0516 - val_loss: 20.4247 - val_model_loss: 1.7046 - val_model_1_loss: 1.3528 - val_model_2_loss: 2.1549 - val_model_3_loss: 3.4823 - val_model_4_loss: 1.2653 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3490 - val_model_2_accuracy: 0.4875 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4770 - val_loss1: 3.2888 - val_loss2: 7.1759\n","Epoch 83/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.6194 - model_loss: 9.3210e-05 - model_1_loss: 0.0011 - model_2_loss: 0.0045 - model_3_loss: 5.4703e-04 - model_4_loss: 0.0184 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.4791 - loss2: 5.1156 - val_loss: 20.2598 - val_model_loss: 1.7233 - val_model_1_loss: 1.3730 - val_model_2_loss: 2.0988 - val_model_3_loss: 3.3263 - val_model_4_loss: 1.2830 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3625 - val_model_2_accuracy: 0.4885 - val_model_3_accuracy: 0.4955 - val_model_4_accuracy: 0.4780 - val_loss1: 3.2913 - val_loss2: 7.1640\n","Epoch 84/300\n","1/1 [==============================] - 8s 8s/step - loss: 7.7220 - model_loss: 0.0812 - model_1_loss: 0.0304 - model_2_loss: 0.2522 - model_3_loss: 0.0291 - model_4_loss: 0.6937 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 1.5156 - loss2: 5.1197 - val_loss: 19.7730 - val_model_loss: 1.7013 - val_model_1_loss: 1.3940 - val_model_2_loss: 1.8774 - val_model_3_loss: 3.1693 - val_model_4_loss: 1.1688 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3785 - val_model_2_accuracy: 0.4820 - val_model_3_accuracy: 0.4940 - val_model_4_accuracy: 0.4570 - val_loss1: 3.3027 - val_loss2: 7.1594\n","Epoch 85/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.6746 - model_loss: 6.9609e-05 - model_1_loss: 0.0071 - model_2_loss: 0.0013 - model_3_loss: 0.0015 - model_4_loss: 0.0025 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.5718 - loss2: 5.0903 - val_loss: 19.3890 - val_model_loss: 1.6796 - val_model_1_loss: 1.4201 - val_model_2_loss: 1.7030 - val_model_3_loss: 3.0284 - val_model_4_loss: 1.0944 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3970 - val_model_2_accuracy: 0.4800 - val_model_3_accuracy: 0.4915 - val_model_4_accuracy: 0.4325 - val_loss1: 3.3158 - val_loss2: 7.1476\n","Epoch 86/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.6194 - model_loss: 2.0404e-05 - model_1_loss: 0.0612 - model_2_loss: 5.1027e-04 - model_3_loss: 5.2591e-04 - model_4_loss: 6.4662e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.3934 - loss2: 5.1637 - val_loss: 19.0450 - val_model_loss: 1.6621 - val_model_1_loss: 1.4174 - val_model_2_loss: 1.5585 - val_model_3_loss: 2.9066 - val_model_4_loss: 1.0584 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3815 - val_model_2_accuracy: 0.4685 - val_model_3_accuracy: 0.4910 - val_model_4_accuracy: 0.4130 - val_loss1: 3.3192 - val_loss2: 7.1228\n","Epoch 87/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4147 - model_loss: 4.6251e-05 - model_1_loss: 8.1376e-04 - model_2_loss: 5.4705e-04 - model_3_loss: 5.6282e-04 - model_4_loss: 7.5808e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2867 - loss2: 5.1259 - val_loss: 18.7796 - val_model_loss: 1.6472 - val_model_1_loss: 1.4145 - val_model_2_loss: 1.4494 - val_model_3_loss: 2.7990 - val_model_4_loss: 1.0521 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3630 - val_model_2_accuracy: 0.4575 - val_model_3_accuracy: 0.4900 - val_model_4_accuracy: 0.4060 - val_loss1: 3.3168 - val_loss2: 7.1007\n","Epoch 88/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.8155 - model_loss: 0.0401 - model_1_loss: 0.0097 - model_2_loss: 0.0028 - model_3_loss: 1.8926e-04 - model_4_loss: 8.8160e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6306 - loss2: 5.1312 - val_loss: 18.5711 - val_model_loss: 1.6439 - val_model_1_loss: 1.4110 - val_model_2_loss: 1.3648 - val_model_3_loss: 2.6966 - val_model_4_loss: 1.0711 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3350 - val_model_2_accuracy: 0.4520 - val_model_3_accuracy: 0.4875 - val_model_4_accuracy: 0.4325 - val_loss1: 3.3083 - val_loss2: 7.0754\n","Epoch 89/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.5965 - model_loss: 2.2777e-04 - model_1_loss: 0.0076 - model_2_loss: 0.0066 - model_3_loss: 0.0178 - model_4_loss: 0.0863 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.5723 - loss2: 4.9054 - val_loss: 18.4124 - val_model_loss: 1.6401 - val_model_1_loss: 1.4140 - val_model_2_loss: 1.3088 - val_model_3_loss: 2.6158 - val_model_4_loss: 1.0899 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3195 - val_model_2_accuracy: 0.4580 - val_model_3_accuracy: 0.4855 - val_model_4_accuracy: 0.4445 - val_loss1: 3.3004 - val_loss2: 7.0433\n","Epoch 90/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4581 - model_loss: 1.0303e-04 - model_1_loss: 0.0595 - model_2_loss: 0.0036 - model_3_loss: 0.0140 - model_4_loss: 0.0010 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.3417 - loss2: 5.0382 - val_loss: 18.3190 - val_model_loss: 1.6392 - val_model_1_loss: 1.4391 - val_model_2_loss: 1.2699 - val_model_3_loss: 2.5471 - val_model_4_loss: 1.1203 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3310 - val_model_2_accuracy: 0.4705 - val_model_3_accuracy: 0.4845 - val_model_4_accuracy: 0.4335 - val_loss1: 3.2902 - val_loss2: 7.0132\n","Epoch 91/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4309 - model_loss: 2.3940e-05 - model_1_loss: 7.9789e-04 - model_2_loss: 8.9091e-04 - model_3_loss: 7.1822e-04 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2158 - loss2: 5.2115 - val_loss: 18.2617 - val_model_loss: 1.6387 - val_model_1_loss: 1.4666 - val_model_2_loss: 1.2456 - val_model_3_loss: 2.4845 - val_model_4_loss: 1.1566 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3410 - val_model_2_accuracy: 0.4720 - val_model_3_accuracy: 0.4825 - val_model_4_accuracy: 0.4215 - val_loss1: 3.2779 - val_loss2: 6.9917\n","Epoch 92/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4740 - model_loss: 2.6642e-05 - model_1_loss: 2.1474e-04 - model_2_loss: 0.0039 - model_3_loss: 0.0023 - model_4_loss: 4.7209e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1756 - loss2: 5.2914 - val_loss: 18.2355 - val_model_loss: 1.6402 - val_model_1_loss: 1.4962 - val_model_2_loss: 1.2318 - val_model_3_loss: 2.4303 - val_model_4_loss: 1.1973 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3515 - val_model_2_accuracy: 0.4665 - val_model_3_accuracy: 0.4820 - val_model_4_accuracy: 0.4285 - val_loss1: 3.2703 - val_loss2: 6.9693\n","Epoch 93/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.5422 - model_loss: 1.2817e-04 - model_1_loss: 2.4169e-04 - model_2_loss: 0.0052 - model_3_loss: 0.0026 - model_4_loss: 3.0317e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.3676 - loss2: 5.1661 - val_loss: 18.2429 - val_model_loss: 1.6454 - val_model_1_loss: 1.5258 - val_model_2_loss: 1.2252 - val_model_3_loss: 2.3882 - val_model_4_loss: 1.2420 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3575 - val_model_2_accuracy: 0.4625 - val_model_3_accuracy: 0.4810 - val_model_4_accuracy: 0.4395 - val_loss1: 3.2641 - val_loss2: 6.9523\n","Epoch 94/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.3633 - model_loss: 1.6351e-05 - model_1_loss: 0.0115 - model_2_loss: 8.3125e-04 - model_3_loss: 4.3886e-04 - model_4_loss: 4.8298e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1555 - loss2: 5.1950 - val_loss: 18.2573 - val_model_loss: 1.6507 - val_model_1_loss: 1.5439 - val_model_2_loss: 1.2243 - val_model_3_loss: 2.3492 - val_model_4_loss: 1.2786 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3640 - val_model_2_accuracy: 0.4515 - val_model_3_accuracy: 0.4795 - val_model_4_accuracy: 0.4470 - val_loss1: 3.2582 - val_loss2: 6.9525\n","Epoch 95/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4696 - model_loss: 3.8506e-04 - model_1_loss: 0.0082 - model_2_loss: 0.0026 - model_3_loss: 0.0034 - model_4_loss: 0.0010 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.4760 - loss2: 4.9779 - val_loss: 18.2856 - val_model_loss: 1.6579 - val_model_1_loss: 1.5553 - val_model_2_loss: 1.2241 - val_model_3_loss: 2.3174 - val_model_4_loss: 1.3165 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3695 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.4795 - val_model_4_accuracy: 0.4590 - val_loss1: 3.2548 - val_loss2: 6.9595\n","Epoch 96/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.6369 - model_loss: 0.0558 - model_1_loss: 3.4308e-04 - model_2_loss: 0.0033 - model_3_loss: 0.0063 - model_4_loss: 0.0480 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.3482 - loss2: 5.1749 - val_loss: 18.3176 - val_model_loss: 1.6754 - val_model_1_loss: 1.5642 - val_model_2_loss: 1.2245 - val_model_3_loss: 2.2822 - val_model_4_loss: 1.3463 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3710 - val_model_2_accuracy: 0.4445 - val_model_3_accuracy: 0.4780 - val_model_4_accuracy: 0.4640 - val_loss1: 3.2529 - val_loss2: 6.9721\n","Epoch 97/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.7148 - model_loss: 0.2326 - model_1_loss: 0.0019 - model_2_loss: 0.0087 - model_3_loss: 0.0017 - model_4_loss: 0.0665 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.3549 - loss2: 5.0484 - val_loss: 18.3339 - val_model_loss: 1.7075 - val_model_1_loss: 1.5714 - val_model_2_loss: 1.2309 - val_model_3_loss: 2.2499 - val_model_4_loss: 1.3375 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3730 - val_model_2_accuracy: 0.4475 - val_model_3_accuracy: 0.4760 - val_model_4_accuracy: 0.4640 - val_loss1: 3.2544 - val_loss2: 6.9824\n","Epoch 98/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.9596 - model_loss: 2.2144e-04 - model_1_loss: 0.0046 - model_2_loss: 0.0049 - model_3_loss: 0.0030 - model_4_loss: 0.0026 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9583 - loss2: 4.9861 - val_loss: 18.3650 - val_model_loss: 1.7469 - val_model_1_loss: 1.5779 - val_model_2_loss: 1.2394 - val_model_3_loss: 2.2294 - val_model_4_loss: 1.3282 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3775 - val_model_2_accuracy: 0.4490 - val_model_3_accuracy: 0.4745 - val_model_4_accuracy: 0.4640 - val_loss1: 3.2574 - val_loss2: 6.9859\n","Epoch 99/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.8475 - model_loss: 2.0228e-04 - model_1_loss: 0.0141 - model_2_loss: 0.0029 - model_3_loss: 5.5252e-04 - model_4_loss: 0.0035 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6868 - loss2: 5.1394 - val_loss: 18.3920 - val_model_loss: 1.8007 - val_model_1_loss: 1.5635 - val_model_2_loss: 1.2433 - val_model_3_loss: 2.2127 - val_model_4_loss: 1.3151 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3835 - val_model_2_accuracy: 0.4520 - val_model_3_accuracy: 0.4725 - val_model_4_accuracy: 0.4620 - val_loss1: 3.2567 - val_loss2: 6.9999\n","Epoch 100/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2845 - model_loss: 2.9405e-06 - model_1_loss: 2.0162e-04 - model_2_loss: 0.0143 - model_3_loss: 0.0102 - model_4_loss: 3.3903e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1530 - loss2: 5.1065 - val_loss: 18.4252 - val_model_loss: 1.8586 - val_model_1_loss: 1.5497 - val_model_2_loss: 1.2463 - val_model_3_loss: 2.1953 - val_model_4_loss: 1.3059 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3810 - val_model_2_accuracy: 0.4510 - val_model_3_accuracy: 0.4705 - val_model_4_accuracy: 0.4625 - val_loss1: 3.2575 - val_loss2: 7.0119\n","Epoch 101/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.3723 - model_loss: 3.0398e-06 - model_1_loss: 0.0012 - model_2_loss: 5.5964e-04 - model_3_loss: 4.3256e-04 - model_4_loss: 3.5563e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2075 - loss2: 5.1625 - val_loss: 18.4577 - val_model_loss: 1.9216 - val_model_1_loss: 1.5361 - val_model_2_loss: 1.2494 - val_model_3_loss: 2.1816 - val_model_4_loss: 1.2917 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3835 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.4670 - val_model_4_accuracy: 0.4640 - val_loss1: 3.2548 - val_loss2: 7.0224\n","Epoch 102/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.3505 - model_loss: 3.0097e-04 - model_1_loss: 0.0263 - model_2_loss: 0.0022 - model_3_loss: 0.0013 - model_4_loss: 2.6166e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2811 - loss2: 5.0392 - val_loss: 18.4836 - val_model_loss: 1.9814 - val_model_1_loss: 1.5001 - val_model_2_loss: 1.2503 - val_model_3_loss: 2.1622 - val_model_4_loss: 1.2824 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.3840 - val_model_2_accuracy: 0.4470 - val_model_3_accuracy: 0.4670 - val_model_4_accuracy: 0.4645 - val_loss1: 3.2583 - val_loss2: 7.0488\n","Epoch 103/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.3335 - model_loss: 6.8321e-05 - model_1_loss: 0.0204 - model_2_loss: 0.0056 - model_3_loss: 0.0045 - model_4_loss: 7.0054e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1756 - loss2: 5.1266 - val_loss: 18.5176 - val_model_loss: 2.0563 - val_model_1_loss: 1.4508 - val_model_2_loss: 1.2501 - val_model_3_loss: 2.1543 - val_model_4_loss: 1.2714 - val_model_accuracy: 0.4940 - val_model_1_accuracy: 0.3860 - val_model_2_accuracy: 0.4460 - val_model_3_accuracy: 0.4660 - val_model_4_accuracy: 0.4650 - val_loss1: 3.2593 - val_loss2: 7.0754\n","Epoch 104/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.6217 - model_loss: 2.3661e-05 - model_1_loss: 0.0017 - model_2_loss: 0.0200 - model_3_loss: 0.0210 - model_4_loss: 5.8773e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6651 - loss2: 4.9133 - val_loss: 18.5375 - val_model_loss: 2.1202 - val_model_1_loss: 1.4037 - val_model_2_loss: 1.2504 - val_model_3_loss: 2.1404 - val_model_4_loss: 1.2687 - val_model_accuracy: 0.4940 - val_model_1_accuracy: 0.3865 - val_model_2_accuracy: 0.4455 - val_model_3_accuracy: 0.4660 - val_model_4_accuracy: 0.4635 - val_loss1: 3.2556 - val_loss2: 7.0984\n","Epoch 105/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4054 - model_loss: 2.5408e-04 - model_1_loss: 4.0715e-04 - model_2_loss: 0.0024 - model_3_loss: 0.0036 - model_4_loss: 5.3334e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.3296 - loss2: 5.0686 - val_loss: 18.5671 - val_model_loss: 2.1907 - val_model_1_loss: 1.3616 - val_model_2_loss: 1.2494 - val_model_3_loss: 2.1369 - val_model_4_loss: 1.2590 - val_model_accuracy: 0.4940 - val_model_1_accuracy: 0.3860 - val_model_2_accuracy: 0.4465 - val_model_3_accuracy: 0.4665 - val_model_4_accuracy: 0.4625 - val_loss1: 3.2479 - val_loss2: 7.1215\n","Epoch 106/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4491 - model_loss: 3.1789e-07 - model_1_loss: 1.3505e-04 - model_2_loss: 0.0015 - model_3_loss: 5.5112e-04 - model_4_loss: 1.0404e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2952 - loss2: 5.1516 - val_loss: 18.6043 - val_model_loss: 2.2684 - val_model_1_loss: 1.3208 - val_model_2_loss: 1.2471 - val_model_3_loss: 2.1227 - val_model_4_loss: 1.2533 - val_model_accuracy: 0.4940 - val_model_1_accuracy: 0.3820 - val_model_2_accuracy: 0.4445 - val_model_3_accuracy: 0.4660 - val_model_4_accuracy: 0.4610 - val_loss1: 3.2446 - val_loss2: 7.1473\n","Epoch 107/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.3691 - model_loss: 4.0110e-05 - model_1_loss: 0.0054 - model_2_loss: 0.0046 - model_3_loss: 0.0015 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2207 - loss2: 5.1357 - val_loss: 18.6447 - val_model_loss: 2.3490 - val_model_1_loss: 1.2829 - val_model_2_loss: 1.2436 - val_model_3_loss: 2.1123 - val_model_4_loss: 1.2470 - val_model_accuracy: 0.4940 - val_model_1_accuracy: 0.3800 - val_model_2_accuracy: 0.4445 - val_model_3_accuracy: 0.4650 - val_model_4_accuracy: 0.4555 - val_loss1: 3.2386 - val_loss2: 7.1712\n","Epoch 108/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2978 - model_loss: 0.0014 - model_1_loss: 0.0065 - model_2_loss: 0.0063 - model_3_loss: 0.0359 - model_4_loss: 2.8303e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1939 - loss2: 5.0536 - val_loss: 18.7197 - val_model_loss: 2.4241 - val_model_1_loss: 1.2531 - val_model_2_loss: 1.2429 - val_model_3_loss: 2.1301 - val_model_4_loss: 1.2423 - val_model_accuracy: 0.4940 - val_model_1_accuracy: 0.3790 - val_model_2_accuracy: 0.4435 - val_model_3_accuracy: 0.4650 - val_model_4_accuracy: 0.4455 - val_loss1: 3.2311 - val_loss2: 7.1962\n","Epoch 109/300\n","1/1 [==============================] - 10s 10s/step - loss: 6.4342 - model_loss: 1.8775e-05 - model_1_loss: 9.7378e-04 - model_2_loss: 0.0040 - model_3_loss: 0.0334 - model_4_loss: 5.3280e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2565 - loss2: 5.1389 - val_loss: 18.8039 - val_model_loss: 2.5003 - val_model_1_loss: 1.2258 - val_model_2_loss: 1.2413 - val_model_3_loss: 2.1455 - val_model_4_loss: 1.2353 - val_model_accuracy: 0.4940 - val_model_1_accuracy: 0.3785 - val_model_2_accuracy: 0.4435 - val_model_3_accuracy: 0.4650 - val_model_4_accuracy: 0.4355 - val_loss1: 3.2263 - val_loss2: 7.2294\n","Epoch 110/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2050 - model_loss: 3.5961e-06 - model_1_loss: 1.7306e-04 - model_2_loss: 5.2179e-04 - model_3_loss: 2.8895e-04 - model_4_loss: 4.7185e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1538 - loss2: 5.0502 - val_loss: 18.8911 - val_model_loss: 2.5892 - val_model_1_loss: 1.2015 - val_model_2_loss: 1.2397 - val_model_3_loss: 2.1553 - val_model_4_loss: 1.2287 - val_model_accuracy: 0.4940 - val_model_1_accuracy: 0.3770 - val_model_2_accuracy: 0.4440 - val_model_3_accuracy: 0.4645 - val_model_4_accuracy: 0.4310 - val_loss1: 3.2220 - val_loss2: 7.2545\n","Epoch 111/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2082 - model_loss: 3.9736e-07 - model_1_loss: 1.1965e-04 - model_2_loss: 0.0012 - model_3_loss: 8.2828e-04 - model_4_loss: 9.7680e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1624 - loss2: 5.0435 - val_loss: 18.9653 - val_model_loss: 2.6697 - val_model_1_loss: 1.1808 - val_model_2_loss: 1.2367 - val_model_3_loss: 2.1628 - val_model_4_loss: 1.2231 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.3770 - val_model_2_accuracy: 0.4435 - val_model_3_accuracy: 0.4640 - val_model_4_accuracy: 0.4300 - val_loss1: 3.2136 - val_loss2: 7.2785\n","Epoch 112/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.3719 - model_loss: 1.3908e-06 - model_1_loss: 1.6648e-04 - model_2_loss: 2.9719e-04 - model_3_loss: 6.5952e-05 - model_4_loss: 4.2853e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.4462 - loss2: 4.9252 - val_loss: 19.0337 - val_model_loss: 2.7526 - val_model_1_loss: 1.1608 - val_model_2_loss: 1.2342 - val_model_3_loss: 2.1652 - val_model_4_loss: 1.2164 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.3775 - val_model_2_accuracy: 0.4405 - val_model_3_accuracy: 0.4635 - val_model_4_accuracy: 0.4250 - val_loss1: 3.2043 - val_loss2: 7.3001\n","Epoch 113/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2149 - model_loss: 0.0027 - model_1_loss: 0.0041 - model_2_loss: 0.0017 - model_3_loss: 0.0010 - model_4_loss: 2.6336e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0724 - loss2: 5.1326 - val_loss: 19.0939 - val_model_loss: 2.8229 - val_model_1_loss: 1.1444 - val_model_2_loss: 1.2327 - val_model_3_loss: 2.1739 - val_model_4_loss: 1.2083 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.3810 - val_model_2_accuracy: 0.4380 - val_model_3_accuracy: 0.4625 - val_model_4_accuracy: 0.4170 - val_loss1: 3.1932 - val_loss2: 7.3185\n","Epoch 114/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.3202 - model_loss: 0.0012 - model_1_loss: 0.0045 - model_2_loss: 0.0186 - model_3_loss: 2.1797e-04 - model_4_loss: 0.0028 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1539 - loss2: 5.1390 - val_loss: 19.1421 - val_model_loss: 2.8923 - val_model_1_loss: 1.1294 - val_model_2_loss: 1.2312 - val_model_3_loss: 2.1765 - val_model_4_loss: 1.2010 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.3855 - val_model_2_accuracy: 0.4435 - val_model_3_accuracy: 0.4615 - val_model_4_accuracy: 0.4100 - val_loss1: 3.1793 - val_loss2: 7.3325\n","Epoch 115/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.5157 - model_loss: 2.0026e-05 - model_1_loss: 7.2972e-04 - model_2_loss: 0.0027 - model_3_loss: 9.4971e-04 - model_4_loss: 0.0077 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6061 - loss2: 4.8975 - val_loss: 19.1750 - val_model_loss: 2.9522 - val_model_1_loss: 1.1153 - val_model_2_loss: 1.2311 - val_model_3_loss: 2.1745 - val_model_4_loss: 1.1931 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.3895 - val_model_2_accuracy: 0.4375 - val_model_3_accuracy: 0.4615 - val_model_4_accuracy: 0.4090 - val_loss1: 3.1672 - val_loss2: 7.3415\n","Epoch 116/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2032 - model_loss: 0.0022 - model_1_loss: 0.0184 - model_2_loss: 0.0080 - model_3_loss: 0.0012 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0245 - loss2: 5.1471 - val_loss: 19.1696 - val_model_loss: 2.9980 - val_model_1_loss: 1.0994 - val_model_2_loss: 1.2315 - val_model_3_loss: 2.1705 - val_model_4_loss: 1.1839 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.3840 - val_model_2_accuracy: 0.4355 - val_model_3_accuracy: 0.4625 - val_model_4_accuracy: 0.4045 - val_loss1: 3.1495 - val_loss2: 7.3368\n","Epoch 117/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.3233 - model_loss: 3.6557e-06 - model_1_loss: 1.0491e-04 - model_2_loss: 2.2726e-04 - model_3_loss: 3.7514e-04 - model_4_loss: 1.4674e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2068 - loss2: 5.1155 - val_loss: 19.1670 - val_model_loss: 3.0506 - val_model_1_loss: 1.0857 - val_model_2_loss: 1.2331 - val_model_3_loss: 2.1653 - val_model_4_loss: 1.1772 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.3850 - val_model_2_accuracy: 0.4325 - val_model_3_accuracy: 0.4620 - val_model_4_accuracy: 0.4070 - val_loss1: 3.1308 - val_loss2: 7.3243\n","Epoch 118/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.8515 - model_loss: 0.2507 - model_1_loss: 0.4357 - model_2_loss: 0.0285 - model_3_loss: 0.0094 - model_4_loss: 0.0039 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1726 - loss2: 4.9508 - val_loss: 19.1420 - val_model_loss: 2.9704 - val_model_1_loss: 1.1392 - val_model_2_loss: 1.2357 - val_model_3_loss: 2.1666 - val_model_4_loss: 1.1677 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.3820 - val_model_2_accuracy: 0.4335 - val_model_3_accuracy: 0.4615 - val_model_4_accuracy: 0.3995 - val_loss1: 3.1233 - val_loss2: 7.3392\n","Epoch 119/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4029 - model_loss: 4.4375e-04 - model_1_loss: 0.0015 - model_2_loss: 0.0023 - model_3_loss: 0.0059 - model_4_loss: 7.3119e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2454 - loss2: 5.1465 - val_loss: 19.1775 - val_model_loss: 2.8915 - val_model_1_loss: 1.2415 - val_model_2_loss: 1.2380 - val_model_3_loss: 2.1651 - val_model_4_loss: 1.1603 - val_model_accuracy: 0.4930 - val_model_1_accuracy: 0.4440 - val_model_2_accuracy: 0.4290 - val_model_3_accuracy: 0.4615 - val_model_4_accuracy: 0.3930 - val_loss1: 3.1195 - val_loss2: 7.3617\n","Epoch 120/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2355 - model_loss: 1.6093e-06 - model_1_loss: 8.0062e-04 - model_2_loss: 0.0073 - model_3_loss: 0.0028 - model_4_loss: 0.0019 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2163 - loss2: 5.0064 - val_loss: 19.2393 - val_model_loss: 2.8421 - val_model_1_loss: 1.3666 - val_model_2_loss: 1.2409 - val_model_3_loss: 2.1566 - val_model_4_loss: 1.1541 - val_model_accuracy: 0.4920 - val_model_1_accuracy: 0.4705 - val_model_2_accuracy: 0.4325 - val_model_3_accuracy: 0.4620 - val_model_4_accuracy: 0.3890 - val_loss1: 3.1086 - val_loss2: 7.3704\n","Epoch 121/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2833 - model_loss: 9.9152e-05 - model_1_loss: 0.0096 - model_2_loss: 0.0012 - model_3_loss: 4.3627e-04 - model_4_loss: 1.2539e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1626 - loss2: 5.1093 - val_loss: 19.2947 - val_model_loss: 2.7920 - val_model_1_loss: 1.5053 - val_model_2_loss: 1.2443 - val_model_3_loss: 2.1510 - val_model_4_loss: 1.1474 - val_model_accuracy: 0.4915 - val_model_1_accuracy: 0.4920 - val_model_2_accuracy: 0.4350 - val_model_3_accuracy: 0.4630 - val_model_4_accuracy: 0.3865 - val_loss1: 3.0922 - val_loss2: 7.3625\n","Epoch 122/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2052 - model_loss: 8.9688e-05 - model_1_loss: 0.0133 - model_2_loss: 0.0014 - model_3_loss: 5.5349e-05 - model_4_loss: 1.3024e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9789 - loss2: 5.2113 - val_loss: 19.3361 - val_model_loss: 2.7636 - val_model_1_loss: 1.6229 - val_model_2_loss: 1.2489 - val_model_3_loss: 2.1442 - val_model_4_loss: 1.1414 - val_model_accuracy: 0.4880 - val_model_1_accuracy: 0.4970 - val_model_2_accuracy: 0.4410 - val_model_3_accuracy: 0.4630 - val_model_4_accuracy: 0.3855 - val_loss1: 3.0722 - val_loss2: 7.3429\n","Epoch 123/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2056 - model_loss: 4.8219e-04 - model_1_loss: 6.8697e-04 - model_2_loss: 4.4069e-04 - model_3_loss: 6.1704e-05 - model_4_loss: 1.0552e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0919 - loss2: 5.1120 - val_loss: 19.3708 - val_model_loss: 2.7410 - val_model_1_loss: 1.7444 - val_model_2_loss: 1.2518 - val_model_3_loss: 2.1343 - val_model_4_loss: 1.1345 - val_model_accuracy: 0.4865 - val_model_1_accuracy: 0.4990 - val_model_2_accuracy: 0.4430 - val_model_3_accuracy: 0.4630 - val_model_4_accuracy: 0.3850 - val_loss1: 3.0465 - val_loss2: 7.3184\n","Epoch 124/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4100 - model_loss: 0.0012 - model_1_loss: 0.0098 - model_2_loss: 0.0010 - model_3_loss: 0.0088 - model_4_loss: 0.0082 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1716 - loss2: 5.2093 - val_loss: 19.3865 - val_model_loss: 2.7029 - val_model_1_loss: 1.8615 - val_model_2_loss: 1.2551 - val_model_3_loss: 2.1276 - val_model_4_loss: 1.1301 - val_model_accuracy: 0.4850 - val_model_1_accuracy: 0.5020 - val_model_2_accuracy: 0.4465 - val_model_3_accuracy: 0.4620 - val_model_4_accuracy: 0.3850 - val_loss1: 3.0197 - val_loss2: 7.2897\n","Epoch 125/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.3365 - model_loss: 0.0134 - model_1_loss: 0.0051 - model_2_loss: 0.0174 - model_3_loss: 0.1318 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 1.0023 - loss2: 5.1653 - val_loss: 19.3436 - val_model_loss: 2.6495 - val_model_1_loss: 1.9691 - val_model_2_loss: 1.2639 - val_model_3_loss: 2.0627 - val_model_4_loss: 1.1261 - val_model_accuracy: 0.4825 - val_model_1_accuracy: 0.5055 - val_model_2_accuracy: 0.4470 - val_model_3_accuracy: 0.4680 - val_model_4_accuracy: 0.3845 - val_loss1: 3.0065 - val_loss2: 7.2658\n","Epoch 126/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.5399 - model_loss: 0.0775 - model_1_loss: 0.3887 - model_2_loss: 0.0020 - model_3_loss: 4.3082e-04 - model_4_loss: 1.3266e-04 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8585 - loss2: 5.2127 - val_loss: 19.1805 - val_model_loss: 2.6668 - val_model_1_loss: 1.9082 - val_model_2_loss: 1.2697 - val_model_3_loss: 2.0026 - val_model_4_loss: 1.1236 - val_model_accuracy: 0.4825 - val_model_1_accuracy: 0.5060 - val_model_2_accuracy: 0.4475 - val_model_3_accuracy: 0.4735 - val_model_4_accuracy: 0.3880 - val_loss1: 2.9854 - val_loss2: 7.2242\n","Epoch 127/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2674 - model_loss: 2.0997e-04 - model_1_loss: 0.0037 - model_2_loss: 3.8928e-04 - model_3_loss: 0.0020 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1083 - loss2: 5.1515 - val_loss: 19.0257 - val_model_loss: 2.6789 - val_model_1_loss: 1.8445 - val_model_2_loss: 1.2756 - val_model_3_loss: 1.9511 - val_model_4_loss: 1.1217 - val_model_accuracy: 0.4825 - val_model_1_accuracy: 0.5055 - val_model_2_accuracy: 0.4465 - val_model_3_accuracy: 0.4750 - val_model_4_accuracy: 0.3915 - val_loss1: 2.9655 - val_loss2: 7.1884\n","Epoch 128/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0833 - model_loss: 2.5251e-04 - model_1_loss: 0.0014 - model_2_loss: 0.0104 - model_3_loss: 0.0014 - model_4_loss: 8.9679e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0851 - loss2: 4.9838 - val_loss: 18.8793 - val_model_loss: 2.6845 - val_model_1_loss: 1.7816 - val_model_2_loss: 1.2792 - val_model_3_loss: 1.9126 - val_model_4_loss: 1.1173 - val_model_accuracy: 0.4810 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.4475 - val_model_3_accuracy: 0.4765 - val_model_4_accuracy: 0.3960 - val_loss1: 2.9464 - val_loss2: 7.1578\n","Epoch 129/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1629 - model_loss: 8.7552e-04 - model_1_loss: 0.0060 - model_2_loss: 7.6115e-04 - model_3_loss: 5.5868e-04 - model_4_loss: 4.1866e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9430 - loss2: 5.2113 - val_loss: 18.7353 - val_model_loss: 2.6831 - val_model_1_loss: 1.7169 - val_model_2_loss: 1.2815 - val_model_3_loss: 1.8761 - val_model_4_loss: 1.1147 - val_model_accuracy: 0.4800 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.4490 - val_model_3_accuracy: 0.4750 - val_model_4_accuracy: 0.4015 - val_loss1: 2.9325 - val_loss2: 7.1306\n","Epoch 130/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2236 - model_loss: 0.0112 - model_1_loss: 0.0075 - model_2_loss: 0.0019 - model_3_loss: 0.0027 - model_4_loss: 6.6292e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0668 - loss2: 5.1329 - val_loss: 18.6092 - val_model_loss: 2.6778 - val_model_1_loss: 1.6492 - val_model_2_loss: 1.2867 - val_model_3_loss: 1.8445 - val_model_4_loss: 1.1124 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4965 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.4725 - val_model_4_accuracy: 0.4095 - val_loss1: 2.9210 - val_loss2: 7.1176\n","Epoch 131/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.4346 - model_loss: 0.0148 - model_1_loss: 0.0064 - model_2_loss: 0.0014 - model_3_loss: 0.0135 - model_4_loss: 6.1677e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.1607 - loss2: 5.2372 - val_loss: 18.5105 - val_model_loss: 2.6873 - val_model_1_loss: 1.5894 - val_model_2_loss: 1.2877 - val_model_3_loss: 1.8237 - val_model_4_loss: 1.1104 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.4880 - val_model_2_accuracy: 0.4490 - val_model_3_accuracy: 0.4685 - val_model_4_accuracy: 0.4085 - val_loss1: 2.9095 - val_loss2: 7.1024\n","Epoch 132/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2676 - model_loss: 5.8030e-05 - model_1_loss: 0.0035 - model_2_loss: 9.5935e-04 - model_3_loss: 8.8990e-04 - model_4_loss: 3.1903e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0091 - loss2: 5.2528 - val_loss: 18.4558 - val_model_loss: 2.7142 - val_model_1_loss: 1.5269 - val_model_2_loss: 1.2940 - val_model_3_loss: 1.8094 - val_model_4_loss: 1.1088 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.4830 - val_model_2_accuracy: 0.4510 - val_model_3_accuracy: 0.4655 - val_model_4_accuracy: 0.4080 - val_loss1: 2.9007 - val_loss2: 7.1017\n","Epoch 133/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2242 - model_loss: 8.2735e-05 - model_1_loss: 6.8273e-04 - model_2_loss: 3.8768e-04 - model_3_loss: 0.0038 - model_4_loss: 6.1478e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9486 - loss2: 5.2700 - val_loss: 18.4161 - val_model_loss: 2.7472 - val_model_1_loss: 1.4821 - val_model_2_loss: 1.2975 - val_model_3_loss: 1.7943 - val_model_4_loss: 1.1068 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4775 - val_model_2_accuracy: 0.4535 - val_model_3_accuracy: 0.4665 - val_model_4_accuracy: 0.4055 - val_loss1: 2.8871 - val_loss2: 7.1012\n","Epoch 134/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2802 - model_loss: 2.5252e-05 - model_1_loss: 0.0064 - model_2_loss: 0.0028 - model_3_loss: 0.0030 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.2377 - loss2: 5.0275 - val_loss: 18.3879 - val_model_loss: 2.7822 - val_model_1_loss: 1.4370 - val_model_2_loss: 1.3045 - val_model_3_loss: 1.7790 - val_model_4_loss: 1.1037 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4600 - val_model_2_accuracy: 0.4560 - val_model_3_accuracy: 0.4660 - val_model_4_accuracy: 0.4030 - val_loss1: 2.8821 - val_loss2: 7.0994\n","Epoch 135/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1103 - model_loss: 1.9987e-05 - model_1_loss: 0.0014 - model_2_loss: 0.0027 - model_3_loss: 0.0294 - model_4_loss: 3.5945e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9749 - loss2: 5.1015 - val_loss: 18.3770 - val_model_loss: 2.8106 - val_model_1_loss: 1.4031 - val_model_2_loss: 1.3088 - val_model_3_loss: 1.7786 - val_model_4_loss: 1.1015 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4545 - val_model_2_accuracy: 0.4595 - val_model_3_accuracy: 0.4665 - val_model_4_accuracy: 0.4075 - val_loss1: 2.8730 - val_loss2: 7.1014\n","Epoch 136/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1473 - model_loss: 5.2567e-05 - model_1_loss: 0.0025 - model_2_loss: 0.0016 - model_3_loss: 7.4855e-04 - model_4_loss: 0.0033 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8953 - loss2: 5.2438 - val_loss: 18.3596 - val_model_loss: 2.8375 - val_model_1_loss: 1.3764 - val_model_2_loss: 1.3128 - val_model_3_loss: 1.7750 - val_model_4_loss: 1.0979 - val_model_accuracy: 0.4800 - val_model_1_accuracy: 0.4540 - val_model_2_accuracy: 0.4615 - val_model_3_accuracy: 0.4690 - val_model_4_accuracy: 0.4120 - val_loss1: 2.8611 - val_loss2: 7.0989\n","Epoch 137/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0621 - model_loss: 1.4629e-04 - model_1_loss: 2.8456e-04 - model_2_loss: 0.0024 - model_3_loss: 0.0022 - model_4_loss: 3.1806e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0607 - loss2: 4.9961 - val_loss: 18.3513 - val_model_loss: 2.8575 - val_model_1_loss: 1.3581 - val_model_2_loss: 1.3132 - val_model_3_loss: 1.7766 - val_model_4_loss: 1.0948 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4610 - val_model_2_accuracy: 0.4635 - val_model_3_accuracy: 0.4665 - val_model_4_accuracy: 0.4110 - val_loss1: 2.8519 - val_loss2: 7.0991\n","Epoch 138/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0950 - model_loss: 3.7551e-06 - model_1_loss: 6.3119e-04 - model_2_loss: 6.8172e-04 - model_3_loss: 0.0018 - model_4_loss: 9.6791e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0628 - loss2: 5.0290 - val_loss: 18.3570 - val_model_loss: 2.8786 - val_model_1_loss: 1.3481 - val_model_2_loss: 1.3181 - val_model_3_loss: 1.7756 - val_model_4_loss: 1.0928 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4610 - val_model_2_accuracy: 0.4650 - val_model_3_accuracy: 0.4650 - val_model_4_accuracy: 0.4125 - val_loss1: 2.8429 - val_loss2: 7.1009\n","Epoch 139/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9803 - model_loss: 9.7704e-05 - model_1_loss: 0.0206 - model_2_loss: 0.0012 - model_3_loss: 7.9057e-04 - model_4_loss: 2.2337e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7107 - loss2: 5.2467 - val_loss: 18.3400 - val_model_loss: 2.8908 - val_model_1_loss: 1.3158 - val_model_2_loss: 1.3216 - val_model_3_loss: 1.7770 - val_model_4_loss: 1.0912 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.4520 - val_model_2_accuracy: 0.4670 - val_model_3_accuracy: 0.4615 - val_model_4_accuracy: 0.4145 - val_loss1: 2.8369 - val_loss2: 7.1068\n","Epoch 140/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1408 - model_loss: 8.2254e-06 - model_1_loss: 0.0034 - model_2_loss: 0.0036 - model_3_loss: 9.3693e-04 - model_4_loss: 0.0024 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9104 - loss2: 5.2199 - val_loss: 18.3267 - val_model_loss: 2.9113 - val_model_1_loss: 1.2864 - val_model_2_loss: 1.3275 - val_model_3_loss: 1.7764 - val_model_4_loss: 1.0880 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.4465 - val_model_2_accuracy: 0.4665 - val_model_3_accuracy: 0.4610 - val_model_4_accuracy: 0.4175 - val_loss1: 2.8289 - val_loss2: 7.1081\n","Epoch 141/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2710 - model_loss: 0.0012 - model_1_loss: 4.8904e-04 - model_2_loss: 0.0027 - model_3_loss: 0.2277 - model_4_loss: 1.4809e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 0.7553 - loss2: 5.2834 - val_loss: 18.3287 - val_model_loss: 2.9267 - val_model_1_loss: 1.2611 - val_model_2_loss: 1.3314 - val_model_3_loss: 1.7856 - val_model_4_loss: 1.0855 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4435 - val_model_2_accuracy: 0.4655 - val_model_3_accuracy: 0.4635 - val_model_4_accuracy: 0.4160 - val_loss1: 2.8194 - val_loss2: 7.1190\n","Epoch 142/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0633 - model_loss: 1.5853e-04 - model_1_loss: 5.8274e-04 - model_2_loss: 9.7199e-04 - model_3_loss: 0.0011 - model_4_loss: 0.0013 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9265 - loss2: 5.1327 - val_loss: 18.3399 - val_model_loss: 2.9365 - val_model_1_loss: 1.2345 - val_model_2_loss: 1.3360 - val_model_3_loss: 1.7955 - val_model_4_loss: 1.0835 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4415 - val_model_2_accuracy: 0.4665 - val_model_3_accuracy: 0.4640 - val_model_4_accuracy: 0.4170 - val_loss1: 2.8091 - val_loss2: 7.1447\n","Epoch 143/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9645 - model_loss: 1.3013e-05 - model_1_loss: 7.7737e-05 - model_2_loss: 3.1862e-04 - model_3_loss: 8.9370e-04 - model_4_loss: 2.0966e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6882 - loss2: 5.2748 - val_loss: 18.3518 - val_model_loss: 2.9442 - val_model_1_loss: 1.2124 - val_model_2_loss: 1.3401 - val_model_3_loss: 1.8087 - val_model_4_loss: 1.0820 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4415 - val_model_2_accuracy: 0.4645 - val_model_3_accuracy: 0.4615 - val_model_4_accuracy: 0.4165 - val_loss1: 2.7973 - val_loss2: 7.1671\n","Epoch 144/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0738 - model_loss: 0.0072 - model_1_loss: 3.8213e-04 - model_2_loss: 4.8104e-04 - model_3_loss: 2.3420e-04 - model_4_loss: 6.9308e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8160 - loss2: 5.2487 - val_loss: 18.3519 - val_model_loss: 2.9432 - val_model_1_loss: 1.1892 - val_model_2_loss: 1.3398 - val_model_3_loss: 1.8174 - val_model_4_loss: 1.0791 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.4375 - val_model_2_accuracy: 0.4620 - val_model_3_accuracy: 0.4610 - val_model_4_accuracy: 0.4175 - val_loss1: 2.7864 - val_loss2: 7.1968\n","Epoch 145/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1013 - model_loss: 2.6046e-04 - model_1_loss: 4.5379e-04 - model_2_loss: 0.0060 - model_3_loss: 1.8909e-04 - model_4_loss: 0.0052 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0465 - loss2: 5.0427 - val_loss: 18.3518 - val_model_loss: 2.9436 - val_model_1_loss: 1.1709 - val_model_2_loss: 1.3376 - val_model_3_loss: 1.8328 - val_model_4_loss: 1.0755 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.4340 - val_model_2_accuracy: 0.4605 - val_model_3_accuracy: 0.4585 - val_model_4_accuracy: 0.4185 - val_loss1: 2.7695 - val_loss2: 7.2220\n","Epoch 146/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1520 - model_loss: 1.9128e-04 - model_1_loss: 0.0149 - model_2_loss: 0.0020 - model_3_loss: 0.0011 - model_4_loss: 0.0015 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8763 - loss2: 5.2560 - val_loss: 18.3612 - val_model_loss: 2.9430 - val_model_1_loss: 1.1595 - val_model_2_loss: 1.3372 - val_model_3_loss: 1.8485 - val_model_4_loss: 1.0727 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.4310 - val_model_2_accuracy: 0.4590 - val_model_3_accuracy: 0.4605 - val_model_4_accuracy: 0.4190 - val_loss1: 2.7542 - val_loss2: 7.2461\n","Epoch 147/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1538 - model_loss: 0.0025 - model_1_loss: 6.4270e-04 - model_2_loss: 0.0099 - model_3_loss: 1.3843e-04 - model_4_loss: 3.4603e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9389 - loss2: 5.2013 - val_loss: 18.3865 - val_model_loss: 2.9440 - val_model_1_loss: 1.1521 - val_model_2_loss: 1.3333 - val_model_3_loss: 1.8665 - val_model_4_loss: 1.0700 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4350 - val_model_2_accuracy: 0.4565 - val_model_3_accuracy: 0.4585 - val_model_4_accuracy: 0.4185 - val_loss1: 2.7392 - val_loss2: 7.2815\n","Epoch 148/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0662 - model_loss: 0.0016 - model_1_loss: 0.0014 - model_2_loss: 0.0066 - model_3_loss: 0.0089 - model_4_loss: 0.0025 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8265 - loss2: 5.2186 - val_loss: 18.4292 - val_model_loss: 2.9512 - val_model_1_loss: 1.1488 - val_model_2_loss: 1.3347 - val_model_3_loss: 1.8864 - val_model_4_loss: 1.0675 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.4375 - val_model_2_accuracy: 0.4535 - val_model_3_accuracy: 0.4595 - val_model_4_accuracy: 0.4170 - val_loss1: 2.7290 - val_loss2: 7.3117\n","Epoch 149/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0951 - model_loss: 1.2092e-04 - model_1_loss: 1.4717e-04 - model_2_loss: 0.0037 - model_3_loss: 1.8874e-04 - model_4_loss: 4.1448e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9808 - loss2: 5.1098 - val_loss: 18.4573 - val_model_loss: 2.9538 - val_model_1_loss: 1.1474 - val_model_2_loss: 1.3335 - val_model_3_loss: 1.8986 - val_model_4_loss: 1.0651 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4360 - val_model_2_accuracy: 0.4510 - val_model_3_accuracy: 0.4590 - val_model_4_accuracy: 0.4210 - val_loss1: 2.7178 - val_loss2: 7.3411\n","Epoch 150/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9284 - model_loss: 7.5101e-06 - model_1_loss: 3.0761e-04 - model_2_loss: 2.5321e-04 - model_3_loss: 1.2626e-04 - model_4_loss: 1.0682e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6461 - loss2: 5.2815 - val_loss: 18.4795 - val_model_loss: 2.9566 - val_model_1_loss: 1.1470 - val_model_2_loss: 1.3341 - val_model_3_loss: 1.9095 - val_model_4_loss: 1.0635 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4385 - val_model_2_accuracy: 0.4505 - val_model_3_accuracy: 0.4595 - val_model_4_accuracy: 0.4200 - val_loss1: 2.7075 - val_loss2: 7.3614\n","Epoch 151/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9162 - model_loss: 4.5498e-06 - model_1_loss: 1.9169e-04 - model_2_loss: 1.6331e-04 - model_3_loss: 4.6587e-05 - model_4_loss: 6.2401e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6405 - loss2: 5.2753 - val_loss: 18.4884 - val_model_loss: 2.9573 - val_model_1_loss: 1.1478 - val_model_2_loss: 1.3346 - val_model_3_loss: 1.9174 - val_model_4_loss: 1.0619 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4400 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.4585 - val_model_4_accuracy: 0.4165 - val_loss1: 2.6979 - val_loss2: 7.3714\n","Epoch 152/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9145 - model_loss: 9.7153e-06 - model_1_loss: 1.6999e-04 - model_2_loss: 1.2804e-04 - model_3_loss: 6.1862e-05 - model_4_loss: 5.5549e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6792 - loss2: 5.2348 - val_loss: 18.4915 - val_model_loss: 2.9572 - val_model_1_loss: 1.1485 - val_model_2_loss: 1.3368 - val_model_3_loss: 1.9269 - val_model_4_loss: 1.0605 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4440 - val_model_2_accuracy: 0.4495 - val_model_3_accuracy: 0.4590 - val_model_4_accuracy: 0.4160 - val_loss1: 2.6871 - val_loss2: 7.3743\n","Epoch 153/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9823 - model_loss: 0.0019 - model_1_loss: 0.0048 - model_2_loss: 4.3658e-04 - model_3_loss: 3.6396e-05 - model_4_loss: 1.4139e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7578 - loss2: 5.2172 - val_loss: 18.4921 - val_model_loss: 2.9584 - val_model_1_loss: 1.1489 - val_model_2_loss: 1.3384 - val_model_3_loss: 1.9366 - val_model_4_loss: 1.0597 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4495 - val_model_2_accuracy: 0.4495 - val_model_3_accuracy: 0.4580 - val_model_4_accuracy: 0.4200 - val_loss1: 2.6751 - val_loss2: 7.3750\n","Epoch 154/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9352 - model_loss: 3.9935e-06 - model_1_loss: 8.0896e-05 - model_2_loss: 3.1427e-04 - model_3_loss: 2.9940e-05 - model_4_loss: 5.4453e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6709 - loss2: 5.2633 - val_loss: 18.4865 - val_model_loss: 2.9564 - val_model_1_loss: 1.1477 - val_model_2_loss: 1.3390 - val_model_3_loss: 1.9444 - val_model_4_loss: 1.0586 - val_model_accuracy: 0.4780 - val_model_1_accuracy: 0.4540 - val_model_2_accuracy: 0.4505 - val_model_3_accuracy: 0.4575 - val_model_4_accuracy: 0.4190 - val_loss1: 2.6648 - val_loss2: 7.3757\n","Epoch 155/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1204 - model_loss: 0.0040 - model_1_loss: 0.0450 - model_2_loss: 0.0113 - model_3_loss: 0.0611 - model_4_loss: 0.0046 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6857 - loss2: 5.3087 - val_loss: 18.4926 - val_model_loss: 2.9543 - val_model_1_loss: 1.1543 - val_model_2_loss: 1.3440 - val_model_3_loss: 1.9509 - val_model_4_loss: 1.0580 - val_model_accuracy: 0.4780 - val_model_1_accuracy: 0.4525 - val_model_2_accuracy: 0.4495 - val_model_3_accuracy: 0.4580 - val_model_4_accuracy: 0.4240 - val_loss1: 2.6562 - val_loss2: 7.3749\n","Epoch 156/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0030 - model_loss: 2.3504e-04 - model_1_loss: 7.5885e-04 - model_2_loss: 5.4146e-04 - model_3_loss: 8.3255e-04 - model_4_loss: 2.9630e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6554 - loss2: 5.3449 - val_loss: 18.4909 - val_model_loss: 2.9548 - val_model_1_loss: 1.1604 - val_model_2_loss: 1.3484 - val_model_3_loss: 1.9539 - val_model_4_loss: 1.0571 - val_model_accuracy: 0.4780 - val_model_1_accuracy: 0.4515 - val_model_2_accuracy: 0.4470 - val_model_3_accuracy: 0.4570 - val_model_4_accuracy: 0.4250 - val_loss1: 2.6470 - val_loss2: 7.3693\n","Epoch 157/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1492 - model_loss: 8.6912e-04 - model_1_loss: 2.9632e-04 - model_2_loss: 8.4588e-04 - model_3_loss: 3.7571e-04 - model_4_loss: 5.0665e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9038 - loss2: 5.2425 - val_loss: 18.4941 - val_model_loss: 2.9580 - val_model_1_loss: 1.1660 - val_model_2_loss: 1.3519 - val_model_3_loss: 1.9537 - val_model_4_loss: 1.0568 - val_model_accuracy: 0.4780 - val_model_1_accuracy: 0.4525 - val_model_2_accuracy: 0.4465 - val_model_3_accuracy: 0.4585 - val_model_4_accuracy: 0.4265 - val_loss1: 2.6381 - val_loss2: 7.3696\n","Epoch 158/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9346 - model_loss: 3.5105e-05 - model_1_loss: 1.7279e-04 - model_2_loss: 4.8677e-04 - model_3_loss: 9.1989e-06 - model_4_loss: 1.8338e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6494 - loss2: 5.2843 - val_loss: 18.4802 - val_model_loss: 2.9597 - val_model_1_loss: 1.1710 - val_model_2_loss: 1.3537 - val_model_3_loss: 1.9518 - val_model_4_loss: 1.0561 - val_model_accuracy: 0.4775 - val_model_1_accuracy: 0.4510 - val_model_2_accuracy: 0.4450 - val_model_3_accuracy: 0.4610 - val_model_4_accuracy: 0.4265 - val_loss1: 2.6270 - val_loss2: 7.3609\n","Epoch 159/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9220 - model_loss: 1.1206e-05 - model_1_loss: 0.0012 - model_2_loss: 5.2408e-04 - model_3_loss: 1.5330e-04 - model_4_loss: 3.9622e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5545 - loss2: 5.3653 - val_loss: 18.4614 - val_model_loss: 2.9640 - val_model_1_loss: 1.1758 - val_model_2_loss: 1.3541 - val_model_3_loss: 1.9487 - val_model_4_loss: 1.0554 - val_model_accuracy: 0.4775 - val_model_1_accuracy: 0.4545 - val_model_2_accuracy: 0.4470 - val_model_3_accuracy: 0.4615 - val_model_4_accuracy: 0.4295 - val_loss1: 2.6162 - val_loss2: 7.3472\n","Epoch 160/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0098 - model_loss: 5.8982e-05 - model_1_loss: 9.0431e-04 - model_2_loss: 2.9581e-04 - model_3_loss: 1.3065e-04 - model_4_loss: 2.0198e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8345 - loss2: 5.1738 - val_loss: 18.4493 - val_model_loss: 2.9738 - val_model_1_loss: 1.1802 - val_model_2_loss: 1.3571 - val_model_3_loss: 1.9497 - val_model_4_loss: 1.0555 - val_model_accuracy: 0.4775 - val_model_1_accuracy: 0.4540 - val_model_2_accuracy: 0.4475 - val_model_3_accuracy: 0.4610 - val_model_4_accuracy: 0.4280 - val_loss1: 2.6054 - val_loss2: 7.3275\n","Epoch 161/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8832 - model_loss: 1.0907e-05 - model_1_loss: 4.3609e-04 - model_2_loss: 0.0013 - model_3_loss: 0.0063 - model_4_loss: 2.5910e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5911 - loss2: 5.2839 - val_loss: 18.4366 - val_model_loss: 2.9836 - val_model_1_loss: 1.1846 - val_model_2_loss: 1.3619 - val_model_3_loss: 1.9527 - val_model_4_loss: 1.0560 - val_model_accuracy: 0.4775 - val_model_1_accuracy: 0.4565 - val_model_2_accuracy: 0.4485 - val_model_3_accuracy: 0.4600 - val_model_4_accuracy: 0.4305 - val_loss1: 2.5919 - val_loss2: 7.3058\n","Epoch 162/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9523 - model_loss: 1.1052e-04 - model_1_loss: 5.6624e-04 - model_2_loss: 4.6284e-04 - model_3_loss: 3.3078e-04 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6399 - loss2: 5.3093 - val_loss: 18.4048 - val_model_loss: 2.9854 - val_model_1_loss: 1.1889 - val_model_2_loss: 1.3588 - val_model_3_loss: 1.9541 - val_model_4_loss: 1.0553 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4600 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.4615 - val_model_4_accuracy: 0.4350 - val_loss1: 2.5782 - val_loss2: 7.2841\n","Epoch 163/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8502 - model_loss: 5.0266e-06 - model_1_loss: 3.1590e-04 - model_2_loss: 1.2901e-04 - model_3_loss: 4.7283e-05 - model_4_loss: 4.7782e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5557 - loss2: 5.2939 - val_loss: 18.3905 - val_model_loss: 2.9956 - val_model_1_loss: 1.1929 - val_model_2_loss: 1.3598 - val_model_3_loss: 1.9504 - val_model_4_loss: 1.0559 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4625 - val_model_2_accuracy: 0.4505 - val_model_3_accuracy: 0.4610 - val_model_4_accuracy: 0.4340 - val_loss1: 2.5697 - val_loss2: 7.2663\n","Epoch 164/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8864 - model_loss: 6.9466e-05 - model_1_loss: 7.0439e-04 - model_2_loss: 3.4592e-04 - model_3_loss: 8.7956e-04 - model_4_loss: 2.4232e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5562 - loss2: 5.3280 - val_loss: 18.3829 - val_model_loss: 3.0061 - val_model_1_loss: 1.1972 - val_model_2_loss: 1.3617 - val_model_3_loss: 1.9512 - val_model_4_loss: 1.0569 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.4600 - val_model_2_accuracy: 0.4515 - val_model_3_accuracy: 0.4635 - val_model_4_accuracy: 0.4330 - val_loss1: 2.5612 - val_loss2: 7.2485\n","Epoch 165/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9991 - model_loss: 1.6689e-05 - model_1_loss: 0.0018 - model_2_loss: 8.0505e-04 - model_3_loss: 0.0019 - model_4_loss: 7.4743e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8700 - loss2: 5.1238 - val_loss: 18.3808 - val_model_loss: 3.0229 - val_model_1_loss: 1.2016 - val_model_2_loss: 1.3629 - val_model_3_loss: 1.9545 - val_model_4_loss: 1.0575 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.4590 - val_model_2_accuracy: 0.4510 - val_model_3_accuracy: 0.4640 - val_model_4_accuracy: 0.4315 - val_loss1: 2.5492 - val_loss2: 7.2322\n","Epoch 166/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9786 - model_loss: 0.0015 - model_1_loss: 0.0014 - model_2_loss: 8.4602e-04 - model_3_loss: 3.6302e-04 - model_4_loss: 4.9613e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6491 - loss2: 5.3249 - val_loss: 18.3644 - val_model_loss: 3.0339 - val_model_1_loss: 1.2055 - val_model_2_loss: 1.3598 - val_model_3_loss: 1.9552 - val_model_4_loss: 1.0569 - val_model_accuracy: 0.4800 - val_model_1_accuracy: 0.4595 - val_model_2_accuracy: 0.4530 - val_model_3_accuracy: 0.4640 - val_model_4_accuracy: 0.4290 - val_loss1: 2.5370 - val_loss2: 7.2161\n","Epoch 167/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0575 - model_loss: 0.0140 - model_1_loss: 0.0021 - model_2_loss: 0.0318 - model_3_loss: 0.1617 - model_4_loss: 0.0043 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 0.5437 - loss2: 5.3000 - val_loss: 18.2810 - val_model_loss: 3.0509 - val_model_1_loss: 1.1712 - val_model_2_loss: 1.3690 - val_model_3_loss: 1.9349 - val_model_4_loss: 1.0607 - val_model_accuracy: 0.4815 - val_model_1_accuracy: 0.4555 - val_model_2_accuracy: 0.4520 - val_model_3_accuracy: 0.4640 - val_model_4_accuracy: 0.4285 - val_loss1: 2.5088 - val_loss2: 7.1856\n","Epoch 171/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0880 - model_loss: 6.4893e-04 - model_1_loss: 0.0023 - model_2_loss: 2.4937e-04 - model_3_loss: 0.0015 - model_4_loss: 3.6624e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9073 - loss2: 5.1757 - val_loss: 18.2483 - val_model_loss: 3.0493 - val_model_1_loss: 1.1660 - val_model_2_loss: 1.3739 - val_model_3_loss: 1.9182 - val_model_4_loss: 1.0611 - val_model_accuracy: 0.4825 - val_model_1_accuracy: 0.4625 - val_model_2_accuracy: 0.4485 - val_model_3_accuracy: 0.4655 - val_model_4_accuracy: 0.4295 - val_loss1: 2.5047 - val_loss2: 7.1752\n","Epoch 172/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1525 - model_loss: 8.2002e-04 - model_1_loss: 0.0179 - model_2_loss: 0.0156 - model_3_loss: 0.0050 - model_4_loss: 0.0159 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8136 - loss2: 5.2838 - val_loss: 18.2214 - val_model_loss: 3.0400 - val_model_1_loss: 1.1639 - val_model_2_loss: 1.3852 - val_model_3_loss: 1.9100 - val_model_4_loss: 1.0620 - val_model_accuracy: 0.4825 - val_model_1_accuracy: 0.4690 - val_model_2_accuracy: 0.4450 - val_model_3_accuracy: 0.4670 - val_model_4_accuracy: 0.4285 - val_loss1: 2.4972 - val_loss2: 7.1631\n","Epoch 173/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9978 - model_loss: 1.3014e-05 - model_1_loss: 7.2798e-04 - model_2_loss: 5.7637e-04 - model_3_loss: 2.6627e-04 - model_4_loss: 7.4699e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5600 - loss2: 5.4362 - val_loss: 18.2184 - val_model_loss: 3.0414 - val_model_1_loss: 1.1616 - val_model_2_loss: 1.3995 - val_model_3_loss: 1.9033 - val_model_4_loss: 1.0632 - val_model_accuracy: 0.4825 - val_model_1_accuracy: 0.4735 - val_model_2_accuracy: 0.4445 - val_model_3_accuracy: 0.4640 - val_model_4_accuracy: 0.4265 - val_loss1: 2.4929 - val_loss2: 7.1565\n","Epoch 174/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8479 - model_loss: 9.6559e-06 - model_1_loss: 2.5887e-04 - model_2_loss: 2.2599e-04 - model_3_loss: 1.5126e-04 - model_4_loss: 4.3251e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5755 - loss2: 5.2717 - val_loss: 18.2101 - val_model_loss: 3.0364 - val_model_1_loss: 1.1602 - val_model_2_loss: 1.4104 - val_model_3_loss: 1.8971 - val_model_4_loss: 1.0639 - val_model_accuracy: 0.4820 - val_model_1_accuracy: 0.4800 - val_model_2_accuracy: 0.4455 - val_model_3_accuracy: 0.4630 - val_model_4_accuracy: 0.4250 - val_loss1: 2.4899 - val_loss2: 7.1521\n","Epoch 175/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9558 - model_loss: 1.0411e-05 - model_1_loss: 3.7037e-04 - model_2_loss: 4.1154e-04 - model_3_loss: 1.6631e-04 - model_4_loss: 1.3473e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6127 - loss2: 5.3419 - val_loss: 18.2193 - val_model_loss: 3.0352 - val_model_1_loss: 1.1585 - val_model_2_loss: 1.4194 - val_model_3_loss: 1.8950 - val_model_4_loss: 1.0655 - val_model_accuracy: 0.4820 - val_model_1_accuracy: 0.4910 - val_model_2_accuracy: 0.4455 - val_model_3_accuracy: 0.4610 - val_model_4_accuracy: 0.4270 - val_loss1: 2.4857 - val_loss2: 7.1599\n","Epoch 176/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9891 - model_loss: 2.2270e-04 - model_1_loss: 4.0024e-04 - model_2_loss: 0.0021 - model_3_loss: 0.0088 - model_4_loss: 7.4489e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7396 - loss2: 5.2373 - val_loss: 18.2170 - val_model_loss: 3.0206 - val_model_1_loss: 1.1584 - val_model_2_loss: 1.4221 - val_model_3_loss: 1.8958 - val_model_4_loss: 1.0666 - val_model_accuracy: 0.4820 - val_model_1_accuracy: 0.4970 - val_model_2_accuracy: 0.4470 - val_model_3_accuracy: 0.4625 - val_model_4_accuracy: 0.4280 - val_loss1: 2.4786 - val_loss2: 7.1749\n","Epoch 177/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9038 - model_loss: 2.7308e-04 - model_1_loss: 0.0065 - model_2_loss: 0.0037 - model_3_loss: 0.0071 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7954 - loss2: 5.0896 - val_loss: 18.2161 - val_model_loss: 3.0057 - val_model_1_loss: 1.1568 - val_model_2_loss: 1.4243 - val_model_3_loss: 1.9012 - val_model_4_loss: 1.0688 - val_model_accuracy: 0.4815 - val_model_1_accuracy: 0.5000 - val_model_2_accuracy: 0.4470 - val_model_3_accuracy: 0.4630 - val_model_4_accuracy: 0.4300 - val_loss1: 2.4715 - val_loss2: 7.1877\n","Epoch 178/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8466 - model_loss: 8.5296e-05 - model_1_loss: 0.0015 - model_2_loss: 0.0062 - model_3_loss: 0.0014 - model_4_loss: 9.5137e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5905 - loss2: 5.2461 - val_loss: 18.2160 - val_model_loss: 2.9917 - val_model_1_loss: 1.1568 - val_model_2_loss: 1.4256 - val_model_3_loss: 1.9063 - val_model_4_loss: 1.0714 - val_model_accuracy: 0.4815 - val_model_1_accuracy: 0.5020 - val_model_2_accuracy: 0.4485 - val_model_3_accuracy: 0.4635 - val_model_4_accuracy: 0.4310 - val_loss1: 2.4639 - val_loss2: 7.2003\n","Epoch 179/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8524 - model_loss: 2.7882e-04 - model_1_loss: 4.9855e-04 - model_2_loss: 3.8039e-04 - model_3_loss: 2.0800e-04 - model_4_loss: 1.6395e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5323 - loss2: 5.3186 - val_loss: 18.2168 - val_model_loss: 2.9771 - val_model_1_loss: 1.1572 - val_model_2_loss: 1.4277 - val_model_3_loss: 1.9109 - val_model_4_loss: 1.0741 - val_model_accuracy: 0.4825 - val_model_1_accuracy: 0.5055 - val_model_2_accuracy: 0.4485 - val_model_3_accuracy: 0.4650 - val_model_4_accuracy: 0.4315 - val_loss1: 2.4599 - val_loss2: 7.2098\n","Epoch 180/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8962 - model_loss: 7.5207e-05 - model_1_loss: 8.0411e-04 - model_2_loss: 4.2439e-04 - model_3_loss: 3.8680e-04 - model_4_loss: 3.5149e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6402 - loss2: 5.2539 - val_loss: 18.2152 - val_model_loss: 2.9631 - val_model_1_loss: 1.1572 - val_model_2_loss: 1.4296 - val_model_3_loss: 1.9154 - val_model_4_loss: 1.0764 - val_model_accuracy: 0.4830 - val_model_1_accuracy: 0.5095 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.4710 - val_model_4_accuracy: 0.4355 - val_loss1: 2.4560 - val_loss2: 7.2175\n","Epoch 181/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8355 - model_loss: 1.5914e-05 - model_1_loss: 0.0057 - model_2_loss: 0.0031 - model_3_loss: 9.1983e-04 - model_4_loss: 4.6330e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5500 - loss2: 5.2753 - val_loss: 18.2051 - val_model_loss: 2.9437 - val_model_1_loss: 1.1571 - val_model_2_loss: 1.4316 - val_model_3_loss: 1.9202 - val_model_4_loss: 1.0781 - val_model_accuracy: 0.4835 - val_model_1_accuracy: 0.5140 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.4725 - val_model_4_accuracy: 0.4320 - val_loss1: 2.4525 - val_loss2: 7.2219\n","Epoch 182/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9454 - model_loss: 1.5311e-04 - model_1_loss: 2.6344e-04 - model_2_loss: 0.0017 - model_3_loss: 0.0030 - model_4_loss: 7.4560e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6281 - loss2: 5.3122 - val_loss: 18.1858 - val_model_loss: 2.9266 - val_model_1_loss: 1.1571 - val_model_2_loss: 1.4293 - val_model_3_loss: 1.9202 - val_model_4_loss: 1.0780 - val_model_accuracy: 0.4835 - val_model_1_accuracy: 0.5180 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.4745 - val_model_4_accuracy: 0.4335 - val_loss1: 2.4489 - val_loss2: 7.2257\n","Epoch 183/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9621 - model_loss: 2.0929e-04 - model_1_loss: 6.1634e-04 - model_2_loss: 0.0031 - model_3_loss: 1.5227e-04 - model_4_loss: 2.2617e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7259 - loss2: 5.2318 - val_loss: 18.1681 - val_model_loss: 2.9078 - val_model_1_loss: 1.1582 - val_model_2_loss: 1.4275 - val_model_3_loss: 1.9236 - val_model_4_loss: 1.0793 - val_model_accuracy: 0.4855 - val_model_1_accuracy: 0.5215 - val_model_2_accuracy: 0.4495 - val_model_3_accuracy: 0.4745 - val_model_4_accuracy: 0.4365 - val_loss1: 2.4439 - val_loss2: 7.2278\n","Epoch 184/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9576 - model_loss: 5.7366e-04 - model_1_loss: 8.3347e-04 - model_2_loss: 6.0223e-04 - model_3_loss: 0.0012 - model_4_loss: 1.4979e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7452 - loss2: 5.2090 - val_loss: 18.1548 - val_model_loss: 2.8924 - val_model_1_loss: 1.1592 - val_model_2_loss: 1.4262 - val_model_3_loss: 1.9266 - val_model_4_loss: 1.0808 - val_model_accuracy: 0.4870 - val_model_1_accuracy: 0.5220 - val_model_2_accuracy: 0.4510 - val_model_3_accuracy: 0.4785 - val_model_4_accuracy: 0.4370 - val_loss1: 2.4413 - val_loss2: 7.2283\n","Epoch 185/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9382 - model_loss: 1.6219e-04 - model_1_loss: 4.1340e-04 - model_2_loss: 0.0038 - model_3_loss: 0.0309 - model_4_loss: 1.8040e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4922 - loss2: 5.4105 - val_loss: 18.1216 - val_model_loss: 2.8770 - val_model_1_loss: 1.1602 - val_model_2_loss: 1.4197 - val_model_3_loss: 1.9170 - val_model_4_loss: 1.0817 - val_model_accuracy: 0.4875 - val_model_1_accuracy: 0.5245 - val_model_2_accuracy: 0.4515 - val_model_3_accuracy: 0.4805 - val_model_4_accuracy: 0.4375 - val_loss1: 2.4374 - val_loss2: 7.2286\n","Epoch 186/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9674 - model_loss: 1.7250e-04 - model_1_loss: 0.0014 - model_2_loss: 0.0104 - model_3_loss: 0.0129 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7112 - loss2: 5.2284 - val_loss: 18.0810 - val_model_loss: 2.8602 - val_model_1_loss: 1.1618 - val_model_2_loss: 1.4097 - val_model_3_loss: 1.9122 - val_model_4_loss: 1.0830 - val_model_accuracy: 0.4875 - val_model_1_accuracy: 0.5290 - val_model_2_accuracy: 0.4540 - val_model_3_accuracy: 0.4860 - val_model_4_accuracy: 0.4355 - val_loss1: 2.4306 - val_loss2: 7.2235\n","Epoch 187/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8284 - model_loss: 9.6558e-06 - model_1_loss: 1.0571e-04 - model_2_loss: 2.4360e-04 - model_3_loss: 1.2685e-04 - model_4_loss: 5.0881e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4402 - loss2: 5.3877 - val_loss: 18.0433 - val_model_loss: 2.8469 - val_model_1_loss: 1.1628 - val_model_2_loss: 1.4036 - val_model_3_loss: 1.9035 - val_model_4_loss: 1.0845 - val_model_accuracy: 0.4885 - val_model_1_accuracy: 0.5335 - val_model_2_accuracy: 0.4550 - val_model_3_accuracy: 0.4880 - val_model_4_accuracy: 0.4345 - val_loss1: 2.4241 - val_loss2: 7.2179\n","Epoch 188/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8268 - model_loss: 9.9141e-06 - model_1_loss: 1.0513e-04 - model_2_loss: 2.3522e-04 - model_3_loss: 1.2096e-04 - model_4_loss: 5.0941e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4391 - loss2: 5.3872 - val_loss: 18.0066 - val_model_loss: 2.8337 - val_model_1_loss: 1.1640 - val_model_2_loss: 1.3985 - val_model_3_loss: 1.8955 - val_model_4_loss: 1.0857 - val_model_accuracy: 0.4885 - val_model_1_accuracy: 0.5370 - val_model_2_accuracy: 0.4535 - val_model_3_accuracy: 0.4930 - val_model_4_accuracy: 0.4335 - val_loss1: 2.4181 - val_loss2: 7.2111\n","Epoch 189/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9015 - model_loss: 1.3654e-04 - model_1_loss: 1.7370e-04 - model_2_loss: 3.3106e-04 - model_3_loss: 1.4691e-04 - model_4_loss: 5.9344e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5415 - loss2: 5.3592 - val_loss: 17.9676 - val_model_loss: 2.8241 - val_model_1_loss: 1.1648 - val_model_2_loss: 1.3949 - val_model_3_loss: 1.8879 - val_model_4_loss: 1.0869 - val_model_accuracy: 0.4890 - val_model_1_accuracy: 0.5395 - val_model_2_accuracy: 0.4540 - val_model_3_accuracy: 0.5000 - val_model_4_accuracy: 0.4340 - val_loss1: 2.4105 - val_loss2: 7.1984\n","Epoch 190/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0264 - model_loss: 2.4696e-05 - model_1_loss: 2.3947e-04 - model_2_loss: 7.9406e-04 - model_3_loss: 1.3726e-04 - model_4_loss: 4.7669e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7027 - loss2: 5.3220 - val_loss: 17.9235 - val_model_loss: 2.8134 - val_model_1_loss: 1.1654 - val_model_2_loss: 1.3884 - val_model_3_loss: 1.8823 - val_model_4_loss: 1.0876 - val_model_accuracy: 0.4920 - val_model_1_accuracy: 0.5410 - val_model_2_accuracy: 0.4545 - val_model_3_accuracy: 0.5025 - val_model_4_accuracy: 0.4365 - val_loss1: 2.4020 - val_loss2: 7.1843\n","Epoch 191/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8206 - model_loss: 1.0749e-05 - model_1_loss: 1.0680e-04 - model_2_loss: 2.1685e-04 - model_3_loss: 1.1067e-04 - model_4_loss: 5.1397e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4364 - loss2: 5.3838 - val_loss: 17.8803 - val_model_loss: 2.7995 - val_model_1_loss: 1.1670 - val_model_2_loss: 1.3851 - val_model_3_loss: 1.8759 - val_model_4_loss: 1.0886 - val_model_accuracy: 0.4925 - val_model_1_accuracy: 0.5450 - val_model_2_accuracy: 0.4565 - val_model_3_accuracy: 0.5110 - val_model_4_accuracy: 0.4395 - val_loss1: 2.3951 - val_loss2: 7.1692\n","Epoch 192/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8485 - model_loss: 1.8668e-04 - model_1_loss: 2.6988e-04 - model_2_loss: 2.9472e-04 - model_3_loss: 1.2217e-04 - model_4_loss: 6.0655e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5023 - loss2: 5.3453 - val_loss: 17.8422 - val_model_loss: 2.7920 - val_model_1_loss: 1.1681 - val_model_2_loss: 1.3834 - val_model_3_loss: 1.8697 - val_model_4_loss: 1.0895 - val_model_accuracy: 0.4915 - val_model_1_accuracy: 0.5460 - val_model_2_accuracy: 0.4570 - val_model_3_accuracy: 0.5135 - val_model_4_accuracy: 0.4380 - val_loss1: 2.3877 - val_loss2: 7.1519\n","Epoch 193/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9144 - model_loss: 4.5922e-04 - model_1_loss: 6.9899e-04 - model_2_loss: 2.8667e-04 - model_3_loss: 2.8353e-04 - model_4_loss: 0.0023 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6811 - loss2: 5.2292 - val_loss: 17.7994 - val_model_loss: 2.7849 - val_model_1_loss: 1.1696 - val_model_2_loss: 1.3801 - val_model_3_loss: 1.8671 - val_model_4_loss: 1.0910 - val_model_accuracy: 0.4930 - val_model_1_accuracy: 0.5475 - val_model_2_accuracy: 0.4575 - val_model_3_accuracy: 0.5155 - val_model_4_accuracy: 0.4390 - val_loss1: 2.3759 - val_loss2: 7.1308\n","Epoch 194/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2321 - model_loss: 0.0260 - model_1_loss: 0.0183 - model_2_loss: 0.0020 - model_3_loss: 0.1165 - model_4_loss: 0.0171 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 0.6567 - loss2: 5.3954 - val_loss: 17.7815 - val_model_loss: 2.7920 - val_model_1_loss: 1.1759 - val_model_2_loss: 1.3765 - val_model_3_loss: 1.8747 - val_model_4_loss: 1.0913 - val_model_accuracy: 0.4930 - val_model_1_accuracy: 0.5515 - val_model_2_accuracy: 0.4580 - val_model_3_accuracy: 0.5175 - val_model_4_accuracy: 0.4410 - val_loss1: 2.3628 - val_loss2: 7.1084\n","Epoch 195/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9832 - model_loss: 1.8385e-04 - model_1_loss: 3.8080e-04 - model_2_loss: 0.0023 - model_3_loss: 7.4755e-04 - model_4_loss: 3.7255e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6527 - loss2: 5.3266 - val_loss: 17.7642 - val_model_loss: 2.7976 - val_model_1_loss: 1.1831 - val_model_2_loss: 1.3701 - val_model_3_loss: 1.8840 - val_model_4_loss: 1.0921 - val_model_accuracy: 0.4965 - val_model_1_accuracy: 0.5590 - val_model_2_accuracy: 0.4590 - val_model_3_accuracy: 0.5225 - val_model_4_accuracy: 0.4440 - val_loss1: 2.3499 - val_loss2: 7.0874\n","Epoch 196/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9288 - model_loss: 4.3737e-04 - model_1_loss: 2.3184e-04 - model_2_loss: 0.0045 - model_3_loss: 0.0030 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4821 - loss2: 5.4374 - val_loss: 17.7490 - val_model_loss: 2.8047 - val_model_1_loss: 1.1906 - val_model_2_loss: 1.3628 - val_model_3_loss: 1.8909 - val_model_4_loss: 1.0934 - val_model_accuracy: 0.4990 - val_model_1_accuracy: 0.5580 - val_model_2_accuracy: 0.4600 - val_model_3_accuracy: 0.5270 - val_model_4_accuracy: 0.4485 - val_loss1: 2.3378 - val_loss2: 7.0688\n","Epoch 197/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8945 - model_loss: 3.4108e-04 - model_1_loss: 1.8442e-04 - model_2_loss: 0.0131 - model_3_loss: 0.0216 - model_4_loss: 3.6106e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4836 - loss2: 5.3753 - val_loss: 17.7210 - val_model_loss: 2.8074 - val_model_1_loss: 1.1979 - val_model_2_loss: 1.3496 - val_model_3_loss: 1.8950 - val_model_4_loss: 1.0956 - val_model_accuracy: 0.5000 - val_model_1_accuracy: 0.5625 - val_model_2_accuracy: 0.4625 - val_model_3_accuracy: 0.5255 - val_model_4_accuracy: 0.4495 - val_loss1: 2.3236 - val_loss2: 7.0520\n","Epoch 198/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9410 - model_loss: 1.8655e-04 - model_1_loss: 3.2657e-04 - model_2_loss: 7.9870e-04 - model_3_loss: 1.1640e-04 - model_4_loss: 1.5529e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6460 - loss2: 5.2933 - val_loss: 17.6929 - val_model_loss: 2.8056 - val_model_1_loss: 1.2048 - val_model_2_loss: 1.3360 - val_model_3_loss: 1.8976 - val_model_4_loss: 1.0966 - val_model_accuracy: 0.4995 - val_model_1_accuracy: 0.5660 - val_model_2_accuracy: 0.4650 - val_model_3_accuracy: 0.5285 - val_model_4_accuracy: 0.4530 - val_loss1: 2.3124 - val_loss2: 7.0399\n","Epoch 199/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1006 - model_loss: 5.5458e-04 - model_1_loss: 8.2589e-04 - model_2_loss: 0.0041 - model_3_loss: 0.0017 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0271 - loss2: 5.0649 - val_loss: 17.6634 - val_model_loss: 2.8043 - val_model_1_loss: 1.2110 - val_model_2_loss: 1.3227 - val_model_3_loss: 1.9035 - val_model_4_loss: 1.0974 - val_model_accuracy: 0.4990 - val_model_1_accuracy: 0.5705 - val_model_2_accuracy: 0.4680 - val_model_3_accuracy: 0.5285 - val_model_4_accuracy: 0.4575 - val_loss1: 2.2966 - val_loss2: 7.0279\n","Epoch 200/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8910 - model_loss: 2.6158e-04 - model_1_loss: 3.1726e-04 - model_2_loss: 9.7481e-04 - model_3_loss: 2.6669e-04 - model_4_loss: 3.5888e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5074 - loss2: 5.3814 - val_loss: 17.6248 - val_model_loss: 2.8014 - val_model_1_loss: 1.2165 - val_model_2_loss: 1.3094 - val_model_3_loss: 1.9057 - val_model_4_loss: 1.0991 - val_model_accuracy: 0.5000 - val_model_1_accuracy: 0.5755 - val_model_2_accuracy: 0.4710 - val_model_3_accuracy: 0.5325 - val_model_4_accuracy: 0.4590 - val_loss1: 2.2824 - val_loss2: 7.0103\n","Epoch 201/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8599 - model_loss: 3.2928e-04 - model_1_loss: 4.9392e-04 - model_2_loss: 3.1422e-04 - model_3_loss: 7.3626e-05 - model_4_loss: 9.6945e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5371 - loss2: 5.3215 - val_loss: 17.5954 - val_model_loss: 2.8082 - val_model_1_loss: 1.2205 - val_model_2_loss: 1.3009 - val_model_3_loss: 1.9048 - val_model_4_loss: 1.1000 - val_model_accuracy: 0.5015 - val_model_1_accuracy: 0.5780 - val_model_2_accuracy: 0.4745 - val_model_3_accuracy: 0.5375 - val_model_4_accuracy: 0.4595 - val_loss1: 2.2682 - val_loss2: 6.9928\n","Epoch 202/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9383 - model_loss: 6.1606e-05 - model_1_loss: 6.7512e-04 - model_2_loss: 0.0013 - model_3_loss: 2.9588e-04 - model_4_loss: 0.0033 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6582 - loss2: 5.2744 - val_loss: 17.5651 - val_model_loss: 2.8112 - val_model_1_loss: 1.2242 - val_model_2_loss: 1.2954 - val_model_3_loss: 1.9065 - val_model_4_loss: 1.1041 - val_model_accuracy: 0.5030 - val_model_1_accuracy: 0.5805 - val_model_2_accuracy: 0.4750 - val_model_3_accuracy: 0.5385 - val_model_4_accuracy: 0.4655 - val_loss1: 2.2530 - val_loss2: 6.9706\n","Epoch 203/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0140 - model_loss: 0.0035 - model_1_loss: 3.3559e-04 - model_2_loss: 8.9146e-04 - model_3_loss: 8.7976e-04 - model_4_loss: 3.5410e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5720 - loss2: 5.4360 - val_loss: 17.5403 - val_model_loss: 2.8163 - val_model_1_loss: 1.2278 - val_model_2_loss: 1.2884 - val_model_3_loss: 1.9055 - val_model_4_loss: 1.1071 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5845 - val_model_2_accuracy: 0.4780 - val_model_3_accuracy: 0.5415 - val_model_4_accuracy: 0.4695 - val_loss1: 2.2415 - val_loss2: 6.9536\n","Epoch 204/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.3345 - model_loss: 0.3796 - model_1_loss: 0.0084 - model_2_loss: 0.0015 - model_3_loss: 9.8951e-04 - model_4_loss: 7.0732e-04 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6259 - loss2: 5.3175 - val_loss: 17.6835 - val_model_loss: 2.9912 - val_model_1_loss: 1.2313 - val_model_2_loss: 1.2812 - val_model_3_loss: 1.9096 - val_model_4_loss: 1.1103 - val_model_accuracy: 0.4840 - val_model_1_accuracy: 0.5875 - val_model_2_accuracy: 0.4835 - val_model_3_accuracy: 0.5445 - val_model_4_accuracy: 0.4720 - val_loss1: 2.2390 - val_loss2: 6.9210\n","Epoch 205/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0507 - model_loss: 3.3012e-04 - model_1_loss: 0.0016 - model_2_loss: 9.4708e-04 - model_3_loss: 0.0058 - model_4_loss: 4.2368e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.0192 - loss2: 5.0224 - val_loss: 17.9758 - val_model_loss: 3.3205 - val_model_1_loss: 1.2323 - val_model_2_loss: 1.2770 - val_model_3_loss: 1.9074 - val_model_4_loss: 1.1131 - val_model_accuracy: 0.4915 - val_model_1_accuracy: 0.5880 - val_model_2_accuracy: 0.4840 - val_model_3_accuracy: 0.5450 - val_model_4_accuracy: 0.4730 - val_loss1: 2.2350 - val_loss2: 6.8905\n","Epoch 206/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9969 - model_loss: 0.0012 - model_1_loss: 0.0108 - model_2_loss: 5.4810e-04 - model_3_loss: 0.0012 - model_4_loss: 4.4595e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4874 - loss2: 5.4954 - val_loss: 18.3479 - val_model_loss: 3.7155 - val_model_1_loss: 1.2425 - val_model_2_loss: 1.2724 - val_model_3_loss: 1.9057 - val_model_4_loss: 1.1161 - val_model_accuracy: 0.4950 - val_model_1_accuracy: 0.5845 - val_model_2_accuracy: 0.4850 - val_model_3_accuracy: 0.5475 - val_model_4_accuracy: 0.4735 - val_loss1: 2.2315 - val_loss2: 6.8642\n","Epoch 207/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0816 - model_loss: 0.0368 - model_1_loss: 0.0086 - model_2_loss: 0.0011 - model_3_loss: 0.0048 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8483 - loss2: 5.1810 - val_loss: 18.7011 - val_model_loss: 4.0831 - val_model_1_loss: 1.2576 - val_model_2_loss: 1.2642 - val_model_3_loss: 1.9076 - val_model_4_loss: 1.1197 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.5860 - val_model_2_accuracy: 0.4860 - val_model_3_accuracy: 0.5510 - val_model_4_accuracy: 0.4735 - val_loss1: 2.2238 - val_loss2: 6.8451\n","Epoch 208/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8837 - model_loss: 2.1359e-04 - model_1_loss: 0.0030 - model_2_loss: 0.0035 - model_3_loss: 0.0026 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6289 - loss2: 5.2440 - val_loss: 19.0271 - val_model_loss: 4.4238 - val_model_1_loss: 1.2735 - val_model_2_loss: 1.2557 - val_model_3_loss: 1.9045 - val_model_4_loss: 1.1215 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.5740 - val_model_2_accuracy: 0.4865 - val_model_3_accuracy: 0.5550 - val_model_4_accuracy: 0.4730 - val_loss1: 2.2169 - val_loss2: 6.8312\n","Epoch 209/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8353 - model_loss: 7.6138e-04 - model_1_loss: 5.0827e-04 - model_2_loss: 2.6441e-04 - model_3_loss: 9.1896e-05 - model_4_loss: 2.9966e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4246 - loss2: 5.4088 - val_loss: 19.3316 - val_model_loss: 4.7399 - val_model_1_loss: 1.2899 - val_model_2_loss: 1.2492 - val_model_3_loss: 1.9014 - val_model_4_loss: 1.1248 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.5715 - val_model_2_accuracy: 0.4885 - val_model_3_accuracy: 0.5590 - val_model_4_accuracy: 0.4745 - val_loss1: 2.2082 - val_loss2: 6.8181\n","Epoch 210/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9930 - model_loss: 3.7712e-04 - model_1_loss: 8.7522e-04 - model_2_loss: 4.1987e-04 - model_3_loss: 0.0012 - model_4_loss: 3.9853e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7015 - loss2: 5.2883 - val_loss: 19.5897 - val_model_loss: 5.0091 - val_model_1_loss: 1.3017 - val_model_2_loss: 1.2428 - val_model_3_loss: 1.8965 - val_model_4_loss: 1.1280 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.5670 - val_model_2_accuracy: 0.4900 - val_model_3_accuracy: 0.5595 - val_model_4_accuracy: 0.4740 - val_loss1: 2.2003 - val_loss2: 6.8114\n","Epoch 211/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0302 - model_loss: 5.1416e-05 - model_1_loss: 0.0126 - model_2_loss: 0.0039 - model_3_loss: 0.0522 - model_4_loss: 0.0028 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6437 - loss2: 5.3149 - val_loss: 19.7815 - val_model_loss: 5.1984 - val_model_1_loss: 1.3165 - val_model_2_loss: 1.2360 - val_model_3_loss: 1.8833 - val_model_4_loss: 1.1311 - val_model_accuracy: 0.4930 - val_model_1_accuracy: 0.5585 - val_model_2_accuracy: 0.4880 - val_model_3_accuracy: 0.5570 - val_model_4_accuracy: 0.4720 - val_loss1: 2.1993 - val_loss2: 6.8169\n","Epoch 212/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8200 - model_loss: 0.0236 - model_1_loss: 0.0011 - model_2_loss: 0.0012 - model_3_loss: 0.0024 - model_4_loss: 5.0227e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4161 - loss2: 5.3752 - val_loss: 19.9126 - val_model_loss: 5.3177 - val_model_1_loss: 1.3352 - val_model_2_loss: 1.2301 - val_model_3_loss: 1.8762 - val_model_4_loss: 1.1352 - val_model_accuracy: 0.4870 - val_model_1_accuracy: 0.5510 - val_model_2_accuracy: 0.4890 - val_model_3_accuracy: 0.5545 - val_model_4_accuracy: 0.4720 - val_loss1: 2.1961 - val_loss2: 6.8219\n","Epoch 213/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0150 - model_loss: 0.0193 - model_1_loss: 0.0036 - model_2_loss: 0.0032 - model_3_loss: 9.2185e-04 - model_4_loss: 0.0031 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7125 - loss2: 5.2723 - val_loss: 19.9217 - val_model_loss: 5.3080 - val_model_1_loss: 1.3525 - val_model_2_loss: 1.2282 - val_model_3_loss: 1.8703 - val_model_4_loss: 1.1396 - val_model_accuracy: 0.4840 - val_model_1_accuracy: 0.5445 - val_model_2_accuracy: 0.4885 - val_model_3_accuracy: 0.5520 - val_model_4_accuracy: 0.4705 - val_loss1: 2.1872 - val_loss2: 6.8359\n","Epoch 214/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8459 - model_loss: 0.0074 - model_1_loss: 0.0010 - model_2_loss: 7.2772e-05 - model_3_loss: 4.4462e-05 - model_4_loss: 4.3969e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5380 - loss2: 5.2989 - val_loss: 19.9095 - val_model_loss: 5.2734 - val_model_1_loss: 1.3739 - val_model_2_loss: 1.2244 - val_model_3_loss: 1.8656 - val_model_4_loss: 1.1417 - val_model_accuracy: 0.4800 - val_model_1_accuracy: 0.5395 - val_model_2_accuracy: 0.4890 - val_model_3_accuracy: 0.5570 - val_model_4_accuracy: 0.4735 - val_loss1: 2.1801 - val_loss2: 6.8506\n","Epoch 215/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1890 - model_loss: 0.1699 - model_1_loss: 4.6156e-04 - model_2_loss: 0.0044 - model_3_loss: 5.7548e-04 - model_4_loss: 0.0017 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7956 - loss2: 5.2164 - val_loss: 19.7763 - val_model_loss: 5.1250 - val_model_1_loss: 1.3952 - val_model_2_loss: 1.2192 - val_model_3_loss: 1.8646 - val_model_4_loss: 1.1446 - val_model_accuracy: 0.4830 - val_model_1_accuracy: 0.5375 - val_model_2_accuracy: 0.4925 - val_model_3_accuracy: 0.5600 - val_model_4_accuracy: 0.4760 - val_loss1: 2.1716 - val_loss2: 6.8560\n","Epoch 216/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9292 - model_loss: 4.4402e-04 - model_1_loss: 5.2025e-04 - model_2_loss: 4.3119e-04 - model_3_loss: 9.3308e-05 - model_4_loss: 2.6560e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5457 - loss2: 5.3817 - val_loss: 19.6480 - val_model_loss: 4.9815 - val_model_1_loss: 1.4139 - val_model_2_loss: 1.2159 - val_model_3_loss: 1.8637 - val_model_4_loss: 1.1476 - val_model_accuracy: 0.4855 - val_model_1_accuracy: 0.5325 - val_model_2_accuracy: 0.4925 - val_model_3_accuracy: 0.5585 - val_model_4_accuracy: 0.4760 - val_loss1: 2.1646 - val_loss2: 6.8609\n","Epoch 217/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2142 - model_loss: 0.1562 - model_1_loss: 0.0051 - model_2_loss: 0.0011 - model_3_loss: 1.2161e-04 - model_4_loss: 4.1036e-04 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8606 - loss2: 5.1907 - val_loss: 19.3263 - val_model_loss: 4.6313 - val_model_1_loss: 1.4261 - val_model_2_loss: 1.2130 - val_model_3_loss: 1.8631 - val_model_4_loss: 1.1507 - val_model_accuracy: 0.4955 - val_model_1_accuracy: 0.5305 - val_model_2_accuracy: 0.4925 - val_model_3_accuracy: 0.5620 - val_model_4_accuracy: 0.4775 - val_loss1: 2.1560 - val_loss2: 6.8861\n","Epoch 218/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8223 - model_loss: 4.3946e-05 - model_1_loss: 2.1293e-04 - model_2_loss: 2.5811e-04 - model_3_loss: 7.1594e-05 - model_4_loss: 1.6377e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4406 - loss2: 5.3810 - val_loss: 19.0482 - val_model_loss: 4.3288 - val_model_1_loss: 1.4398 - val_model_2_loss: 1.2105 - val_model_3_loss: 1.8634 - val_model_4_loss: 1.1539 - val_model_accuracy: 0.4950 - val_model_1_accuracy: 0.5315 - val_model_2_accuracy: 0.4950 - val_model_3_accuracy: 0.5605 - val_model_4_accuracy: 0.4755 - val_loss1: 2.1472 - val_loss2: 6.9046\n","Epoch 219/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8717 - model_loss: 5.1397e-05 - model_1_loss: 1.7812e-04 - model_2_loss: 1.8531e-04 - model_3_loss: 1.8333e-04 - model_4_loss: 3.0270e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4853 - loss2: 5.3855 - val_loss: 18.8103 - val_model_loss: 4.0675 - val_model_1_loss: 1.4533 - val_model_2_loss: 1.2083 - val_model_3_loss: 1.8648 - val_model_4_loss: 1.1569 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.5310 - val_model_2_accuracy: 0.4980 - val_model_3_accuracy: 0.5610 - val_model_4_accuracy: 0.4755 - val_loss1: 2.1393 - val_loss2: 6.9202\n","Epoch 220/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8905 - model_loss: 1.5477e-05 - model_1_loss: 1.0448e-04 - model_2_loss: 7.4204e-05 - model_3_loss: 4.0448e-05 - model_4_loss: 9.9193e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4867 - loss2: 5.4035 - val_loss: 18.6162 - val_model_loss: 3.8551 - val_model_1_loss: 1.4655 - val_model_2_loss: 1.2059 - val_model_3_loss: 1.8641 - val_model_4_loss: 1.1582 - val_model_accuracy: 0.4865 - val_model_1_accuracy: 0.5275 - val_model_2_accuracy: 0.4985 - val_model_3_accuracy: 0.5640 - val_model_4_accuracy: 0.4760 - val_loss1: 2.1329 - val_loss2: 6.9346\n","Epoch 221/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9469 - model_loss: 2.6029e-04 - model_1_loss: 3.4464e-04 - model_2_loss: 0.0014 - model_3_loss: 4.9269e-04 - model_4_loss: 1.7120e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5763 - loss2: 5.3680 - val_loss: 18.4778 - val_model_loss: 3.6978 - val_model_1_loss: 1.4777 - val_model_2_loss: 1.2050 - val_model_3_loss: 1.8633 - val_model_4_loss: 1.1612 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.5255 - val_model_2_accuracy: 0.5005 - val_model_3_accuracy: 0.5650 - val_model_4_accuracy: 0.4770 - val_loss1: 2.1278 - val_loss2: 6.9451\n","Epoch 222/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0062 - model_loss: 1.5894e-05 - model_1_loss: 2.9615e-04 - model_2_loss: 6.9212e-04 - model_3_loss: 1.1712e-04 - model_4_loss: 7.3331e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8135 - loss2: 5.1909 - val_loss: 18.3604 - val_model_loss: 3.5584 - val_model_1_loss: 1.4845 - val_model_2_loss: 1.2020 - val_model_3_loss: 1.8626 - val_model_4_loss: 1.1642 - val_model_accuracy: 0.4765 - val_model_1_accuracy: 0.5255 - val_model_2_accuracy: 0.4985 - val_model_3_accuracy: 0.5635 - val_model_4_accuracy: 0.4765 - val_loss1: 2.1203 - val_loss2: 6.9685\n","Epoch 223/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8642 - model_loss: 1.0337e-04 - model_1_loss: 2.4419e-04 - model_2_loss: 3.9053e-04 - model_3_loss: 5.0324e-05 - model_4_loss: 3.7737e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5815 - loss2: 5.2815 - val_loss: 18.2678 - val_model_loss: 3.4423 - val_model_1_loss: 1.4945 - val_model_2_loss: 1.1981 - val_model_3_loss: 1.8662 - val_model_4_loss: 1.1677 - val_model_accuracy: 0.4760 - val_model_1_accuracy: 0.5260 - val_model_2_accuracy: 0.4980 - val_model_3_accuracy: 0.5685 - val_model_4_accuracy: 0.4790 - val_loss1: 2.1132 - val_loss2: 6.9858\n","Epoch 224/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8331 - model_loss: 3.1789e-06 - model_1_loss: 4.5268e-04 - model_2_loss: 1.9047e-04 - model_3_loss: 1.0512e-04 - model_4_loss: 2.4060e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4581 - loss2: 5.3739 - val_loss: 18.2108 - val_model_loss: 3.3690 - val_model_1_loss: 1.5049 - val_model_2_loss: 1.1959 - val_model_3_loss: 1.8698 - val_model_4_loss: 1.1719 - val_model_accuracy: 0.4825 - val_model_1_accuracy: 0.5270 - val_model_2_accuracy: 0.4975 - val_model_3_accuracy: 0.5720 - val_model_4_accuracy: 0.4780 - val_loss1: 2.1032 - val_loss2: 6.9962\n","Epoch 225/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9025 - model_loss: 5.9444e-04 - model_1_loss: 0.0159 - model_2_loss: 0.0017 - model_3_loss: 4.8049e-04 - model_4_loss: 6.7061e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5365 - loss2: 5.3466 - val_loss: 18.1612 - val_model_loss: 3.3134 - val_model_1_loss: 1.5001 - val_model_2_loss: 1.1937 - val_model_3_loss: 1.8744 - val_model_4_loss: 1.1755 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.5265 - val_model_2_accuracy: 0.4980 - val_model_3_accuracy: 0.5775 - val_model_4_accuracy: 0.4770 - val_loss1: 2.0968 - val_loss2: 7.0074\n","Epoch 226/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8354 - model_loss: 9.6415e-05 - model_1_loss: 1.7101e-04 - model_2_loss: 1.4291e-04 - model_3_loss: 7.4698e-05 - model_4_loss: 4.4271e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5653 - loss2: 5.2691 - val_loss: 18.1156 - val_model_loss: 3.2701 - val_model_1_loss: 1.4959 - val_model_2_loss: 1.1923 - val_model_3_loss: 1.8793 - val_model_4_loss: 1.1781 - val_model_accuracy: 0.5025 - val_model_1_accuracy: 0.5290 - val_model_2_accuracy: 0.5000 - val_model_3_accuracy: 0.5830 - val_model_4_accuracy: 0.4770 - val_loss1: 2.0886 - val_loss2: 7.0113\n","Epoch 227/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2251 - model_loss: 0.0538 - model_1_loss: 0.0025 - model_2_loss: 0.0111 - model_3_loss: 0.0173 - model_4_loss: 0.0304 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.9460 - loss2: 5.1639 - val_loss: 18.1238 - val_model_loss: 3.2813 - val_model_1_loss: 1.4910 - val_model_2_loss: 1.1894 - val_model_3_loss: 1.8812 - val_model_4_loss: 1.1824 - val_model_accuracy: 0.5015 - val_model_1_accuracy: 0.5300 - val_model_2_accuracy: 0.5000 - val_model_3_accuracy: 0.5830 - val_model_4_accuracy: 0.4770 - val_loss1: 2.0802 - val_loss2: 7.0183\n","Epoch 228/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8715 - model_loss: 0.0021 - model_1_loss: 0.0017 - model_2_loss: 9.1884e-04 - model_3_loss: 0.0011 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5349 - loss2: 5.3292 - val_loss: 18.1399 - val_model_loss: 3.2980 - val_model_1_loss: 1.4843 - val_model_2_loss: 1.1891 - val_model_3_loss: 1.8833 - val_model_4_loss: 1.1866 - val_model_accuracy: 0.5025 - val_model_1_accuracy: 0.5315 - val_model_2_accuracy: 0.4990 - val_model_3_accuracy: 0.5820 - val_model_4_accuracy: 0.4750 - val_loss1: 2.0746 - val_loss2: 7.0239\n","Epoch 229/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8556 - model_loss: 1.8477e-06 - model_1_loss: 7.8149e-04 - model_2_loss: 1.2718e-04 - model_3_loss: 3.7151e-05 - model_4_loss: 2.6077e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6206 - loss2: 5.2338 - val_loss: 18.1507 - val_model_loss: 3.3132 - val_model_1_loss: 1.4778 - val_model_2_loss: 1.1894 - val_model_3_loss: 1.8817 - val_model_4_loss: 1.1888 - val_model_accuracy: 0.5025 - val_model_1_accuracy: 0.5325 - val_model_2_accuracy: 0.4980 - val_model_3_accuracy: 0.5820 - val_model_4_accuracy: 0.4770 - val_loss1: 2.0710 - val_loss2: 7.0288\n","Epoch 230/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9643 - model_loss: 1.5024e-04 - model_1_loss: 3.1805e-04 - model_2_loss: 5.2506e-04 - model_3_loss: 1.0591e-04 - model_4_loss: 4.2505e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6445 - loss2: 5.3183 - val_loss: 18.1600 - val_model_loss: 3.3185 - val_model_1_loss: 1.4724 - val_model_2_loss: 1.1872 - val_model_3_loss: 1.8843 - val_model_4_loss: 1.1928 - val_model_accuracy: 0.5035 - val_model_1_accuracy: 0.5345 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.5815 - val_model_4_accuracy: 0.4710 - val_loss1: 2.0648 - val_loss2: 7.0401\n","Epoch 231/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9255 - model_loss: 0.0031 - model_1_loss: 2.1531e-04 - model_2_loss: 1.2136e-04 - model_3_loss: 8.1175e-05 - model_4_loss: 1.9358e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4789 - loss2: 5.4428 - val_loss: 18.1585 - val_model_loss: 3.3178 - val_model_1_loss: 1.4694 - val_model_2_loss: 1.1853 - val_model_3_loss: 1.8869 - val_model_4_loss: 1.1952 - val_model_accuracy: 0.5015 - val_model_1_accuracy: 0.5375 - val_model_2_accuracy: 0.4955 - val_model_3_accuracy: 0.5820 - val_model_4_accuracy: 0.4660 - val_loss1: 2.0569 - val_loss2: 7.0471\n","Epoch 232/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0122 - model_loss: 0.0025 - model_1_loss: 5.8710e-04 - model_2_loss: 3.0994e-04 - model_3_loss: 8.0752e-04 - model_4_loss: 3.4546e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.8144 - loss2: 5.1933 - val_loss: 18.1619 - val_model_loss: 3.3312 - val_model_1_loss: 1.4656 - val_model_2_loss: 1.1836 - val_model_3_loss: 1.8879 - val_model_4_loss: 1.1985 - val_model_accuracy: 0.5015 - val_model_1_accuracy: 0.5380 - val_model_2_accuracy: 0.4950 - val_model_3_accuracy: 0.5805 - val_model_4_accuracy: 0.4640 - val_loss1: 2.0472 - val_loss2: 7.0479\n","Epoch 233/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8606 - model_loss: 5.3425e-04 - model_1_loss: 0.0017 - model_2_loss: 3.1461e-04 - model_3_loss: 7.9685e-05 - model_4_loss: 4.6552e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5368 - loss2: 5.3207 - val_loss: 18.1624 - val_model_loss: 3.3469 - val_model_1_loss: 1.4651 - val_model_2_loss: 1.1815 - val_model_3_loss: 1.8913 - val_model_4_loss: 1.2015 - val_model_accuracy: 0.5025 - val_model_1_accuracy: 0.5390 - val_model_2_accuracy: 0.4945 - val_model_3_accuracy: 0.5800 - val_model_4_accuracy: 0.4645 - val_loss1: 2.0337 - val_loss2: 7.0424\n","Epoch 234/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9169 - model_loss: 5.6576e-05 - model_1_loss: 8.1687e-04 - model_2_loss: 0.0012 - model_3_loss: 9.6231e-05 - model_4_loss: 6.6147e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5555 - loss2: 5.3586 - val_loss: 18.1343 - val_model_loss: 3.3405 - val_model_1_loss: 1.4643 - val_model_2_loss: 1.1792 - val_model_3_loss: 1.8951 - val_model_4_loss: 1.2045 - val_model_accuracy: 0.5030 - val_model_1_accuracy: 0.5415 - val_model_2_accuracy: 0.4945 - val_model_3_accuracy: 0.5825 - val_model_4_accuracy: 0.4650 - val_loss1: 2.0167 - val_loss2: 7.0341\n","Epoch 235/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9161 - model_loss: 2.6979e-05 - model_1_loss: 0.0022 - model_2_loss: 4.5577e-04 - model_3_loss: 3.1578e-04 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5575 - loss2: 5.3546 - val_loss: 18.1211 - val_model_loss: 3.3464 - val_model_1_loss: 1.4624 - val_model_2_loss: 1.1778 - val_model_3_loss: 1.8957 - val_model_4_loss: 1.2078 - val_model_accuracy: 0.5030 - val_model_1_accuracy: 0.5425 - val_model_2_accuracy: 0.4925 - val_model_3_accuracy: 0.5815 - val_model_4_accuracy: 0.4650 - val_loss1: 2.0043 - val_loss2: 7.0267\n","Epoch 236/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9367 - model_loss: 1.4724e-04 - model_1_loss: 6.2736e-04 - model_2_loss: 0.0015 - model_3_loss: 3.1933e-04 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6912 - loss2: 5.2418 - val_loss: 18.1057 - val_model_loss: 3.3488 - val_model_1_loss: 1.4611 - val_model_2_loss: 1.1764 - val_model_3_loss: 1.9004 - val_model_4_loss: 1.2116 - val_model_accuracy: 0.5030 - val_model_1_accuracy: 0.5420 - val_model_2_accuracy: 0.4905 - val_model_3_accuracy: 0.5820 - val_model_4_accuracy: 0.4655 - val_loss1: 1.9908 - val_loss2: 7.0166\n","Epoch 237/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8758 - model_loss: 2.5689e-05 - model_1_loss: 0.0021 - model_2_loss: 0.0013 - model_3_loss: 1.8028e-04 - model_4_loss: 2.8515e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5562 - loss2: 5.3156 - val_loss: 18.0849 - val_model_loss: 3.3548 - val_model_1_loss: 1.4592 - val_model_2_loss: 1.1777 - val_model_3_loss: 1.8998 - val_model_4_loss: 1.2150 - val_model_accuracy: 0.5050 - val_model_1_accuracy: 0.5415 - val_model_2_accuracy: 0.4905 - val_model_3_accuracy: 0.5805 - val_model_4_accuracy: 0.4635 - val_loss1: 1.9753 - val_loss2: 7.0033\n","Epoch 238/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8863 - model_loss: 5.1964e-04 - model_1_loss: 2.3680e-04 - model_2_loss: 8.5527e-05 - model_3_loss: 4.3270e-05 - model_4_loss: 2.3622e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4711 - loss2: 5.4140 - val_loss: 18.0591 - val_model_loss: 3.3500 - val_model_1_loss: 1.4611 - val_model_2_loss: 1.1772 - val_model_3_loss: 1.9032 - val_model_4_loss: 1.2176 - val_model_accuracy: 0.5090 - val_model_1_accuracy: 0.5420 - val_model_2_accuracy: 0.4910 - val_model_3_accuracy: 0.5835 - val_model_4_accuracy: 0.4635 - val_loss1: 1.9627 - val_loss2: 6.9872\n","Epoch 239/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8941 - model_loss: 7.4505e-06 - model_1_loss: 6.4690e-04 - model_2_loss: 0.0011 - model_3_loss: 1.9494e-04 - model_4_loss: 3.2377e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6434 - loss2: 5.2484 - val_loss: 18.0458 - val_model_loss: 3.3576 - val_model_1_loss: 1.4608 - val_model_2_loss: 1.1787 - val_model_3_loss: 1.9058 - val_model_4_loss: 1.2209 - val_model_accuracy: 0.5080 - val_model_1_accuracy: 0.5425 - val_model_2_accuracy: 0.4910 - val_model_3_accuracy: 0.5835 - val_model_4_accuracy: 0.4615 - val_loss1: 1.9501 - val_loss2: 6.9719\n","Epoch 240/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8388 - model_loss: 6.0598e-06 - model_1_loss: 8.2723e-04 - model_2_loss: 3.3717e-04 - model_3_loss: 2.6092e-04 - model_4_loss: 8.3916e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4877 - loss2: 5.3488 - val_loss: 18.0129 - val_model_loss: 3.3503 - val_model_1_loss: 1.4618 - val_model_2_loss: 1.1798 - val_model_3_loss: 1.9084 - val_model_4_loss: 1.2235 - val_model_accuracy: 0.5070 - val_model_1_accuracy: 0.5435 - val_model_2_accuracy: 0.4915 - val_model_3_accuracy: 0.5835 - val_model_4_accuracy: 0.4610 - val_loss1: 1.9378 - val_loss2: 6.9513\n","Epoch 241/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8404 - model_loss: 3.7092e-05 - model_1_loss: 4.7611e-04 - model_2_loss: 1.0645e-04 - model_3_loss: 1.2662e-04 - model_4_loss: 2.1906e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4345 - loss2: 5.4050 - val_loss: 17.9977 - val_model_loss: 3.3529 - val_model_1_loss: 1.4650 - val_model_2_loss: 1.1805 - val_model_3_loss: 1.9128 - val_model_4_loss: 1.2253 - val_model_accuracy: 0.5060 - val_model_1_accuracy: 0.5415 - val_model_2_accuracy: 0.4920 - val_model_3_accuracy: 0.5850 - val_model_4_accuracy: 0.4600 - val_loss1: 1.9299 - val_loss2: 6.9312\n","Epoch 242/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8696 - model_loss: 7.6889e-06 - model_1_loss: 6.9974e-04 - model_2_loss: 1.9626e-04 - model_3_loss: 2.8351e-04 - model_4_loss: 1.8016e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4928 - loss2: 5.3754 - val_loss: 17.9808 - val_model_loss: 3.3556 - val_model_1_loss: 1.4685 - val_model_2_loss: 1.1803 - val_model_3_loss: 1.9161 - val_model_4_loss: 1.2270 - val_model_accuracy: 0.5050 - val_model_1_accuracy: 0.5430 - val_model_2_accuracy: 0.4920 - val_model_3_accuracy: 0.5880 - val_model_4_accuracy: 0.4605 - val_loss1: 1.9206 - val_loss2: 6.9127\n","Epoch 243/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9368 - model_loss: 0.0019 - model_1_loss: 5.5153e-04 - model_2_loss: 0.0018 - model_3_loss: 9.6417e-04 - model_4_loss: 4.6008e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5182 - loss2: 5.4129 - val_loss: 17.9591 - val_model_loss: 3.3529 - val_model_1_loss: 1.4702 - val_model_2_loss: 1.1815 - val_model_3_loss: 1.9211 - val_model_4_loss: 1.2294 - val_model_accuracy: 0.5060 - val_model_1_accuracy: 0.5445 - val_model_2_accuracy: 0.4935 - val_model_3_accuracy: 0.5880 - val_model_4_accuracy: 0.4615 - val_loss1: 1.9108 - val_loss2: 6.8933\n","Epoch 244/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9622 - model_loss: 0.0066 - model_1_loss: 0.0015 - model_2_loss: 3.5233e-04 - model_3_loss: 3.8950e-04 - model_4_loss: 2.3367e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6883 - loss2: 5.2647 - val_loss: 17.9554 - val_model_loss: 3.3667 - val_model_1_loss: 1.4713 - val_model_2_loss: 1.1824 - val_model_3_loss: 1.9249 - val_model_4_loss: 1.2334 - val_model_accuracy: 0.5055 - val_model_1_accuracy: 0.5455 - val_model_2_accuracy: 0.4935 - val_model_3_accuracy: 0.5885 - val_model_4_accuracy: 0.4575 - val_loss1: 1.9017 - val_loss2: 6.8751\n","Epoch 245/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8881 - model_loss: 1.2139e-05 - model_1_loss: 8.1895e-04 - model_2_loss: 0.0107 - model_3_loss: 0.0021 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5393 - loss2: 5.3335 - val_loss: 17.9414 - val_model_loss: 3.3665 - val_model_1_loss: 1.4745 - val_model_2_loss: 1.1923 - val_model_3_loss: 1.9302 - val_model_4_loss: 1.2356 - val_model_accuracy: 0.5050 - val_model_1_accuracy: 0.5460 - val_model_2_accuracy: 0.4890 - val_model_3_accuracy: 0.5890 - val_model_4_accuracy: 0.4595 - val_loss1: 1.8916 - val_loss2: 6.8507\n","Epoch 246/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8022 - model_loss: 1.2521e-04 - model_1_loss: 6.5928e-04 - model_2_loss: 2.2527e-04 - model_3_loss: 6.9471e-05 - model_4_loss: 2.0145e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.3925 - loss2: 5.4084 - val_loss: 17.9381 - val_model_loss: 3.3697 - val_model_1_loss: 1.4806 - val_model_2_loss: 1.1999 - val_model_3_loss: 1.9372 - val_model_4_loss: 1.2377 - val_model_accuracy: 0.5050 - val_model_1_accuracy: 0.5470 - val_model_2_accuracy: 0.4865 - val_model_3_accuracy: 0.5890 - val_model_4_accuracy: 0.4620 - val_loss1: 1.8848 - val_loss2: 6.8282\n","Epoch 247/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8381 - model_loss: 1.4424e-05 - model_1_loss: 2.0430e-04 - model_2_loss: 1.3351e-04 - model_3_loss: 7.4338e-05 - model_4_loss: 1.3284e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5785 - loss2: 5.2590 - val_loss: 17.9357 - val_model_loss: 3.3794 - val_model_1_loss: 1.4841 - val_model_2_loss: 1.2075 - val_model_3_loss: 1.9405 - val_model_4_loss: 1.2404 - val_model_accuracy: 0.5050 - val_model_1_accuracy: 0.5470 - val_model_2_accuracy: 0.4865 - val_model_3_accuracy: 0.5895 - val_model_4_accuracy: 0.4620 - val_loss1: 1.8767 - val_loss2: 6.8070\n","Epoch 248/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9150 - model_loss: 4.6486e-04 - model_1_loss: 2.1654e-04 - model_2_loss: 3.1179e-04 - model_3_loss: 6.4453e-04 - model_4_loss: 4.3262e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5584 - loss2: 5.3545 - val_loss: 17.9226 - val_model_loss: 3.3770 - val_model_1_loss: 1.4924 - val_model_2_loss: 1.2134 - val_model_3_loss: 1.9515 - val_model_4_loss: 1.2413 - val_model_accuracy: 0.5005 - val_model_1_accuracy: 0.5450 - val_model_2_accuracy: 0.4880 - val_model_3_accuracy: 0.5920 - val_model_4_accuracy: 0.4620 - val_loss1: 1.8655 - val_loss2: 6.7816\n","Epoch 249/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9534 - model_loss: 0.0401 - model_1_loss: 0.0025 - model_2_loss: 0.0016 - model_3_loss: 0.0012 - model_4_loss: 0.0013 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7731 - loss2: 5.1336 - val_loss: 17.9298 - val_model_loss: 3.3877 - val_model_1_loss: 1.4968 - val_model_2_loss: 1.2198 - val_model_3_loss: 1.9592 - val_model_4_loss: 1.2455 - val_model_accuracy: 0.5010 - val_model_1_accuracy: 0.5435 - val_model_2_accuracy: 0.4890 - val_model_3_accuracy: 0.5945 - val_model_4_accuracy: 0.4605 - val_loss1: 1.8551 - val_loss2: 6.7657\n","Epoch 250/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.2691 - model_loss: 0.2062 - model_1_loss: 0.0056 - model_2_loss: 0.0046 - model_3_loss: 0.0048 - model_4_loss: 0.0081 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7535 - loss2: 5.2864 - val_loss: 17.9427 - val_model_loss: 3.4263 - val_model_1_loss: 1.5009 - val_model_2_loss: 1.2285 - val_model_3_loss: 1.9702 - val_model_4_loss: 1.2487 - val_model_accuracy: 0.4990 - val_model_1_accuracy: 0.5430 - val_model_2_accuracy: 0.4875 - val_model_3_accuracy: 0.5950 - val_model_4_accuracy: 0.4620 - val_loss1: 1.8429 - val_loss2: 6.7252\n","Epoch 251/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9289 - model_loss: 5.3646e-04 - model_1_loss: 0.0163 - model_2_loss: 0.0095 - model_3_loss: 0.0014 - model_4_loss: 0.0150 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5811 - loss2: 5.3051 - val_loss: 18.0304 - val_model_loss: 3.5099 - val_model_1_loss: 1.5097 - val_model_2_loss: 1.2467 - val_model_3_loss: 1.9820 - val_model_4_loss: 1.2575 - val_model_accuracy: 0.4990 - val_model_1_accuracy: 0.5430 - val_model_2_accuracy: 0.4855 - val_model_3_accuracy: 0.5960 - val_model_4_accuracy: 0.4670 - val_loss1: 1.8337 - val_loss2: 6.6911\n","Epoch 252/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8744 - model_loss: 1.4841e-05 - model_1_loss: 0.0011 - model_2_loss: 8.9917e-05 - model_3_loss: 6.5299e-05 - model_4_loss: 2.0323e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5742 - loss2: 5.2987 - val_loss: 18.1403 - val_model_loss: 3.6307 - val_model_1_loss: 1.5176 - val_model_2_loss: 1.2617 - val_model_3_loss: 1.9902 - val_model_4_loss: 1.2625 - val_model_accuracy: 0.4915 - val_model_1_accuracy: 0.5450 - val_model_2_accuracy: 0.4830 - val_model_3_accuracy: 0.5980 - val_model_4_accuracy: 0.4675 - val_loss1: 1.8228 - val_loss2: 6.6548\n","Epoch 253/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9760 - model_loss: 1.0530e-05 - model_1_loss: 0.0011 - model_2_loss: 0.0025 - model_3_loss: 2.0408e-04 - model_4_loss: 5.8273e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6307 - loss2: 5.3409 - val_loss: 18.2934 - val_model_loss: 3.7892 - val_model_1_loss: 1.5258 - val_model_2_loss: 1.2782 - val_model_3_loss: 1.9994 - val_model_4_loss: 1.2697 - val_model_accuracy: 0.4820 - val_model_1_accuracy: 0.5465 - val_model_2_accuracy: 0.4830 - val_model_3_accuracy: 0.6010 - val_model_4_accuracy: 0.4705 - val_loss1: 1.8102 - val_loss2: 6.6209\n","Epoch 254/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0404 - model_loss: 1.0212e-05 - model_1_loss: 2.3966e-04 - model_2_loss: 2.8841e-04 - model_3_loss: 2.8928e-04 - model_4_loss: 1.9504e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6722 - loss2: 5.3672 - val_loss: 18.4720 - val_model_loss: 3.9789 - val_model_1_loss: 1.5291 - val_model_2_loss: 1.2956 - val_model_3_loss: 2.0028 - val_model_4_loss: 1.2772 - val_model_accuracy: 0.4760 - val_model_1_accuracy: 0.5455 - val_model_2_accuracy: 0.4775 - val_model_3_accuracy: 0.6020 - val_model_4_accuracy: 0.4735 - val_loss1: 1.7986 - val_loss2: 6.5897\n","Epoch 255/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8116 - model_loss: 4.9719e-04 - model_1_loss: 8.0510e-04 - model_2_loss: 0.0049 - model_3_loss: 0.0019 - model_4_loss: 0.0031 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4626 - loss2: 5.3377 - val_loss: 18.6663 - val_model_loss: 4.1812 - val_model_1_loss: 1.5361 - val_model_2_loss: 1.3115 - val_model_3_loss: 2.0118 - val_model_4_loss: 1.2864 - val_model_accuracy: 0.4740 - val_model_1_accuracy: 0.5455 - val_model_2_accuracy: 0.4745 - val_model_3_accuracy: 0.6025 - val_model_4_accuracy: 0.4770 - val_loss1: 1.7846 - val_loss2: 6.5546\n","Epoch 256/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.7943 - model_loss: 2.3246e-06 - model_1_loss: 1.2855e-04 - model_2_loss: 1.4856e-04 - model_3_loss: 6.4407e-05 - model_4_loss: 1.2939e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5599 - loss2: 5.2339 - val_loss: 18.8546 - val_model_loss: 4.3800 - val_model_1_loss: 1.5408 - val_model_2_loss: 1.3213 - val_model_3_loss: 2.0164 - val_model_4_loss: 1.2939 - val_model_accuracy: 0.4715 - val_model_1_accuracy: 0.5465 - val_model_2_accuracy: 0.4750 - val_model_3_accuracy: 0.6040 - val_model_4_accuracy: 0.4780 - val_loss1: 1.7763 - val_loss2: 6.5261\n","Epoch 257/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8126 - model_loss: 1.8636e-05 - model_1_loss: 2.2558e-04 - model_2_loss: 3.5515e-04 - model_3_loss: 7.6069e-05 - model_4_loss: 1.8243e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4948 - loss2: 5.3170 - val_loss: 19.0006 - val_model_loss: 4.5286 - val_model_1_loss: 1.5491 - val_model_2_loss: 1.3298 - val_model_3_loss: 2.0289 - val_model_4_loss: 1.3008 - val_model_accuracy: 0.4640 - val_model_1_accuracy: 0.5470 - val_model_2_accuracy: 0.4745 - val_model_3_accuracy: 0.6080 - val_model_4_accuracy: 0.4770 - val_loss1: 1.7651 - val_loss2: 6.4983\n","Epoch 258/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9674 - model_loss: 0.0031 - model_1_loss: 0.0019 - model_2_loss: 0.0141 - model_3_loss: 0.0016 - model_4_loss: 0.0036 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7530 - loss2: 5.1900 - val_loss: 19.1166 - val_model_loss: 4.6650 - val_model_1_loss: 1.5552 - val_model_2_loss: 1.3196 - val_model_3_loss: 2.0378 - val_model_4_loss: 1.3097 - val_model_accuracy: 0.4590 - val_model_1_accuracy: 0.5475 - val_model_2_accuracy: 0.4750 - val_model_3_accuracy: 0.6110 - val_model_4_accuracy: 0.4760 - val_loss1: 1.7530 - val_loss2: 6.4763\n","Epoch 259/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8901 - model_loss: 3.8147e-06 - model_1_loss: 8.1736e-04 - model_2_loss: 3.8211e-04 - model_3_loss: 5.2145e-04 - model_4_loss: 2.6853e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5254 - loss2: 5.3627 - val_loss: 19.2110 - val_model_loss: 4.7832 - val_model_1_loss: 1.5623 - val_model_2_loss: 1.3101 - val_model_3_loss: 2.0464 - val_model_4_loss: 1.3173 - val_model_accuracy: 0.4535 - val_model_1_accuracy: 0.5480 - val_model_2_accuracy: 0.4795 - val_model_3_accuracy: 0.6120 - val_model_4_accuracy: 0.4770 - val_loss1: 1.7388 - val_loss2: 6.4528\n","Epoch 260/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8957 - model_loss: 2.8102e-04 - model_1_loss: 2.9520e-04 - model_2_loss: 3.7182e-04 - model_3_loss: 6.1586e-05 - model_4_loss: 2.3702e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6204 - loss2: 5.2741 - val_loss: 19.2788 - val_model_loss: 4.8799 - val_model_1_loss: 1.5649 - val_model_2_loss: 1.3011 - val_model_3_loss: 2.0548 - val_model_4_loss: 1.3247 - val_model_accuracy: 0.4495 - val_model_1_accuracy: 0.5490 - val_model_2_accuracy: 0.4800 - val_model_3_accuracy: 0.6155 - val_model_4_accuracy: 0.4790 - val_loss1: 1.7221 - val_loss2: 6.4312\n","Epoch 261/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.1567 - model_loss: 0.1380 - model_1_loss: 0.0104 - model_2_loss: 0.0232 - model_3_loss: 0.0021 - model_4_loss: 0.0089 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7302 - loss2: 5.2441 - val_loss: 19.2127 - val_model_loss: 4.8153 - val_model_1_loss: 1.5837 - val_model_2_loss: 1.3055 - val_model_3_loss: 2.0659 - val_model_4_loss: 1.3338 - val_model_accuracy: 0.4425 - val_model_1_accuracy: 0.5490 - val_model_2_accuracy: 0.4835 - val_model_3_accuracy: 0.6150 - val_model_4_accuracy: 0.4815 - val_loss1: 1.7095 - val_loss2: 6.3990\n","Epoch 262/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9210 - model_loss: 5.4693e-04 - model_1_loss: 0.0027 - model_2_loss: 0.0084 - model_3_loss: 0.0292 - model_4_loss: 7.2201e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6017 - loss2: 5.2778 - val_loss: 19.1386 - val_model_loss: 4.7375 - val_model_1_loss: 1.5967 - val_model_2_loss: 1.3056 - val_model_3_loss: 2.0802 - val_model_4_loss: 1.3404 - val_model_accuracy: 0.4380 - val_model_1_accuracy: 0.5470 - val_model_2_accuracy: 0.4920 - val_model_3_accuracy: 0.6215 - val_model_4_accuracy: 0.4810 - val_loss1: 1.7003 - val_loss2: 6.3778\n","Epoch 263/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.7978 - model_loss: 6.7803e-05 - model_1_loss: 4.2219e-04 - model_2_loss: 9.0918e-04 - model_3_loss: 5.4635e-05 - model_4_loss: 3.5517e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5186 - loss2: 5.2775 - val_loss: 19.0276 - val_model_loss: 4.6254 - val_model_1_loss: 1.6104 - val_model_2_loss: 1.3064 - val_model_3_loss: 2.0965 - val_model_4_loss: 1.3457 - val_model_accuracy: 0.4315 - val_model_1_accuracy: 0.5470 - val_model_2_accuracy: 0.5000 - val_model_3_accuracy: 0.6235 - val_model_4_accuracy: 0.4790 - val_loss1: 1.6876 - val_loss2: 6.3557\n","Epoch 264/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.7910 - model_loss: 1.6907e-05 - model_1_loss: 2.6647e-04 - model_2_loss: 2.4652e-04 - model_3_loss: 6.2736e-05 - model_4_loss: 1.2297e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4550 - loss2: 5.3353 - val_loss: 18.9332 - val_model_loss: 4.5215 - val_model_1_loss: 1.6228 - val_model_2_loss: 1.3086 - val_model_3_loss: 2.1149 - val_model_4_loss: 1.3518 - val_model_accuracy: 0.4305 - val_model_1_accuracy: 0.5460 - val_model_2_accuracy: 0.5015 - val_model_3_accuracy: 0.6245 - val_model_4_accuracy: 0.4810 - val_loss1: 1.6772 - val_loss2: 6.3363\n","Epoch 265/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8776 - model_loss: 2.0330e-04 - model_1_loss: 0.0012 - model_2_loss: 0.0170 - model_3_loss: 1.7351e-04 - model_4_loss: 0.0028 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4608 - loss2: 5.3955 - val_loss: 18.8418 - val_model_loss: 4.4340 - val_model_1_loss: 1.6364 - val_model_2_loss: 1.2978 - val_model_3_loss: 2.1299 - val_model_4_loss: 1.3549 - val_model_accuracy: 0.4270 - val_model_1_accuracy: 0.5445 - val_model_2_accuracy: 0.5125 - val_model_3_accuracy: 0.6295 - val_model_4_accuracy: 0.4835 - val_loss1: 1.6669 - val_loss2: 6.3219\n","Epoch 266/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9059 - model_loss: 1.0695e-04 - model_1_loss: 0.0069 - model_2_loss: 0.0098 - model_3_loss: 0.0034 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7516 - loss2: 5.1329 - val_loss: 18.7410 - val_model_loss: 4.3442 - val_model_1_loss: 1.6400 - val_model_2_loss: 1.2871 - val_model_3_loss: 2.1459 - val_model_4_loss: 1.3541 - val_model_accuracy: 0.4265 - val_model_1_accuracy: 0.5420 - val_model_2_accuracy: 0.5210 - val_model_3_accuracy: 0.6330 - val_model_4_accuracy: 0.4835 - val_loss1: 1.6561 - val_loss2: 6.3137\n","Epoch 267/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8748 - model_loss: 7.1838e-05 - model_1_loss: 3.7529e-04 - model_2_loss: 1.8431e-04 - model_3_loss: 1.5281e-04 - model_4_loss: 2.2539e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5852 - loss2: 5.2885 - val_loss: 18.6700 - val_model_loss: 4.2906 - val_model_1_loss: 1.6386 - val_model_2_loss: 1.2771 - val_model_3_loss: 2.1550 - val_model_4_loss: 1.3550 - val_model_accuracy: 0.4245 - val_model_1_accuracy: 0.5405 - val_model_2_accuracy: 0.5220 - val_model_3_accuracy: 0.6340 - val_model_4_accuracy: 0.4850 - val_loss1: 1.6473 - val_loss2: 6.3064\n","Epoch 268/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8175 - model_loss: 3.6596e-05 - model_1_loss: 2.0376e-04 - model_2_loss: 8.6064e-05 - model_3_loss: 5.5545e-05 - model_4_loss: 1.5512e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4334 - loss2: 5.3835 - val_loss: 18.5934 - val_model_loss: 4.2122 - val_model_1_loss: 1.6438 - val_model_2_loss: 1.2707 - val_model_3_loss: 2.1717 - val_model_4_loss: 1.3571 - val_model_accuracy: 0.4235 - val_model_1_accuracy: 0.5405 - val_model_2_accuracy: 0.5265 - val_model_3_accuracy: 0.6345 - val_model_4_accuracy: 0.4835 - val_loss1: 1.6395 - val_loss2: 6.2983\n","Epoch 269/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9363 - model_loss: 3.5325e-05 - model_1_loss: 3.8920e-04 - model_2_loss: 3.4881e-04 - model_3_loss: 2.3186e-05 - model_4_loss: 2.5650e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7289 - loss2: 5.2063 - val_loss: 18.5279 - val_model_loss: 4.1459 - val_model_1_loss: 1.6471 - val_model_2_loss: 1.2671 - val_model_3_loss: 2.1827 - val_model_4_loss: 1.3602 - val_model_accuracy: 0.4210 - val_model_1_accuracy: 0.5410 - val_model_2_accuracy: 0.5270 - val_model_3_accuracy: 0.6355 - val_model_4_accuracy: 0.4825 - val_loss1: 1.6314 - val_loss2: 6.2934\n","Epoch 270/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9386 - model_loss: 2.6724e-04 - model_1_loss: 1.7132e-04 - model_2_loss: 6.7786e-05 - model_3_loss: 1.7682e-05 - model_4_loss: 2.1277e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5455 - loss2: 5.3923 - val_loss: 18.4620 - val_model_loss: 4.0814 - val_model_1_loss: 1.6505 - val_model_2_loss: 1.2635 - val_model_3_loss: 2.1909 - val_model_4_loss: 1.3616 - val_model_accuracy: 0.4190 - val_model_1_accuracy: 0.5415 - val_model_2_accuracy: 0.5295 - val_model_3_accuracy: 0.6370 - val_model_4_accuracy: 0.4815 - val_loss1: 1.6251 - val_loss2: 6.2891\n","Epoch 271/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8529 - model_loss: 5.6423e-05 - model_1_loss: 4.0511e-04 - model_2_loss: 2.4398e-04 - model_3_loss: 1.4087e-04 - model_4_loss: 1.3801e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5606 - loss2: 5.2914 - val_loss: 18.4128 - val_model_loss: 4.0305 - val_model_1_loss: 1.6540 - val_model_2_loss: 1.2620 - val_model_3_loss: 2.2024 - val_model_4_loss: 1.3645 - val_model_accuracy: 0.4180 - val_model_1_accuracy: 0.5410 - val_model_2_accuracy: 0.5325 - val_model_3_accuracy: 0.6390 - val_model_4_accuracy: 0.4790 - val_loss1: 1.6165 - val_loss2: 6.2828\n","Epoch 272/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.7767 - model_loss: 3.8681e-05 - model_1_loss: 5.7287e-04 - model_2_loss: 1.5219e-04 - model_3_loss: 6.3708e-05 - model_4_loss: 1.5877e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.3388 - loss2: 5.4369 - val_loss: 18.3691 - val_model_loss: 3.9817 - val_model_1_loss: 1.6596 - val_model_2_loss: 1.2617 - val_model_3_loss: 2.2141 - val_model_4_loss: 1.3684 - val_model_accuracy: 0.4180 - val_model_1_accuracy: 0.5405 - val_model_2_accuracy: 0.5340 - val_model_3_accuracy: 0.6395 - val_model_4_accuracy: 0.4755 - val_loss1: 1.6074 - val_loss2: 6.2762\n","Epoch 273/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9713 - model_loss: 2.1063e-04 - model_1_loss: 2.7856e-04 - model_2_loss: 2.0767e-04 - model_3_loss: 1.7514e-04 - model_4_loss: 1.7934e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6979 - loss2: 5.2723 - val_loss: 18.3178 - val_model_loss: 3.9308 - val_model_1_loss: 1.6676 - val_model_2_loss: 1.2607 - val_model_3_loss: 2.2264 - val_model_4_loss: 1.3700 - val_model_accuracy: 0.4175 - val_model_1_accuracy: 0.5395 - val_model_2_accuracy: 0.5365 - val_model_3_accuracy: 0.6395 - val_model_4_accuracy: 0.4760 - val_loss1: 1.5949 - val_loss2: 6.2673\n","Epoch 274/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9343 - model_loss: 5.5119e-04 - model_1_loss: 5.8670e-04 - model_2_loss: 1.3638e-04 - model_3_loss: 7.5310e-05 - model_4_loss: 3.4556e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6312 - loss2: 5.3014 - val_loss: 18.2660 - val_model_loss: 3.8769 - val_model_1_loss: 1.6729 - val_model_2_loss: 1.2608 - val_model_3_loss: 2.2379 - val_model_4_loss: 1.3721 - val_model_accuracy: 0.4170 - val_model_1_accuracy: 0.5385 - val_model_2_accuracy: 0.5340 - val_model_3_accuracy: 0.6410 - val_model_4_accuracy: 0.4770 - val_loss1: 1.5841 - val_loss2: 6.2613\n","Epoch 275/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8400 - model_loss: 1.9258e-04 - model_1_loss: 3.1805e-04 - model_2_loss: 4.6400e-04 - model_3_loss: 1.2664e-04 - model_4_loss: 4.2206e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4219 - loss2: 5.4166 - val_loss: 18.2356 - val_model_loss: 3.8359 - val_model_1_loss: 1.6794 - val_model_2_loss: 1.2613 - val_model_3_loss: 2.2525 - val_model_4_loss: 1.3738 - val_model_accuracy: 0.4165 - val_model_1_accuracy: 0.5380 - val_model_2_accuracy: 0.5345 - val_model_3_accuracy: 0.6410 - val_model_4_accuracy: 0.4760 - val_loss1: 1.5773 - val_loss2: 6.2554\n","Epoch 276/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8261 - model_loss: 0.0011 - model_1_loss: 4.6310e-04 - model_2_loss: 7.3552e-04 - model_3_loss: 2.9381e-04 - model_4_loss: 2.8126e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5278 - loss2: 5.2956 - val_loss: 18.2004 - val_model_loss: 3.8073 - val_model_1_loss: 1.6829 - val_model_2_loss: 1.2623 - val_model_3_loss: 2.2563 - val_model_4_loss: 1.3763 - val_model_accuracy: 0.4155 - val_model_1_accuracy: 0.5375 - val_model_2_accuracy: 0.5340 - val_model_3_accuracy: 0.6415 - val_model_4_accuracy: 0.4740 - val_loss1: 1.5670 - val_loss2: 6.2485\n","Epoch 277/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8981 - model_loss: 2.8130e-04 - model_1_loss: 0.0013 - model_2_loss: 2.1566e-04 - model_3_loss: 1.0310e-04 - model_4_loss: 0.0020 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6218 - loss2: 5.2726 - val_loss: 18.1660 - val_model_loss: 3.7603 - val_model_1_loss: 1.6910 - val_model_2_loss: 1.2649 - val_model_3_loss: 2.2656 - val_model_4_loss: 1.3768 - val_model_accuracy: 0.4155 - val_model_1_accuracy: 0.5370 - val_model_2_accuracy: 0.5345 - val_model_3_accuracy: 0.6420 - val_model_4_accuracy: 0.4720 - val_loss1: 1.5594 - val_loss2: 6.2481\n","Epoch 278/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.7688 - model_loss: 2.1301e-04 - model_1_loss: 7.2222e-04 - model_2_loss: 1.3189e-04 - model_3_loss: 2.0464e-05 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4284 - loss2: 5.3381 - val_loss: 18.1409 - val_model_loss: 3.7194 - val_model_1_loss: 1.7003 - val_model_2_loss: 1.2677 - val_model_3_loss: 2.2759 - val_model_4_loss: 1.3788 - val_model_accuracy: 0.4155 - val_model_1_accuracy: 0.5370 - val_model_2_accuracy: 0.5375 - val_model_3_accuracy: 0.6420 - val_model_4_accuracy: 0.4700 - val_loss1: 1.5541 - val_loss2: 6.2448\n","Epoch 279/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8325 - model_loss: 6.2479e-05 - model_1_loss: 4.7761e-04 - model_2_loss: 5.0516e-04 - model_3_loss: 4.7305e-04 - model_4_loss: 5.4683e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5266 - loss2: 5.3039 - val_loss: 18.1226 - val_model_loss: 3.6903 - val_model_1_loss: 1.7083 - val_model_2_loss: 1.2695 - val_model_3_loss: 2.2839 - val_model_4_loss: 1.3806 - val_model_accuracy: 0.4155 - val_model_1_accuracy: 0.5370 - val_model_2_accuracy: 0.5390 - val_model_3_accuracy: 0.6425 - val_model_4_accuracy: 0.4705 - val_loss1: 1.5491 - val_loss2: 6.2408\n","Epoch 280/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8357 - model_loss: 8.1215e-04 - model_1_loss: 7.7861e-04 - model_2_loss: 0.0013 - model_3_loss: 7.1894e-04 - model_4_loss: 4.0495e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6611 - loss2: 5.1707 - val_loss: 18.1030 - val_model_loss: 3.6651 - val_model_1_loss: 1.7099 - val_model_2_loss: 1.2711 - val_model_3_loss: 2.2838 - val_model_4_loss: 1.3837 - val_model_accuracy: 0.4155 - val_model_1_accuracy: 0.5370 - val_model_2_accuracy: 0.5395 - val_model_3_accuracy: 0.6430 - val_model_4_accuracy: 0.4710 - val_loss1: 1.5453 - val_loss2: 6.2442\n","Epoch 281/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8851 - model_loss: 8.4333e-05 - model_1_loss: 0.0022 - model_2_loss: 5.8649e-04 - model_3_loss: 9.5435e-05 - model_4_loss: 0.0073 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5130 - loss2: 5.3618 - val_loss: 18.0811 - val_model_loss: 3.6341 - val_model_1_loss: 1.7128 - val_model_2_loss: 1.2733 - val_model_3_loss: 2.2878 - val_model_4_loss: 1.3809 - val_model_accuracy: 0.4155 - val_model_1_accuracy: 0.5365 - val_model_2_accuracy: 0.5375 - val_model_3_accuracy: 0.6430 - val_model_4_accuracy: 0.4720 - val_loss1: 1.5424 - val_loss2: 6.2497\n","Epoch 282/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9296 - model_loss: 0.0062 - model_1_loss: 4.2154e-04 - model_2_loss: 4.4273e-04 - model_3_loss: 1.2308e-04 - model_4_loss: 2.4852e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5225 - loss2: 5.3996 - val_loss: 18.0558 - val_model_loss: 3.5994 - val_model_1_loss: 1.7156 - val_model_2_loss: 1.2754 - val_model_3_loss: 2.2908 - val_model_4_loss: 1.3792 - val_model_accuracy: 0.4155 - val_model_1_accuracy: 0.5355 - val_model_2_accuracy: 0.5370 - val_model_3_accuracy: 0.6435 - val_model_4_accuracy: 0.4750 - val_loss1: 1.5418 - val_loss2: 6.2535\n","Epoch 283/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0036 - model_loss: 0.0014 - model_1_loss: 7.3656e-04 - model_2_loss: 8.4235e-04 - model_3_loss: 5.5138e-04 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7669 - loss2: 5.2318 - val_loss: 17.9911 - val_model_loss: 3.5322 - val_model_1_loss: 1.7125 - val_model_2_loss: 1.2743 - val_model_3_loss: 2.2833 - val_model_4_loss: 1.3754 - val_model_accuracy: 0.4160 - val_model_1_accuracy: 0.5355 - val_model_2_accuracy: 0.5355 - val_model_3_accuracy: 0.6430 - val_model_4_accuracy: 0.4745 - val_loss1: 1.5409 - val_loss2: 6.2724\n","Epoch 284/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8342 - model_loss: 1.6194e-04 - model_1_loss: 0.0024 - model_2_loss: 0.0019 - model_3_loss: 6.7842e-04 - model_4_loss: 5.1824e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6056 - loss2: 5.2229 - val_loss: 17.9367 - val_model_loss: 3.4567 - val_model_1_loss: 1.7147 - val_model_2_loss: 1.2778 - val_model_3_loss: 2.2892 - val_model_4_loss: 1.3739 - val_model_accuracy: 0.4165 - val_model_1_accuracy: 0.5365 - val_model_2_accuracy: 0.5345 - val_model_3_accuracy: 0.6430 - val_model_4_accuracy: 0.4755 - val_loss1: 1.5392 - val_loss2: 6.2852\n","Epoch 285/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8310 - model_loss: 1.2685e-04 - model_1_loss: 5.9939e-04 - model_2_loss: 4.5900e-04 - model_3_loss: 2.6049e-04 - model_4_loss: 2.9837e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4605 - loss2: 5.3688 - val_loss: 17.8737 - val_model_loss: 3.3726 - val_model_1_loss: 1.7184 - val_model_2_loss: 1.2807 - val_model_3_loss: 2.2970 - val_model_4_loss: 1.3758 - val_model_accuracy: 0.4160 - val_model_1_accuracy: 0.5365 - val_model_2_accuracy: 0.5365 - val_model_3_accuracy: 0.6430 - val_model_4_accuracy: 0.4755 - val_loss1: 1.5369 - val_loss2: 6.2923\n","Epoch 286/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0580 - model_loss: 8.2387e-04 - model_1_loss: 2.5435e-04 - model_2_loss: 6.2050e-04 - model_3_loss: 2.4239e-05 - model_4_loss: 2.6868e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.7148 - loss2: 5.3412 - val_loss: 17.8173 - val_model_loss: 3.2847 - val_model_1_loss: 1.7217 - val_model_2_loss: 1.2824 - val_model_3_loss: 2.3081 - val_model_4_loss: 1.3762 - val_model_accuracy: 0.4165 - val_model_1_accuracy: 0.5370 - val_model_2_accuracy: 0.5390 - val_model_3_accuracy: 0.6445 - val_model_4_accuracy: 0.4775 - val_loss1: 1.5390 - val_loss2: 6.3052\n","Epoch 287/300\n","1/1 [==============================] - 8s 8s/step - loss: 6.0117 - model_loss: 2.1305e-04 - model_1_loss: 9.8855e-04 - model_2_loss: 1.5197e-04 - model_3_loss: 5.8766e-05 - model_4_loss: 4.6110e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6239 - loss2: 5.3859 - val_loss: 17.7796 - val_model_loss: 3.2169 - val_model_1_loss: 1.7224 - val_model_2_loss: 1.2825 - val_model_3_loss: 2.3138 - val_model_4_loss: 1.3774 - val_model_accuracy: 0.4175 - val_model_1_accuracy: 0.5380 - val_model_2_accuracy: 0.5400 - val_model_3_accuracy: 0.6435 - val_model_4_accuracy: 0.4790 - val_loss1: 1.5427 - val_loss2: 6.3239\n","Epoch 288/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8184 - model_loss: 6.5223e-05 - model_1_loss: 1.9231e-04 - model_2_loss: 1.3245e-04 - model_3_loss: 1.3490e-05 - model_4_loss: 3.5993e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4360 - loss2: 5.3816 - val_loss: 17.7429 - val_model_loss: 3.1492 - val_model_1_loss: 1.7263 - val_model_2_loss: 1.2836 - val_model_3_loss: 2.3223 - val_model_4_loss: 1.3809 - val_model_accuracy: 0.4160 - val_model_1_accuracy: 0.5380 - val_model_2_accuracy: 0.5410 - val_model_3_accuracy: 0.6425 - val_model_4_accuracy: 0.4805 - val_loss1: 1.5430 - val_loss2: 6.3376\n","Epoch 289/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9568 - model_loss: 4.2317e-05 - model_1_loss: 0.0037 - model_2_loss: 0.0011 - model_3_loss: 4.1525e-04 - model_4_loss: 4.4181e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5532 - loss2: 5.3979 - val_loss: 17.7221 - val_model_loss: 3.1040 - val_model_1_loss: 1.7311 - val_model_2_loss: 1.2845 - val_model_3_loss: 2.3288 - val_model_4_loss: 1.3838 - val_model_accuracy: 0.4165 - val_model_1_accuracy: 0.5375 - val_model_2_accuracy: 0.5410 - val_model_3_accuracy: 0.6430 - val_model_4_accuracy: 0.4815 - val_loss1: 1.5427 - val_loss2: 6.3472\n","Epoch 290/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9485 - model_loss: 0.0110 - model_1_loss: 7.2529e-04 - model_2_loss: 6.8318e-04 - model_3_loss: 0.0029 - model_4_loss: 0.0029 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6284 - loss2: 5.3020 - val_loss: 17.6901 - val_model_loss: 3.0462 - val_model_1_loss: 1.7380 - val_model_2_loss: 1.2866 - val_model_3_loss: 2.3359 - val_model_4_loss: 1.3837 - val_model_accuracy: 0.4145 - val_model_1_accuracy: 0.5380 - val_model_2_accuracy: 0.5430 - val_model_3_accuracy: 0.6425 - val_model_4_accuracy: 0.4820 - val_loss1: 1.5410 - val_loss2: 6.3587\n","Epoch 291/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.7765 - model_loss: 0.0015 - model_1_loss: 3.8854e-04 - model_2_loss: 2.8136e-04 - model_3_loss: 1.8893e-04 - model_4_loss: 3.2983e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5381 - loss2: 5.2356 - val_loss: 17.6606 - val_model_loss: 2.9960 - val_model_1_loss: 1.7415 - val_model_2_loss: 1.2882 - val_model_3_loss: 2.3483 - val_model_4_loss: 1.3843 - val_model_accuracy: 0.4130 - val_model_1_accuracy: 0.5395 - val_model_2_accuracy: 0.5405 - val_model_3_accuracy: 0.6425 - val_model_4_accuracy: 0.4855 - val_loss1: 1.5391 - val_loss2: 6.3633\n","Epoch 292/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8546 - model_loss: 1.8423e-04 - model_1_loss: 4.7843e-04 - model_2_loss: 1.3826e-04 - model_3_loss: 2.3325e-05 - model_4_loss: 3.4524e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.5023 - loss2: 5.3511 - val_loss: 17.6333 - val_model_loss: 2.9568 - val_model_1_loss: 1.7476 - val_model_2_loss: 1.2903 - val_model_3_loss: 2.3591 - val_model_4_loss: 1.3844 - val_model_accuracy: 0.4130 - val_model_1_accuracy: 0.5395 - val_model_2_accuracy: 0.5425 - val_model_3_accuracy: 0.6425 - val_model_4_accuracy: 0.4870 - val_loss1: 1.5350 - val_loss2: 6.3600\n","Epoch 293/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8375 - model_loss: 6.8462e-05 - model_1_loss: 4.4856e-04 - model_2_loss: 2.4059e-04 - model_3_loss: 1.7782e-05 - model_4_loss: 4.7296e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.3145 - loss2: 5.5218 - val_loss: 17.6002 - val_model_loss: 2.9070 - val_model_1_loss: 1.7552 - val_model_2_loss: 1.2929 - val_model_3_loss: 2.3739 - val_model_4_loss: 1.3864 - val_model_accuracy: 0.4125 - val_model_1_accuracy: 0.5400 - val_model_2_accuracy: 0.5430 - val_model_3_accuracy: 0.6425 - val_model_4_accuracy: 0.4880 - val_loss1: 1.5299 - val_loss2: 6.3548\n","Epoch 294/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.9929 - model_loss: 0.0064 - model_1_loss: 0.0024 - model_2_loss: 0.0022 - model_3_loss: 0.0044 - model_4_loss: 0.0046 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6339 - loss2: 5.3390 - val_loss: 17.5981 - val_model_loss: 2.8723 - val_model_1_loss: 1.7666 - val_model_2_loss: 1.2972 - val_model_3_loss: 2.3890 - val_model_4_loss: 1.3928 - val_model_accuracy: 0.4135 - val_model_1_accuracy: 0.5405 - val_model_2_accuracy: 0.5450 - val_model_3_accuracy: 0.6420 - val_model_4_accuracy: 0.4945 - val_loss1: 1.5259 - val_loss2: 6.3543\n","Epoch 295/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.7696 - model_loss: 5.6877e-05 - model_1_loss: 4.8616e-04 - model_2_loss: 1.6105e-04 - model_3_loss: 6.6926e-05 - model_4_loss: 1.2863e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4196 - loss2: 5.3491 - val_loss: 17.5651 - val_model_loss: 2.8263 - val_model_1_loss: 1.7760 - val_model_2_loss: 1.2995 - val_model_3_loss: 2.4000 - val_model_4_loss: 1.3975 - val_model_accuracy: 0.4160 - val_model_1_accuracy: 0.5410 - val_model_2_accuracy: 0.5455 - val_model_3_accuracy: 0.6430 - val_model_4_accuracy: 0.4980 - val_loss1: 1.5197 - val_loss2: 6.3461\n","Epoch 296/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.7671 - model_loss: 9.3868e-05 - model_1_loss: 3.7431e-04 - model_2_loss: 2.0681e-04 - model_3_loss: 3.2682e-05 - model_4_loss: 1.7885e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.3525 - loss2: 5.4137 - val_loss: 17.5356 - val_model_loss: 2.7902 - val_model_1_loss: 1.7831 - val_model_2_loss: 1.3013 - val_model_3_loss: 2.4092 - val_model_4_loss: 1.4026 - val_model_accuracy: 0.4175 - val_model_1_accuracy: 0.5425 - val_model_2_accuracy: 0.5470 - val_model_3_accuracy: 0.6435 - val_model_4_accuracy: 0.4990 - val_loss1: 1.5124 - val_loss2: 6.3368\n","Epoch 297/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.7780 - model_loss: 5.9300e-05 - model_1_loss: 6.3075e-04 - model_2_loss: 7.6188e-04 - model_3_loss: 2.6416e-04 - model_4_loss: 2.3381e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4240 - loss2: 5.3521 - val_loss: 17.5051 - val_model_loss: 2.7584 - val_model_1_loss: 1.7889 - val_model_2_loss: 1.3029 - val_model_3_loss: 2.4177 - val_model_4_loss: 1.4079 - val_model_accuracy: 0.4200 - val_model_1_accuracy: 0.5430 - val_model_2_accuracy: 0.5480 - val_model_3_accuracy: 0.6430 - val_model_4_accuracy: 0.5030 - val_loss1: 1.5040 - val_loss2: 6.3252\n","Epoch 298/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8480 - model_loss: 4.0211e-05 - model_1_loss: 0.0047 - model_2_loss: 0.0013 - model_3_loss: 0.0014 - model_4_loss: 0.0019 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.3523 - loss2: 5.4864 - val_loss: 17.4873 - val_model_loss: 2.7369 - val_model_1_loss: 1.8033 - val_model_2_loss: 1.3034 - val_model_3_loss: 2.4201 - val_model_4_loss: 1.4139 - val_model_accuracy: 0.4185 - val_model_1_accuracy: 0.5415 - val_model_2_accuracy: 0.5485 - val_model_3_accuracy: 0.6420 - val_model_4_accuracy: 0.5040 - val_loss1: 1.4971 - val_loss2: 6.3127\n","Epoch 299/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8762 - model_loss: 2.0453e-04 - model_1_loss: 6.1495e-04 - model_2_loss: 2.2048e-04 - model_3_loss: 8.7644e-05 - model_4_loss: 6.1390e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.6494 - loss2: 5.2251 - val_loss: 17.4407 - val_model_loss: 2.6983 - val_model_1_loss: 1.8125 - val_model_2_loss: 1.3050 - val_model_3_loss: 2.4250 - val_model_4_loss: 1.4163 - val_model_accuracy: 0.4235 - val_model_1_accuracy: 0.5395 - val_model_2_accuracy: 0.5485 - val_model_3_accuracy: 0.6420 - val_model_4_accuracy: 0.5070 - val_loss1: 1.4851 - val_loss2: 6.2985\n","Epoch 300/300\n","1/1 [==============================] - 8s 8s/step - loss: 5.8377 - model_loss: 4.1718e-04 - model_1_loss: 3.0660e-04 - model_2_loss: 3.9582e-04 - model_3_loss: 1.2955e-04 - model_4_loss: 4.3001e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 0.4648 - loss2: 5.3712 - val_loss: 17.4085 - val_model_loss: 2.6661 - val_model_1_loss: 1.8206 - val_model_2_loss: 1.3078 - val_model_3_loss: 2.4311 - val_model_4_loss: 1.4223 - val_model_accuracy: 0.4220 - val_model_1_accuracy: 0.5380 - val_model_2_accuracy: 0.5490 - val_model_3_accuracy: 0.6415 - val_model_4_accuracy: 0.5085 - val_loss1: 1.4763 - val_loss2: 6.2842\n","Epoch 00207: early stopping and save the model\n"]}],"source":["#construct joint training for the five base models\n","input_size = (100, 100, 3)\n","model0 = create_ResNet(input_shape=input_size, num_classes=2, num_filters = 64, random_seed=1)\n","model1 = create_ResNet(input_shape=input_size, num_classes=2, num_filters = 64, random_seed=2)\n","model2 = create_ResNet(input_shape=input_size, num_classes=2, num_filters = 64, random_seed=3)\n","model3 = create_ResNet(input_shape=input_size, num_classes=2, num_filters = 64, random_seed=4)\n","model4 = create_ResNet(input_shape=input_size, num_classes=2, num_filters = 64, random_seed=5)\n","allinputs = keras.Input(shape=input_size)\n","output0, feature_maps0 = model0(allinputs)\n","output1, feature_maps1 = model1(allinputs)\n","output2, feature_maps2 = model2(allinputs)\n","output3, feature_maps3 = model3(allinputs)\n","output4, feature_maps4 = model4(allinputs)\n","model_train = keras.Model(\n","    inputs=allinputs, outputs=[output0, output1, output2, output3, output4])\n","\n","#implement distance loss\n","loss1, loss2, loss = cosine_euclidean_sum_loss(x=[feature_maps0, feature_maps1, feature_maps2, feature_maps3, feature_maps4], \n","                                      cosine_weight=1, euclidean_weight=1, mask=True, max_norm=False)\n","\n","model_train.add_loss(loss)\n","model_train.add_metric(loss1, name=\"loss1\", aggregation='mean')\n","model_train.add_metric(loss2, name=\"loss2\", aggregation='mean')\n","\n","model_train.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                    loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'],\n","                    metrics=['accuracy'])\n","\n","#construct training and validation samples\n","train_sequence = KGTdata(x_train, y_train, batch_size=10, train=True)\n","validation_sequence = KGTdata(x_val, y_val, batch_size=10, train=False)\n","\n","#training \n","history = model_train.fit(\n","    train_sequence,\n","    epochs=300,\n","    validation_data=validation_sequence,\n","    #validation_steps=36,\n","    callbacks=CustomEarlyStoppingAndSave(\n","        save_path='100_samples_seed_fix.h5',\n","        patience=10))\n","frame = pd.DataFrame({\n","    'loss':\n","    history.history['loss'],\n","    'loss1':\n","    history.history['loss1'],\n","    'loss2':\n","    history.history['loss2'],\n","    'model_0_loss':\n","    history.history['model_loss'],\n","    'model_1_loss':\n","    history.history['model_1_loss'],\n","    'model_2_loss':\n","    history.history['model_2_loss'],\n","    'model_3_loss':\n","    history.history['model_3_loss'],\n","    'model_4_loss':\n","    history.history['model_4_loss'],\n","    'model_0_accuracy':\n","    history.history['model_accuracy'],\n","    'model_1_accuracy':\n","    history.history['model_1_accuracy'],\n","    'model_2_accuracy':\n","    history.history['model_2_accuracy'],\n","    'model_3_accuracy':\n","    history.history['model_3_accuracy'],\n","    'model_4_accuracy':\n","    history.history['model_4_accuracy'],\n","    'val_loss':\n","    history.history['val_loss'],\n","    'val_loss1':\n","    history.history['val_loss1'],\n","    'val_loss2':\n","    history.history['val_loss2'],\n","    'val_model_0_loss':\n","    history.history['val_model_loss'],\n","    'val_model_1_loss':\n","    history.history['val_model_1_loss'],\n","    'val_model_2_loss':\n","    history.history['val_model_2_loss'],\n","    'val_model_3_loss':\n","    history.history['val_model_3_loss'],\n","    'val_model_4_loss':\n","    history.history['val_model_4_loss'],\n","    'val_model_0_accuracy':\n","    history.history['val_model_accuracy'],\n","    'val_model_1_accuracy':\n","    history.history['val_model_1_accuracy'],\n","    'val_model_2_accuracy':\n","    history.history['val_model_2_accuracy'],\n","    'val_model_3_accuracy':\n","    history.history['val_model_3_accuracy'],\n","    'val_model_4_accuracy':\n","    history.history['val_model_4_accuracy'],\n","})\n","#frame.to_excel('table_{numsample}_samples_seed_{numseed}.xlsx'.format(numsample=100, numseed='fix'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8Q68bw0VAfd","executionInfo":{"status":"ok","timestamp":1651064144704,"user_tz":-120,"elapsed":22832,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"2fb23202-0495-4192-e599-67e31d72c8a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["408/408 [==============================] - 20s 45ms/step - loss: 17.8893 - model_loss: 3.9161 - model_1_loss: 1.0882 - model_2_loss: 1.1728 - model_3_loss: 1.6329 - model_4_loss: 1.0067 - model_accuracy: 0.5088 - model_1_accuracy: 0.5761 - model_2_accuracy: 0.5079 - model_3_accuracy: 0.5678 - model_4_accuracy: 0.4946 - loss1: 2.2163 - loss2: 6.8565\n"]}],"source":["#evaluation of the five base models\n","evaluate = model_train.evaluate(x_test,[keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test)],batch_size=10)\n","evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p79zKgdTxTgO","executionInfo":{"status":"ok","timestamp":1651064158036,"user_tz":-120,"elapsed":13334,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"850afb63-7fe8-4e50-af52-3f3292a0bcd3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5243123772102161"]},"metadata":{},"execution_count":12}],"source":["#soft voting ensemble\n","def SoftVotingEnsemble(model, x, y):\n","  data_size = x.shape[0]\n","  predictions = tf.argmax(tf.reduce_mean(model.predict(x), axis = 0),axis=1)\n","  accuracy = np.sum(\n","     predictions == y) / data_size\n","  return accuracy\n","SoftVotingEnsemble(model_train, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ML_FZOLCe79"},"outputs":[],"source":["class eCustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(eCustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_accuracy') \n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        #self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXwnG-CQCfbJ"},"outputs":[],"source":["class eKGTdata(keras.utils.Sequence):\n","    def __init__(self, data_x, data_y, batch_size, train):\n","      self.data_x = data_x\n","      self.data_y = data_y\n","      self.train = train\n","      self.batch_size = batch_size\n","\n","    def __len__(self):\n","      return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","      batch_x = self.data_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n","                            \n","      batch_y = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n","      if self.train == True:\n","          batch_x = Data_Aug(batch_x)\n","\n","      batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","      batch_y = keras.utils.to_categorical(batch_y, 2)\n","      return batch_x, batch_y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oql4eIoXC5mF","executionInfo":{"status":"ok","timestamp":1651065981581,"user_tz":-120,"elapsed":439498,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"fbfbda54-ee37-4e6f-bd51-dc464fef92c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1/1 [==============================] - 14s 14s/step - loss: 0.6486 - accuracy: 0.6667 - val_loss: 25.5015 - val_accuracy: 0.5095\n","Epoch 2/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0967 - accuracy: 1.0000 - val_loss: 28.3012 - val_accuracy: 0.5145\n","Epoch 3/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 21.4410 - val_accuracy: 0.5250\n","Epoch 4/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 17.2348 - val_accuracy: 0.5245\n","Epoch 5/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 15.8750 - val_accuracy: 0.5260\n","Epoch 6/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 14.2956 - val_accuracy: 0.5260\n","Epoch 7/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 13.1114 - val_accuracy: 0.5295\n","Epoch 8/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 12.5859 - val_accuracy: 0.5320\n","Epoch 9/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 11.3401 - val_accuracy: 0.5400\n","Epoch 10/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 10.6344 - val_accuracy: 0.5435\n","Epoch 11/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 9.7659 - val_accuracy: 0.5460\n","Epoch 12/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.1786 - accuracy: 1.0000 - val_loss: 9.4983 - val_accuracy: 0.5465\n","Epoch 13/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 8.8959 - val_accuracy: 0.5500\n","Epoch 14/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 8.3887 - val_accuracy: 0.5520\n","Epoch 15/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 7.8890 - val_accuracy: 0.5570\n","Epoch 16/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 7.6025 - val_accuracy: 0.5610\n","Epoch 17/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 7.0828 - val_accuracy: 0.5680\n","Epoch 18/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 6.6600 - val_accuracy: 0.5730\n","Epoch 19/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 6.4227 - val_accuracy: 0.5785\n","Epoch 20/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.2024 - val_accuracy: 0.5850\n","Epoch 21/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 5.9471 - val_accuracy: 0.5895\n","Epoch 22/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 5.6971 - val_accuracy: 0.5930\n","Epoch 23/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 5.5905 - val_accuracy: 0.5980\n","Epoch 24/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 5.4310 - val_accuracy: 0.6040\n","Epoch 25/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.2540 - val_accuracy: 0.6070\n","Epoch 26/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 5.1126 - val_accuracy: 0.6090\n","Epoch 27/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 4.8395 - val_accuracy: 0.6135\n","Epoch 28/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 4.7275 - val_accuracy: 0.6195\n","Epoch 29/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 4.6255 - val_accuracy: 0.6245\n","Epoch 30/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 4.4814 - val_accuracy: 0.6290\n","Epoch 31/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 4.3361 - val_accuracy: 0.6345\n","Epoch 32/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.2188 - val_accuracy: 0.6365\n","Epoch 33/50\n","1/1 [==============================] - 8s 8s/step - loss: 8.1291e-04 - accuracy: 1.0000 - val_loss: 4.1250 - val_accuracy: 0.6410\n","Epoch 34/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 4.0190 - val_accuracy: 0.6455\n","Epoch 35/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.9239 - val_accuracy: 0.6460\n","Epoch 36/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 3.8214 - val_accuracy: 0.6495\n","Epoch 37/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 3.7261 - val_accuracy: 0.6515\n","Epoch 38/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.5283 - accuracy: 0.8333 - val_loss: 3.6529 - val_accuracy: 0.6565\n","Epoch 39/50\n","1/1 [==============================] - 11s 11s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.5713 - val_accuracy: 0.6605\n","Epoch 40/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 3.4905 - val_accuracy: 0.6615\n","Epoch 41/50\n","1/1 [==============================] - 8s 8s/step - loss: 3.2977e-04 - accuracy: 1.0000 - val_loss: 3.4132 - val_accuracy: 0.6620\n","Epoch 42/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.3271 - val_accuracy: 0.6630\n","Epoch 43/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.2393 - val_accuracy: 0.6640\n","Epoch 44/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.1773 - val_accuracy: 0.6650\n","Epoch 45/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.1266 - val_accuracy: 0.6670\n","Epoch 46/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.0616 - val_accuracy: 0.6690\n","Epoch 47/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 3.0062 - val_accuracy: 0.6720\n","Epoch 48/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.1499 - accuracy: 0.8333 - val_loss: 2.9440 - val_accuracy: 0.6740\n","Epoch 49/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.8847 - val_accuracy: 0.6760\n","Epoch 50/50\n","1/1 [==============================] - 8s 8s/step - loss: 0.3169 - accuracy: 0.8333 - val_loss: 2.8484 - val_accuracy: 0.6760\n","Epoch 00049: early stopping and save the model\n","408/408 [==============================] - 18s 41ms/step - loss: 2.3938 - accuracy: 0.6827\n"]}],"source":["#feature fusion model\n","input_size = (100, 100, 3)\n","model_path = '100_samples_seed_fix.h5'\n","model = keras.models.load_model(model_path)\n","extractor_1 = keras.models.Model(inputs=model.layers[1].inputs,outputs=model.layers[1].layers[56].output)\n","extractor_2 = keras.models.Model(inputs=model.layers[2].inputs,outputs=model.layers[2].layers[56].output)\n","extractor_3 = keras.models.Model(inputs=model.layers[3].inputs,outputs=model.layers[3].layers[56].output)\n","extractor_4 = keras.models.Model(inputs=model.layers[4].inputs,outputs=model.layers[4].layers[56].output)\n","extractor_5 = keras.models.Model(inputs=model.layers[5].inputs,outputs=model.layers[5].layers[56].output)\n","extractor_1.trainable = False\n","extractor_2.trainable = False\n","extractor_3.trainable = False\n","extractor_4.trainable = False\n","extractor_5.trainable = False\n","inputs = keras.Input(shape = input_size)\n","features_1 = extractor_1(inputs, training = False)\n","features_2 = extractor_2(inputs, training = False)\n","features_3 = extractor_3(inputs, training = False)\n","features_4 = extractor_4(inputs, training = False)\n","features_5 = extractor_5(inputs, training = False)\n","\n","x = keras.layers.Concatenate(axis=-1)([features_1,features_2,features_3,features_4,features_5])\n","\n","x = keras.layers.Flatten()(x)\n","x = keras.layers.Dense(128,  name='dense_100')(x)\n","x = keras.layers.BatchNormalization()(x)\n","x = keras.layers.Activation('relu')(x)\n","x = keras.layers.Dropout(0.5)(x)\n","outputs = keras.layers.Dense(2, activation='softmax', name='dense_101')(x)\n","ensemble = keras.Model(inputs = inputs, outputs = outputs)\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","train_sequence = eKGTdata(x_train, y_train, batch_size=10, train=True)\n","validation_sequence = eKGTdata(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=50,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FH_Ry7tpC_G_","executionInfo":{"status":"ok","timestamp":1651066172182,"user_tz":-120,"elapsed":190605,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"2cb2b02f-6682-4ab3-ac28-a5237d690c08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1/1 [==============================] - 19s 19s/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.8274 - val_accuracy: 0.6700\n","Epoch 2/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.8308 - val_accuracy: 0.6635\n","Epoch 3/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.8563 - val_accuracy: 0.6510\n","Epoch 4/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.9369 - val_accuracy: 0.6395\n","Epoch 5/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.9736 - val_accuracy: 0.6375\n","Epoch 6/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.9876 - val_accuracy: 0.6315\n","Epoch 7/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.9911 - val_accuracy: 0.6275\n","Epoch 8/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 3.0106 - val_accuracy: 0.6165\n","Epoch 9/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.0285 - val_accuracy: 0.6110\n","Epoch 10/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 3.0775 - val_accuracy: 0.6045\n","Epoch 11/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.1117 - val_accuracy: 0.6000\n","Epoch 12/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 3.1410 - val_accuracy: 0.5950\n","Epoch 13/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.1869 - val_accuracy: 0.5860\n","Epoch 14/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 3.2062 - val_accuracy: 0.5805\n","Epoch 15/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.2244 - val_accuracy: 0.5745\n","Epoch 16/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 3.2444 - val_accuracy: 0.5705\n","Epoch 17/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 3.2793 - val_accuracy: 0.5635\n","Epoch 18/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 3.2919 - val_accuracy: 0.5610\n","Epoch 19/20\n","1/1 [==============================] - 8s 8s/step - loss: 7.4900e-04 - accuracy: 1.0000 - val_loss: 3.3098 - val_accuracy: 0.5565\n","Epoch 20/20\n","1/1 [==============================] - 8s 8s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.3258 - val_accuracy: 0.5520\n","Epoch 00001: early stopping and save the model\n","408/408 [==============================] - 18s 41ms/step - loss: 2.3370 - accuracy: 0.6768\n"]}],"source":["#finetuning\n","extractor_1.trainable = True\n","extractor_2.trainable = True\n","extractor_3.trainable = True\n","extractor_4.trainable = True\n","extractor_5.trainable = True\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","#train_sequence = ecifar10data(sampled_x_train, sampled_y_train, batch_size=10, train=False)\n","#validation_sequence = ecifar10data(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=20,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"y1W3vPZQppO3","executionInfo":{"status":"ok","timestamp":1651066194660,"user_tz":-120,"elapsed":22480,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"e886c3b7-7d1e-49df-f49c-4d55b173b313"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'              precision    recall  f1-score   support\\n\\n           0     0.9286    0.3953    0.5545      2072\\n           1     0.6072    0.9685    0.7464      2000\\n\\n    accuracy                         0.6768      4072\\n   macro avg     0.7679    0.6819    0.6505      4072\\nweighted avg     0.7707    0.6768    0.6488      4072\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}],"source":["#f1 score\n","predict = tf.argmax(ensemble.predict(x_test),axis=-1)\n","classification_report(y_test, predict,digits=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uglJj7xnC9Wm"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"BSDResNetEX.ipynb","provenance":[],"mount_file_id":"10lupBxfsSZqpdGO5kuLOapuRiRtAzrEf","authorship_tag":"ABX9TyPyLCGibyb4+QHwfqgXFfdQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}