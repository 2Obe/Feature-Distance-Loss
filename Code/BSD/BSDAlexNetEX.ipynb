{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1651079289707,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"},"user_tz":-120},"id":"tt00VOZ_d5dq","outputId":"062781a7-30f5-4ba6-b4e1-d8a5ecc545d6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n!unzip '/content/drive/MyDrive/KGT/KGT_validation.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/KGT_test.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/100_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/50_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/20_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/10_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/5_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/3_samples.zip' -d '/content'\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["#unzip BSD dataset\n","!unzip '/content/drive/MyDrive/KGT/KGT_validation.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/KGT_test.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/100_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/50_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/20_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/10_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/5_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/3_samples.zip' -d '/content'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlirJGkod7y0"},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","from tensorflow import keras\n","from sklearn import model_selection\n","from sklearn.metrics import classification_report\n","import imgaug.augmenters as iaa\n","import imgaug as ia\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TGGKlSyFBJn"},"outputs":[],"source":["ia.seed(1)\n","def Data_Aug(samples):\n","    randomaug = iaa.Sometimes(\n","        0.5,\n","        iaa.OneOf([\n","            iaa.Sequential([\n","                iaa.AllChannelsCLAHE(clip_limit=(1, 10)),\n","                iaa.Affine(rotate=(-5, 5))\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(translate_percent={\n","                    \"x\": (-0.2, 0.2),\n","                    \"y\": (-0.2, 0.2)\n","                }),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(rotate=(-10, 10)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.PerspectiveTransform(scale=(0, 0.15)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ])\n","        ]))\n","\n","\n","    return randomaug.augment_images(samples)\n","\n","def resize_images(imgs, hight, width):\n","    seq = iaa.Resize({\"height\": hight, \"width\": width})\n","    aug = seq.augment_images(imgs)\n","    return aug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RJ3uDY9FgNZ"},"outputs":[],"source":["#load NEU dataset\n","def load_data(dir_path, labels_dict):\n","  all_names = os.listdir(dir_path)\n","  data_x = []\n","  data_y = []\n","  for name in all_names:\n","    img = keras.preprocessing.image.load_img(os.path.join(dir_path, name), target_size=(100,100))\n","    img = keras.preprocessing.image.img_to_array(img,dtype='uint8')\n","    data_x.append(img)\n","    lab = labels_dict[name[:1]]\n","    data_y.append(lab)\n","  data_x = np.array(data_x)\n","  data_y = np.array(data_y)\n","  return data_x, data_y\n","class KGTdata(keras.utils.Sequence):\n","    def __init__(self, data_x, data_y, batch_size, train):\n","      self.data_x = data_x\n","      self.data_y = data_y\n","      self.train = train\n","      self.batch_size = batch_size\n","\n","    def __len__(self):\n","      return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","      batch_x = self.data_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n","                            \n","      batch_y = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n","      if self.train == True:\n","          batch_x = Data_Aug(batch_x)\n","\n","      batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","      batch_y = keras.utils.to_categorical(batch_y, 2)\n","      return batch_x, [batch_y, batch_y, batch_y, batch_y, batch_y]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4U_n_3bce9u4"},"outputs":[],"source":["#save the best model during training \n","class CustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(CustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_model_accuracy') + logs.get(\n","            'val_model_1_accuracy') + logs.get(\n","                'val_model_2_accuracy') \n","                #+ logs.get(\n","                 #   'val_model_3_accuracy') + logs.get('val_model_4_accuracy')\n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1BPrwTrBVE2"},"outputs":[],"source":["#Cosine&Euclidean distance loss\n","def descriptor(X, mask = False, max_norm = False):\n","  X = tf.reduce_mean(X, axis=3)\n","  if mask:\n","    mean_X = tf.reduce_mean(X, axis = [1,2], keepdims= True)\n","    X = tf.where(X > mean_X, X , tf.zeros_like(X, dtype=tf.float32))\n","  if max_norm:\n","    max_X=tf.reduce_max(X, axis = [1,2], keepdims= True)\n","    X = tf.math.divide_no_nan(X, max_X)\n","  return X \n","  \n","def compute_euclidean_sum(X, Y):\n","  L2_distance = tf.reduce_mean(tf.exp(-(X - Y)**2), axis= [1,2])\n","  return tf.reduce_mean(L2_distance)\n","\n","def compute_cosine_sum(X, Y):\n","  X = tf.reshape(X, [tf.shape(X)[0], -1])\n","  Y = tf.reshape(Y, [tf.shape(Y)[0], -1])\n","  loss = -keras.losses.cosine_similarity(X,Y,axis=-1)\n","  return tf.reduce_mean(loss)\n","\n","def cosine_euclidean_sum_loss(x, cosine_weight, euclidean_weight, mask, max_norm):\n","  descriptor0 = descriptor(x[0], mask=mask, max_norm=max_norm)\n","  descriptor1 = descriptor(x[1], mask=mask, max_norm=max_norm)\n","  descriptor2 = descriptor(x[2], mask=mask, max_norm=max_norm)\n","  descriptor3 = descriptor(x[3], mask=mask, max_norm=max_norm)\n","  descriptor4 = descriptor(x[4], mask=mask, max_norm=max_norm)\n","  cosine_sum = compute_cosine_sum(descriptor0, descriptor1)+compute_cosine_sum(descriptor0, descriptor2)+compute_cosine_sum(descriptor0, descriptor3)+compute_cosine_sum(descriptor0, descriptor4)+compute_cosine_sum(descriptor1, descriptor2)+compute_cosine_sum(descriptor1, descriptor3)+compute_cosine_sum(descriptor1, descriptor4)+compute_cosine_sum(descriptor2, descriptor3)+compute_cosine_sum(descriptor2, descriptor4)+compute_cosine_sum(descriptor3, descriptor4)\n","  euclidean_sum = compute_euclidean_sum(descriptor0, descriptor1)+compute_euclidean_sum(descriptor0, descriptor2)+compute_euclidean_sum(descriptor0, descriptor3)+compute_euclidean_sum(descriptor0, descriptor4)+compute_euclidean_sum(descriptor1, descriptor2)+compute_euclidean_sum(descriptor1, descriptor3)+compute_euclidean_sum(descriptor1, descriptor4)+compute_euclidean_sum(descriptor2, descriptor3)+compute_euclidean_sum(descriptor2, descriptor4)+compute_euclidean_sum(descriptor3, descriptor4)\n","  return cosine_sum, euclidean_sum, cosine_weight*cosine_sum+euclidean_weight*euclidean_sum  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMRptakCHOr_"},"outputs":[],"source":["#create single AlexNet model\n","def create_AlexNet(input_shape, num_classes=6, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  x = keras.layers.Conv2D(96, (3,3), strides=(2,2), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","  \n","  x = keras.layers.Conv2D(256, (3,3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x) \n","  x = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n"," \n","  x = keras.layers.Conv2D(384, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x) \n","  x = keras.layers.Conv2D(384, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x) \n","  x = keras.layers.Conv2D(256, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  feature_maps = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","  \n","  x = keras.layers.Flatten()(feature_maps)\n","  #x = keras.layers.Dense(256,activation='relu')(x)\n","  #x = keras.layers.Dropout(0.5)(x)\n","  x = keras.layers.Dense(128,activation='relu')(x)\n","  x = keras.layers.Dropout(0.5)(x)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n","  model = keras.Model(inputs=inputs, outputs=[outputs,feature_maps])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8mni5GQeq_2"},"outputs":[],"source":["#load training, validation and testing images\n","training_data_path = '100_samples'\n","validation_data_path = 'KGT_validation'\n","test_data_path = 'KGT_test'\n","labels_dict = {'N': 0, 'P': 1}\n","x_train, y_train = load_data(training_data_path, labels_dict)\n","x_val, y_val = load_data(validation_data_path, labels_dict)\n","x_test, y_test = load_data(test_data_path, labels_dict)\n","_, x_val, _, y_val = model_selection.train_test_split(\n","    x_val,\n","    y_val,\n","    test_size=2000,\n","    random_state=0,\n","    stratify=y_val)\n","x_test = x_test/255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nf634qPVt_Mq","executionInfo":{"status":"ok","timestamp":1651080065292,"user_tz":-120,"elapsed":753067,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"7f710a71-2815-4ada-ae72-9ca0376b0a8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","1/1 [==============================] - 12s 12s/step - loss: 12.4981 - model_loss: 0.8707 - model_1_loss: 1.8979 - model_2_loss: 2.2722 - model_3_loss: 2.0370 - model_4_loss: 0.5230 - model_accuracy: 0.6667 - model_1_accuracy: 0.3333 - model_2_accuracy: 0.3333 - model_3_accuracy: 0.3333 - model_4_accuracy: 0.6667 - loss1: 8.8910 - loss2: 9.0330 - val_loss: 9.6507 - val_model_loss: 0.9574 - val_model_1_loss: 0.7573 - val_model_2_loss: 1.0478 - val_model_3_loss: 0.6850 - val_model_4_loss: 1.1923 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.5035 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.5360 - val_model_4_accuracy: 0.5040 - val_loss1: 9.0505 - val_loss2: 9.7148\n","Epoch 2/300\n","1/1 [==============================] - 2s 2s/step - loss: 14.2125 - model_loss: 2.0808 - model_1_loss: 0.5366 - model_2_loss: 4.0007 - model_3_loss: 0.6924 - model_4_loss: 2.1005 - model_accuracy: 0.5000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.5000 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.6667 - loss1: 8.7228 - loss2: 8.8021 - val_loss: 9.0465 - val_model_loss: 0.8529 - val_model_1_loss: 0.9717 - val_model_2_loss: 0.7169 - val_model_3_loss: 0.7904 - val_model_4_loss: 0.7102 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4950 - val_model_3_accuracy: 0.4970 - val_model_4_accuracy: 0.5050 - val_loss1: 9.0376 - val_loss2: 9.7113\n","Epoch 3/300\n","1/1 [==============================] - 2s 2s/step - loss: 12.8516 - model_loss: 1.2315 - model_1_loss: 1.1690 - model_2_loss: 1.3305 - model_3_loss: 3.6175 - model_4_loss: 0.6062 - model_accuracy: 0.6667 - model_1_accuracy: 0.5000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.5000 - model_4_accuracy: 0.6667 - loss1: 8.8942 - loss2: 8.9953 - val_loss: 9.7515 - val_model_loss: 1.4152 - val_model_1_loss: 0.7219 - val_model_2_loss: 1.0173 - val_model_3_loss: 0.6975 - val_model_4_loss: 0.8923 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4600 - val_model_2_accuracy: 0.5040 - val_model_3_accuracy: 0.5330 - val_model_4_accuracy: 0.5040 - val_loss1: 9.0430 - val_loss2: 9.7153\n","Epoch 4/300\n","1/1 [==============================] - 3s 3s/step - loss: 9.6289 - model_loss: 1.2123 - model_1_loss: 0.6695 - model_2_loss: 1.5531 - model_3_loss: 0.8328 - model_4_loss: 0.4995 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.8333 - loss1: 8.8227 - loss2: 9.0094 - val_loss: 10.4263 - val_model_loss: 1.4115 - val_model_1_loss: 0.9584 - val_model_2_loss: 1.0330 - val_model_3_loss: 0.7103 - val_model_4_loss: 1.3037 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.5040 - val_model_3_accuracy: 0.5245 - val_model_4_accuracy: 0.5040 - val_loss1: 9.0466 - val_loss2: 9.7205\n","Epoch 5/300\n","1/1 [==============================] - 2s 2s/step - loss: 14.2263 - model_loss: 1.0355 - model_1_loss: 1.0161 - model_2_loss: 2.7735 - model_3_loss: 0.3497 - model_4_loss: 4.1900 - model_accuracy: 0.8333 - model_1_accuracy: 0.3333 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.6667 - loss1: 8.8228 - loss2: 9.0008 - val_loss: 9.6548 - val_model_loss: 1.0908 - val_model_1_loss: 1.0196 - val_model_2_loss: 0.7607 - val_model_3_loss: 0.8607 - val_model_4_loss: 0.9145 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.5040 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5040 - val_loss1: 9.0441 - val_loss2: 9.7294\n","Epoch 6/300\n","1/1 [==============================] - 2s 2s/step - loss: 7.5822 - model_loss: 1.2061 - model_1_loss: 0.4774 - model_2_loss: 0.1494 - model_3_loss: 0.0934 - model_4_loss: 0.9006 - model_accuracy: 0.5000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.6153 - loss2: 8.9526 - val_loss: 8.8610 - val_model_loss: 0.7099 - val_model_1_loss: 0.8087 - val_model_2_loss: 0.7031 - val_model_3_loss: 0.9112 - val_model_4_loss: 0.7174 - val_model_accuracy: 0.5060 - val_model_1_accuracy: 0.5045 - val_model_2_accuracy: 0.4600 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4520 - val_loss1: 9.0477 - val_loss2: 9.7385\n","Epoch 7/300\n","1/1 [==============================] - 2s 2s/step - loss: 10.1453 - model_loss: 1.5520 - model_1_loss: 0.0923 - model_2_loss: 0.4702 - model_3_loss: 0.9591 - model_4_loss: 2.2994 - model_accuracy: 0.6667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.6667 - loss1: 8.6479 - loss2: 8.9677 - val_loss: 8.6979 - val_model_loss: 0.7052 - val_model_1_loss: 0.7276 - val_model_2_loss: 0.7684 - val_model_3_loss: 0.7750 - val_model_4_loss: 0.7119 - val_model_accuracy: 0.5350 - val_model_1_accuracy: 0.4445 - val_model_2_accuracy: 0.4920 - val_model_3_accuracy: 0.4815 - val_model_4_accuracy: 0.4825 - val_loss1: 9.0449 - val_loss2: 9.7461\n","Epoch 8/300\n","1/1 [==============================] - 2s 2s/step - loss: 8.4632 - model_loss: 1.7950 - model_1_loss: 0.0375 - model_2_loss: 0.0739 - model_3_loss: 1.1217 - model_4_loss: 0.4852 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.8333 - loss1: 8.9855 - loss2: 9.1426 - val_loss: 9.0349 - val_model_loss: 0.7132 - val_model_1_loss: 0.7396 - val_model_2_loss: 0.9087 - val_model_3_loss: 0.9157 - val_model_4_loss: 0.7451 - val_model_accuracy: 0.5290 - val_model_1_accuracy: 0.4710 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4955 - val_model_4_accuracy: 0.4940 - val_loss1: 9.0499 - val_loss2: 9.7534\n","Epoch 9/300\n","1/1 [==============================] - 2s 2s/step - loss: 9.1561 - model_loss: 0.9594 - model_1_loss: 2.1927 - model_2_loss: 0.0821 - model_3_loss: 0.7841 - model_4_loss: 0.4091 - model_accuracy: 0.5000 - model_1_accuracy: 0.5000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.6667 - loss1: 8.5622 - loss2: 8.9528 - val_loss: 9.5560 - val_model_loss: 0.7240 - val_model_1_loss: 0.9494 - val_model_2_loss: 1.0449 - val_model_3_loss: 1.0985 - val_model_4_loss: 0.7206 - val_model_accuracy: 0.5095 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5045 - val_loss1: 9.0609 - val_loss2: 9.7633\n","Epoch 10/300\n","1/1 [==============================] - 2s 2s/step - loss: 6.3969 - model_loss: 0.4057 - model_1_loss: 0.5496 - model_2_loss: 0.2479 - model_3_loss: 0.1458 - model_4_loss: 0.0844 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 9.0108 - loss2: 9.1617 - val_loss: 9.9194 - val_model_loss: 0.7688 - val_model_1_loss: 1.0663 - val_model_2_loss: 1.0603 - val_model_3_loss: 1.2880 - val_model_4_loss: 0.7134 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4455 - val_loss1: 9.0680 - val_loss2: 9.7719\n","Epoch 11/300\n","1/1 [==============================] - 2s 2s/step - loss: 7.0578 - model_loss: 1.4206 - model_1_loss: 0.3864 - model_2_loss: 0.0878 - model_3_loss: 0.1490 - model_4_loss: 0.0942 - model_accuracy: 0.8333 - model_1_accuracy: 0.6667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.9268 - loss2: 9.1299 - val_loss: 10.5444 - val_model_loss: 0.9933 - val_model_1_loss: 1.3338 - val_model_2_loss: 1.0962 - val_model_3_loss: 1.3740 - val_model_4_loss: 0.7167 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4505 - val_loss1: 9.0824 - val_loss2: 9.7831\n","Epoch 12/300\n","1/1 [==============================] - 2s 2s/step - loss: 8.2101 - model_loss: 1.1035 - model_1_loss: 0.2536 - model_2_loss: 1.2642 - model_3_loss: 0.2287 - model_4_loss: 0.7297 - model_accuracy: 0.6667 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.6667 - loss1: 8.3822 - loss2: 8.7863 - val_loss: 10.8263 - val_model_loss: 1.0614 - val_model_1_loss: 1.4944 - val_model_2_loss: 1.1846 - val_model_3_loss: 1.3267 - val_model_4_loss: 0.7275 - val_model_accuracy: 0.4940 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4990 - val_loss1: 9.0844 - val_loss2: 9.7911\n","Epoch 13/300\n","1/1 [==============================] - 2s 2s/step - loss: 7.3301 - model_loss: 0.5928 - model_1_loss: 0.0061 - model_2_loss: 0.3939 - model_3_loss: 0.2481 - model_4_loss: 1.2467 - model_accuracy: 0.6667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.3333 - loss1: 8.7733 - loss2: 9.1179 - val_loss: 10.7068 - val_model_loss: 0.9468 - val_model_1_loss: 1.6083 - val_model_2_loss: 1.0356 - val_model_3_loss: 1.3259 - val_model_4_loss: 0.7612 - val_model_accuracy: 0.4835 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5035 - val_loss1: 9.0786 - val_loss2: 9.7963\n","Epoch 14/300\n","1/1 [==============================] - 2s 2s/step - loss: 6.6109 - model_loss: 0.0712 - model_1_loss: 0.0219 - model_2_loss: 0.0550 - model_3_loss: 0.3866 - model_4_loss: 1.4141 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.5000 - loss1: 8.4412 - loss2: 8.8290 - val_loss: 10.6584 - val_model_loss: 0.8973 - val_model_1_loss: 1.6755 - val_model_2_loss: 0.9548 - val_model_3_loss: 1.2716 - val_model_4_loss: 0.8308 - val_model_accuracy: 0.4760 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4955 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5075 - val_loss1: 9.0766 - val_loss2: 9.8000\n","Epoch 15/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.5380 - model_loss: 0.0720 - model_1_loss: 0.5082 - model_2_loss: 0.0451 - model_3_loss: 0.0368 - model_4_loss: 0.3558 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.1622 - loss2: 8.7799 - val_loss: 10.3755 - val_model_loss: 0.8384 - val_model_1_loss: 1.5230 - val_model_2_loss: 0.9100 - val_model_3_loss: 1.2127 - val_model_4_loss: 0.8668 - val_model_accuracy: 0.4715 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4930 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5065 - val_loss1: 9.0686 - val_loss2: 9.8054\n","Epoch 16/300\n","1/1 [==============================] - 2s 2s/step - loss: 7.8261 - model_loss: 0.2806 - model_1_loss: 0.0051 - model_2_loss: 1.2337 - model_3_loss: 0.0115 - model_4_loss: 1.4069 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.6667 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.8628 - loss2: 9.1366 - val_loss: 10.0052 - val_model_loss: 0.7819 - val_model_1_loss: 1.3822 - val_model_2_loss: 0.8361 - val_model_3_loss: 1.1488 - val_model_4_loss: 0.8349 - val_model_accuracy: 0.4460 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4825 - val_model_3_accuracy: 0.4955 - val_model_4_accuracy: 0.5005 - val_loss1: 9.0617 - val_loss2: 9.8085\n","Epoch 17/300\n","1/1 [==============================] - 2s 2s/step - loss: 7.5206 - model_loss: 0.1724 - model_1_loss: 1.2227 - model_2_loss: 0.7576 - model_3_loss: 0.3513 - model_4_loss: 0.3357 - model_accuracy: 0.8333 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 8.4801 - loss2: 8.8172 - val_loss: 9.7794 - val_model_loss: 0.7842 - val_model_1_loss: 1.3845 - val_model_2_loss: 0.7982 - val_model_3_loss: 0.9988 - val_model_4_loss: 0.7921 - val_model_accuracy: 0.4365 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4605 - val_model_3_accuracy: 0.4925 - val_model_4_accuracy: 0.5005 - val_loss1: 9.0620 - val_loss2: 9.8122\n","Epoch 18/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.9470 - model_loss: 0.2499 - model_1_loss: 0.0199 - model_2_loss: 0.4818 - model_3_loss: 0.4204 - model_4_loss: 0.0014 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.6463 - loss2: 9.0085 - val_loss: 9.7618 - val_model_loss: 0.7952 - val_model_1_loss: 1.3872 - val_model_2_loss: 0.8002 - val_model_3_loss: 0.9945 - val_model_4_loss: 0.7631 - val_model_accuracy: 0.4570 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4580 - val_model_3_accuracy: 0.4925 - val_model_4_accuracy: 0.4920 - val_loss1: 9.0615 - val_loss2: 9.8150\n","Epoch 19/300\n","1/1 [==============================] - 2s 2s/step - loss: 6.3267 - model_loss: 0.0210 - model_1_loss: 0.3335 - model_2_loss: 0.3214 - model_3_loss: 0.2317 - model_4_loss: 0.7273 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.6667 - loss1: 8.4936 - loss2: 8.9010 - val_loss: 10.1182 - val_model_loss: 0.8228 - val_model_1_loss: 1.6062 - val_model_2_loss: 0.8558 - val_model_3_loss: 1.0662 - val_model_4_loss: 0.7478 - val_model_accuracy: 0.4865 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4860 - val_model_3_accuracy: 0.4940 - val_model_4_accuracy: 0.3905 - val_loss1: 9.0570 - val_loss2: 9.8151\n","Epoch 20/300\n","1/1 [==============================] - 2s 2s/step - loss: 6.8361 - model_loss: 0.7241 - model_1_loss: 0.6919 - model_2_loss: 0.0328 - model_3_loss: 0.7947 - model_4_loss: 0.0021 - model_accuracy: 0.6667 - model_1_accuracy: 0.6667 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.6667 - model_4_accuracy: 1.0000 - loss1: 8.2964 - loss2: 8.8454 - val_loss: 10.5385 - val_model_loss: 0.9570 - val_model_1_loss: 1.5617 - val_model_2_loss: 0.9293 - val_model_3_loss: 1.2632 - val_model_4_loss: 0.8139 - val_model_accuracy: 0.4635 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4940 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4945 - val_loss1: 9.0450 - val_loss2: 9.8178\n","Epoch 21/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.9602 - model_loss: 0.0051 - model_1_loss: 4.8555e-04 - model_2_loss: 0.0084 - model_3_loss: 0.1397 - model_4_loss: 0.0900 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5367 - loss2: 8.9639 - val_loss: 11.0654 - val_model_loss: 1.1508 - val_model_1_loss: 1.5114 - val_model_2_loss: 1.0056 - val_model_3_loss: 1.4852 - val_model_4_loss: 0.9065 - val_model_accuracy: 0.4875 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4960 - val_loss1: 9.0297 - val_loss2: 9.8182\n","Epoch 22/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.0276 - model_loss: 0.0371 - model_1_loss: 0.0076 - model_2_loss: 0.0131 - model_3_loss: 0.1282 - model_4_loss: 0.1230 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.5449 - loss2: 8.9225 - val_loss: 11.5472 - val_model_loss: 1.3309 - val_model_1_loss: 1.4666 - val_model_2_loss: 1.0847 - val_model_3_loss: 1.6842 - val_model_4_loss: 0.9830 - val_model_accuracy: 0.4920 - val_model_1_accuracy: 0.4955 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4960 - val_loss1: 9.0139 - val_loss2: 9.8180\n","Epoch 23/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.9110 - model_loss: 0.0185 - model_1_loss: 0.0497 - model_2_loss: 1.3212e-04 - model_3_loss: 0.0809 - model_4_loss: 0.0982 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4396 - loss2: 8.8726 - val_loss: 11.9271 - val_model_loss: 1.4793 - val_model_1_loss: 1.4577 - val_model_2_loss: 1.1640 - val_model_3_loss: 1.8177 - val_model_4_loss: 1.0189 - val_model_accuracy: 0.4955 - val_model_1_accuracy: 0.4955 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4960 - val_loss1: 8.9974 - val_loss2: 9.8170\n","Epoch 24/300\n","1/1 [==============================] - 2s 2s/step - loss: 7.0848 - model_loss: 0.7998 - model_1_loss: 0.9898 - model_2_loss: 0.0040 - model_3_loss: 0.7676 - model_4_loss: 0.0124 - model_accuracy: 0.6667 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.6667 - model_4_accuracy: 1.0000 - loss1: 8.1501 - loss2: 8.7244 - val_loss: 11.6053 - val_model_loss: 1.3621 - val_model_1_loss: 1.1841 - val_model_2_loss: 1.2319 - val_model_3_loss: 1.8008 - val_model_4_loss: 1.0451 - val_model_accuracy: 0.4930 - val_model_1_accuracy: 0.4950 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4960 - val_loss1: 8.9805 - val_loss2: 9.8227\n","Epoch 25/300\n","1/1 [==============================] - 2s 2s/step - loss: 11.1885 - model_loss: 2.1378 - model_1_loss: 1.2641 - model_2_loss: 0.8715 - model_3_loss: 0.6185 - model_4_loss: 1.7832 - model_accuracy: 0.6667 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.6667 - loss1: 8.1530 - loss2: 8.7391 - val_loss: 10.7530 - val_model_loss: 1.1063 - val_model_1_loss: 1.0021 - val_model_2_loss: 1.1359 - val_model_3_loss: 1.6068 - val_model_4_loss: 0.9358 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4880 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4960 - val_loss1: 8.9493 - val_loss2: 9.8275\n","Epoch 26/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.6703 - model_loss: 0.0050 - model_1_loss: 0.0745 - model_2_loss: 0.0014 - model_3_loss: 0.0113 - model_4_loss: 0.0082 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2571 - loss2: 8.8287 - val_loss: 10.1517 - val_model_loss: 0.9337 - val_model_1_loss: 0.9202 - val_model_2_loss: 1.0550 - val_model_3_loss: 1.4313 - val_model_4_loss: 0.8590 - val_model_accuracy: 0.4735 - val_model_1_accuracy: 0.4775 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4960 - val_loss1: 8.9220 - val_loss2: 9.8307\n","Epoch 27/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.0618 - model_loss: 0.0100 - model_1_loss: 0.4901 - model_2_loss: 0.0154 - model_3_loss: 0.0010 - model_4_loss: 0.0512 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1197 - loss2: 8.6835 - val_loss: 9.7663 - val_model_loss: 0.8391 - val_model_1_loss: 0.9023 - val_model_2_loss: 0.9915 - val_model_3_loss: 1.2774 - val_model_4_loss: 0.8147 - val_model_accuracy: 0.4730 - val_model_1_accuracy: 0.4725 - val_model_2_accuracy: 0.4940 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4875 - val_loss1: 8.8994 - val_loss2: 9.8327\n","Epoch 28/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.4529 - model_loss: 0.1709 - model_1_loss: 0.4590 - model_2_loss: 0.0013 - model_3_loss: 0.0818 - model_4_loss: 0.0809 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4296 - loss2: 8.8827 - val_loss: 9.5631 - val_model_loss: 0.8106 - val_model_1_loss: 0.9202 - val_model_2_loss: 0.9405 - val_model_3_loss: 1.1716 - val_model_4_loss: 0.7907 - val_model_accuracy: 0.4680 - val_model_1_accuracy: 0.4800 - val_model_2_accuracy: 0.4935 - val_model_3_accuracy: 0.4950 - val_model_4_accuracy: 0.4095 - val_loss1: 8.8755 - val_loss2: 9.8343\n","Epoch 29/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.7058 - model_loss: 0.7395 - model_1_loss: 0.1052 - model_2_loss: 0.0011 - model_3_loss: 0.0435 - model_4_loss: 0.0771 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5744 - loss2: 9.0418 - val_loss: 9.4579 - val_model_loss: 0.8074 - val_model_1_loss: 0.9497 - val_model_2_loss: 0.9007 - val_model_3_loss: 1.0927 - val_model_4_loss: 0.7882 - val_model_accuracy: 0.4735 - val_model_1_accuracy: 0.4890 - val_model_2_accuracy: 0.4920 - val_model_3_accuracy: 0.4945 - val_model_4_accuracy: 0.3890 - val_loss1: 8.8549 - val_loss2: 9.8360\n","Epoch 30/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.5668 - model_loss: 0.0412 - model_1_loss: 0.1006 - model_2_loss: 0.5418 - model_3_loss: 0.0046 - model_4_loss: 0.2930 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.2792 - loss2: 8.9208 - val_loss: 9.5222 - val_model_loss: 0.8086 - val_model_1_loss: 1.0228 - val_model_2_loss: 0.9383 - val_model_3_loss: 1.0264 - val_model_4_loss: 0.8167 - val_model_accuracy: 0.4730 - val_model_1_accuracy: 0.4935 - val_model_2_accuracy: 0.4935 - val_model_3_accuracy: 0.4930 - val_model_4_accuracy: 0.4495 - val_loss1: 8.8352 - val_loss2: 9.8367\n","Epoch 31/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.7058 - model_loss: 0.0099 - model_1_loss: 0.0081 - model_2_loss: 0.0013 - model_3_loss: 0.0078 - model_4_loss: 0.0041 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4525 - loss2: 8.9661 - val_loss: 9.6168 - val_model_loss: 0.8151 - val_model_1_loss: 1.1032 - val_model_2_loss: 0.9763 - val_model_3_loss: 0.9750 - val_model_4_loss: 0.8481 - val_model_accuracy: 0.4655 - val_model_1_accuracy: 0.4935 - val_model_2_accuracy: 0.4935 - val_model_3_accuracy: 0.4920 - val_model_4_accuracy: 0.4880 - val_loss1: 8.8149 - val_loss2: 9.8369\n","Epoch 32/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.3227 - model_loss: 0.3150 - model_1_loss: 0.2005 - model_2_loss: 0.1288 - model_3_loss: 0.0224 - model_4_loss: 0.0814 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2668 - loss2: 8.8238 - val_loss: 9.7670 - val_model_loss: 0.8549 - val_model_1_loss: 1.1285 - val_model_2_loss: 1.0846 - val_model_3_loss: 0.9354 - val_model_4_loss: 0.8758 - val_model_accuracy: 0.4755 - val_model_1_accuracy: 0.4945 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4870 - val_model_4_accuracy: 0.4935 - val_loss1: 8.7917 - val_loss2: 9.8379\n","Epoch 33/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.6824 - model_loss: 0.1445 - model_1_loss: 0.1667 - model_2_loss: 0.0019 - model_3_loss: 0.0302 - model_4_loss: 0.0037 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8038 - loss2: 8.6689 - val_loss: 9.9014 - val_model_loss: 0.8756 - val_model_1_loss: 1.1582 - val_model_2_loss: 1.1980 - val_model_3_loss: 0.8901 - val_model_4_loss: 0.9036 - val_model_accuracy: 0.4700 - val_model_1_accuracy: 0.4955 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4775 - val_model_4_accuracy: 0.4955 - val_loss1: 8.7678 - val_loss2: 9.8393\n","Epoch 34/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.8628 - model_loss: 0.0404 - model_1_loss: 0.0450 - model_2_loss: 0.1685 - model_3_loss: 0.0775 - model_4_loss: 0.0515 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0764 - loss2: 8.8367 - val_loss: 9.8882 - val_model_loss: 0.8974 - val_model_1_loss: 1.1276 - val_model_2_loss: 1.2380 - val_model_3_loss: 0.8537 - val_model_4_loss: 0.9095 - val_model_accuracy: 0.4670 - val_model_1_accuracy: 0.4950 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4465 - val_model_4_accuracy: 0.4935 - val_loss1: 8.7398 - val_loss2: 9.8398\n","Epoch 35/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.0794 - model_loss: 0.0142 - model_1_loss: 0.0013 - model_2_loss: 1.1398e-04 - model_3_loss: 0.4152 - model_4_loss: 1.7915e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.4072 - loss2: 8.8956 - val_loss: 9.8664 - val_model_loss: 0.9180 - val_model_1_loss: 1.0983 - val_model_2_loss: 1.2736 - val_model_3_loss: 0.8192 - val_model_4_loss: 0.9105 - val_model_accuracy: 0.4615 - val_model_1_accuracy: 0.4940 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.3900 - val_model_4_accuracy: 0.4915 - val_loss1: 8.7100 - val_loss2: 9.8396\n","Epoch 36/300\n","1/1 [==============================] - 3s 3s/step - loss: 5.0402 - model_loss: 0.0051 - model_1_loss: 6.0108e-04 - model_2_loss: 0.0268 - model_3_loss: 0.6055 - model_4_loss: 5.5527e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.9271 - loss2: 8.7606 - val_loss: 9.8540 - val_model_loss: 0.9411 - val_model_1_loss: 1.0711 - val_model_2_loss: 1.2845 - val_model_3_loss: 0.8179 - val_model_4_loss: 0.9079 - val_model_accuracy: 0.4655 - val_model_1_accuracy: 0.4940 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.3905 - val_model_4_accuracy: 0.4865 - val_loss1: 8.6791 - val_loss2: 9.8393\n","Epoch 37/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.7142 - model_loss: 0.0897 - model_1_loss: 0.0012 - model_2_loss: 0.0025 - model_3_loss: 0.0062 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3441 - loss2: 8.8240 - val_loss: 9.8628 - val_model_loss: 0.9852 - val_model_1_loss: 1.0459 - val_model_2_loss: 1.2922 - val_model_3_loss: 0.8204 - val_model_4_loss: 0.9042 - val_model_accuracy: 0.4685 - val_model_1_accuracy: 0.4935 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.3855 - val_model_4_accuracy: 0.4775 - val_loss1: 8.6456 - val_loss2: 9.8386\n","Epoch 38/300\n","1/1 [==============================] - 2s 2s/step - loss: 7.5569 - model_loss: 0.1740 - model_1_loss: 0.8116 - model_2_loss: 0.1276 - model_3_loss: 1.9324 - model_4_loss: 3.2908e-04 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.1368 - loss2: 8.8532 - val_loss: 10.0584 - val_model_loss: 1.0171 - val_model_1_loss: 1.1928 - val_model_2_loss: 1.2627 - val_model_3_loss: 0.8854 - val_model_4_loss: 0.9016 - val_model_accuracy: 0.4715 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4355 - val_model_4_accuracy: 0.4645 - val_loss1: 8.6138 - val_loss2: 9.8387\n","Epoch 39/300\n","1/1 [==============================] - 2s 2s/step - loss: 6.4616 - model_loss: 0.3739 - model_1_loss: 0.0037 - model_2_loss: 0.7865 - model_3_loss: 0.4207 - model_4_loss: 0.4912 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 7.8993 - loss2: 8.7179 - val_loss: 10.2382 - val_model_loss: 1.0114 - val_model_1_loss: 1.3335 - val_model_2_loss: 1.1492 - val_model_3_loss: 1.0912 - val_model_4_loss: 0.8752 - val_model_accuracy: 0.4690 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4950 - val_model_3_accuracy: 0.4930 - val_model_4_accuracy: 0.4180 - val_loss1: 8.5717 - val_loss2: 9.8373\n","Epoch 40/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.7367 - model_loss: 0.0101 - model_1_loss: 0.0093 - model_2_loss: 0.0030 - model_3_loss: 0.1215 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.2908 - loss2: 8.9268 - val_loss: 10.5025 - val_model_loss: 1.0119 - val_model_1_loss: 1.4607 - val_model_2_loss: 1.0460 - val_model_3_loss: 1.3699 - val_model_4_loss: 0.8541 - val_model_accuracy: 0.4675 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4930 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3725 - val_loss1: 8.5362 - val_loss2: 9.8353\n","Epoch 41/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.3652 - model_loss: 0.0074 - model_1_loss: 0.0139 - model_2_loss: 4.9759e-04 - model_3_loss: 0.0023 - model_4_loss: 0.0026 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7992 - loss2: 8.7768 - val_loss: 10.7711 - val_model_loss: 1.0171 - val_model_1_loss: 1.5665 - val_model_2_loss: 0.9641 - val_model_3_loss: 1.6434 - val_model_4_loss: 0.8392 - val_model_accuracy: 0.4660 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4865 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3755 - val_loss1: 8.4982 - val_loss2: 9.8327\n","Epoch 42/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.0916 - model_loss: 0.1193 - model_1_loss: 0.5339 - model_2_loss: 4.5832e-05 - model_3_loss: 0.0059 - model_4_loss: 0.0711 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8538 - loss2: 8.6895 - val_loss: 10.8617 - val_model_loss: 1.0781 - val_model_1_loss: 1.4450 - val_model_2_loss: 0.9022 - val_model_3_loss: 1.8776 - val_model_4_loss: 0.8416 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4685 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.3780 - val_loss1: 8.4510 - val_loss2: 9.8314\n","Epoch 43/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.5753 - model_loss: 0.0401 - model_1_loss: 0.0092 - model_2_loss: 0.1362 - model_3_loss: 0.0034 - model_4_loss: 0.1610 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 7.5835 - loss2: 8.6734 - val_loss: 11.0532 - val_model_loss: 1.1687 - val_model_1_loss: 1.3326 - val_model_2_loss: 0.8908 - val_model_3_loss: 2.0768 - val_model_4_loss: 0.8881 - val_model_accuracy: 0.4900 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4615 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4260 - val_loss1: 8.4096 - val_loss2: 9.8298\n","Epoch 44/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.4515 - model_loss: 9.9538e-04 - model_1_loss: 0.0012 - model_2_loss: 0.0346 - model_3_loss: 6.5510e-04 - model_4_loss: 1.4978e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9499 - loss2: 8.7797 - val_loss: 11.2591 - val_model_loss: 1.2589 - val_model_1_loss: 1.2293 - val_model_2_loss: 0.8971 - val_model_3_loss: 2.2491 - val_model_4_loss: 0.9500 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4610 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4845 - val_loss1: 8.3666 - val_loss2: 9.8274\n","Epoch 45/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.2596 - model_loss: 9.7685e-04 - model_1_loss: 0.1480 - model_2_loss: 0.0233 - model_3_loss: 0.8682 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.5605 - loss2: 8.7398 - val_loss: 11.1340 - val_model_loss: 1.3464 - val_model_1_loss: 1.1140 - val_model_2_loss: 0.9147 - val_model_3_loss: 2.0891 - val_model_4_loss: 1.0156 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.4955 - val_model_2_accuracy: 0.4670 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4935 - val_loss1: 8.3253 - val_loss2: 9.8284\n","Epoch 46/300\n","1/1 [==============================] - 2s 2s/step - loss: 9.3844 - model_loss: 1.1438 - model_1_loss: 0.0285 - model_2_loss: 1.7878 - model_3_loss: 0.9568 - model_4_loss: 1.2018 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.8333 - loss1: 7.6679 - loss2: 8.6332 - val_loss: 10.9599 - val_model_loss: 1.4773 - val_model_1_loss: 1.0206 - val_model_2_loss: 0.9633 - val_model_3_loss: 1.7544 - val_model_4_loss: 1.1154 - val_model_accuracy: 0.4955 - val_model_1_accuracy: 0.4920 - val_model_2_accuracy: 0.4790 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4960 - val_loss1: 8.2750 - val_loss2: 9.8289\n","Epoch 47/300\n","1/1 [==============================] - 2s 2s/step - loss: 8.8956 - model_loss: 0.8825 - model_1_loss: 0.5959 - model_2_loss: 1.1423 - model_3_loss: 0.9618 - model_4_loss: 1.1918 - model_accuracy: 0.5000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.6667 - loss1: 7.3770 - loss2: 8.6571 - val_loss: 10.3932 - val_model_loss: 1.4001 - val_model_1_loss: 0.9583 - val_model_2_loss: 0.9725 - val_model_3_loss: 1.3284 - val_model_4_loss: 1.1326 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.4765 - val_model_2_accuracy: 0.4815 - val_model_3_accuracy: 0.4955 - val_model_4_accuracy: 0.4960 - val_loss1: 8.2195 - val_loss2: 9.8301\n","Epoch 48/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.8455 - model_loss: 0.0363 - model_1_loss: 0.7308 - model_2_loss: 0.7223 - model_3_loss: 0.0017 - model_4_loss: 4.3933e-04 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8294 - loss2: 8.7870 - val_loss: 10.1113 - val_model_loss: 1.3215 - val_model_1_loss: 1.0115 - val_model_2_loss: 1.0253 - val_model_3_loss: 1.0239 - val_model_4_loss: 1.1544 - val_model_accuracy: 0.4920 - val_model_1_accuracy: 0.4840 - val_model_2_accuracy: 0.4885 - val_model_3_accuracy: 0.4630 - val_model_4_accuracy: 0.4960 - val_loss1: 8.1667 - val_loss2: 9.8301\n","Epoch 49/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.7041 - model_loss: 0.0268 - model_1_loss: 0.0043 - model_2_loss: 0.2743 - model_3_loss: 0.0340 - model_4_loss: 0.1261 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 7.6020 - loss2: 8.7527 - val_loss: 10.1173 - val_model_loss: 1.2658 - val_model_1_loss: 1.0678 - val_model_2_loss: 1.1365 - val_model_3_loss: 0.8842 - val_model_4_loss: 1.2158 - val_model_accuracy: 0.4840 - val_model_1_accuracy: 0.4920 - val_model_2_accuracy: 0.4940 - val_model_3_accuracy: 0.3915 - val_model_4_accuracy: 0.4960 - val_loss1: 8.1118 - val_loss2: 9.8279\n","Epoch 50/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.8405 - model_loss: 0.0029 - model_1_loss: 0.0325 - model_2_loss: 0.0018 - model_3_loss: 0.6678 - model_4_loss: 0.0215 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.3667 - loss2: 8.6128 - val_loss: 10.2383 - val_model_loss: 1.2203 - val_model_1_loss: 1.1128 - val_model_2_loss: 1.2468 - val_model_3_loss: 0.8597 - val_model_4_loss: 1.2813 - val_model_accuracy: 0.4695 - val_model_1_accuracy: 0.4920 - val_model_2_accuracy: 0.4950 - val_model_3_accuracy: 0.3885 - val_model_4_accuracy: 0.4960 - val_loss1: 8.0524 - val_loss2: 9.8249\n","Epoch 51/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.3258 - model_loss: 4.4185e-04 - model_1_loss: 0.0017 - model_2_loss: 0.0086 - model_3_loss: 0.0167 - model_4_loss: 0.2937 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 7.1533 - loss2: 8.5606 - val_loss: 10.2504 - val_model_loss: 1.1828 - val_model_1_loss: 1.1556 - val_model_2_loss: 1.3483 - val_model_3_loss: 0.8432 - val_model_4_loss: 1.2329 - val_model_accuracy: 0.4540 - val_model_1_accuracy: 0.4940 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.3895 - val_model_4_accuracy: 0.4960 - val_loss1: 7.9929 - val_loss2: 9.8210\n","Epoch 52/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.6937 - model_loss: 0.0460 - model_1_loss: 0.0822 - model_2_loss: 0.3579 - model_3_loss: 0.2575 - model_4_loss: 0.1250 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 6.8197 - loss2: 8.3063 - val_loss: 10.1499 - val_model_loss: 1.1436 - val_model_1_loss: 1.2531 - val_model_2_loss: 1.3317 - val_model_3_loss: 0.8375 - val_model_4_loss: 1.1227 - val_model_accuracy: 0.4395 - val_model_1_accuracy: 0.4955 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.3915 - val_model_4_accuracy: 0.4945 - val_loss1: 7.9409 - val_loss2: 9.8168\n","Epoch 53/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.1389 - model_loss: 0.0251 - model_1_loss: 0.0045 - model_2_loss: 0.0171 - model_3_loss: 0.0028 - model_4_loss: 0.0565 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.2047 - loss2: 8.6135 - val_loss: 10.0524 - val_model_loss: 1.1007 - val_model_1_loss: 1.3431 - val_model_2_loss: 1.3112 - val_model_3_loss: 0.8323 - val_model_4_loss: 1.0263 - val_model_accuracy: 0.4440 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.3935 - val_model_4_accuracy: 0.4710 - val_loss1: 7.8963 - val_loss2: 9.8133\n","Epoch 54/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.0276 - model_loss: 0.0040 - model_1_loss: 0.0130 - model_2_loss: 0.0080 - model_3_loss: 0.0615 - model_4_loss: 0.0130 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.0040 - loss2: 8.5222 - val_loss: 9.9962 - val_model_loss: 1.0750 - val_model_1_loss: 1.4240 - val_model_2_loss: 1.2941 - val_model_3_loss: 0.8308 - val_model_4_loss: 0.9561 - val_model_accuracy: 0.4465 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4955 - val_model_3_accuracy: 0.3950 - val_model_4_accuracy: 0.4095 - val_loss1: 7.8513 - val_loss2: 9.8092\n","Epoch 55/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.0746 - model_loss: 0.0025 - model_1_loss: 0.3733 - model_2_loss: 0.6720 - model_3_loss: 0.0065 - model_4_loss: 0.0174 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.1334 - loss2: 8.7235 - val_loss: 9.7012 - val_model_loss: 1.0582 - val_model_1_loss: 1.3542 - val_model_2_loss: 1.1556 - val_model_3_loss: 0.8311 - val_model_4_loss: 0.9046 - val_model_accuracy: 0.4430 - val_model_1_accuracy: 0.4955 - val_model_2_accuracy: 0.4905 - val_model_3_accuracy: 0.3995 - val_model_4_accuracy: 0.3715 - val_loss1: 7.8139 - val_loss2: 9.8099\n","Epoch 56/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.2127 - model_loss: 0.0460 - model_1_loss: 0.3656 - model_2_loss: 0.1311 - model_3_loss: 0.7355 - model_4_loss: 0.1252 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 6.7704 - loss2: 8.4807 - val_loss: 9.3154 - val_model_loss: 1.0455 - val_model_1_loss: 1.1543 - val_model_2_loss: 0.9972 - val_model_3_loss: 0.8668 - val_model_4_loss: 0.8647 - val_model_accuracy: 0.4350 - val_model_1_accuracy: 0.4845 - val_model_2_accuracy: 0.4425 - val_model_3_accuracy: 0.4215 - val_model_4_accuracy: 0.3890 - val_loss1: 7.7926 - val_loss2: 9.8145\n","Epoch 57/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.9362 - model_loss: 0.0139 - model_1_loss: 1.1271e-04 - model_2_loss: 0.2706 - model_3_loss: 1.5320e-04 - model_4_loss: 0.0144 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.4441 - loss2: 8.3011 - val_loss: 9.0944 - val_model_loss: 1.0427 - val_model_1_loss: 1.0193 - val_model_2_loss: 0.8795 - val_model_3_loss: 0.9209 - val_model_4_loss: 0.8559 - val_model_accuracy: 0.4410 - val_model_1_accuracy: 0.4490 - val_model_2_accuracy: 0.3815 - val_model_3_accuracy: 0.4615 - val_model_4_accuracy: 0.4345 - val_loss1: 7.7707 - val_loss2: 9.8173\n","Epoch 58/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.2514 - model_loss: 0.2565 - model_1_loss: 0.0069 - model_2_loss: 0.1184 - model_3_loss: 0.0036 - model_4_loss: 0.1223 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 6.6316 - loss2: 8.5592 - val_loss: 9.0357 - val_model_loss: 1.0322 - val_model_1_loss: 0.9411 - val_model_2_loss: 0.8401 - val_model_3_loss: 0.9845 - val_model_4_loss: 0.8711 - val_model_accuracy: 0.4565 - val_model_1_accuracy: 0.4310 - val_model_2_accuracy: 0.4685 - val_model_3_accuracy: 0.4875 - val_model_4_accuracy: 0.4825 - val_loss1: 7.7517 - val_loss2: 9.8197\n","Epoch 59/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.2302 - model_loss: 0.0332 - model_1_loss: 0.0078 - model_2_loss: 0.2258 - model_3_loss: 1.2718e-04 - model_4_loss: 0.0472 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.9738 - loss2: 8.5835 - val_loss: 9.0746 - val_model_loss: 1.0357 - val_model_1_loss: 0.9111 - val_model_2_loss: 0.8404 - val_model_3_loss: 1.0512 - val_model_4_loss: 0.8904 - val_model_accuracy: 0.4660 - val_model_1_accuracy: 0.4370 - val_model_2_accuracy: 0.4940 - val_model_3_accuracy: 0.4940 - val_model_4_accuracy: 0.4960 - val_loss1: 7.7096 - val_loss2: 9.8190\n","Epoch 60/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.7877 - model_loss: 3.3304e-04 - model_1_loss: 2.1872e-04 - model_2_loss: 1.3406e-04 - model_3_loss: 0.0126 - model_4_loss: 0.0041 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.6935 - loss2: 8.4710 - val_loss: 9.1627 - val_model_loss: 1.0442 - val_model_1_loss: 0.9118 - val_model_2_loss: 0.8492 - val_model_3_loss: 1.1214 - val_model_4_loss: 0.9128 - val_model_accuracy: 0.4830 - val_model_1_accuracy: 0.4350 - val_model_2_accuracy: 0.5010 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5045 - val_loss1: 7.6646 - val_loss2: 9.8173\n","Epoch 61/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.8322 - model_loss: 0.0095 - model_1_loss: 0.0261 - model_2_loss: 0.0225 - model_3_loss: 0.0218 - model_4_loss: 0.0387 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.5776 - loss2: 8.4976 - val_loss: 9.2679 - val_model_loss: 1.0539 - val_model_1_loss: 0.9310 - val_model_2_loss: 0.8624 - val_model_3_loss: 1.1943 - val_model_4_loss: 0.9296 - val_model_accuracy: 0.4815 - val_model_1_accuracy: 0.4565 - val_model_2_accuracy: 0.5025 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5100 - val_loss1: 7.6118 - val_loss2: 9.8143\n","Epoch 62/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.9820 - model_loss: 0.0011 - model_1_loss: 1.5546e-04 - model_2_loss: 0.0699 - model_3_loss: 0.0064 - model_4_loss: 0.0384 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.8646 - loss2: 8.6742 - val_loss: 9.3813 - val_model_loss: 1.0641 - val_model_1_loss: 0.9606 - val_model_2_loss: 0.8815 - val_model_3_loss: 1.2613 - val_model_4_loss: 0.9442 - val_model_accuracy: 0.4835 - val_model_1_accuracy: 0.4670 - val_model_2_accuracy: 0.5055 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.5135 - val_loss1: 7.5582 - val_loss2: 9.8109\n","Epoch 63/300\n","1/1 [==============================] - 2s 2s/step - loss: 6.3422 - model_loss: 0.3636 - model_1_loss: 0.3504 - model_2_loss: 1.1486 - model_3_loss: 0.0861 - model_4_loss: 0.7517 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 6.4504 - loss2: 8.3349 - val_loss: 9.3066 - val_model_loss: 1.0443 - val_model_1_loss: 0.9642 - val_model_2_loss: 0.8538 - val_model_3_loss: 1.2996 - val_model_4_loss: 0.9184 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4670 - val_model_2_accuracy: 0.5025 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4990 - val_loss1: 7.4720 - val_loss2: 9.8055\n","Epoch 64/300\n","1/1 [==============================] - 2s 2s/step - loss: 8.3398 - model_loss: 0.1257 - model_1_loss: 2.3842 - model_2_loss: 0.7120 - model_3_loss: 0.4483 - model_4_loss: 0.8751 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 6.7385 - loss2: 8.5029 - val_loss: 9.1447 - val_model_loss: 1.0403 - val_model_1_loss: 0.9174 - val_model_2_loss: 0.8268 - val_model_3_loss: 1.3216 - val_model_4_loss: 0.8695 - val_model_accuracy: 0.4525 - val_model_1_accuracy: 0.4370 - val_model_2_accuracy: 0.4725 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4665 - val_loss1: 7.3584 - val_loss2: 9.7979\n","Epoch 65/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.9574 - model_loss: 0.0073 - model_1_loss: 0.0461 - model_2_loss: 0.0057 - model_3_loss: 6.4630e-04 - model_4_loss: 0.0441 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.8536 - loss2: 8.5347 - val_loss: 9.1568 - val_model_loss: 1.0727 - val_model_1_loss: 0.9228 - val_model_2_loss: 0.8399 - val_model_3_loss: 1.3372 - val_model_4_loss: 0.8655 - val_model_accuracy: 0.4485 - val_model_1_accuracy: 0.4320 - val_model_2_accuracy: 0.4100 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4075 - val_loss1: 7.2584 - val_loss2: 9.7896\n","Epoch 66/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.2833 - model_loss: 0.3464 - model_1_loss: 9.3793e-04 - model_2_loss: 0.0034 - model_3_loss: 0.0019 - model_4_loss: 0.3190 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 6.3890 - loss2: 8.3434 - val_loss: 9.4416 - val_model_loss: 1.2060 - val_model_1_loss: 0.9648 - val_model_2_loss: 0.8841 - val_model_3_loss: 1.3478 - val_model_4_loss: 0.9672 - val_model_accuracy: 0.4445 - val_model_1_accuracy: 0.4480 - val_model_2_accuracy: 0.4205 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4175 - val_loss1: 7.1654 - val_loss2: 9.7801\n","Epoch 67/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.2314 - model_loss: 0.0010 - model_1_loss: 0.5631 - model_2_loss: 0.1127 - model_3_loss: 0.0333 - model_4_loss: 5.6366e-04 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.2016 - loss2: 8.3974 - val_loss: 10.0517 - val_model_loss: 1.3907 - val_model_1_loss: 1.1587 - val_model_2_loss: 0.9476 - val_model_3_loss: 1.3591 - val_model_4_loss: 1.1587 - val_model_accuracy: 0.4565 - val_model_1_accuracy: 0.4780 - val_model_2_accuracy: 0.4545 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4925 - val_loss1: 7.0966 - val_loss2: 9.7718\n","Epoch 68/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.4874 - model_loss: 0.1720 - model_1_loss: 0.0024 - model_2_loss: 0.0086 - model_3_loss: 0.7416 - model_4_loss: 0.1804 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 5.9381 - loss2: 8.2697 - val_loss: 10.6152 - val_model_loss: 1.5085 - val_model_1_loss: 1.4643 - val_model_2_loss: 1.0230 - val_model_3_loss: 1.3082 - val_model_4_loss: 1.3046 - val_model_accuracy: 0.4775 - val_model_1_accuracy: 0.4950 - val_model_2_accuracy: 0.4810 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4960 - val_loss1: 7.0370 - val_loss2: 9.7627\n","Epoch 69/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.4764 - model_loss: 0.0091 - model_1_loss: 1.7682e-05 - model_2_loss: 0.0081 - model_3_loss: 4.4000e-04 - model_4_loss: 5.0053e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.0999 - loss2: 8.1658 - val_loss: 11.1832 - val_model_loss: 1.6047 - val_model_1_loss: 1.7972 - val_model_2_loss: 1.1008 - val_model_3_loss: 1.2562 - val_model_4_loss: 1.4471 - val_model_accuracy: 0.4880 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4935 - val_model_3_accuracy: 0.4930 - val_model_4_accuracy: 0.4960 - val_loss1: 6.9791 - val_loss2: 9.7520\n","Epoch 70/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.6113 - model_loss: 0.0080 - model_1_loss: 1.1837 - model_2_loss: 0.1646 - model_3_loss: 0.0025 - model_4_loss: 1.1399e-04 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.6945 - loss2: 8.1012 - val_loss: 11.4652 - val_model_loss: 1.6904 - val_model_1_loss: 1.8923 - val_model_2_loss: 1.1361 - val_model_3_loss: 1.2113 - val_model_4_loss: 1.5823 - val_model_accuracy: 0.4925 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4950 - val_model_3_accuracy: 0.4910 - val_model_4_accuracy: 0.4960 - val_loss1: 6.9306 - val_loss2: 9.7491\n","Epoch 71/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.4513 - model_loss: 0.0693 - model_1_loss: 0.0214 - model_2_loss: 0.0381 - model_3_loss: 3.6288e-04 - model_4_loss: 0.0089 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.8172 - loss2: 8.0940 - val_loss: 11.6031 - val_model_loss: 1.7086 - val_model_1_loss: 1.9502 - val_model_2_loss: 1.1504 - val_model_3_loss: 1.1693 - val_model_4_loss: 1.6987 - val_model_accuracy: 0.4925 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4950 - val_model_3_accuracy: 0.4880 - val_model_4_accuracy: 0.4960 - val_loss1: 6.8770 - val_loss2: 9.7454\n","Epoch 72/300\n","1/1 [==============================] - 2s 2s/step - loss: 7.4663 - model_loss: 1.3842 - model_1_loss: 1.0386 - model_2_loss: 0.8074 - model_3_loss: 0.8908 - model_4_loss: 0.2281 - model_accuracy: 0.8333 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 5.4326 - loss2: 8.0176 - val_loss: 11.1998 - val_model_loss: 1.4876 - val_model_1_loss: 1.8405 - val_model_2_loss: 1.0857 - val_model_3_loss: 1.1733 - val_model_4_loss: 1.7136 - val_model_accuracy: 0.4760 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4925 - val_model_3_accuracy: 0.4895 - val_model_4_accuracy: 0.4960 - val_loss1: 6.8236 - val_loss2: 9.7460\n","Epoch 73/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.6443 - model_loss: 0.0033 - model_1_loss: 0.1709 - model_2_loss: 0.0383 - model_3_loss: 1.1624e-04 - model_4_loss: 0.0548 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.9395 - loss2: 8.1410 - val_loss: 10.7210 - val_model_loss: 1.3124 - val_model_1_loss: 1.6480 - val_model_2_loss: 1.0196 - val_model_3_loss: 1.1743 - val_model_4_loss: 1.6965 - val_model_accuracy: 0.4430 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4770 - val_model_3_accuracy: 0.4895 - val_model_4_accuracy: 0.4960 - val_loss1: 6.7656 - val_loss2: 9.7473\n","Epoch 74/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.3158 - model_loss: 0.1148 - model_1_loss: 0.4299 - model_2_loss: 0.0113 - model_3_loss: 0.1041 - model_4_loss: 0.1624 - model_accuracy: 1.0000 - model_1_accuracy: 0.6667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 6.1577 - loss2: 8.2876 - val_loss: 10.1753 - val_model_loss: 1.2330 - val_model_1_loss: 1.3786 - val_model_2_loss: 0.9674 - val_model_3_loss: 1.1486 - val_model_4_loss: 1.6073 - val_model_accuracy: 0.4395 - val_model_1_accuracy: 0.4910 - val_model_2_accuracy: 0.4495 - val_model_3_accuracy: 0.4880 - val_model_4_accuracy: 0.4960 - val_loss1: 6.7059 - val_loss2: 9.7494\n","Epoch 75/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.2883 - model_loss: 5.7648e-04 - model_1_loss: 0.0456 - model_2_loss: 0.1066 - model_3_loss: 0.0134 - model_4_loss: 0.0142 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.4047 - loss2: 8.1120 - val_loss: 9.7162 - val_model_loss: 1.1753 - val_model_1_loss: 1.1683 - val_model_2_loss: 0.9062 - val_model_3_loss: 1.1324 - val_model_4_loss: 1.5207 - val_model_accuracy: 0.4385 - val_model_1_accuracy: 0.4835 - val_model_2_accuracy: 0.4215 - val_model_3_accuracy: 0.4875 - val_model_4_accuracy: 0.4960 - val_loss1: 6.6518 - val_loss2: 9.7506\n","Epoch 76/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.1610 - model_loss: 6.5020e-04 - model_1_loss: 0.0975 - model_2_loss: 0.0188 - model_3_loss: 0.0021 - model_4_loss: 0.0055 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.2769 - loss2: 7.9614 - val_loss: 9.3742 - val_model_loss: 1.1372 - val_model_1_loss: 1.0241 - val_model_2_loss: 0.8615 - val_model_3_loss: 1.1187 - val_model_4_loss: 1.4466 - val_model_accuracy: 0.4355 - val_model_1_accuracy: 0.4900 - val_model_2_accuracy: 0.4105 - val_model_3_accuracy: 0.4850 - val_model_4_accuracy: 0.4960 - val_loss1: 6.5973 - val_loss2: 9.7502\n","Epoch 77/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.1080 - model_loss: 0.0018 - model_1_loss: 0.0026 - model_2_loss: 4.2890e-04 - model_3_loss: 6.0479e-04 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.3897 - loss2: 8.1300 - val_loss: 9.1500 - val_model_loss: 1.1143 - val_model_1_loss: 0.9519 - val_model_2_loss: 0.8339 - val_model_3_loss: 1.1104 - val_model_4_loss: 1.3847 - val_model_accuracy: 0.4465 - val_model_1_accuracy: 0.4370 - val_model_2_accuracy: 0.4235 - val_model_3_accuracy: 0.4835 - val_model_4_accuracy: 0.4960 - val_loss1: 6.5348 - val_loss2: 9.7481\n","Epoch 78/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.1819 - model_loss: 0.0014 - model_1_loss: 0.0062 - model_2_loss: 7.4450e-04 - model_3_loss: 0.0107 - model_4_loss: 0.0067 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.4945 - loss2: 8.1770 - val_loss: 8.9827 - val_model_loss: 1.0961 - val_model_1_loss: 0.9231 - val_model_2_loss: 0.8165 - val_model_3_loss: 1.1030 - val_model_4_loss: 1.3193 - val_model_accuracy: 0.4625 - val_model_1_accuracy: 0.4430 - val_model_2_accuracy: 0.4515 - val_model_3_accuracy: 0.4830 - val_model_4_accuracy: 0.4955 - val_loss1: 6.4750 - val_loss2: 9.7451\n","Epoch 79/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.2886 - model_loss: 0.0906 - model_1_loss: 3.5384e-04 - model_2_loss: 0.0011 - model_3_loss: 0.0140 - model_4_loss: 3.0972e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.5581 - loss2: 8.0679 - val_loss: 8.8978 - val_model_loss: 1.1080 - val_model_1_loss: 0.9234 - val_model_2_loss: 0.8075 - val_model_3_loss: 1.1018 - val_model_4_loss: 1.2637 - val_model_accuracy: 0.4645 - val_model_1_accuracy: 0.4220 - val_model_2_accuracy: 0.4670 - val_model_3_accuracy: 0.4805 - val_model_4_accuracy: 0.4940 - val_loss1: 6.4128 - val_loss2: 9.7399\n","Epoch 80/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.1564 - model_loss: 0.4258 - model_1_loss: 0.0569 - model_2_loss: 0.2932 - model_3_loss: 0.1843 - model_4_loss: 0.0325 - model_accuracy: 0.6667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 5.5212 - loss2: 8.0626 - val_loss: 8.9973 - val_model_loss: 1.2064 - val_model_1_loss: 0.9406 - val_model_2_loss: 0.8090 - val_model_3_loss: 1.1445 - val_model_4_loss: 1.2394 - val_model_accuracy: 0.4405 - val_model_1_accuracy: 0.4270 - val_model_2_accuracy: 0.4690 - val_model_3_accuracy: 0.4845 - val_model_4_accuracy: 0.4920 - val_loss1: 6.3413 - val_loss2: 9.7328\n","Epoch 81/300\n","1/1 [==============================] - 3s 3s/step - loss: 6.8126 - model_loss: 0.0625 - model_1_loss: 0.7697 - model_2_loss: 1.0195 - model_3_loss: 1.4359 - model_4_loss: 0.3810 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 5.4714 - loss2: 8.1676 - val_loss: 9.3218 - val_model_loss: 1.3379 - val_model_1_loss: 0.9321 - val_model_2_loss: 0.8131 - val_model_3_loss: 1.3309 - val_model_4_loss: 1.2957 - val_model_accuracy: 0.4380 - val_model_1_accuracy: 0.4220 - val_model_2_accuracy: 0.4555 - val_model_3_accuracy: 0.4920 - val_model_4_accuracy: 0.4940 - val_loss1: 6.2523 - val_loss2: 9.7208\n","Epoch 82/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.2072 - model_loss: 0.0031 - model_1_loss: 0.0110 - model_2_loss: 0.0607 - model_3_loss: 0.0027 - model_4_loss: 5.5125e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.4589 - loss2: 7.9943 - val_loss: 9.6615 - val_model_loss: 1.4828 - val_model_1_loss: 0.9325 - val_model_2_loss: 0.8178 - val_model_3_loss: 1.5111 - val_model_4_loss: 1.3470 - val_model_accuracy: 0.4295 - val_model_1_accuracy: 0.4310 - val_model_2_accuracy: 0.4340 - val_model_3_accuracy: 0.4950 - val_model_4_accuracy: 0.4950 - val_loss1: 6.1699 - val_loss2: 9.7079\n","Epoch 83/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.8150 - model_loss: 0.2206 - model_1_loss: 0.4166 - model_2_loss: 0.2570 - model_3_loss: 0.0139 - model_4_loss: 0.0455 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.9203 - loss2: 8.0246 - val_loss: 10.0815 - val_model_loss: 1.6568 - val_model_1_loss: 0.9483 - val_model_2_loss: 0.8313 - val_model_3_loss: 1.6857 - val_model_4_loss: 1.4239 - val_model_accuracy: 0.4220 - val_model_1_accuracy: 0.4345 - val_model_2_accuracy: 0.4125 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4950 - val_loss1: 6.1017 - val_loss2: 9.6938\n","Epoch 84/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.3757 - model_loss: 0.1183 - model_1_loss: 0.0321 - model_2_loss: 0.2126 - model_3_loss: 0.0136 - model_4_loss: 3.2244e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.1807 - loss2: 8.1688 - val_loss: 10.4491 - val_model_loss: 1.7656 - val_model_1_loss: 0.9779 - val_model_2_loss: 0.8601 - val_model_3_loss: 1.8446 - val_model_4_loss: 1.4963 - val_model_accuracy: 0.4225 - val_model_1_accuracy: 0.4355 - val_model_2_accuracy: 0.4220 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4955 - val_loss1: 6.0413 - val_loss2: 9.6795\n","Epoch 85/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.7291 - model_loss: 0.0366 - model_1_loss: 0.0678 - model_2_loss: 0.0906 - model_3_loss: 0.6379 - model_4_loss: 0.1311 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.6667 - model_4_accuracy: 1.0000 - loss1: 4.7427 - loss2: 7.8749 - val_loss: 10.6167 - val_model_loss: 1.8495 - val_model_1_loss: 1.0114 - val_model_2_loss: 0.8960 - val_model_3_loss: 1.8455 - val_model_4_loss: 1.5338 - val_model_accuracy: 0.4220 - val_model_1_accuracy: 0.4370 - val_model_2_accuracy: 0.4220 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4955 - val_loss1: 5.9943 - val_loss2: 9.6683\n","Epoch 86/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.8881 - model_loss: 0.0094 - model_1_loss: 0.0337 - model_2_loss: 0.0037 - model_3_loss: 2.4412e-04 - model_4_loss: 0.1100 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.6706 - loss2: 7.9151 - val_loss: 10.7126 - val_model_loss: 1.8987 - val_model_1_loss: 1.0576 - val_model_2_loss: 0.9390 - val_model_3_loss: 1.8472 - val_model_4_loss: 1.5139 - val_model_accuracy: 0.4210 - val_model_1_accuracy: 0.4490 - val_model_2_accuracy: 0.4230 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4950 - val_loss1: 5.9468 - val_loss2: 9.6563\n","Epoch 87/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.7675 - model_loss: 0.0136 - model_1_loss: 0.0033 - model_2_loss: 0.0055 - model_3_loss: 0.0099 - model_4_loss: 0.0021 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.6983 - loss2: 7.6817 - val_loss: 10.8048 - val_model_loss: 1.9355 - val_model_1_loss: 1.1103 - val_model_2_loss: 0.9864 - val_model_3_loss: 1.8444 - val_model_4_loss: 1.4975 - val_model_accuracy: 0.4190 - val_model_1_accuracy: 0.4560 - val_model_2_accuracy: 0.4420 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4940 - val_loss1: 5.8972 - val_loss2: 9.6432\n","Epoch 88/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.1894 - model_loss: 1.3582 - model_1_loss: 0.2058 - model_2_loss: 0.0675 - model_3_loss: 0.8507 - model_4_loss: 0.0325 - model_accuracy: 0.6667 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 4.5596 - loss2: 7.8985 - val_loss: 10.4679 - val_model_loss: 1.7738 - val_model_1_loss: 1.1064 - val_model_2_loss: 1.0165 - val_model_3_loss: 1.6959 - val_model_4_loss: 1.4696 - val_model_accuracy: 0.4200 - val_model_1_accuracy: 0.4575 - val_model_2_accuracy: 0.4460 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4880 - val_loss1: 5.8478 - val_loss2: 9.6361\n","Epoch 89/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.9741 - model_loss: 1.7512 - model_1_loss: 0.0051 - model_2_loss: 0.7071 - model_3_loss: 0.0404 - model_4_loss: 0.5312 - model_accuracy: 0.6667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.6667 - loss1: 5.0836 - loss2: 7.9473 - val_loss: 9.7163 - val_model_loss: 1.4764 - val_model_1_loss: 1.1042 - val_model_2_loss: 0.9129 - val_model_3_loss: 1.5492 - val_model_4_loss: 1.2951 - val_model_accuracy: 0.4370 - val_model_1_accuracy: 0.4470 - val_model_2_accuracy: 0.4210 - val_model_3_accuracy: 0.4935 - val_model_4_accuracy: 0.4400 - val_loss1: 5.7937 - val_loss2: 9.6332\n","Epoch 90/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.4189 - model_loss: 4.5327e-04 - model_1_loss: 0.4754 - model_2_loss: 0.0451 - model_3_loss: 9.8033e-05 - model_4_loss: 1.4021e-04 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.0184 - loss2: 7.7717 - val_loss: 9.1775 - val_model_loss: 1.3276 - val_model_1_loss: 1.0697 - val_model_2_loss: 0.8424 - val_model_3_loss: 1.4198 - val_model_4_loss: 1.1626 - val_model_accuracy: 0.4835 - val_model_1_accuracy: 0.4310 - val_model_2_accuracy: 0.4200 - val_model_3_accuracy: 0.4915 - val_model_4_accuracy: 0.3805 - val_loss1: 5.7469 - val_loss2: 9.6358\n","Epoch 91/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.5941 - model_loss: 0.0022 - model_1_loss: 1.9455e-04 - model_2_loss: 8.3571e-04 - model_3_loss: 3.7588e-05 - model_4_loss: 3.4690e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.4166 - loss2: 7.6434 - val_loss: 8.8465 - val_model_loss: 1.2823 - val_model_1_loss: 1.0597 - val_model_2_loss: 0.8027 - val_model_3_loss: 1.3034 - val_model_4_loss: 1.0642 - val_model_accuracy: 0.5200 - val_model_1_accuracy: 0.4445 - val_model_2_accuracy: 0.4560 - val_model_3_accuracy: 0.4855 - val_model_4_accuracy: 0.3730 - val_loss1: 5.7047 - val_loss2: 9.6370\n","Epoch 92/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.8010 - model_loss: 0.0086 - model_1_loss: 0.1476 - model_2_loss: 0.0025 - model_3_loss: 0.0017 - model_4_loss: 2.0663e-06 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.5153 - loss2: 7.6622 - val_loss: 8.6791 - val_model_loss: 1.3017 - val_model_1_loss: 1.0784 - val_model_2_loss: 0.7840 - val_model_3_loss: 1.2045 - val_model_4_loss: 0.9980 - val_model_accuracy: 0.5415 - val_model_1_accuracy: 0.4470 - val_model_2_accuracy: 0.4925 - val_model_3_accuracy: 0.4800 - val_model_4_accuracy: 0.3870 - val_loss1: 5.6613 - val_loss2: 9.6361\n","Epoch 93/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.7077 - model_loss: 5.6050e-04 - model_1_loss: 0.0137 - model_2_loss: 0.0224 - model_3_loss: 3.7987e-05 - model_4_loss: 1.9963e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.5634 - loss2: 7.7797 - val_loss: 8.6094 - val_model_loss: 1.3502 - val_model_1_loss: 1.1135 - val_model_2_loss: 0.7794 - val_model_3_loss: 1.1203 - val_model_4_loss: 0.9569 - val_model_accuracy: 0.5460 - val_model_1_accuracy: 0.4595 - val_model_2_accuracy: 0.5055 - val_model_3_accuracy: 0.4740 - val_model_4_accuracy: 0.4265 - val_loss1: 5.6147 - val_loss2: 9.6329\n","Epoch 94/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.3706 - model_loss: 0.3972 - model_1_loss: 0.0219 - model_2_loss: 0.0243 - model_3_loss: 0.0167 - model_4_loss: 0.1005 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.8389 - loss2: 7.8119 - val_loss: 8.5678 - val_model_loss: 1.3457 - val_model_1_loss: 1.1607 - val_model_2_loss: 0.7814 - val_model_3_loss: 1.0515 - val_model_4_loss: 0.9584 - val_model_accuracy: 0.5500 - val_model_1_accuracy: 0.4775 - val_model_2_accuracy: 0.5145 - val_model_3_accuracy: 0.4695 - val_model_4_accuracy: 0.4500 - val_loss1: 5.5772 - val_loss2: 9.6278\n","Epoch 95/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.0714 - model_loss: 1.1196 - model_1_loss: 1.1317 - model_2_loss: 0.0456 - model_3_loss: 0.0544 - model_4_loss: 0.1093 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.4563 - loss2: 7.6515 - val_loss: 8.3904 - val_model_loss: 1.2400 - val_model_1_loss: 1.1600 - val_model_2_loss: 0.7842 - val_model_3_loss: 0.9837 - val_model_4_loss: 0.9684 - val_model_accuracy: 0.5490 - val_model_1_accuracy: 0.4680 - val_model_2_accuracy: 0.5180 - val_model_3_accuracy: 0.4630 - val_model_4_accuracy: 0.4600 - val_loss1: 5.5453 - val_loss2: 9.6282\n","Epoch 96/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.8949 - model_loss: 0.0021 - model_1_loss: 4.3423e-04 - model_2_loss: 0.0024 - model_3_loss: 4.3261e-04 - model_4_loss: 0.0118 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.9773 - loss2: 7.7790 - val_loss: 8.2572 - val_model_loss: 1.1564 - val_model_1_loss: 1.1638 - val_model_2_loss: 0.7869 - val_model_3_loss: 0.9305 - val_model_4_loss: 0.9816 - val_model_accuracy: 0.5445 - val_model_1_accuracy: 0.4640 - val_model_2_accuracy: 0.5200 - val_model_3_accuracy: 0.4665 - val_model_4_accuracy: 0.4705 - val_loss1: 5.5132 - val_loss2: 9.6257\n","Epoch 97/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.0435 - model_loss: 1.1505 - model_1_loss: 0.1385 - model_2_loss: 0.1052 - model_3_loss: 0.0243 - model_4_loss: 0.0406 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.3920 - loss2: 7.7671 - val_loss: 8.1484 - val_model_loss: 1.0676 - val_model_1_loss: 1.1785 - val_model_2_loss: 0.7887 - val_model_3_loss: 0.8935 - val_model_4_loss: 1.0003 - val_model_accuracy: 0.5360 - val_model_1_accuracy: 0.4595 - val_model_2_accuracy: 0.5190 - val_model_3_accuracy: 0.4635 - val_model_4_accuracy: 0.4630 - val_loss1: 5.4772 - val_loss2: 9.6230\n","Epoch 98/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.1450 - model_loss: 0.0575 - model_1_loss: 8.9387e-04 - model_2_loss: 0.1813 - model_3_loss: 0.0135 - model_4_loss: 2.8536e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.9935 - loss2: 7.8969 - val_loss: 8.1178 - val_model_loss: 1.0350 - val_model_1_loss: 1.1943 - val_model_2_loss: 0.7949 - val_model_3_loss: 0.8680 - val_model_4_loss: 1.0210 - val_model_accuracy: 0.5060 - val_model_1_accuracy: 0.4585 - val_model_2_accuracy: 0.5145 - val_model_3_accuracy: 0.4620 - val_model_4_accuracy: 0.4580 - val_loss1: 5.4474 - val_loss2: 9.6179\n","Epoch 99/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.8239 - model_loss: 0.0305 - model_1_loss: 0.6572 - model_2_loss: 0.1074 - model_3_loss: 6.0467e-04 - model_4_loss: 0.1042 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 5.0512 - loss2: 7.9713 - val_loss: 8.1593 - val_model_loss: 1.0599 - val_model_1_loss: 1.2006 - val_model_2_loss: 0.8060 - val_model_3_loss: 0.8469 - val_model_4_loss: 1.0624 - val_model_accuracy: 0.4760 - val_model_1_accuracy: 0.4555 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4720 - val_model_4_accuracy: 0.4270 - val_loss1: 5.4053 - val_loss2: 9.6146\n","Epoch 100/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.7594 - model_loss: 5.9838e-04 - model_1_loss: 8.4040e-04 - model_2_loss: 0.0426 - model_3_loss: 0.0075 - model_4_loss: 3.2225e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.6484 - loss2: 7.6751 - val_loss: 8.2922 - val_model_loss: 1.1262 - val_model_1_loss: 1.2278 - val_model_2_loss: 0.8255 - val_model_3_loss: 0.8336 - val_model_4_loss: 1.1161 - val_model_accuracy: 0.4580 - val_model_1_accuracy: 0.4460 - val_model_2_accuracy: 0.4765 - val_model_3_accuracy: 0.4900 - val_model_4_accuracy: 0.4025 - val_loss1: 5.3654 - val_loss2: 9.6086\n","Epoch 101/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.2330 - model_loss: 0.1897 - model_1_loss: 7.7993e-04 - model_2_loss: 0.0302 - model_3_loss: 0.3152 - model_4_loss: 0.0056 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 4.6122 - loss2: 7.7080 - val_loss: 8.5419 - val_model_loss: 1.2628 - val_model_1_loss: 1.2687 - val_model_2_loss: 0.8510 - val_model_3_loss: 0.8331 - val_model_4_loss: 1.1810 - val_model_accuracy: 0.4515 - val_model_1_accuracy: 0.4360 - val_model_2_accuracy: 0.4510 - val_model_3_accuracy: 0.4970 - val_model_4_accuracy: 0.3945 - val_loss1: 5.3307 - val_loss2: 9.6012\n","Epoch 102/300\n","1/1 [==============================] - 2s 2s/step - loss: 6.9784 - model_loss: 0.0582 - model_1_loss: 0.1609 - model_2_loss: 0.1027 - model_3_loss: 2.7954 - model_4_loss: 1.2506 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 4.4773 - loss2: 7.4378 - val_loss: 9.0350 - val_model_loss: 1.4304 - val_model_1_loss: 1.3620 - val_model_2_loss: 0.8987 - val_model_3_loss: 0.8576 - val_model_4_loss: 1.3433 - val_model_accuracy: 0.4455 - val_model_1_accuracy: 0.4350 - val_model_2_accuracy: 0.4360 - val_model_3_accuracy: 0.4600 - val_model_4_accuracy: 0.3910 - val_loss1: 5.3271 - val_loss2: 9.5916\n","Epoch 103/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.7137 - model_loss: 0.0107 - model_1_loss: 0.0026 - model_2_loss: 0.1668 - model_3_loss: 0.0708 - model_4_loss: 0.0096 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.1589 - loss2: 7.4728 - val_loss: 9.6044 - val_model_loss: 1.5970 - val_model_1_loss: 1.4728 - val_model_2_loss: 0.9644 - val_model_3_loss: 0.9077 - val_model_4_loss: 1.5218 - val_model_accuracy: 0.4690 - val_model_1_accuracy: 0.4365 - val_model_2_accuracy: 0.4305 - val_model_3_accuracy: 0.4625 - val_model_4_accuracy: 0.3845 - val_loss1: 5.3233 - val_loss2: 9.5804\n","Epoch 104/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.6924 - model_loss: 0.1190 - model_1_loss: 0.0095 - model_2_loss: 0.0061 - model_3_loss: 0.0061 - model_4_loss: 0.0054 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.3105 - loss2: 7.8222 - val_loss: 10.1390 - val_model_loss: 1.7199 - val_model_1_loss: 1.5833 - val_model_2_loss: 1.0402 - val_model_3_loss: 0.9660 - val_model_4_loss: 1.6949 - val_model_accuracy: 0.4765 - val_model_1_accuracy: 0.4360 - val_model_2_accuracy: 0.4250 - val_model_3_accuracy: 0.4580 - val_model_4_accuracy: 0.3960 - val_loss1: 5.3126 - val_loss2: 9.5687\n","Epoch 105/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.6117 - model_loss: 0.0221 - model_1_loss: 0.0012 - model_2_loss: 0.0084 - model_3_loss: 0.0087 - model_4_loss: 0.0043 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.3567 - loss2: 7.7717 - val_loss: 10.6679 - val_model_loss: 1.8269 - val_model_1_loss: 1.6954 - val_model_2_loss: 1.1216 - val_model_3_loss: 1.0270 - val_model_4_loss: 1.8682 - val_model_accuracy: 0.4840 - val_model_1_accuracy: 0.4450 - val_model_2_accuracy: 0.4365 - val_model_3_accuracy: 0.4645 - val_model_4_accuracy: 0.4205 - val_loss1: 5.3019 - val_loss2: 9.5559\n","Epoch 106/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.9794 - model_loss: 0.3333 - model_1_loss: 4.8186e-04 - model_2_loss: 0.0526 - model_3_loss: 2.6557e-04 - model_4_loss: 0.0085 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.4072 - loss2: 7.6136 - val_loss: 11.0870 - val_model_loss: 1.8455 - val_model_1_loss: 1.8076 - val_model_2_loss: 1.1985 - val_model_3_loss: 1.0888 - val_model_4_loss: 2.0281 - val_model_accuracy: 0.4815 - val_model_1_accuracy: 0.4565 - val_model_2_accuracy: 0.4400 - val_model_3_accuracy: 0.4705 - val_model_4_accuracy: 0.4345 - val_loss1: 5.2825 - val_loss2: 9.5416\n","Epoch 107/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.7968 - model_loss: 0.0527 - model_1_loss: 0.3260 - model_2_loss: 0.0281 - model_3_loss: 0.0081 - model_4_loss: 0.0150 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.9903 - loss2: 7.4350 - val_loss: 11.3414 - val_model_loss: 1.8446 - val_model_1_loss: 1.8034 - val_model_2_loss: 1.2665 - val_model_3_loss: 1.1502 - val_model_4_loss: 2.1814 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4565 - val_model_2_accuracy: 0.4460 - val_model_3_accuracy: 0.4790 - val_model_4_accuracy: 0.4530 - val_loss1: 5.2376 - val_loss2: 9.5278\n","Epoch 108/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.5283 - model_loss: 4.7831e-04 - model_1_loss: 0.0360 - model_2_loss: 0.0267 - model_3_loss: 2.8999e-04 - model_4_loss: 0.0221 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.1154 - loss2: 7.7008 - val_loss: 11.5087 - val_model_loss: 1.8375 - val_model_1_loss: 1.7704 - val_model_2_loss: 1.3197 - val_model_3_loss: 1.2094 - val_model_4_loss: 2.3004 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4530 - val_model_2_accuracy: 0.4510 - val_model_3_accuracy: 0.4860 - val_model_4_accuracy: 0.4635 - val_loss1: 5.1911 - val_loss2: 9.5149\n","Epoch 109/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.4836 - model_loss: 0.0065 - model_1_loss: 0.0018 - model_2_loss: 0.0070 - model_3_loss: 0.0112 - model_4_loss: 1.0193e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.1556 - loss2: 7.5840 - val_loss: 11.6552 - val_model_loss: 1.8300 - val_model_1_loss: 1.7334 - val_model_2_loss: 1.3685 - val_model_3_loss: 1.2660 - val_model_4_loss: 2.4092 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4515 - val_model_2_accuracy: 0.4585 - val_model_3_accuracy: 0.4880 - val_model_4_accuracy: 0.4690 - val_loss1: 5.1459 - val_loss2: 9.5016\n","Epoch 110/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.4213 - model_loss: 0.0050 - model_1_loss: 6.5072e-04 - model_2_loss: 0.0021 - model_3_loss: 4.9663e-05 - model_4_loss: 6.4393e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.0822 - loss2: 7.4343 - val_loss: 11.7897 - val_model_loss: 1.8206 - val_model_1_loss: 1.6971 - val_model_2_loss: 1.4151 - val_model_3_loss: 1.3178 - val_model_4_loss: 2.5158 - val_model_accuracy: 0.4780 - val_model_1_accuracy: 0.4510 - val_model_2_accuracy: 0.4580 - val_model_3_accuracy: 0.4895 - val_model_4_accuracy: 0.4760 - val_loss1: 5.0981 - val_loss2: 9.4866\n","Epoch 111/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.3455 - model_loss: 3.4920e-04 - model_1_loss: 4.1064e-05 - model_2_loss: 0.0012 - model_3_loss: 0.0066 - model_4_loss: 6.6558e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.9321 - loss2: 7.4244 - val_loss: 11.8932 - val_model_loss: 1.8066 - val_model_1_loss: 1.6601 - val_model_2_loss: 1.4575 - val_model_3_loss: 1.3601 - val_model_4_loss: 2.6124 - val_model_accuracy: 0.4780 - val_model_1_accuracy: 0.4505 - val_model_2_accuracy: 0.4585 - val_model_3_accuracy: 0.4900 - val_model_4_accuracy: 0.4800 - val_loss1: 5.0459 - val_loss2: 9.4718\n","Epoch 112/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.4539 - model_loss: 9.1183e-05 - model_1_loss: 3.0991e-04 - model_2_loss: 0.0029 - model_3_loss: 7.2772e-04 - model_4_loss: 2.9124e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.1599 - loss2: 7.3921 - val_loss: 12.0171 - val_model_loss: 1.8017 - val_model_1_loss: 1.6321 - val_model_2_loss: 1.5011 - val_model_3_loss: 1.4029 - val_model_4_loss: 2.7088 - val_model_accuracy: 0.4765 - val_model_1_accuracy: 0.4475 - val_model_2_accuracy: 0.4605 - val_model_3_accuracy: 0.4910 - val_model_4_accuracy: 0.4830 - val_loss1: 4.9957 - val_loss2: 9.4547\n","Epoch 113/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.3777 - model_loss: 0.0037 - model_1_loss: 0.0085 - model_2_loss: 0.0406 - model_3_loss: 0.0065 - model_4_loss: 0.0127 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.8690 - loss2: 7.4250 - val_loss: 12.1289 - val_model_loss: 1.7971 - val_model_1_loss: 1.6178 - val_model_2_loss: 1.5157 - val_model_3_loss: 1.4424 - val_model_4_loss: 2.8112 - val_model_accuracy: 0.4765 - val_model_1_accuracy: 0.4480 - val_model_2_accuracy: 0.4575 - val_model_3_accuracy: 0.4925 - val_model_4_accuracy: 0.4845 - val_loss1: 4.9457 - val_loss2: 9.4377\n","Epoch 114/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.4270 - model_loss: 0.0035 - model_1_loss: 0.0206 - model_2_loss: 0.0274 - model_3_loss: 7.3001e-04 - model_4_loss: 0.0064 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.9879 - loss2: 7.4875 - val_loss: 12.1709 - val_model_loss: 1.7910 - val_model_1_loss: 1.5947 - val_model_2_loss: 1.5023 - val_model_3_loss: 1.4768 - val_model_4_loss: 2.8902 - val_model_accuracy: 0.4760 - val_model_1_accuracy: 0.4470 - val_model_2_accuracy: 0.4490 - val_model_3_accuracy: 0.4935 - val_model_4_accuracy: 0.4860 - val_loss1: 4.8894 - val_loss2: 9.4210\n","Epoch 115/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.1147 - model_loss: 0.0457 - model_1_loss: 0.0023 - model_2_loss: 0.0390 - model_3_loss: 1.1191 - model_4_loss: 1.4700 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.5000 - loss1: 4.1257 - loss2: 7.5154 - val_loss: 11.2448 - val_model_loss: 1.7680 - val_model_1_loss: 1.5773 - val_model_2_loss: 1.4611 - val_model_3_loss: 1.3595 - val_model_4_loss: 2.1924 - val_model_accuracy: 0.4725 - val_model_1_accuracy: 0.4495 - val_model_2_accuracy: 0.4415 - val_model_3_accuracy: 0.4905 - val_model_4_accuracy: 0.4585 - val_loss1: 4.8305 - val_loss2: 9.4226\n","Epoch 116/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.4048 - model_loss: 0.2400 - model_1_loss: 0.0120 - model_2_loss: 0.0123 - model_3_loss: 0.0104 - model_4_loss: 4.1484e-04 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.5297 - loss2: 7.2967 - val_loss: 10.5379 - val_model_loss: 1.8071 - val_model_1_loss: 1.5593 - val_model_2_loss: 1.4252 - val_model_3_loss: 1.2550 - val_model_4_loss: 1.6315 - val_model_accuracy: 0.4765 - val_model_1_accuracy: 0.4470 - val_model_2_accuracy: 0.4375 - val_model_3_accuracy: 0.4865 - val_model_4_accuracy: 0.4070 - val_loss1: 4.7775 - val_loss2: 9.4200\n","Epoch 117/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.4308 - model_loss: 0.0186 - model_1_loss: 0.0126 - model_2_loss: 7.7858e-04 - model_3_loss: 0.0024 - model_4_loss: 3.8820e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 4.0470 - loss2: 7.4566 - val_loss: 9.9897 - val_model_loss: 1.8373 - val_model_1_loss: 1.5387 - val_model_2_loss: 1.3959 - val_model_3_loss: 1.1652 - val_model_4_loss: 1.2210 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.4495 - val_model_2_accuracy: 0.4300 - val_model_3_accuracy: 0.4810 - val_model_4_accuracy: 0.4170 - val_loss1: 4.7219 - val_loss2: 9.4130\n","Epoch 118/300\n","1/1 [==============================] - 2s 2s/step - loss: 5.2966 - model_loss: 0.1806 - model_1_loss: 0.5868 - model_2_loss: 0.9537 - model_3_loss: 0.3173 - model_4_loss: 1.0186 - model_accuracy: 0.8333 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 3.7470 - loss2: 7.3183 - val_loss: 9.7141 - val_model_loss: 1.9090 - val_model_1_loss: 1.5306 - val_model_2_loss: 1.3551 - val_model_3_loss: 1.1234 - val_model_4_loss: 0.9962 - val_model_accuracy: 0.4865 - val_model_1_accuracy: 0.4515 - val_model_2_accuracy: 0.4320 - val_model_3_accuracy: 0.4745 - val_model_4_accuracy: 0.4390 - val_loss1: 4.6593 - val_loss2: 9.4050\n","Epoch 119/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.3754 - model_loss: 6.9608e-04 - model_1_loss: 0.0119 - model_2_loss: 0.0205 - model_3_loss: 0.0093 - model_4_loss: 0.1129 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.6976 - loss2: 7.4247 - val_loss: 9.5895 - val_model_loss: 1.9788 - val_model_1_loss: 1.5169 - val_model_2_loss: 1.3528 - val_model_3_loss: 1.0903 - val_model_4_loss: 0.8808 - val_model_accuracy: 0.4900 - val_model_1_accuracy: 0.4520 - val_model_2_accuracy: 0.4345 - val_model_3_accuracy: 0.4705 - val_model_4_accuracy: 0.4760 - val_loss1: 4.6004 - val_loss2: 9.3940\n","Epoch 120/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1293 - model_loss: 0.0031 - model_1_loss: 0.0064 - model_2_loss: 0.0053 - model_3_loss: 0.0017 - model_4_loss: 0.0041 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.4894 - loss2: 7.2828 - val_loss: 9.4913 - val_model_loss: 2.0387 - val_model_1_loss: 1.4973 - val_model_2_loss: 1.3436 - val_model_3_loss: 1.0594 - val_model_4_loss: 0.8123 - val_model_accuracy: 0.4910 - val_model_1_accuracy: 0.4525 - val_model_2_accuracy: 0.4395 - val_model_3_accuracy: 0.4655 - val_model_4_accuracy: 0.5185 - val_loss1: 4.5420 - val_loss2: 9.3814\n","Epoch 121/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1555 - model_loss: 0.0087 - model_1_loss: 0.0067 - model_2_loss: 0.0064 - model_3_loss: 0.0030 - model_4_loss: 0.0037 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.5155 - loss2: 7.3847 - val_loss: 9.4302 - val_model_loss: 2.0951 - val_model_1_loss: 1.4779 - val_model_2_loss: 1.3361 - val_model_3_loss: 1.0328 - val_model_4_loss: 0.7762 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.4500 - val_model_2_accuracy: 0.4380 - val_model_3_accuracy: 0.4600 - val_model_4_accuracy: 0.5695 - val_loss1: 4.4874 - val_loss2: 9.3666\n","Epoch 122/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.5233 - model_loss: 0.0038 - model_1_loss: 0.0067 - model_2_loss: 7.8593e-04 - model_3_loss: 0.0224 - model_4_loss: 0.2748 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 3.6810 - loss2: 7.4855 - val_loss: 9.4121 - val_model_loss: 2.1476 - val_model_1_loss: 1.4643 - val_model_2_loss: 1.3303 - val_model_3_loss: 1.0185 - val_model_4_loss: 0.7659 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.4485 - val_model_2_accuracy: 0.4400 - val_model_3_accuracy: 0.4590 - val_model_4_accuracy: 0.5760 - val_loss1: 4.4357 - val_loss2: 9.3516\n","Epoch 123/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1329 - model_loss: 0.0054 - model_1_loss: 9.7761e-05 - model_2_loss: 0.0011 - model_3_loss: 0.0019 - model_4_loss: 0.0345 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.4669 - loss2: 7.1310 - val_loss: 9.3814 - val_model_loss: 2.1931 - val_model_1_loss: 1.4502 - val_model_2_loss: 1.3217 - val_model_3_loss: 1.0021 - val_model_4_loss: 0.7580 - val_model_accuracy: 0.4945 - val_model_1_accuracy: 0.4495 - val_model_2_accuracy: 0.4415 - val_model_3_accuracy: 0.4590 - val_model_4_accuracy: 0.5840 - val_loss1: 4.3790 - val_loss2: 9.3351\n","Epoch 124/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.6630 - model_loss: 0.2079 - model_1_loss: 0.0087 - model_2_loss: 0.0466 - model_3_loss: 0.0164 - model_4_loss: 0.1311 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 3.7688 - loss2: 7.3582 - val_loss: 9.2057 - val_model_loss: 2.1166 - val_model_1_loss: 1.4318 - val_model_2_loss: 1.2878 - val_model_3_loss: 0.9865 - val_model_4_loss: 0.7572 - val_model_accuracy: 0.4940 - val_model_1_accuracy: 0.4510 - val_model_2_accuracy: 0.4410 - val_model_3_accuracy: 0.4600 - val_model_4_accuracy: 0.5800 - val_loss1: 4.3199 - val_loss2: 9.3197\n","Epoch 125/300\n","1/1 [==============================] - 3s 3s/step - loss: 4.7059 - model_loss: 0.3580 - model_1_loss: 0.5264 - model_2_loss: 0.4615 - model_3_loss: 0.2627 - model_4_loss: 1.0359 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 3.3872 - loss2: 7.3561 - val_loss: 9.2348 - val_model_loss: 2.0104 - val_model_1_loss: 1.5660 - val_model_2_loss: 1.2853 - val_model_3_loss: 1.0159 - val_model_4_loss: 0.7620 - val_model_accuracy: 0.4920 - val_model_1_accuracy: 0.4610 - val_model_2_accuracy: 0.4415 - val_model_3_accuracy: 0.4650 - val_model_4_accuracy: 0.5685 - val_loss1: 4.2600 - val_loss2: 9.3030\n","Epoch 126/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.5176 - model_loss: 0.0031 - model_1_loss: 0.0024 - model_2_loss: 0.0979 - model_3_loss: 0.0072 - model_4_loss: 0.4064 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 3.2715 - loss2: 7.2971 - val_loss: 9.2881 - val_model_loss: 1.9193 - val_model_1_loss: 1.7160 - val_model_2_loss: 1.2427 - val_model_3_loss: 1.0444 - val_model_4_loss: 0.7985 - val_model_accuracy: 0.4905 - val_model_1_accuracy: 0.4730 - val_model_2_accuracy: 0.4425 - val_model_3_accuracy: 0.4660 - val_model_4_accuracy: 0.5235 - val_loss1: 4.2056 - val_loss2: 9.2869\n","Epoch 127/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.2825 - model_loss: 0.1682 - model_1_loss: 0.0071 - model_2_loss: 0.0050 - model_3_loss: 0.0085 - model_4_loss: 0.0165 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.4298 - loss2: 7.2467 - val_loss: 9.3081 - val_model_loss: 1.7879 - val_model_1_loss: 1.8592 - val_model_2_loss: 1.2000 - val_model_3_loss: 1.0684 - val_model_4_loss: 0.8488 - val_model_accuracy: 0.4865 - val_model_1_accuracy: 0.4780 - val_model_2_accuracy: 0.4390 - val_model_3_accuracy: 0.4670 - val_model_4_accuracy: 0.4870 - val_loss1: 4.1604 - val_loss2: 9.2706\n","Epoch 128/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.7632 - model_loss: 0.0592 - model_1_loss: 0.1019 - model_2_loss: 0.0944 - model_3_loss: 0.1626 - model_4_loss: 0.3355 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 3.2816 - loss2: 7.3759 - val_loss: 9.3372 - val_model_loss: 1.6626 - val_model_1_loss: 1.9308 - val_model_2_loss: 1.1789 - val_model_3_loss: 1.1215 - val_model_4_loss: 0.9275 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.4810 - val_model_2_accuracy: 0.4400 - val_model_3_accuracy: 0.4700 - val_model_4_accuracy: 0.4570 - val_loss1: 4.1066 - val_loss2: 9.2529\n","Epoch 129/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.9790 - model_loss: 0.0051 - model_1_loss: 0.0307 - model_2_loss: 0.0058 - model_3_loss: 0.0694 - model_4_loss: 0.0028 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.0133 - loss2: 7.1749 - val_loss: 9.3538 - val_model_loss: 1.5478 - val_model_1_loss: 1.9687 - val_model_2_loss: 1.1558 - val_model_3_loss: 1.1771 - val_model_4_loss: 1.0119 - val_model_accuracy: 0.4685 - val_model_1_accuracy: 0.4830 - val_model_2_accuracy: 0.4395 - val_model_3_accuracy: 0.4715 - val_model_4_accuracy: 0.4610 - val_loss1: 4.0615 - val_loss2: 9.2366\n","Epoch 130/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.2047 - model_loss: 4.1989e-04 - model_1_loss: 0.1189 - model_2_loss: 0.0297 - model_3_loss: 0.0035 - model_4_loss: 0.0297 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.3064 - loss2: 7.3829 - val_loss: 9.2096 - val_model_loss: 1.4514 - val_model_1_loss: 1.8258 - val_model_2_loss: 1.1232 - val_model_3_loss: 1.2311 - val_model_4_loss: 1.1069 - val_model_accuracy: 0.4585 - val_model_1_accuracy: 0.4770 - val_model_2_accuracy: 0.4350 - val_model_3_accuracy: 0.4740 - val_model_4_accuracy: 0.4730 - val_loss1: 4.0201 - val_loss2: 9.2235\n","Epoch 131/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.9176 - model_loss: 0.0097 - model_1_loss: 0.1277 - model_2_loss: 0.0056 - model_3_loss: 0.0793 - model_4_loss: 0.4268 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.6667 - loss1: 3.7755 - loss2: 7.6145 - val_loss: 8.9380 - val_model_loss: 1.3793 - val_model_1_loss: 1.5828 - val_model_2_loss: 1.0988 - val_model_3_loss: 1.2675 - val_model_4_loss: 1.1589 - val_model_accuracy: 0.4540 - val_model_1_accuracy: 0.4655 - val_model_2_accuracy: 0.4340 - val_model_3_accuracy: 0.4745 - val_model_4_accuracy: 0.4785 - val_loss1: 3.9805 - val_loss2: 9.2091\n","Epoch 132/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1363 - model_loss: 0.0312 - model_1_loss: 0.0157 - model_2_loss: 0.0104 - model_3_loss: 0.0188 - model_4_loss: 0.0030 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.3813 - loss2: 7.3313 - val_loss: 8.7398 - val_model_loss: 1.3281 - val_model_1_loss: 1.3943 - val_model_2_loss: 1.0801 - val_model_3_loss: 1.2994 - val_model_4_loss: 1.2066 - val_model_accuracy: 0.4525 - val_model_1_accuracy: 0.4545 - val_model_2_accuracy: 0.4335 - val_model_3_accuracy: 0.4750 - val_model_4_accuracy: 0.4810 - val_loss1: 3.9434 - val_loss2: 9.1947\n","Epoch 133/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.2871 - model_loss: 0.0015 - model_1_loss: 0.0022 - model_2_loss: 0.0351 - model_3_loss: 0.0169 - model_4_loss: 0.1622 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 3.4058 - loss2: 7.3254 - val_loss: 8.5399 - val_model_loss: 1.2800 - val_model_1_loss: 1.2604 - val_model_2_loss: 1.0555 - val_model_3_loss: 1.3209 - val_model_4_loss: 1.2095 - val_model_accuracy: 0.4515 - val_model_1_accuracy: 0.4390 - val_model_2_accuracy: 0.4280 - val_model_3_accuracy: 0.4755 - val_model_4_accuracy: 0.4795 - val_loss1: 3.9093 - val_loss2: 9.1802\n","Epoch 134/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1337 - model_loss: 0.0065 - model_1_loss: 0.1822 - model_2_loss: 0.0069 - model_3_loss: 0.0101 - model_4_loss: 0.0037 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.1481 - loss2: 7.0065 - val_loss: 8.5081 - val_model_loss: 1.2517 - val_model_1_loss: 1.2587 - val_model_2_loss: 1.0371 - val_model_3_loss: 1.3465 - val_model_4_loss: 1.2164 - val_model_accuracy: 0.4510 - val_model_1_accuracy: 0.4390 - val_model_2_accuracy: 0.4250 - val_model_3_accuracy: 0.4755 - val_model_4_accuracy: 0.4760 - val_loss1: 3.8786 - val_loss2: 9.1670\n","Epoch 135/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.0804 - model_loss: 0.0390 - model_1_loss: 0.0017 - model_2_loss: 0.0219 - model_3_loss: 0.1410 - model_4_loss: 0.0109 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 3.0025 - loss2: 7.2913 - val_loss: 8.4144 - val_model_loss: 1.2263 - val_model_1_loss: 1.2506 - val_model_2_loss: 1.0090 - val_model_3_loss: 1.3272 - val_model_4_loss: 1.2195 - val_model_accuracy: 0.4465 - val_model_1_accuracy: 0.4395 - val_model_2_accuracy: 0.4350 - val_model_3_accuracy: 0.4735 - val_model_4_accuracy: 0.4745 - val_loss1: 3.8481 - val_loss2: 9.1558\n","Epoch 136/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.0080 - model_loss: 0.0109 - model_1_loss: 0.0139 - model_2_loss: 0.0082 - model_3_loss: 4.3683e-04 - model_4_loss: 0.0068 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.2226 - loss2: 7.1309 - val_loss: 8.3645 - val_model_loss: 1.2128 - val_model_1_loss: 1.2601 - val_model_2_loss: 0.9898 - val_model_3_loss: 1.3086 - val_model_4_loss: 1.2253 - val_model_accuracy: 0.4470 - val_model_1_accuracy: 0.4435 - val_model_2_accuracy: 0.4445 - val_model_3_accuracy: 0.4730 - val_model_4_accuracy: 0.4710 - val_loss1: 3.8212 - val_loss2: 9.1426\n","Epoch 137/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.3954 - model_loss: 0.1549 - model_1_loss: 0.0841 - model_2_loss: 0.0189 - model_3_loss: 0.0094 - model_4_loss: 0.2335 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 3.0528 - loss2: 7.3644 - val_loss: 8.3200 - val_model_loss: 1.2354 - val_model_1_loss: 1.2848 - val_model_2_loss: 0.9813 - val_model_3_loss: 1.2851 - val_model_4_loss: 1.1810 - val_model_accuracy: 0.4475 - val_model_1_accuracy: 0.4505 - val_model_2_accuracy: 0.4515 - val_model_3_accuracy: 0.4725 - val_model_4_accuracy: 0.4540 - val_loss1: 3.7915 - val_loss2: 9.1322\n","Epoch 138/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.9019 - model_loss: 0.0080 - model_1_loss: 1.4542e-04 - model_2_loss: 0.0114 - model_3_loss: 0.0024 - model_4_loss: 3.4112e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.0394 - loss2: 7.1971 - val_loss: 8.2688 - val_model_loss: 1.2568 - val_model_1_loss: 1.3062 - val_model_2_loss: 0.9731 - val_model_3_loss: 1.2592 - val_model_4_loss: 1.1375 - val_model_accuracy: 0.4470 - val_model_1_accuracy: 0.4520 - val_model_2_accuracy: 0.4575 - val_model_3_accuracy: 0.4715 - val_model_4_accuracy: 0.4380 - val_loss1: 3.7598 - val_loss2: 9.1210\n","Epoch 139/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.3290 - model_loss: 0.0015 - model_1_loss: 0.4207 - model_2_loss: 0.0090 - model_3_loss: 5.3520e-05 - model_4_loss: 0.0173 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.0520 - loss2: 7.0894 - val_loss: 8.3809 - val_model_loss: 1.2783 - val_model_1_loss: 1.4741 - val_model_2_loss: 0.9705 - val_model_3_loss: 1.2332 - val_model_4_loss: 1.1035 - val_model_accuracy: 0.4470 - val_model_1_accuracy: 0.4715 - val_model_2_accuracy: 0.4600 - val_model_3_accuracy: 0.4715 - val_model_4_accuracy: 0.4230 - val_loss1: 3.7311 - val_loss2: 9.1137\n","Epoch 140/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.0652 - model_loss: 0.0057 - model_1_loss: 0.0183 - model_2_loss: 0.0822 - model_3_loss: 0.0034 - model_4_loss: 0.0920 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.0229 - loss2: 7.0418 - val_loss: 8.6876 - val_model_loss: 1.3083 - val_model_1_loss: 1.7260 - val_model_2_loss: 1.0376 - val_model_3_loss: 1.2124 - val_model_4_loss: 1.0969 - val_model_accuracy: 0.4435 - val_model_1_accuracy: 0.4815 - val_model_2_accuracy: 0.4355 - val_model_3_accuracy: 0.4755 - val_model_4_accuracy: 0.4205 - val_loss1: 3.7029 - val_loss2: 9.0993\n","Epoch 141/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1442 - model_loss: 0.0193 - model_1_loss: 0.0747 - model_2_loss: 0.0263 - model_3_loss: 0.1397 - model_4_loss: 0.0110 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 3.0165 - loss2: 7.2976 - val_loss: 9.1336 - val_model_loss: 1.3586 - val_model_1_loss: 2.0165 - val_model_2_loss: 1.1190 - val_model_3_loss: 1.2556 - val_model_4_loss: 1.0904 - val_model_accuracy: 0.4445 - val_model_1_accuracy: 0.4900 - val_model_2_accuracy: 0.4270 - val_model_3_accuracy: 0.4705 - val_model_4_accuracy: 0.4210 - val_loss1: 3.6789 - val_loss2: 9.0835\n","Epoch 142/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.9571 - model_loss: 0.0029 - model_1_loss: 0.0104 - model_2_loss: 0.0040 - model_3_loss: 0.0017 - model_4_loss: 0.0491 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.0632 - loss2: 7.1503 - val_loss: 9.5632 - val_model_loss: 1.4079 - val_model_1_loss: 2.3058 - val_model_2_loss: 1.2065 - val_model_3_loss: 1.2931 - val_model_4_loss: 1.0684 - val_model_accuracy: 0.4465 - val_model_1_accuracy: 0.4920 - val_model_2_accuracy: 0.4275 - val_model_3_accuracy: 0.4700 - val_model_4_accuracy: 0.4235 - val_loss1: 3.6565 - val_loss2: 9.0661\n","Epoch 143/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7580 - model_loss: 1.2644e-04 - model_1_loss: 0.0014 - model_2_loss: 1.3762e-04 - model_3_loss: 4.3628e-05 - model_4_loss: 0.0061 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.8021 - loss2: 6.9846 - val_loss: 9.9537 - val_model_loss: 1.4507 - val_model_1_loss: 2.5707 - val_model_2_loss: 1.2938 - val_model_3_loss: 1.3231 - val_model_4_loss: 1.0468 - val_model_accuracy: 0.4460 - val_model_1_accuracy: 0.4930 - val_model_2_accuracy: 0.4345 - val_model_3_accuracy: 0.4700 - val_model_4_accuracy: 0.4275 - val_loss1: 3.6324 - val_loss2: 9.0481\n","Epoch 144/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7394 - model_loss: 4.2093e-04 - model_1_loss: 0.0020 - model_2_loss: 0.0065 - model_3_loss: 0.0042 - model_4_loss: 0.0042 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7306 - loss2: 7.1363 - val_loss: 10.3493 - val_model_loss: 1.4998 - val_model_1_loss: 2.8210 - val_model_2_loss: 1.3844 - val_model_3_loss: 1.3559 - val_model_4_loss: 1.0320 - val_model_accuracy: 0.4470 - val_model_1_accuracy: 0.4930 - val_model_2_accuracy: 0.4420 - val_model_3_accuracy: 0.4685 - val_model_4_accuracy: 0.4330 - val_loss1: 3.6098 - val_loss2: 9.0265\n","Epoch 145/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8314 - model_loss: 0.0041 - model_1_loss: 0.0070 - model_2_loss: 0.0049 - model_3_loss: 0.0403 - model_4_loss: 0.0037 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.8063 - loss2: 7.3658 - val_loss: 10.6869 - val_model_loss: 1.5429 - val_model_1_loss: 3.0266 - val_model_2_loss: 1.4680 - val_model_3_loss: 1.3916 - val_model_4_loss: 1.0146 - val_model_accuracy: 0.4465 - val_model_1_accuracy: 0.4930 - val_model_2_accuracy: 0.4460 - val_model_3_accuracy: 0.4685 - val_model_4_accuracy: 0.4425 - val_loss1: 3.5858 - val_loss2: 9.0072\n","Epoch 146/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.1344 - model_loss: 0.0299 - model_1_loss: 1.1730 - model_2_loss: 0.0112 - model_3_loss: 0.0073 - model_4_loss: 0.0173 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.0717 - loss2: 7.1955 - val_loss: 10.3775 - val_model_loss: 1.5538 - val_model_1_loss: 2.6401 - val_model_2_loss: 1.5289 - val_model_3_loss: 1.4251 - val_model_4_loss: 1.0006 - val_model_accuracy: 0.4450 - val_model_1_accuracy: 0.4925 - val_model_2_accuracy: 0.4500 - val_model_3_accuracy: 0.4700 - val_model_4_accuracy: 0.4480 - val_loss1: 3.5567 - val_loss2: 9.0125\n","Epoch 147/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.9159 - model_loss: 0.0026 - model_1_loss: 0.0403 - model_2_loss: 8.8118e-04 - model_3_loss: 0.0242 - model_4_loss: 0.0076 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.9316 - loss2: 7.4921 - val_loss: 10.0658 - val_model_loss: 1.5644 - val_model_1_loss: 2.2535 - val_model_2_loss: 1.5909 - val_model_3_loss: 1.4513 - val_model_4_loss: 0.9913 - val_model_accuracy: 0.4445 - val_model_1_accuracy: 0.4885 - val_model_2_accuracy: 0.4555 - val_model_3_accuracy: 0.4700 - val_model_4_accuracy: 0.4585 - val_loss1: 3.5273 - val_loss2: 9.0153\n","Epoch 148/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.9982 - model_loss: 0.1061 - model_1_loss: 0.1149 - model_2_loss: 0.0166 - model_3_loss: 0.0038 - model_4_loss: 0.0196 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7526 - loss2: 7.2162 - val_loss: 9.7972 - val_model_loss: 1.6197 - val_model_1_loss: 1.9006 - val_model_2_loss: 1.6166 - val_model_3_loss: 1.4737 - val_model_4_loss: 0.9877 - val_model_accuracy: 0.4440 - val_model_1_accuracy: 0.4845 - val_model_2_accuracy: 0.4600 - val_model_3_accuracy: 0.4705 - val_model_4_accuracy: 0.4635 - val_loss1: 3.4964 - val_loss2: 9.0164\n","Epoch 149/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.9907 - model_loss: 0.0270 - model_1_loss: 0.0596 - model_2_loss: 0.0596 - model_3_loss: 9.7788e-04 - model_4_loss: 0.0920 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7716 - loss2: 7.3172 - val_loss: 9.3339 - val_model_loss: 1.6400 - val_model_1_loss: 1.5376 - val_model_2_loss: 1.5261 - val_model_3_loss: 1.4835 - val_model_4_loss: 0.9640 - val_model_accuracy: 0.4450 - val_model_1_accuracy: 0.4920 - val_model_2_accuracy: 0.4510 - val_model_3_accuracy: 0.4695 - val_model_4_accuracy: 0.4850 - val_loss1: 3.4626 - val_loss2: 9.0256\n","Epoch 150/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7157 - model_loss: 2.4060e-05 - model_1_loss: 0.0306 - model_2_loss: 7.1028e-04 - model_3_loss: 5.7419e-06 - model_4_loss: 7.7917e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.6709 - loss2: 6.9752 - val_loss: 8.9781 - val_model_loss: 1.6548 - val_model_1_loss: 1.2803 - val_model_2_loss: 1.4434 - val_model_3_loss: 1.4894 - val_model_4_loss: 0.9420 - val_model_accuracy: 0.4465 - val_model_1_accuracy: 0.5145 - val_model_2_accuracy: 0.4475 - val_model_3_accuracy: 0.4680 - val_model_4_accuracy: 0.5060 - val_loss1: 3.4333 - val_loss2: 9.0295\n","Epoch 151/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6592 - model_loss: 0.0021 - model_1_loss: 6.9462e-04 - model_2_loss: 5.6602e-05 - model_3_loss: 9.0774e-04 - model_4_loss: 1.9304e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.6198 - loss2: 6.9054 - val_loss: 8.7176 - val_model_loss: 1.6717 - val_model_1_loss: 1.0972 - val_model_2_loss: 1.3726 - val_model_3_loss: 1.4973 - val_model_4_loss: 0.9249 - val_model_accuracy: 0.4495 - val_model_1_accuracy: 0.5425 - val_model_2_accuracy: 0.4435 - val_model_3_accuracy: 0.4670 - val_model_4_accuracy: 0.5150 - val_loss1: 3.4052 - val_loss2: 9.0282\n","Epoch 152/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7267 - model_loss: 4.8035e-05 - model_1_loss: 0.0120 - model_2_loss: 2.6454e-04 - model_3_loss: 5.4292e-04 - model_4_loss: 3.6032e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7359 - loss2: 6.9098 - val_loss: 8.5203 - val_model_loss: 1.6861 - val_model_1_loss: 0.9764 - val_model_2_loss: 1.3074 - val_model_3_loss: 1.5021 - val_model_4_loss: 0.9091 - val_model_accuracy: 0.4495 - val_model_1_accuracy: 0.5695 - val_model_2_accuracy: 0.4440 - val_model_3_accuracy: 0.4680 - val_model_4_accuracy: 0.5320 - val_loss1: 3.3759 - val_loss2: 9.0236\n","Epoch 153/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1493 - model_loss: 0.0107 - model_1_loss: 0.4004 - model_2_loss: 7.4341e-04 - model_3_loss: 1.1206e-04 - model_4_loss: 0.0306 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7034 - loss2: 7.0996 - val_loss: 8.4945 - val_model_loss: 1.7190 - val_model_1_loss: 0.9794 - val_model_2_loss: 1.2522 - val_model_3_loss: 1.5092 - val_model_4_loss: 0.9076 - val_model_accuracy: 0.4480 - val_model_1_accuracy: 0.5580 - val_model_2_accuracy: 0.4415 - val_model_3_accuracy: 0.4680 - val_model_4_accuracy: 0.5345 - val_loss1: 3.3534 - val_loss2: 9.0092\n","Epoch 154/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7768 - model_loss: 2.6552e-04 - model_1_loss: 5.1574e-05 - model_2_loss: 0.0019 - model_3_loss: 8.2680e-04 - model_4_loss: 0.0052 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.8363 - loss2: 7.0076 - val_loss: 8.4755 - val_model_loss: 1.7473 - val_model_1_loss: 0.9872 - val_model_2_loss: 1.2072 - val_model_3_loss: 1.5138 - val_model_4_loss: 0.9054 - val_model_accuracy: 0.4470 - val_model_1_accuracy: 0.5470 - val_model_2_accuracy: 0.4450 - val_model_3_accuracy: 0.4675 - val_model_4_accuracy: 0.5370 - val_loss1: 3.3301 - val_loss2: 8.9926\n","Epoch 155/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.4119 - model_loss: 0.0144 - model_1_loss: 0.2172 - model_2_loss: 0.2950 - model_3_loss: 0.0067 - model_4_loss: 0.1287 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 2.7700 - loss2: 7.2969 - val_loss: 8.7260 - val_model_loss: 1.7703 - val_model_1_loss: 1.1088 - val_model_2_loss: 1.2862 - val_model_3_loss: 1.5230 - val_model_4_loss: 0.9359 - val_model_accuracy: 0.4485 - val_model_1_accuracy: 0.5340 - val_model_2_accuracy: 0.4450 - val_model_3_accuracy: 0.4685 - val_model_4_accuracy: 0.5270 - val_loss1: 3.3069 - val_loss2: 8.9690\n","Epoch 156/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7411 - model_loss: 6.2883e-04 - model_1_loss: 0.0018 - model_2_loss: 0.0033 - model_3_loss: 0.0010 - model_4_loss: 0.0076 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7437 - loss2: 7.1003 - val_loss: 8.9891 - val_model_loss: 1.7907 - val_model_1_loss: 1.2458 - val_model_2_loss: 1.3662 - val_model_3_loss: 1.5265 - val_model_4_loss: 0.9715 - val_model_accuracy: 0.4510 - val_model_1_accuracy: 0.5225 - val_model_2_accuracy: 0.4445 - val_model_3_accuracy: 0.4685 - val_model_4_accuracy: 0.5105 - val_loss1: 3.2824 - val_loss2: 8.9434\n","Epoch 157/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7471 - model_loss: 6.3273e-05 - model_1_loss: 6.2004e-05 - model_2_loss: 0.0020 - model_3_loss: 5.4893e-05 - model_4_loss: 2.8636e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7731 - loss2: 7.1615 - val_loss: 9.2370 - val_model_loss: 1.8026 - val_model_1_loss: 1.3856 - val_model_2_loss: 1.4410 - val_model_3_loss: 1.5261 - val_model_4_loss: 1.0062 - val_model_accuracy: 0.4525 - val_model_1_accuracy: 0.5120 - val_model_2_accuracy: 0.4505 - val_model_3_accuracy: 0.4680 - val_model_4_accuracy: 0.5015 - val_loss1: 3.2593 - val_loss2: 8.9187\n","Epoch 158/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8352 - model_loss: 0.0050 - model_1_loss: 2.5529e-04 - model_2_loss: 0.0050 - model_3_loss: 8.8399e-05 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.9379 - loss2: 7.0933 - val_loss: 9.4943 - val_model_loss: 1.8122 - val_model_1_loss: 1.5336 - val_model_2_loss: 1.5154 - val_model_3_loss: 1.5274 - val_model_4_loss: 1.0420 - val_model_accuracy: 0.4525 - val_model_1_accuracy: 0.5075 - val_model_2_accuracy: 0.4575 - val_model_3_accuracy: 0.4685 - val_model_4_accuracy: 0.4955 - val_loss1: 3.2385 - val_loss2: 8.8903\n","Epoch 159/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5081 - model_loss: 0.0034 - model_1_loss: 1.4540e-04 - model_2_loss: 7.4915e-05 - model_3_loss: 9.5383e-05 - model_4_loss: 8.4792e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3147 - loss2: 6.9227 - val_loss: 9.7146 - val_model_loss: 1.8155 - val_model_1_loss: 1.6734 - val_model_2_loss: 1.5800 - val_model_3_loss: 1.5222 - val_model_4_loss: 1.0727 - val_model_accuracy: 0.4525 - val_model_1_accuracy: 0.5055 - val_model_2_accuracy: 0.4610 - val_model_3_accuracy: 0.4685 - val_model_4_accuracy: 0.4935 - val_loss1: 3.2155 - val_loss2: 8.8635\n","Epoch 160/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8727 - model_loss: 0.0028 - model_1_loss: 1.9684e-04 - model_2_loss: 0.0093 - model_3_loss: 5.8843e-05 - model_4_loss: 1.2707e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.0194 - loss2: 7.0107 - val_loss: 9.9455 - val_model_loss: 1.8231 - val_model_1_loss: 1.8164 - val_model_2_loss: 1.6363 - val_model_3_loss: 1.5228 - val_model_4_loss: 1.1085 - val_model_accuracy: 0.4510 - val_model_1_accuracy: 0.5005 - val_model_2_accuracy: 0.4630 - val_model_3_accuracy: 0.4700 - val_model_4_accuracy: 0.4880 - val_loss1: 3.1934 - val_loss2: 8.8335\n","Epoch 161/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4906 - model_loss: 0.0047 - model_1_loss: 0.0012 - model_2_loss: 8.3637e-04 - model_3_loss: 0.0011 - model_4_loss: 0.0022 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2937 - loss2: 6.6755 - val_loss: 10.1376 - val_model_loss: 1.8175 - val_model_1_loss: 1.9504 - val_model_2_loss: 1.6848 - val_model_3_loss: 1.5194 - val_model_4_loss: 1.1394 - val_model_accuracy: 0.4515 - val_model_1_accuracy: 0.4950 - val_model_2_accuracy: 0.4670 - val_model_3_accuracy: 0.4705 - val_model_4_accuracy: 0.4880 - val_loss1: 3.1719 - val_loss2: 8.8041\n","Epoch 162/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6181 - model_loss: 0.0027 - model_1_loss: 0.0118 - model_2_loss: 0.0406 - model_3_loss: 2.6539e-04 - model_4_loss: 7.0188e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4221 - loss2: 7.0208 - val_loss: 10.2603 - val_model_loss: 1.8146 - val_model_1_loss: 2.0582 - val_model_2_loss: 1.6777 - val_model_3_loss: 1.5235 - val_model_4_loss: 1.1728 - val_model_accuracy: 0.4515 - val_model_1_accuracy: 0.4930 - val_model_2_accuracy: 0.4640 - val_model_3_accuracy: 0.4720 - val_model_4_accuracy: 0.4855 - val_loss1: 3.1495 - val_loss2: 8.7763\n","Epoch 163/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4664 - model_loss: 0.0042 - model_1_loss: 0.0229 - model_2_loss: 8.0428e-05 - model_3_loss: 4.3620e-04 - model_4_loss: 3.1278e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2228 - loss2: 6.5406 - val_loss: 10.3050 - val_model_loss: 1.8034 - val_model_1_loss: 2.1321 - val_model_2_loss: 1.6583 - val_model_3_loss: 1.5151 - val_model_4_loss: 1.1949 - val_model_accuracy: 0.4505 - val_model_1_accuracy: 0.4935 - val_model_2_accuracy: 0.4635 - val_model_3_accuracy: 0.4735 - val_model_4_accuracy: 0.4850 - val_loss1: 3.1271 - val_loss2: 8.7514\n","Epoch 164/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4593 - model_loss: 5.3581e-04 - model_1_loss: 2.2386e-04 - model_2_loss: 3.6297e-05 - model_3_loss: 5.5384e-05 - model_4_loss: 3.8627e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2547 - loss2: 6.6145 - val_loss: 10.3529 - val_model_loss: 1.7965 - val_model_1_loss: 2.2023 - val_model_2_loss: 1.6404 - val_model_3_loss: 1.5091 - val_model_4_loss: 1.2162 - val_model_accuracy: 0.4495 - val_model_1_accuracy: 0.4920 - val_model_2_accuracy: 0.4630 - val_model_3_accuracy: 0.4770 - val_model_4_accuracy: 0.4825 - val_loss1: 3.1042 - val_loss2: 8.7262\n","Epoch 165/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8188 - model_loss: 0.0434 - model_1_loss: 0.0013 - model_2_loss: 1.4775e-04 - model_3_loss: 0.0014 - model_4_loss: 8.5489e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.8526 - loss2: 6.9066 - val_loss: 10.3424 - val_model_loss: 1.7197 - val_model_1_loss: 2.2714 - val_model_2_loss: 1.6280 - val_model_3_loss: 1.5066 - val_model_4_loss: 1.2387 - val_model_accuracy: 0.4520 - val_model_1_accuracy: 0.4915 - val_model_2_accuracy: 0.4625 - val_model_3_accuracy: 0.4780 - val_model_4_accuracy: 0.4830 - val_loss1: 3.0858 - val_loss2: 8.6995\n","Epoch 166/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6608 - model_loss: 0.0336 - model_1_loss: 0.0185 - model_2_loss: 0.0212 - model_3_loss: 0.0025 - model_4_loss: 0.0320 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3986 - loss2: 7.0703 - val_loss: 10.2808 - val_model_loss: 1.6659 - val_model_1_loss: 2.3064 - val_model_2_loss: 1.5914 - val_model_3_loss: 1.5037 - val_model_4_loss: 1.2463 - val_model_accuracy: 0.4505 - val_model_1_accuracy: 0.4910 - val_model_2_accuracy: 0.4595 - val_model_3_accuracy: 0.4780 - val_model_4_accuracy: 0.4850 - val_loss1: 3.0664 - val_loss2: 8.6756\n","Epoch 167/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.9361 - model_loss: 0.0926 - model_1_loss: 0.0814 - model_2_loss: 0.3687 - model_3_loss: 0.0015 - model_4_loss: 0.0084 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1120 - loss2: 6.5504 - val_loss: 10.5076 - val_model_loss: 1.7696 - val_model_1_loss: 2.1855 - val_model_2_loss: 1.8351 - val_model_3_loss: 1.5002 - val_model_4_loss: 1.2560 - val_model_accuracy: 0.4495 - val_model_1_accuracy: 0.4945 - val_model_2_accuracy: 0.4720 - val_model_3_accuracy: 0.4780 - val_model_4_accuracy: 0.4850 - val_loss1: 3.0564 - val_loss2: 8.6605\n","Epoch 168/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4238 - model_loss: 3.5821e-05 - model_1_loss: 1.6152e-05 - model_2_loss: 0.0043 - model_3_loss: 2.0713e-04 - model_4_loss: 7.4930e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1771 - loss2: 6.5970 - val_loss: 10.6493 - val_model_loss: 1.8587 - val_model_1_loss: 2.0713 - val_model_2_loss: 2.0204 - val_model_3_loss: 1.4889 - val_model_4_loss: 1.2553 - val_model_accuracy: 0.4475 - val_model_1_accuracy: 0.4930 - val_model_2_accuracy: 0.4800 - val_model_3_accuracy: 0.4805 - val_model_4_accuracy: 0.4875 - val_loss1: 3.0447 - val_loss2: 8.6465\n","Epoch 169/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4594 - model_loss: 3.2332e-04 - model_1_loss: 0.0069 - model_2_loss: 3.2208e-04 - model_3_loss: 7.5498e-06 - model_4_loss: 0.0026 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2395 - loss2: 6.5907 - val_loss: 10.7712 - val_model_loss: 1.9446 - val_model_1_loss: 1.9648 - val_model_2_loss: 2.1813 - val_model_3_loss: 1.4792 - val_model_4_loss: 1.2533 - val_model_accuracy: 0.4525 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4875 - val_model_3_accuracy: 0.4830 - val_model_4_accuracy: 0.4905 - val_loss1: 3.0328 - val_loss2: 8.6309\n","Epoch 170/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6867 - model_loss: 0.1676 - model_1_loss: 0.0453 - model_2_loss: 0.0110 - model_3_loss: 0.0046 - model_4_loss: 0.0032 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2471 - loss2: 6.6293 - val_loss: 10.7906 - val_model_loss: 1.9011 - val_model_1_loss: 1.9051 - val_model_2_loss: 2.3109 - val_model_3_loss: 1.4788 - val_model_4_loss: 1.2544 - val_model_accuracy: 0.4440 - val_model_1_accuracy: 0.4975 - val_model_2_accuracy: 0.4895 - val_model_3_accuracy: 0.4830 - val_model_4_accuracy: 0.4920 - val_loss1: 3.0189 - val_loss2: 8.6149\n","Epoch 171/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.9607 - model_loss: 0.2832 - model_1_loss: 0.0015 - model_2_loss: 0.0340 - model_3_loss: 0.0026 - model_4_loss: 0.0043 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.5866 - loss2: 6.8331 - val_loss: 10.4835 - val_model_loss: 1.6240 - val_model_1_loss: 1.8539 - val_model_2_loss: 2.3277 - val_model_3_loss: 1.4815 - val_model_4_loss: 1.2601 - val_model_accuracy: 0.4435 - val_model_1_accuracy: 0.4985 - val_model_2_accuracy: 0.4900 - val_model_3_accuracy: 0.4830 - val_model_4_accuracy: 0.4930 - val_loss1: 3.0126 - val_loss2: 8.6009\n","Epoch 172/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.9442 - model_loss: 0.0073 - model_1_loss: 0.8176 - model_2_loss: 1.3940 - model_3_loss: 0.1579 - model_4_loss: 0.0028 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.4671 - loss2: 6.6231 - val_loss: 9.0685 - val_model_loss: 1.4065 - val_model_1_loss: 1.5812 - val_model_2_loss: 1.4747 - val_model_3_loss: 1.4181 - val_model_4_loss: 1.2634 - val_model_accuracy: 0.4640 - val_model_1_accuracy: 0.4965 - val_model_2_accuracy: 0.4650 - val_model_3_accuracy: 0.4885 - val_model_4_accuracy: 0.4935 - val_loss1: 2.9862 - val_loss2: 8.6304\n","Epoch 173/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5344 - model_loss: 2.2484e-04 - model_1_loss: 0.0156 - model_2_loss: 0.0216 - model_3_loss: 0.0070 - model_4_loss: 5.0345e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3258 - loss2: 6.5304 - val_loss: 8.1531 - val_model_loss: 1.2546 - val_model_1_loss: 1.3902 - val_model_2_loss: 0.9566 - val_model_3_loss: 1.3667 - val_model_4_loss: 1.2665 - val_model_accuracy: 0.4990 - val_model_1_accuracy: 0.4865 - val_model_2_accuracy: 0.4655 - val_model_3_accuracy: 0.4925 - val_model_4_accuracy: 0.4950 - val_loss1: 2.9722 - val_loss2: 8.6505\n","Epoch 174/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4863 - model_loss: 1.2974e-05 - model_1_loss: 9.4141e-04 - model_2_loss: 9.1260e-04 - model_3_loss: 6.2584e-06 - model_4_loss: 7.0792e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3166 - loss2: 6.5081 - val_loss: 7.7354 - val_model_loss: 1.1649 - val_model_1_loss: 1.2506 - val_model_2_loss: 0.8230 - val_model_3_loss: 1.3174 - val_model_4_loss: 1.2651 - val_model_accuracy: 0.5205 - val_model_1_accuracy: 0.4780 - val_model_2_accuracy: 0.5950 - val_model_3_accuracy: 0.4965 - val_model_4_accuracy: 0.4985 - val_loss1: 2.9626 - val_loss2: 8.6633\n","Epoch 175/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6423 - model_loss: 4.1342e-05 - model_1_loss: 7.3342e-04 - model_2_loss: 0.0027 - model_3_loss: 6.9195e-05 - model_4_loss: 0.0051 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.6038 - loss2: 6.6363 - val_loss: 7.6348 - val_model_loss: 1.1281 - val_model_1_loss: 1.1515 - val_model_2_loss: 0.9123 - val_model_3_loss: 1.2726 - val_model_4_loss: 1.2581 - val_model_accuracy: 0.5700 - val_model_1_accuracy: 0.4740 - val_model_2_accuracy: 0.5580 - val_model_3_accuracy: 0.5030 - val_model_4_accuracy: 0.5005 - val_loss1: 2.9572 - val_loss2: 8.6705\n","Epoch 176/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6100 - model_loss: 0.0019 - model_1_loss: 0.0644 - model_2_loss: 0.0072 - model_3_loss: 0.0012 - model_4_loss: 0.0229 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3358 - loss2: 6.8906 - val_loss: 7.6829 - val_model_loss: 1.1283 - val_model_1_loss: 1.0906 - val_model_2_loss: 1.0700 - val_model_3_loss: 1.2393 - val_model_4_loss: 1.2436 - val_model_accuracy: 0.6000 - val_model_1_accuracy: 0.4815 - val_model_2_accuracy: 0.5225 - val_model_3_accuracy: 0.5105 - val_model_4_accuracy: 0.5035 - val_loss1: 2.9549 - val_loss2: 8.6736\n","Epoch 177/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.0891 - model_loss: 0.1986 - model_1_loss: 1.2251e-04 - model_2_loss: 0.4471 - model_3_loss: 8.9179e-05 - model_4_loss: 0.0069 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.6667 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2139 - loss2: 6.5866 - val_loss: 7.6012 - val_model_loss: 1.1253 - val_model_1_loss: 1.0475 - val_model_2_loss: 1.0929 - val_model_3_loss: 1.2066 - val_model_4_loss: 1.2285 - val_model_accuracy: 0.5785 - val_model_1_accuracy: 0.4980 - val_model_2_accuracy: 0.5240 - val_model_3_accuracy: 0.5150 - val_model_4_accuracy: 0.5090 - val_loss1: 2.9331 - val_loss2: 8.6764\n","Epoch 178/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7822 - model_loss: 0.1508 - model_1_loss: 0.0243 - model_2_loss: 0.2974 - model_3_loss: 0.0074 - model_4_loss: 0.0026 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9391 - loss2: 6.6037 - val_loss: 7.5034 - val_model_loss: 1.1596 - val_model_1_loss: 1.0275 - val_model_2_loss: 1.0293 - val_model_3_loss: 1.1883 - val_model_4_loss: 1.2143 - val_model_accuracy: 0.5220 - val_model_1_accuracy: 0.5140 - val_model_2_accuracy: 0.5355 - val_model_3_accuracy: 0.5220 - val_model_4_accuracy: 0.5145 - val_loss1: 2.9012 - val_loss2: 8.6749\n","Epoch 179/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5194 - model_loss: 0.0041 - model_1_loss: 0.0114 - model_2_loss: 0.1647 - model_3_loss: 2.9145e-05 - model_4_loss: 0.0116 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9982 - loss2: 6.5704 - val_loss: 7.4649 - val_model_loss: 1.2522 - val_model_1_loss: 1.0135 - val_model_2_loss: 0.9491 - val_model_3_loss: 1.1720 - val_model_4_loss: 1.2062 - val_model_accuracy: 0.4865 - val_model_1_accuracy: 0.5270 - val_model_2_accuracy: 0.5530 - val_model_3_accuracy: 0.5265 - val_model_4_accuracy: 0.5210 - val_loss1: 2.8766 - val_loss2: 8.6703\n","Epoch 180/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1316 - model_loss: 0.0041 - model_1_loss: 0.2751 - model_2_loss: 0.5012 - model_3_loss: 0.0011 - model_4_loss: 2.5346e-04 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0441 - loss2: 6.5575 - val_loss: 7.4243 - val_model_loss: 1.3884 - val_model_1_loss: 1.0338 - val_model_2_loss: 0.7857 - val_model_3_loss: 1.1566 - val_model_4_loss: 1.1983 - val_model_accuracy: 0.4590 - val_model_1_accuracy: 0.4950 - val_model_2_accuracy: 0.6095 - val_model_3_accuracy: 0.5315 - val_model_4_accuracy: 0.5245 - val_loss1: 2.8555 - val_loss2: 8.6726\n","Epoch 181/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5383 - model_loss: 0.0015 - model_1_loss: 0.0142 - model_2_loss: 0.1810 - model_3_loss: 8.5364e-04 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0247 - loss2: 6.5329 - val_loss: 7.5815 - val_model_loss: 1.5512 - val_model_1_loss: 1.0752 - val_model_2_loss: 0.7624 - val_model_3_loss: 1.1458 - val_model_4_loss: 1.1941 - val_model_accuracy: 0.4455 - val_model_1_accuracy: 0.4925 - val_model_2_accuracy: 0.5585 - val_model_3_accuracy: 0.5385 - val_model_4_accuracy: 0.5280 - val_loss1: 2.8389 - val_loss2: 8.6692\n","Epoch 182/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6218 - model_loss: 7.9616e-04 - model_1_loss: 0.0254 - model_2_loss: 0.0033 - model_3_loss: 5.8015e-06 - model_4_loss: 0.0054 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.5156 - loss2: 6.5820 - val_loss: 7.9237 - val_model_loss: 1.7199 - val_model_1_loss: 1.1453 - val_model_2_loss: 0.8932 - val_model_3_loss: 1.1345 - val_model_4_loss: 1.1843 - val_model_accuracy: 0.4455 - val_model_1_accuracy: 0.4990 - val_model_2_accuracy: 0.5115 - val_model_3_accuracy: 0.5440 - val_model_4_accuracy: 0.5320 - val_loss1: 2.8271 - val_loss2: 8.6621\n","Epoch 183/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3659 - model_loss: 0.0049 - model_1_loss: 3.0496e-05 - model_2_loss: 0.0353 - model_3_loss: 0.0019 - model_4_loss: 3.3179e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9748 - loss2: 6.7209 - val_loss: 8.3406 - val_model_loss: 1.8833 - val_model_1_loss: 1.2239 - val_model_2_loss: 1.1018 - val_model_3_loss: 1.1215 - val_model_4_loss: 1.1688 - val_model_accuracy: 0.4420 - val_model_1_accuracy: 0.5080 - val_model_2_accuracy: 0.4680 - val_model_3_accuracy: 0.5540 - val_model_4_accuracy: 0.5350 - val_loss1: 2.8171 - val_loss2: 8.6535\n","Epoch 184/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4033 - model_loss: 8.6868e-05 - model_1_loss: 4.7027e-04 - model_2_loss: 0.0153 - model_3_loss: 0.0050 - model_4_loss: 0.0220 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0534 - loss2: 6.6747 - val_loss: 8.8075 - val_model_loss: 2.0401 - val_model_1_loss: 1.3081 - val_model_2_loss: 1.3340 - val_model_3_loss: 1.1172 - val_model_4_loss: 1.1697 - val_model_accuracy: 0.4525 - val_model_1_accuracy: 0.5165 - val_model_2_accuracy: 0.4705 - val_model_3_accuracy: 0.5580 - val_model_4_accuracy: 0.5360 - val_loss1: 2.8126 - val_loss2: 8.6426\n","Epoch 185/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7291 - model_loss: 0.0029 - model_1_loss: 1.5833e-04 - model_2_loss: 0.1215 - model_3_loss: 8.5175e-04 - model_4_loss: 1.0126e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.5343 - loss2: 6.7282 - val_loss: 9.2176 - val_model_loss: 2.1878 - val_model_1_loss: 1.3989 - val_model_2_loss: 1.5070 - val_model_3_loss: 1.1165 - val_model_4_loss: 1.1721 - val_model_accuracy: 0.4605 - val_model_1_accuracy: 0.5170 - val_model_2_accuracy: 0.4715 - val_model_3_accuracy: 0.5610 - val_model_4_accuracy: 0.5370 - val_loss1: 2.8079 - val_loss2: 8.6285\n","Epoch 186/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1746 - model_loss: 0.3561 - model_1_loss: 6.4731e-04 - model_2_loss: 0.4017 - model_3_loss: 0.0118 - model_4_loss: 0.0802 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9655 - loss2: 6.8268 - val_loss: 9.0692 - val_model_loss: 1.9314 - val_model_1_loss: 1.4924 - val_model_2_loss: 1.5663 - val_model_3_loss: 1.1325 - val_model_4_loss: 1.1144 - val_model_accuracy: 0.4475 - val_model_1_accuracy: 0.5200 - val_model_2_accuracy: 0.4720 - val_model_3_accuracy: 0.5585 - val_model_4_accuracy: 0.5585 - val_loss1: 2.8029 - val_loss2: 8.6146\n","Epoch 187/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3168 - model_loss: 1.4007e-05 - model_1_loss: 0.0032 - model_2_loss: 0.0030 - model_3_loss: 1.7881e-07 - model_4_loss: 2.4769e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9862 - loss2: 6.3465 - val_loss: 8.9001 - val_model_loss: 1.6932 - val_model_1_loss: 1.5735 - val_model_2_loss: 1.6044 - val_model_3_loss: 1.1391 - val_model_4_loss: 1.0600 - val_model_accuracy: 0.4475 - val_model_1_accuracy: 0.5190 - val_model_2_accuracy: 0.4740 - val_model_3_accuracy: 0.5590 - val_model_4_accuracy: 0.5785 - val_loss1: 2.7997 - val_loss2: 8.5996\n","Epoch 188/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3335 - model_loss: 1.4444e-05 - model_1_loss: 3.2471e-04 - model_2_loss: 0.0033 - model_3_loss: 4.8870e-05 - model_4_loss: 2.7576e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0266 - loss2: 6.3302 - val_loss: 8.7654 - val_model_loss: 1.4930 - val_model_1_loss: 1.6506 - val_model_2_loss: 1.6337 - val_model_3_loss: 1.1448 - val_model_4_loss: 1.0160 - val_model_accuracy: 0.4555 - val_model_1_accuracy: 0.5190 - val_model_2_accuracy: 0.4735 - val_model_3_accuracy: 0.5585 - val_model_4_accuracy: 0.5970 - val_loss1: 2.7963 - val_loss2: 8.5829\n","Epoch 189/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3059 - model_loss: 1.8300e-04 - model_1_loss: 3.3547e-04 - model_2_loss: 0.0024 - model_3_loss: 1.8000e-05 - model_4_loss: 1.2159e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9634 - loss2: 6.4239 - val_loss: 8.6811 - val_model_loss: 1.3361 - val_model_1_loss: 1.7270 - val_model_2_loss: 1.6574 - val_model_3_loss: 1.1521 - val_model_4_loss: 0.9824 - val_model_accuracy: 0.4745 - val_model_1_accuracy: 0.5185 - val_model_2_accuracy: 0.4730 - val_model_3_accuracy: 0.5615 - val_model_4_accuracy: 0.6110 - val_loss1: 2.7958 - val_loss2: 8.5642\n","Epoch 190/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5898 - model_loss: 1.8785e-04 - model_1_loss: 0.0014 - model_2_loss: 0.0240 - model_3_loss: 0.0091 - model_4_loss: 0.0015 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4349 - loss2: 6.7247 - val_loss: 8.6083 - val_model_loss: 1.2148 - val_model_1_loss: 1.7939 - val_model_2_loss: 1.6607 - val_model_3_loss: 1.1598 - val_model_4_loss: 0.9552 - val_model_accuracy: 0.4995 - val_model_1_accuracy: 0.5175 - val_model_2_accuracy: 0.4725 - val_model_3_accuracy: 0.5640 - val_model_4_accuracy: 0.6250 - val_loss1: 2.7931 - val_loss2: 8.5462\n","Epoch 191/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3733 - model_loss: 4.8812e-05 - model_1_loss: 4.6307e-05 - model_2_loss: 3.4569e-04 - model_3_loss: 5.6822e-06 - model_4_loss: 4.9273e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1178 - loss2: 6.2785 - val_loss: 8.5616 - val_model_loss: 1.1225 - val_model_1_loss: 1.8567 - val_model_2_loss: 1.6620 - val_model_3_loss: 1.1652 - val_model_4_loss: 0.9332 - val_model_accuracy: 0.5200 - val_model_1_accuracy: 0.5170 - val_model_2_accuracy: 0.4725 - val_model_3_accuracy: 0.5645 - val_model_4_accuracy: 0.6370 - val_loss1: 2.7916 - val_loss2: 8.5254\n","Epoch 192/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3714 - model_loss: 8.5006e-04 - model_1_loss: 3.9234e-04 - model_2_loss: 0.0471 - model_3_loss: 4.2871e-05 - model_4_loss: 1.3212e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0129 - loss2: 6.3318 - val_loss: 8.5360 - val_model_loss: 1.0594 - val_model_1_loss: 1.9184 - val_model_2_loss: 1.6500 - val_model_3_loss: 1.1721 - val_model_4_loss: 0.9176 - val_model_accuracy: 0.5415 - val_model_1_accuracy: 0.5155 - val_model_2_accuracy: 0.4715 - val_model_3_accuracy: 0.5620 - val_model_4_accuracy: 0.6435 - val_loss1: 2.7867 - val_loss2: 8.5036\n","Epoch 193/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7550 - model_loss: 0.0820 - model_1_loss: 0.0042 - model_2_loss: 0.0038 - model_3_loss: 0.2275 - model_4_loss: 2.8273e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.2217 - loss2: 6.5283 - val_loss: 8.6780 - val_model_loss: 1.0521 - val_model_1_loss: 1.9757 - val_model_2_loss: 1.6437 - val_model_3_loss: 1.2837 - val_model_4_loss: 0.9081 - val_model_accuracy: 0.5430 - val_model_1_accuracy: 0.5130 - val_model_2_accuracy: 0.4725 - val_model_3_accuracy: 0.5345 - val_model_4_accuracy: 0.6555 - val_loss1: 2.7809 - val_loss2: 8.4842\n","Epoch 194/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8438 - model_loss: 0.0715 - model_1_loss: 0.0396 - model_2_loss: 0.0853 - model_3_loss: 0.0197 - model_4_loss: 6.0738e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.5957 - loss2: 6.5848 - val_loss: 8.6762 - val_model_loss: 1.0264 - val_model_1_loss: 1.9907 - val_model_2_loss: 1.5480 - val_model_3_loss: 1.3996 - val_model_4_loss: 0.9012 - val_model_accuracy: 0.5560 - val_model_1_accuracy: 0.5165 - val_model_2_accuracy: 0.4750 - val_model_3_accuracy: 0.5165 - val_model_4_accuracy: 0.6605 - val_loss1: 2.7739 - val_loss2: 8.4669\n","Epoch 195/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7750 - model_loss: 0.0016 - model_1_loss: 0.0089 - model_2_loss: 0.0324 - model_3_loss: 1.4938e-04 - model_4_loss: 6.6690e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7769 - loss2: 6.8683 - val_loss: 8.6546 - val_model_loss: 1.0076 - val_model_1_loss: 1.9803 - val_model_2_loss: 1.4495 - val_model_3_loss: 1.5153 - val_model_4_loss: 0.8966 - val_model_accuracy: 0.5665 - val_model_1_accuracy: 0.5205 - val_model_2_accuracy: 0.4765 - val_model_3_accuracy: 0.5050 - val_model_4_accuracy: 0.6675 - val_loss1: 2.7658 - val_loss2: 8.4487\n","Epoch 196/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5331 - model_loss: 3.5878e-04 - model_1_loss: 0.0018 - model_2_loss: 0.0025 - model_3_loss: 0.0015 - model_4_loss: 1.0093e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4034 - loss2: 6.5031 - val_loss: 8.6122 - val_model_loss: 0.9915 - val_model_1_loss: 1.9574 - val_model_2_loss: 1.3552 - val_model_3_loss: 1.6158 - val_model_4_loss: 0.8927 - val_model_accuracy: 0.5755 - val_model_1_accuracy: 0.5265 - val_model_2_accuracy: 0.4810 - val_model_3_accuracy: 0.4975 - val_model_4_accuracy: 0.6720 - val_loss1: 2.7559 - val_loss2: 8.4305\n","Epoch 197/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5436 - model_loss: 2.9909e-04 - model_1_loss: 0.0021 - model_2_loss: 0.0093 - model_3_loss: 4.4659e-05 - model_4_loss: 0.0023 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3901 - loss2: 6.6877 - val_loss: 8.5946 - val_model_loss: 0.9810 - val_model_1_loss: 1.9375 - val_model_2_loss: 1.2753 - val_model_3_loss: 1.7163 - val_model_4_loss: 0.8916 - val_model_accuracy: 0.5875 - val_model_1_accuracy: 0.5300 - val_model_2_accuracy: 0.4845 - val_model_3_accuracy: 0.4915 - val_model_4_accuracy: 0.6735 - val_loss1: 2.7448 - val_loss2: 8.4106\n","Epoch 198/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5955 - model_loss: 5.5820e-04 - model_1_loss: 1.5099e-04 - model_2_loss: 1.4592e-04 - model_3_loss: 1.5377e-05 - model_4_loss: 2.8887e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.5332 - loss2: 6.5610 - val_loss: 8.5892 - val_model_loss: 0.9741 - val_model_1_loss: 1.9197 - val_model_2_loss: 1.2092 - val_model_3_loss: 1.8084 - val_model_4_loss: 0.8920 - val_model_accuracy: 0.5915 - val_model_1_accuracy: 0.5360 - val_model_2_accuracy: 0.4895 - val_model_3_accuracy: 0.4885 - val_model_4_accuracy: 0.6745 - val_loss1: 2.7331 - val_loss2: 8.3873\n","Epoch 199/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1176 - model_loss: 0.0015 - model_1_loss: 0.0881 - model_2_loss: 0.3895 - model_3_loss: 0.0133 - model_4_loss: 0.0077 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.5646 - loss2: 6.7062 - val_loss: 8.2892 - val_model_loss: 0.9697 - val_model_1_loss: 1.7576 - val_model_2_loss: 1.0293 - val_model_3_loss: 1.8628 - val_model_4_loss: 0.8919 - val_model_accuracy: 0.5925 - val_model_1_accuracy: 0.5415 - val_model_2_accuracy: 0.5065 - val_model_3_accuracy: 0.4855 - val_model_4_accuracy: 0.6820 - val_loss1: 2.7186 - val_loss2: 8.3728\n","Epoch 200/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6088 - model_loss: 5.1866e-04 - model_1_loss: 0.0275 - model_2_loss: 0.0041 - model_3_loss: 1.4504e-06 - model_4_loss: 0.0022 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4850 - loss2: 6.6394 - val_loss: 8.0076 - val_model_loss: 0.9668 - val_model_1_loss: 1.5646 - val_model_2_loss: 0.9043 - val_model_3_loss: 1.9079 - val_model_4_loss: 0.8938 - val_model_accuracy: 0.6000 - val_model_1_accuracy: 0.5560 - val_model_2_accuracy: 0.5420 - val_model_3_accuracy: 0.4860 - val_model_4_accuracy: 0.6885 - val_loss1: 2.7045 - val_loss2: 8.3594\n","Epoch 201/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4240 - model_loss: 0.0037 - model_1_loss: 7.7088e-06 - model_2_loss: 0.0018 - model_3_loss: 1.7324e-05 - model_4_loss: 4.6707e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1946 - loss2: 6.4222 - val_loss: 7.8134 - val_model_loss: 0.9666 - val_model_1_loss: 1.4137 - val_model_2_loss: 0.8234 - val_model_3_loss: 1.9491 - val_model_4_loss: 0.8988 - val_model_accuracy: 0.6025 - val_model_1_accuracy: 0.5555 - val_model_2_accuracy: 0.5890 - val_model_3_accuracy: 0.4850 - val_model_4_accuracy: 0.6875 - val_loss1: 2.6892 - val_loss2: 8.3438\n","Epoch 202/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6102 - model_loss: 0.0034 - model_1_loss: 1.6663e-04 - model_2_loss: 0.0222 - model_3_loss: 4.4204e-05 - model_4_loss: 0.0350 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4407 - loss2: 6.5813 - val_loss: 7.7039 - val_model_loss: 0.9672 - val_model_1_loss: 1.3055 - val_model_2_loss: 0.7848 - val_model_3_loss: 1.9899 - val_model_4_loss: 0.9042 - val_model_accuracy: 0.6035 - val_model_1_accuracy: 0.5730 - val_model_2_accuracy: 0.6325 - val_model_3_accuracy: 0.4840 - val_model_4_accuracy: 0.6890 - val_loss1: 2.6722 - val_loss2: 8.3265\n","Epoch 203/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8202 - model_loss: 0.1381 - model_1_loss: 0.0069 - model_2_loss: 0.1148 - model_3_loss: 2.7040e-05 - model_4_loss: 7.0024e-04 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4726 - loss2: 6.4685 - val_loss: 7.6642 - val_model_loss: 0.9831 - val_model_1_loss: 1.2356 - val_model_2_loss: 0.7758 - val_model_3_loss: 2.0215 - val_model_4_loss: 0.9078 - val_model_accuracy: 0.5825 - val_model_1_accuracy: 0.5760 - val_model_2_accuracy: 0.6410 - val_model_3_accuracy: 0.4835 - val_model_4_accuracy: 0.6890 - val_loss1: 2.6507 - val_loss2: 8.3032\n","Epoch 204/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.4431 - model_loss: 0.1363 - model_1_loss: 0.0288 - model_2_loss: 0.3987 - model_3_loss: 0.3700 - model_4_loss: 0.0193 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.2919 - loss2: 6.8824 - val_loss: 7.3550 - val_model_loss: 1.0735 - val_model_1_loss: 1.2217 - val_model_2_loss: 0.7891 - val_model_3_loss: 1.6372 - val_model_4_loss: 0.9125 - val_model_accuracy: 0.5400 - val_model_1_accuracy: 0.5705 - val_model_2_accuracy: 0.6140 - val_model_3_accuracy: 0.5005 - val_model_4_accuracy: 0.6905 - val_loss1: 2.6153 - val_loss2: 8.2670\n","Epoch 205/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5083 - model_loss: 0.0105 - model_1_loss: 0.0050 - model_2_loss: 0.0295 - model_3_loss: 0.0024 - model_4_loss: 0.0023 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2685 - loss2: 6.4873 - val_loss: 7.2627 - val_model_loss: 1.2333 - val_model_1_loss: 1.2219 - val_model_2_loss: 0.8116 - val_model_3_loss: 1.3743 - val_model_4_loss: 0.9156 - val_model_accuracy: 0.5060 - val_model_1_accuracy: 0.5685 - val_model_2_accuracy: 0.5960 - val_model_3_accuracy: 0.5530 - val_model_4_accuracy: 0.6915 - val_loss1: 2.5889 - val_loss2: 8.2302\n","Epoch 206/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8314 - model_loss: 0.0073 - model_1_loss: 0.2046 - model_2_loss: 0.1223 - model_3_loss: 5.4434e-05 - model_4_loss: 0.0227 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3081 - loss2: 6.4096 - val_loss: 7.4258 - val_model_loss: 1.4302 - val_model_1_loss: 1.2429 - val_model_2_loss: 0.8920 - val_model_3_loss: 1.2480 - val_model_4_loss: 0.9192 - val_model_accuracy: 0.4890 - val_model_1_accuracy: 0.5715 - val_model_2_accuracy: 0.5580 - val_model_3_accuracy: 0.6355 - val_model_4_accuracy: 0.6830 - val_loss1: 2.5668 - val_loss2: 8.2000\n","Epoch 207/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1830 - model_loss: 0.0742 - model_1_loss: 0.3930 - model_2_loss: 0.1316 - model_3_loss: 0.0941 - model_4_loss: 0.0034 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3126 - loss2: 6.6062 - val_loss: 7.6767 - val_model_loss: 1.5353 - val_model_1_loss: 1.3248 - val_model_2_loss: 0.9632 - val_model_3_loss: 1.2430 - val_model_4_loss: 0.9261 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.5710 - val_model_2_accuracy: 0.5340 - val_model_3_accuracy: 0.7135 - val_model_4_accuracy: 0.6780 - val_loss1: 2.5515 - val_loss2: 8.1684\n","Epoch 208/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.6733 - model_loss: 0.0656 - model_1_loss: 0.4427 - model_2_loss: 0.0118 - model_3_loss: 1.5278 - model_4_loss: 0.3056 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 1.9976 - loss2: 6.4191 - val_loss: 7.8834 - val_model_loss: 1.5108 - val_model_1_loss: 1.4844 - val_model_2_loss: 1.0429 - val_model_3_loss: 1.1765 - val_model_4_loss: 0.9874 - val_model_accuracy: 0.4750 - val_model_1_accuracy: 0.5205 - val_model_2_accuracy: 0.5100 - val_model_3_accuracy: 0.7165 - val_model_4_accuracy: 0.6315 - val_loss1: 2.5468 - val_loss2: 8.1610\n","Epoch 209/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2066 - model_loss: 0.0108 - model_1_loss: 9.0995e-06 - model_2_loss: 0.0024 - model_3_loss: 7.5094e-04 - model_4_loss: 1.8357e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7781 - loss2: 6.0695 - val_loss: 8.2547 - val_model_loss: 1.5015 - val_model_1_loss: 1.6826 - val_model_2_loss: 1.1238 - val_model_3_loss: 1.1339 - val_model_4_loss: 1.1324 - val_model_accuracy: 0.4750 - val_model_1_accuracy: 0.4895 - val_model_2_accuracy: 0.4935 - val_model_3_accuracy: 0.7190 - val_model_4_accuracy: 0.5910 - val_loss1: 2.5462 - val_loss2: 8.1486\n","Epoch 210/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3417 - model_loss: 0.0030 - model_1_loss: 0.0066 - model_2_loss: 0.0092 - model_3_loss: 3.6395e-04 - model_4_loss: 0.0035 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0060 - loss2: 6.3195 - val_loss: 8.7340 - val_model_loss: 1.5017 - val_model_1_loss: 1.8974 - val_model_2_loss: 1.2022 - val_model_3_loss: 1.0989 - val_model_4_loss: 1.3530 - val_model_accuracy: 0.4730 - val_model_1_accuracy: 0.4805 - val_model_2_accuracy: 0.4765 - val_model_3_accuracy: 0.7150 - val_model_4_accuracy: 0.5290 - val_loss1: 2.5486 - val_loss2: 8.1329\n","Epoch 211/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.8697 - model_loss: 0.0265 - model_1_loss: 0.0077 - model_2_loss: 0.2187 - model_3_loss: 1.2767 - model_4_loss: 5.0040e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.0708 - loss2: 6.0823 - val_loss: 9.4195 - val_model_loss: 1.5519 - val_model_1_loss: 2.1155 - val_model_2_loss: 1.4147 - val_model_3_loss: 1.0310 - val_model_4_loss: 1.6148 - val_model_accuracy: 0.4660 - val_model_1_accuracy: 0.4730 - val_model_2_accuracy: 0.4645 - val_model_3_accuracy: 0.6540 - val_model_4_accuracy: 0.4800 - val_loss1: 2.5707 - val_loss2: 8.1243\n","Epoch 212/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7705 - model_loss: 0.0094 - model_1_loss: 0.0027 - model_2_loss: 0.1399 - model_3_loss: 0.4020 - model_4_loss: 8.2443e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 1.8183 - loss2: 6.1312 - val_loss: 10.2080 - val_model_loss: 1.6061 - val_model_1_loss: 2.3136 - val_model_2_loss: 1.5456 - val_model_3_loss: 1.1554 - val_model_4_loss: 1.8839 - val_model_accuracy: 0.4630 - val_model_1_accuracy: 0.4665 - val_model_2_accuracy: 0.4660 - val_model_3_accuracy: 0.5740 - val_model_4_accuracy: 0.4675 - val_loss1: 2.5946 - val_loss2: 8.1228\n","Epoch 213/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.9120 - model_loss: 0.0062 - model_1_loss: 0.1681 - model_2_loss: 0.0035 - model_3_loss: 0.3223 - model_4_loss: 0.0440 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.1111 - loss2: 6.2469 - val_loss: 11.6579 - val_model_loss: 1.6728 - val_model_1_loss: 2.8890 - val_model_2_loss: 1.6713 - val_model_3_loss: 1.6649 - val_model_4_loss: 2.0387 - val_model_accuracy: 0.4620 - val_model_1_accuracy: 0.4705 - val_model_2_accuracy: 0.4695 - val_model_3_accuracy: 0.5130 - val_model_4_accuracy: 0.4685 - val_loss1: 2.6305 - val_loss2: 8.1184\n","Epoch 214/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8179 - model_loss: 3.4098e-04 - model_1_loss: 0.4708 - model_2_loss: 0.0029 - model_3_loss: 1.3338e-04 - model_4_loss: 0.0585 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9392 - loss2: 6.3120 - val_loss: 12.7897 - val_model_loss: 1.7327 - val_model_1_loss: 3.1342 - val_model_2_loss: 1.7850 - val_model_3_loss: 2.3266 - val_model_4_loss: 2.0739 - val_model_accuracy: 0.4615 - val_model_1_accuracy: 0.4750 - val_model_2_accuracy: 0.4720 - val_model_3_accuracy: 0.4700 - val_model_4_accuracy: 0.4680 - val_loss1: 2.6608 - val_loss2: 8.1359\n","Epoch 215/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.5785 - model_loss: 0.0017 - model_1_loss: 0.0085 - model_2_loss: 0.4798 - model_3_loss: 0.7112 - model_4_loss: 0.0536 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.0138 - loss2: 6.3360 - val_loss: 12.9052 - val_model_loss: 1.7857 - val_model_1_loss: 3.3240 - val_model_2_loss: 1.6346 - val_model_3_loss: 2.5086 - val_model_4_loss: 1.9051 - val_model_accuracy: 0.4620 - val_model_1_accuracy: 0.4755 - val_model_2_accuracy: 0.4660 - val_model_3_accuracy: 0.4745 - val_model_4_accuracy: 0.4675 - val_loss1: 2.6779 - val_loss2: 8.1637\n","Epoch 216/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3239 - model_loss: 1.0788e-05 - model_1_loss: 5.9796e-04 - model_2_loss: 0.0065 - model_3_loss: 0.0092 - model_4_loss: 0.0038 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9899 - loss2: 6.1759 - val_loss: 12.9677 - val_model_loss: 1.8357 - val_model_1_loss: 3.4870 - val_model_2_loss: 1.5094 - val_model_3_loss: 2.6434 - val_model_4_loss: 1.7363 - val_model_accuracy: 0.4610 - val_model_1_accuracy: 0.4805 - val_model_2_accuracy: 0.4695 - val_model_3_accuracy: 0.4785 - val_model_4_accuracy: 0.4740 - val_loss1: 2.6936 - val_loss2: 8.1826\n","Epoch 217/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1119 - model_loss: 0.0312 - model_1_loss: 0.3057 - model_2_loss: 0.1060 - model_3_loss: 0.0684 - model_4_loss: 0.1971 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 2.1554 - loss2: 6.5182 - val_loss: 12.0556 - val_model_loss: 1.7867 - val_model_1_loss: 3.1992 - val_model_2_loss: 1.3742 - val_model_3_loss: 2.5920 - val_model_4_loss: 1.3506 - val_model_accuracy: 0.4635 - val_model_1_accuracy: 0.4785 - val_model_2_accuracy: 0.4710 - val_model_3_accuracy: 0.4790 - val_model_4_accuracy: 0.5230 - val_loss1: 2.6844 - val_loss2: 8.2163\n","Epoch 218/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2450 - model_loss: 6.9067e-05 - model_1_loss: 4.7882e-06 - model_2_loss: 0.0145 - model_3_loss: 0.0042 - model_4_loss: 7.8478e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8338 - loss2: 6.1861 - val_loss: 11.3184 - val_model_loss: 1.7359 - val_model_1_loss: 2.9164 - val_model_2_loss: 1.2752 - val_model_3_loss: 2.5271 - val_model_4_loss: 1.1124 - val_model_accuracy: 0.4730 - val_model_1_accuracy: 0.4820 - val_model_2_accuracy: 0.4790 - val_model_3_accuracy: 0.4770 - val_model_4_accuracy: 0.5945 - val_loss1: 2.6787 - val_loss2: 8.2421\n","Epoch 219/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6866 - model_loss: 0.0022 - model_1_loss: 0.0016 - model_2_loss: 5.2411e-04 - model_3_loss: 0.3320 - model_4_loss: 0.0133 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.0262 - loss2: 6.4790 - val_loss: 10.3982 - val_model_loss: 1.6993 - val_model_1_loss: 2.6553 - val_model_2_loss: 1.2037 - val_model_3_loss: 2.0842 - val_model_4_loss: 1.0100 - val_model_accuracy: 0.4765 - val_model_1_accuracy: 0.4805 - val_model_2_accuracy: 0.4690 - val_model_3_accuracy: 0.4675 - val_model_4_accuracy: 0.6200 - val_loss1: 2.6643 - val_loss2: 8.2700\n","Epoch 220/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2742 - model_loss: 1.4563e-05 - model_1_loss: 0.0010 - model_2_loss: 2.8120e-04 - model_3_loss: 0.0046 - model_4_loss: 2.3483e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9157 - loss2: 6.2085 - val_loss: 9.6965 - val_model_loss: 1.6700 - val_model_1_loss: 2.4202 - val_model_2_loss: 1.1510 - val_model_3_loss: 1.7042 - val_model_4_loss: 1.0093 - val_model_accuracy: 0.4915 - val_model_1_accuracy: 0.4740 - val_model_2_accuracy: 0.4740 - val_model_3_accuracy: 0.4680 - val_model_4_accuracy: 0.6570 - val_loss1: 2.6550 - val_loss2: 8.2875\n","Epoch 221/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5231 - model_loss: 9.1490e-04 - model_1_loss: 1.6680e-04 - model_2_loss: 0.2012 - model_3_loss: 8.8916e-04 - model_4_loss: 5.1689e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0019 - loss2: 6.3782 - val_loss: 9.1750 - val_model_loss: 1.6553 - val_model_1_loss: 2.2260 - val_model_2_loss: 1.0670 - val_model_3_loss: 1.4159 - val_model_4_loss: 1.0725 - val_model_accuracy: 0.4995 - val_model_1_accuracy: 0.4780 - val_model_2_accuracy: 0.4860 - val_model_3_accuracy: 0.5020 - val_model_4_accuracy: 0.6660 - val_loss1: 2.6464 - val_loss2: 8.3014\n","Epoch 222/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7561 - model_loss: 2.5433e-04 - model_1_loss: 0.0016 - model_2_loss: 0.0025 - model_3_loss: 0.0202 - model_4_loss: 0.3644 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 2.0879 - loss2: 6.4640 - val_loss: 8.7285 - val_model_loss: 1.6439 - val_model_1_loss: 2.0620 - val_model_2_loss: 1.0186 - val_model_3_loss: 1.2019 - val_model_4_loss: 1.0694 - val_model_accuracy: 0.5045 - val_model_1_accuracy: 0.4775 - val_model_2_accuracy: 0.5105 - val_model_3_accuracy: 0.5375 - val_model_4_accuracy: 0.6575 - val_loss1: 2.6332 - val_loss2: 8.3236\n","Epoch 223/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5433 - model_loss: 0.0010 - model_1_loss: 7.1525e-07 - model_2_loss: 3.4765e-04 - model_3_loss: 4.8149e-04 - model_4_loss: 0.1554 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 2.1025 - loss2: 6.6954 - val_loss: 8.3681 - val_model_loss: 1.6319 - val_model_1_loss: 1.9214 - val_model_2_loss: 0.9931 - val_model_3_loss: 1.0556 - val_model_4_loss: 1.0386 - val_model_accuracy: 0.5075 - val_model_1_accuracy: 0.4855 - val_model_2_accuracy: 0.5295 - val_model_3_accuracy: 0.5920 - val_model_4_accuracy: 0.6395 - val_loss1: 2.6202 - val_loss2: 8.3474\n","Epoch 224/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3142 - model_loss: 0.0014 - model_1_loss: 1.0331e-06 - model_2_loss: 0.0967 - model_3_loss: 3.7924e-04 - model_4_loss: 0.0010 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7989 - loss2: 6.3037 - val_loss: 8.1526 - val_model_loss: 1.6186 - val_model_1_loss: 1.8001 - val_model_2_loss: 0.9773 - val_model_3_loss: 0.9652 - val_model_4_loss: 1.0688 - val_model_accuracy: 0.5140 - val_model_1_accuracy: 0.4975 - val_model_2_accuracy: 0.5385 - val_model_3_accuracy: 0.6240 - val_model_4_accuracy: 0.6100 - val_loss1: 2.6090 - val_loss2: 8.3631\n","Epoch 225/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5008 - model_loss: 3.6629e-04 - model_1_loss: 2.0067e-06 - model_2_loss: 0.0031 - model_3_loss: 1.3900e-04 - model_4_loss: 1.2898e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3398 - loss2: 6.5448 - val_loss: 8.0662 - val_model_loss: 1.6083 - val_model_1_loss: 1.7032 - val_model_2_loss: 0.9680 - val_model_3_loss: 0.9228 - val_model_4_loss: 1.1458 - val_model_accuracy: 0.5170 - val_model_1_accuracy: 0.5100 - val_model_2_accuracy: 0.5495 - val_model_3_accuracy: 0.6380 - val_model_4_accuracy: 0.5850 - val_loss1: 2.5990 - val_loss2: 8.3723\n","Epoch 226/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2860 - model_loss: 5.7618e-07 - model_1_loss: 5.1312e-05 - model_2_loss: 4.7161e-04 - model_3_loss: 0.0012 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9155 - loss2: 6.5031 - val_loss: 8.0780 - val_model_loss: 1.6007 - val_model_1_loss: 1.6281 - val_model_2_loss: 0.9634 - val_model_3_loss: 0.9137 - val_model_4_loss: 1.2587 - val_model_accuracy: 0.5265 - val_model_1_accuracy: 0.5235 - val_model_2_accuracy: 0.5525 - val_model_3_accuracy: 0.6555 - val_model_4_accuracy: 0.5575 - val_loss1: 2.5893 - val_loss2: 8.3753\n","Epoch 227/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.4817 - model_loss: 0.2362 - model_1_loss: 1.0798 - model_2_loss: 0.5146 - model_3_loss: 0.1883 - model_4_loss: 0.0448 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.1597 - loss2: 6.7618 - val_loss: 7.8914 - val_model_loss: 1.5080 - val_model_1_loss: 1.4508 - val_model_2_loss: 0.9447 - val_model_3_loss: 0.9340 - val_model_4_loss: 1.3419 - val_model_accuracy: 0.5665 - val_model_1_accuracy: 0.5380 - val_model_2_accuracy: 0.5520 - val_model_3_accuracy: 0.6575 - val_model_4_accuracy: 0.5350 - val_loss1: 2.5850 - val_loss2: 8.3886\n","Epoch 228/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5937 - model_loss: 0.1526 - model_1_loss: 7.2722e-05 - model_2_loss: 0.0900 - model_3_loss: 0.0133 - model_4_loss: 0.0027 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0186 - loss2: 6.5129 - val_loss: 8.2254 - val_model_loss: 1.4785 - val_model_1_loss: 1.6964 - val_model_2_loss: 0.9290 - val_model_3_loss: 0.9832 - val_model_4_loss: 1.4241 - val_model_accuracy: 0.6035 - val_model_1_accuracy: 0.5680 - val_model_2_accuracy: 0.5380 - val_model_3_accuracy: 0.6580 - val_model_4_accuracy: 0.5145 - val_loss1: 2.5895 - val_loss2: 8.3909\n","Epoch 229/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2107 - model_loss: 0.0023 - model_1_loss: 2.4835e-06 - model_2_loss: 0.0566 - model_3_loss: 0.0084 - model_4_loss: 0.0013 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6428 - loss2: 6.4162 - val_loss: 8.9331 - val_model_loss: 1.5504 - val_model_1_loss: 2.1752 - val_model_2_loss: 0.9363 - val_model_3_loss: 1.0449 - val_model_4_loss: 1.5043 - val_model_accuracy: 0.6045 - val_model_1_accuracy: 0.5550 - val_model_2_accuracy: 0.5215 - val_model_3_accuracy: 0.6625 - val_model_4_accuracy: 0.4935 - val_loss1: 2.6053 - val_loss2: 8.3852\n","Epoch 230/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5203 - model_loss: 0.0643 - model_1_loss: 0.0141 - model_2_loss: 7.6149e-04 - model_3_loss: 1.4653e-04 - model_4_loss: 1.1008e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2111 - loss2: 6.7075 - val_loss: 9.7526 - val_model_loss: 1.6487 - val_model_1_loss: 2.7196 - val_model_2_loss: 0.9580 - val_model_3_loss: 1.1135 - val_model_4_loss: 1.5838 - val_model_accuracy: 0.5985 - val_model_1_accuracy: 0.5200 - val_model_2_accuracy: 0.5085 - val_model_3_accuracy: 0.6610 - val_model_4_accuracy: 0.4875 - val_loss1: 2.6208 - val_loss2: 8.3741\n","Epoch 231/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2214 - model_loss: 0.0016 - model_1_loss: 1.4337e-04 - model_2_loss: 0.0019 - model_3_loss: 0.0010 - model_4_loss: 5.5843e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7872 - loss2: 6.4608 - val_loss: 10.5902 - val_model_loss: 1.7601 - val_model_1_loss: 3.2649 - val_model_2_loss: 0.9884 - val_model_3_loss: 1.1885 - val_model_4_loss: 1.6530 - val_model_accuracy: 0.6010 - val_model_1_accuracy: 0.5060 - val_model_2_accuracy: 0.5035 - val_model_3_accuracy: 0.6560 - val_model_4_accuracy: 0.4740 - val_loss1: 2.6350 - val_loss2: 8.3580\n","Epoch 232/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5432 - model_loss: 0.1065 - model_1_loss: 0.0110 - model_2_loss: 0.0481 - model_3_loss: 0.0010 - model_4_loss: 0.0192 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.0295 - loss2: 6.8530 - val_loss: 11.2488 - val_model_loss: 1.7821 - val_model_1_loss: 3.7484 - val_model_2_loss: 1.0175 - val_model_3_loss: 1.2591 - val_model_4_loss: 1.7049 - val_model_accuracy: 0.6000 - val_model_1_accuracy: 0.5050 - val_model_2_accuracy: 0.4985 - val_model_3_accuracy: 0.6450 - val_model_4_accuracy: 0.4675 - val_loss1: 2.6394 - val_loss2: 8.3403\n","Epoch 233/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3011 - model_loss: 0.0223 - model_1_loss: 0.0141 - model_2_loss: 0.0106 - model_3_loss: 4.0549e-04 - model_4_loss: 2.9237e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8354 - loss2: 6.7138 - val_loss: 11.8000 - val_model_loss: 1.7945 - val_model_1_loss: 4.1484 - val_model_2_loss: 1.0429 - val_model_3_loss: 1.3303 - val_model_4_loss: 1.7456 - val_model_accuracy: 0.6005 - val_model_1_accuracy: 0.5045 - val_model_2_accuracy: 0.5000 - val_model_3_accuracy: 0.6335 - val_model_4_accuracy: 0.4645 - val_loss1: 2.6441 - val_loss2: 8.3229\n","Epoch 234/300\n","1/1 [==============================] - 2s 2s/step - loss: 6.1322 - model_loss: 0.4442 - model_1_loss: 3.7523 - model_2_loss: 0.0058 - model_3_loss: 0.5557 - model_4_loss: 0.0023 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.0781 - loss2: 6.6578 - val_loss: 10.7829 - val_model_loss: 1.6246 - val_model_1_loss: 3.3509 - val_model_2_loss: 1.0693 - val_model_3_loss: 1.2304 - val_model_4_loss: 1.7835 - val_model_accuracy: 0.6075 - val_model_1_accuracy: 0.5055 - val_model_2_accuracy: 0.5070 - val_model_3_accuracy: 0.6565 - val_model_4_accuracy: 0.4610 - val_loss1: 2.6098 - val_loss2: 8.3869\n","Epoch 235/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.7306 - model_loss: 0.5444 - model_1_loss: 2.7456 - model_2_loss: 0.0258 - model_3_loss: 0.0038 - model_4_loss: 0.0028 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1469 - loss2: 6.6952 - val_loss: 9.1676 - val_model_loss: 1.4953 - val_model_1_loss: 1.9107 - val_model_2_loss: 1.0894 - val_model_3_loss: 1.1515 - val_model_4_loss: 1.8176 - val_model_accuracy: 0.5825 - val_model_1_accuracy: 0.5490 - val_model_2_accuracy: 0.5095 - val_model_3_accuracy: 0.6735 - val_model_4_accuracy: 0.4570 - val_loss1: 2.5581 - val_loss2: 8.4812\n","Epoch 236/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6897 - model_loss: 0.0393 - model_1_loss: 0.0045 - model_2_loss: 0.0376 - model_3_loss: 0.0030 - model_4_loss: 0.1670 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1896 - loss2: 6.8705 - val_loss: 8.4092 - val_model_loss: 1.6623 - val_model_1_loss: 1.3170 - val_model_2_loss: 1.0943 - val_model_3_loss: 1.0910 - val_model_4_loss: 1.5534 - val_model_accuracy: 0.4985 - val_model_1_accuracy: 0.5355 - val_model_2_accuracy: 0.5105 - val_model_3_accuracy: 0.6890 - val_model_4_accuracy: 0.4930 - val_loss1: 2.5272 - val_loss2: 8.5506\n","Epoch 237/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3463 - model_loss: 0.0011 - model_1_loss: 2.2676e-04 - model_2_loss: 0.0167 - model_3_loss: 0.0791 - model_4_loss: 7.1281e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8329 - loss2: 6.6531 - val_loss: 8.6996 - val_model_loss: 2.0431 - val_model_1_loss: 1.4697 - val_model_2_loss: 1.0869 - val_model_3_loss: 1.0185 - val_model_4_loss: 1.3945 - val_model_accuracy: 0.4665 - val_model_1_accuracy: 0.5350 - val_model_2_accuracy: 0.5120 - val_model_3_accuracy: 0.7090 - val_model_4_accuracy: 0.5405 - val_loss1: 2.5138 - val_loss2: 8.5979\n","Epoch 238/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3392 - model_loss: 8.7918e-04 - model_1_loss: 5.5283e-04 - model_2_loss: 0.0036 - model_3_loss: 1.9174e-04 - model_4_loss: 6.0513e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9772 - loss2: 6.9061 - val_loss: 9.4374 - val_model_loss: 2.4969 - val_model_1_loss: 1.8754 - val_model_2_loss: 1.0779 - val_model_3_loss: 0.9728 - val_model_4_loss: 1.3229 - val_model_accuracy: 0.4690 - val_model_1_accuracy: 0.4950 - val_model_2_accuracy: 0.5175 - val_model_3_accuracy: 0.7235 - val_model_4_accuracy: 0.5820 - val_loss1: 2.5202 - val_loss2: 8.6275\n","Epoch 239/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5779 - model_loss: 0.1085 - model_1_loss: 3.4688e-05 - model_2_loss: 0.0050 - model_3_loss: 0.0062 - model_4_loss: 0.0085 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2028 - loss2: 6.9687 - val_loss: 10.1456 - val_model_loss: 2.7793 - val_model_1_loss: 2.3295 - val_model_2_loss: 1.0733 - val_model_3_loss: 0.9427 - val_model_4_loss: 1.3212 - val_model_accuracy: 0.4655 - val_model_1_accuracy: 0.4770 - val_model_2_accuracy: 0.5200 - val_model_3_accuracy: 0.7150 - val_model_4_accuracy: 0.6045 - val_loss1: 2.5350 - val_loss2: 8.6422\n","Epoch 240/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5138 - model_loss: 2.8178e-04 - model_1_loss: 2.4636e-06 - model_2_loss: 0.0992 - model_3_loss: 0.0510 - model_4_loss: 0.0356 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9710 - loss2: 6.8439 - val_loss: 10.8389 - val_model_loss: 3.0264 - val_model_1_loss: 2.7465 - val_model_2_loss: 1.0924 - val_model_3_loss: 0.9291 - val_model_4_loss: 1.3370 - val_model_accuracy: 0.4680 - val_model_1_accuracy: 0.4850 - val_model_2_accuracy: 0.5145 - val_model_3_accuracy: 0.7045 - val_model_4_accuracy: 0.6140 - val_loss1: 2.5503 - val_loss2: 8.6459\n","Epoch 241/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3185 - model_loss: 0.0031 - model_1_loss: 4.8875e-06 - model_2_loss: 2.1247e-04 - model_3_loss: 2.2799e-04 - model_4_loss: 3.9099e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9668 - loss2: 6.6254 - val_loss: 11.5054 - val_model_loss: 3.2431 - val_model_1_loss: 3.1303 - val_model_2_loss: 1.1115 - val_model_3_loss: 0.9287 - val_model_4_loss: 1.3754 - val_model_accuracy: 0.4700 - val_model_1_accuracy: 0.4880 - val_model_2_accuracy: 0.5100 - val_model_3_accuracy: 0.6950 - val_model_4_accuracy: 0.6205 - val_loss1: 2.5690 - val_loss2: 8.6388\n","Epoch 242/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5045 - model_loss: 0.0012 - model_1_loss: 3.2338e-04 - model_2_loss: 5.3843e-04 - model_3_loss: 4.3873e-04 - model_4_loss: 3.6359e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3254 - loss2: 6.7858 - val_loss: 12.1241 - val_model_loss: 3.4341 - val_model_1_loss: 3.4680 - val_model_2_loss: 1.1341 - val_model_3_loss: 0.9382 - val_model_4_loss: 1.4260 - val_model_accuracy: 0.4700 - val_model_1_accuracy: 0.4880 - val_model_2_accuracy: 0.5085 - val_model_3_accuracy: 0.6775 - val_model_4_accuracy: 0.6205 - val_loss1: 2.5848 - val_loss2: 8.6257\n","Epoch 243/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8847 - model_loss: 3.5216e-04 - model_1_loss: 0.0420 - model_2_loss: 0.0090 - model_3_loss: 5.3002e-04 - model_4_loss: 0.3106 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 2.3254 - loss2: 7.1897 - val_loss: 12.4657 - val_model_loss: 3.6189 - val_model_1_loss: 3.6859 - val_model_2_loss: 1.1589 - val_model_3_loss: 0.9564 - val_model_4_loss: 1.3189 - val_model_accuracy: 0.4720 - val_model_1_accuracy: 0.4840 - val_model_2_accuracy: 0.5045 - val_model_3_accuracy: 0.6640 - val_model_4_accuracy: 0.6270 - val_loss1: 2.5921 - val_loss2: 8.6129\n","Epoch 244/300\n","1/1 [==============================] - 2s 2s/step - loss: 3.4045 - model_loss: 0.1419 - model_1_loss: 1.3365 - model_2_loss: 0.0708 - model_3_loss: 0.3566 - model_4_loss: 0.0805 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.1276 - loss2: 7.0892 - val_loss: 12.0393 - val_model_loss: 3.5880 - val_model_1_loss: 3.2638 - val_model_2_loss: 1.1903 - val_model_3_loss: 1.0342 - val_model_4_loss: 1.2318 - val_model_accuracy: 0.4700 - val_model_1_accuracy: 0.4900 - val_model_2_accuracy: 0.5030 - val_model_3_accuracy: 0.6150 - val_model_4_accuracy: 0.6255 - val_loss1: 2.5962 - val_loss2: 8.6609\n","Epoch 245/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5380 - model_loss: 0.0013 - model_1_loss: 2.2209e-04 - model_2_loss: 0.0014 - model_3_loss: 6.0398e-06 - model_4_loss: 0.1988 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 2.0156 - loss2: 6.5692 - val_loss: 11.6926 - val_model_loss: 3.5326 - val_model_1_loss: 2.8991 - val_model_2_loss: 1.2195 - val_model_3_loss: 1.1552 - val_model_4_loss: 1.1517 - val_model_accuracy: 0.4680 - val_model_1_accuracy: 0.4850 - val_model_2_accuracy: 0.5050 - val_model_3_accuracy: 0.5720 - val_model_4_accuracy: 0.6185 - val_loss1: 2.5995 - val_loss2: 8.6940\n","Epoch 246/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.6719 - model_loss: 0.0116 - model_1_loss: 1.3833 - model_2_loss: 0.0057 - model_3_loss: 6.6267e-05 - model_4_loss: 1.7235e-04 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8709 - loss2: 6.7111 - val_loss: 11.0299 - val_model_loss: 3.4115 - val_model_1_loss: 2.1427 - val_model_2_loss: 1.2410 - val_model_3_loss: 1.3028 - val_model_4_loss: 1.1876 - val_model_accuracy: 0.4665 - val_model_1_accuracy: 0.4765 - val_model_2_accuracy: 0.5095 - val_model_3_accuracy: 0.5330 - val_model_4_accuracy: 0.6085 - val_loss1: 2.6123 - val_loss2: 8.7635\n","Epoch 247/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6658 - model_loss: 0.1351 - model_1_loss: 3.2186e-06 - model_2_loss: 0.0023 - model_3_loss: 3.8820e-05 - model_4_loss: 1.6491e-06 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3655 - loss2: 6.9128 - val_loss: 10.5089 - val_model_loss: 3.1298 - val_model_1_loss: 1.5904 - val_model_2_loss: 1.2651 - val_model_3_loss: 1.4710 - val_model_4_loss: 1.2944 - val_model_accuracy: 0.4665 - val_model_1_accuracy: 0.4880 - val_model_2_accuracy: 0.5075 - val_model_3_accuracy: 0.5060 - val_model_4_accuracy: 0.6060 - val_loss1: 2.6351 - val_loss2: 8.8136\n","Epoch 248/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4990 - model_loss: 2.0476e-04 - model_1_loss: 0.0063 - model_2_loss: 0.0071 - model_3_loss: 3.6079e-04 - model_4_loss: 3.0200e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2665 - loss2: 7.0349 - val_loss: 10.1858 - val_model_loss: 2.8480 - val_model_1_loss: 1.2287 - val_model_2_loss: 1.2753 - val_model_3_loss: 1.6317 - val_model_4_loss: 1.4267 - val_model_accuracy: 0.4670 - val_model_1_accuracy: 0.5435 - val_model_2_accuracy: 0.5095 - val_model_3_accuracy: 0.4985 - val_model_4_accuracy: 0.5815 - val_loss1: 2.6659 - val_loss2: 8.8493\n","Epoch 249/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.4486 - model_loss: 0.7297 - model_1_loss: 0.0139 - model_2_loss: 0.0126 - model_3_loss: 0.0110 - model_4_loss: 0.0055 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.6154 - loss2: 7.3632 - val_loss: 9.5643 - val_model_loss: 2.0473 - val_model_1_loss: 1.0619 - val_model_2_loss: 1.2787 - val_model_3_loss: 1.7900 - val_model_4_loss: 1.5844 - val_model_accuracy: 0.5250 - val_model_1_accuracy: 0.6105 - val_model_2_accuracy: 0.5130 - val_model_3_accuracy: 0.4935 - val_model_4_accuracy: 0.5530 - val_loss1: 2.7162 - val_loss2: 8.8786\n","Epoch 250/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.9909 - model_loss: 0.1029 - model_1_loss: 0.2076 - model_2_loss: 0.0406 - model_3_loss: 0.4960 - model_4_loss: 0.2965 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.6667 - loss1: 2.9414 - loss2: 7.5319 - val_loss: 8.9560 - val_model_loss: 1.7686 - val_model_1_loss: 1.0120 - val_model_2_loss: 1.2707 - val_model_3_loss: 1.6301 - val_model_4_loss: 1.4367 - val_model_accuracy: 0.5615 - val_model_1_accuracy: 0.6525 - val_model_2_accuracy: 0.5180 - val_model_3_accuracy: 0.4965 - val_model_4_accuracy: 0.5820 - val_loss1: 2.7865 - val_loss2: 8.8916\n","Epoch 251/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.7726 - model_loss: 6.0796e-06 - model_1_loss: 0.7772 - model_2_loss: 0.1031 - model_3_loss: 0.0267 - model_4_loss: 0.0327 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.9194 - loss2: 7.4643 - val_loss: 8.4073 - val_model_loss: 1.5727 - val_model_1_loss: 0.9716 - val_model_2_loss: 1.2169 - val_model_3_loss: 1.4817 - val_model_4_loss: 1.3083 - val_model_accuracy: 0.5945 - val_model_1_accuracy: 0.6555 - val_model_2_accuracy: 0.5330 - val_model_3_accuracy: 0.5100 - val_model_4_accuracy: 0.6130 - val_loss1: 2.8235 - val_loss2: 8.8862\n","Epoch 252/300\n","1/1 [==============================] - 3s 3s/step - loss: 1.8982 - model_loss: 6.4769e-06 - model_1_loss: 0.0064 - model_2_loss: 2.7405e-04 - model_3_loss: 1.1921e-07 - model_4_loss: 1.0729e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.0783 - loss2: 7.0467 - val_loss: 8.0173 - val_model_loss: 1.4513 - val_model_1_loss: 0.9415 - val_model_2_loss: 1.1680 - val_model_3_loss: 1.3591 - val_model_4_loss: 1.2259 - val_model_accuracy: 0.6235 - val_model_1_accuracy: 0.6585 - val_model_2_accuracy: 0.5460 - val_model_3_accuracy: 0.5205 - val_model_4_accuracy: 0.6445 - val_loss1: 2.8557 - val_loss2: 8.8744\n","Epoch 253/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.3953 - model_loss: 0.0030 - model_1_loss: 0.3947 - model_2_loss: 0.0086 - model_3_loss: 1.5874e-05 - model_4_loss: 0.0024 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.2365 - loss2: 7.3657 - val_loss: 7.7824 - val_model_loss: 1.3941 - val_model_1_loss: 0.9305 - val_model_2_loss: 1.1314 - val_model_3_loss: 1.2708 - val_model_4_loss: 1.1853 - val_model_accuracy: 0.6480 - val_model_1_accuracy: 0.6325 - val_model_2_accuracy: 0.5695 - val_model_3_accuracy: 0.5395 - val_model_4_accuracy: 0.6715 - val_loss1: 2.8559 - val_loss2: 8.8477\n","Epoch 254/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8889 - model_loss: 2.5829e-07 - model_1_loss: 2.0682e-05 - model_2_loss: 1.0803e-04 - model_3_loss: 0.0416 - model_4_loss: 1.9868e-07 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.9742 - loss2: 7.2018 - val_loss: 7.6705 - val_model_loss: 1.3767 - val_model_1_loss: 0.9529 - val_model_2_loss: 1.1021 - val_model_3_loss: 1.1987 - val_model_4_loss: 1.1734 - val_model_accuracy: 0.6560 - val_model_1_accuracy: 0.5910 - val_model_2_accuracy: 0.5805 - val_model_3_accuracy: 0.5680 - val_model_4_accuracy: 0.6900 - val_loss1: 2.8513 - val_loss2: 8.8197\n","Epoch 255/300\n","1/1 [==============================] - 2s 2s/step - loss: 4.1406 - model_loss: 1.4024 - model_1_loss: 0.6171 - model_2_loss: 0.1219 - model_3_loss: 0.0861 - model_4_loss: 8.3664e-05 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 3.1235 - loss2: 7.0252 - val_loss: 7.7494 - val_model_loss: 1.3705 - val_model_1_loss: 1.0520 - val_model_2_loss: 1.1268 - val_model_3_loss: 1.1787 - val_model_4_loss: 1.1841 - val_model_accuracy: 0.6340 - val_model_1_accuracy: 0.5335 - val_model_2_accuracy: 0.5775 - val_model_3_accuracy: 0.5910 - val_model_4_accuracy: 0.7075 - val_loss1: 2.7968 - val_loss2: 8.7768\n","Epoch 256/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.8464 - model_loss: 2.8809e-06 - model_1_loss: 0.0024 - model_2_loss: 2.0492e-04 - model_3_loss: 0.0363 - model_4_loss: 4.7684e-07 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.9104 - loss2: 7.0451 - val_loss: 7.9487 - val_model_loss: 1.4210 - val_model_1_loss: 1.1854 - val_model_2_loss: 1.1487 - val_model_3_loss: 1.1701 - val_model_4_loss: 1.2094 - val_model_accuracy: 0.6095 - val_model_1_accuracy: 0.4995 - val_model_2_accuracy: 0.5765 - val_model_3_accuracy: 0.6135 - val_model_4_accuracy: 0.7205 - val_loss1: 2.7548 - val_loss2: 8.7348\n","Epoch 257/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7044 - model_loss: 6.6359e-06 - model_1_loss: 0.0014 - model_2_loss: 8.3256e-04 - model_3_loss: 0.0025 - model_4_loss: 1.8676e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.7092 - loss2: 6.9009 - val_loss: 8.2138 - val_model_loss: 1.5053 - val_model_1_loss: 1.3288 - val_model_2_loss: 1.1653 - val_model_3_loss: 1.1694 - val_model_4_loss: 1.2495 - val_model_accuracy: 0.5870 - val_model_1_accuracy: 0.4800 - val_model_2_accuracy: 0.5760 - val_model_3_accuracy: 0.6330 - val_model_4_accuracy: 0.7305 - val_loss1: 2.7218 - val_loss2: 8.6904\n","Epoch 258/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6127 - model_loss: 3.3650e-04 - model_1_loss: 0.0433 - model_2_loss: 0.0232 - model_3_loss: 7.2942e-05 - model_4_loss: 1.3732e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3903 - loss2: 7.0107 - val_loss: 8.4858 - val_model_loss: 1.6218 - val_model_1_loss: 1.4469 - val_model_2_loss: 1.1691 - val_model_3_loss: 1.1760 - val_model_4_loss: 1.2919 - val_model_accuracy: 0.5635 - val_model_1_accuracy: 0.4675 - val_model_2_accuracy: 0.5745 - val_model_3_accuracy: 0.6470 - val_model_4_accuracy: 0.7405 - val_loss1: 2.6951 - val_loss2: 8.6488\n","Epoch 259/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6872 - model_loss: 8.3246e-06 - model_1_loss: 0.2814 - model_2_loss: 4.3447e-05 - model_3_loss: 2.2620e-04 - model_4_loss: 6.7412e-04 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1321 - loss2: 6.7775 - val_loss: 8.6495 - val_model_loss: 1.7447 - val_model_1_loss: 1.4413 - val_model_2_loss: 1.1678 - val_model_3_loss: 1.1857 - val_model_4_loss: 1.3423 - val_model_accuracy: 0.5475 - val_model_1_accuracy: 0.4640 - val_model_2_accuracy: 0.5770 - val_model_3_accuracy: 0.6625 - val_model_4_accuracy: 0.7380 - val_loss1: 2.6743 - val_loss2: 8.6121\n","Epoch 260/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5043 - model_loss: 1.5417e-04 - model_1_loss: 0.0079 - model_2_loss: 0.0059 - model_3_loss: 2.4297e-04 - model_4_loss: 7.6492e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2791 - loss2: 7.0108 - val_loss: 8.8041 - val_model_loss: 1.8673 - val_model_1_loss: 1.4273 - val_model_2_loss: 1.1610 - val_model_3_loss: 1.1976 - val_model_4_loss: 1.3947 - val_model_accuracy: 0.5275 - val_model_1_accuracy: 0.4640 - val_model_2_accuracy: 0.5780 - val_model_3_accuracy: 0.6760 - val_model_4_accuracy: 0.7385 - val_loss1: 2.6546 - val_loss2: 8.5785\n","Epoch 261/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7685 - model_loss: 0.0216 - model_1_loss: 0.0857 - model_2_loss: 0.0951 - model_3_loss: 0.0160 - model_4_loss: 0.1174 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 2.1670 - loss2: 6.9832 - val_loss: 8.7861 - val_model_loss: 1.9657 - val_model_1_loss: 1.3813 - val_model_2_loss: 1.1048 - val_model_3_loss: 1.2141 - val_model_4_loss: 1.3762 - val_model_accuracy: 0.5225 - val_model_1_accuracy: 0.4635 - val_model_2_accuracy: 0.5900 - val_model_3_accuracy: 0.6860 - val_model_4_accuracy: 0.7365 - val_loss1: 2.6325 - val_loss2: 8.5549\n","Epoch 262/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1688 - model_loss: 0.4693 - model_1_loss: 0.0872 - model_2_loss: 0.0017 - model_3_loss: 0.0027 - model_4_loss: 1.4149e-04 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.5244 - loss2: 6.9122 - val_loss: 8.2833 - val_model_loss: 1.6083 - val_model_1_loss: 1.2854 - val_model_2_loss: 1.0560 - val_model_3_loss: 1.2303 - val_model_4_loss: 1.3615 - val_model_accuracy: 0.5490 - val_model_1_accuracy: 0.4705 - val_model_2_accuracy: 0.6040 - val_model_3_accuracy: 0.6905 - val_model_4_accuracy: 0.7370 - val_loss1: 2.6297 - val_loss2: 8.5389\n","Epoch 263/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5091 - model_loss: 4.8753e-05 - model_1_loss: 0.0013 - model_2_loss: 4.5969e-05 - model_3_loss: 3.9935e-06 - model_4_loss: 3.9736e-08 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3204 - loss2: 6.9495 - val_loss: 7.9185 - val_model_loss: 1.3597 - val_model_1_loss: 1.2022 - val_model_2_loss: 1.0183 - val_model_3_loss: 1.2475 - val_model_4_loss: 1.3510 - val_model_accuracy: 0.5735 - val_model_1_accuracy: 0.4860 - val_model_2_accuracy: 0.6110 - val_model_3_accuracy: 0.6935 - val_model_4_accuracy: 0.7390 - val_loss1: 2.6273 - val_loss2: 8.5208\n","Epoch 264/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4795 - model_loss: 2.5311e-05 - model_1_loss: 0.0286 - model_2_loss: 2.7940e-04 - model_3_loss: 3.7632e-04 - model_4_loss: 6.0200e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2416 - loss2: 6.5874 - val_loss: 7.6603 - val_model_loss: 1.1958 - val_model_1_loss: 1.1269 - val_model_2_loss: 0.9864 - val_model_3_loss: 1.2667 - val_model_4_loss: 1.3474 - val_model_accuracy: 0.6075 - val_model_1_accuracy: 0.5025 - val_model_2_accuracy: 0.6225 - val_model_3_accuracy: 0.6980 - val_model_4_accuracy: 0.7375 - val_loss1: 2.6239 - val_loss2: 8.4999\n","Epoch 265/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.0604 - model_loss: 0.5494 - model_1_loss: 0.0228 - model_2_loss: 0.0055 - model_3_loss: 6.9044e-04 - model_4_loss: 0.0032 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2575 - loss2: 7.0001 - val_loss: 7.4726 - val_model_loss: 1.0785 - val_model_1_loss: 1.0645 - val_model_2_loss: 0.9662 - val_model_3_loss: 1.2830 - val_model_4_loss: 1.3377 - val_model_accuracy: 0.6510 - val_model_1_accuracy: 0.5165 - val_model_2_accuracy: 0.6305 - val_model_3_accuracy: 0.6985 - val_model_4_accuracy: 0.7370 - val_loss1: 2.6371 - val_loss2: 8.4825\n","Epoch 266/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.2544 - model_loss: 0.0103 - model_1_loss: 0.4989 - model_2_loss: 0.1374 - model_3_loss: 0.1088 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3048 - loss2: 6.9053 - val_loss: 7.3349 - val_model_loss: 1.0967 - val_model_1_loss: 0.8973 - val_model_2_loss: 0.9322 - val_model_3_loss: 1.3257 - val_model_4_loss: 1.3318 - val_model_accuracy: 0.6795 - val_model_1_accuracy: 0.5510 - val_model_2_accuracy: 0.6550 - val_model_3_accuracy: 0.7245 - val_model_4_accuracy: 0.7335 - val_loss1: 2.6548 - val_loss2: 8.4796\n","Epoch 267/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4885 - model_loss: 0.0023 - model_1_loss: 0.0137 - model_2_loss: 3.2006e-05 - model_3_loss: 0.0044 - model_4_loss: 7.8677e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2477 - loss2: 6.8825 - val_loss: 7.4113 - val_model_loss: 1.1906 - val_model_1_loss: 0.8122 - val_model_2_loss: 0.9411 - val_model_3_loss: 1.3820 - val_model_4_loss: 1.3270 - val_model_accuracy: 0.6730 - val_model_1_accuracy: 0.6120 - val_model_2_accuracy: 0.6875 - val_model_3_accuracy: 0.7355 - val_model_4_accuracy: 0.7305 - val_loss1: 2.6693 - val_loss2: 8.4744\n","Epoch 268/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5116 - model_loss: 5.5115e-04 - model_1_loss: 0.0013 - model_2_loss: 8.0664e-06 - model_3_loss: 1.5662e-04 - model_4_loss: 1.1722e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.3673 - loss2: 6.5188 - val_loss: 7.6348 - val_model_loss: 1.3244 - val_model_1_loss: 0.7804 - val_model_2_loss: 0.9828 - val_model_3_loss: 1.4538 - val_model_4_loss: 1.3286 - val_model_accuracy: 0.6570 - val_model_1_accuracy: 0.6590 - val_model_2_accuracy: 0.6945 - val_model_3_accuracy: 0.7395 - val_model_4_accuracy: 0.7290 - val_loss1: 2.6833 - val_loss2: 8.4625\n","Epoch 269/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7108 - model_loss: 0.0178 - model_1_loss: 0.0985 - model_2_loss: 5.1879e-04 - model_3_loss: 7.8940e-04 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4860 - loss2: 6.9787 - val_loss: 7.8816 - val_model_loss: 1.4407 - val_model_1_loss: 0.7878 - val_model_2_loss: 1.0429 - val_model_3_loss: 1.5202 - val_model_4_loss: 1.3226 - val_model_accuracy: 0.6370 - val_model_1_accuracy: 0.6665 - val_model_2_accuracy: 0.6885 - val_model_3_accuracy: 0.7435 - val_model_4_accuracy: 0.7255 - val_loss1: 2.6893 - val_loss2: 8.4539\n","Epoch 270/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.1558 - model_loss: 0.3257 - model_1_loss: 0.1889 - model_2_loss: 1.9361e-04 - model_3_loss: 0.0015 - model_4_loss: 6.2032e-04 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.6096 - loss2: 6.6801 - val_loss: 7.8695 - val_model_loss: 1.2817 - val_model_1_loss: 0.8111 - val_model_2_loss: 1.1161 - val_model_3_loss: 1.5886 - val_model_4_loss: 1.3184 - val_model_accuracy: 0.6490 - val_model_1_accuracy: 0.6620 - val_model_2_accuracy: 0.6715 - val_model_3_accuracy: 0.7400 - val_model_4_accuracy: 0.7225 - val_loss1: 2.6630 - val_loss2: 8.4416\n","Epoch 271/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5086 - model_loss: 0.0343 - model_1_loss: 0.0934 - model_2_loss: 3.1924e-04 - model_3_loss: 4.3289e-05 - model_4_loss: 4.5697e-07 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1070 - loss2: 6.5416 - val_loss: 7.9419 - val_model_loss: 1.1849 - val_model_1_loss: 0.8360 - val_model_2_loss: 1.1993 - val_model_3_loss: 1.6611 - val_model_4_loss: 1.3190 - val_model_accuracy: 0.6495 - val_model_1_accuracy: 0.6600 - val_model_2_accuracy: 0.6615 - val_model_3_accuracy: 0.7385 - val_model_4_accuracy: 0.7220 - val_loss1: 2.6405 - val_loss2: 8.4283\n","Epoch 272/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5015 - model_loss: 5.3059e-04 - model_1_loss: 0.0357 - model_2_loss: 9.0137e-04 - model_3_loss: 4.7200e-04 - model_4_loss: 0.0057 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2624 - loss2: 6.5406 - val_loss: 8.1079 - val_model_loss: 1.1790 - val_model_1_loss: 0.8577 - val_model_2_loss: 1.2869 - val_model_3_loss: 1.7351 - val_model_4_loss: 1.3185 - val_model_accuracy: 0.6480 - val_model_1_accuracy: 0.6585 - val_model_2_accuracy: 0.6420 - val_model_3_accuracy: 0.7385 - val_model_4_accuracy: 0.7220 - val_loss1: 2.6202 - val_loss2: 8.4133\n","Epoch 273/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5590 - model_loss: 0.0279 - model_1_loss: 0.0583 - model_2_loss: 2.6878e-04 - model_3_loss: 2.1855e-07 - model_4_loss: 3.5495e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2705 - loss2: 6.7397 - val_loss: 8.3522 - val_model_loss: 1.2706 - val_model_1_loss: 0.8719 - val_model_2_loss: 1.3697 - val_model_3_loss: 1.8048 - val_model_4_loss: 1.3159 - val_model_accuracy: 0.6255 - val_model_1_accuracy: 0.6630 - val_model_2_accuracy: 0.6235 - val_model_3_accuracy: 0.7375 - val_model_4_accuracy: 0.7180 - val_loss1: 2.5988 - val_loss2: 8.3966\n","Epoch 274/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4742 - model_loss: 2.2002e-04 - model_1_loss: 0.0203 - model_2_loss: 0.0131 - model_3_loss: 0.0105 - model_4_loss: 1.4131e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1754 - loss2: 6.8443 - val_loss: 8.6809 - val_model_loss: 1.4573 - val_model_1_loss: 0.8836 - val_model_2_loss: 1.4408 - val_model_3_loss: 1.8752 - val_model_4_loss: 1.3145 - val_model_accuracy: 0.5840 - val_model_1_accuracy: 0.6655 - val_model_2_accuracy: 0.6105 - val_model_3_accuracy: 0.7325 - val_model_4_accuracy: 0.7150 - val_loss1: 2.5812 - val_loss2: 8.3772\n","Epoch 275/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5637 - model_loss: 5.7816e-06 - model_1_loss: 0.0014 - model_2_loss: 3.4030e-04 - model_3_loss: 4.1524e-06 - model_4_loss: 1.9907e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.4545 - loss2: 6.6937 - val_loss: 9.0781 - val_model_loss: 1.7155 - val_model_1_loss: 0.8954 - val_model_2_loss: 1.5061 - val_model_3_loss: 1.9465 - val_model_4_loss: 1.3147 - val_model_accuracy: 0.5395 - val_model_1_accuracy: 0.6695 - val_model_2_accuracy: 0.6030 - val_model_3_accuracy: 0.7275 - val_model_4_accuracy: 0.7135 - val_loss1: 2.5643 - val_loss2: 8.3548\n","Epoch 276/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3815 - model_loss: 3.3041e-04 - model_1_loss: 0.0866 - model_2_loss: 0.0031 - model_3_loss: 0.0224 - model_4_loss: 2.0483e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8666 - loss2: 6.7128 - val_loss: 9.4628 - val_model_loss: 2.0296 - val_model_1_loss: 0.8963 - val_model_2_loss: 1.5536 - val_model_3_loss: 1.9805 - val_model_4_loss: 1.3117 - val_model_accuracy: 0.5025 - val_model_1_accuracy: 0.6800 - val_model_2_accuracy: 0.5995 - val_model_3_accuracy: 0.7265 - val_model_4_accuracy: 0.7135 - val_loss1: 2.5484 - val_loss2: 8.3343\n","Epoch 277/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2077 - model_loss: 4.2019e-05 - model_1_loss: 0.0047 - model_2_loss: 9.8179e-04 - model_3_loss: 7.3988e-04 - model_4_loss: 7.7825e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7270 - loss2: 6.7391 - val_loss: 9.8679 - val_model_loss: 2.3577 - val_model_1_loss: 0.9008 - val_model_2_loss: 1.5985 - val_model_3_loss: 2.0159 - val_model_4_loss: 1.3109 - val_model_accuracy: 0.4910 - val_model_1_accuracy: 0.6825 - val_model_2_accuracy: 0.5960 - val_model_3_accuracy: 0.7260 - val_model_4_accuracy: 0.7130 - val_loss1: 2.5374 - val_loss2: 8.3115\n","Epoch 278/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4350 - model_loss: 1.2665e-04 - model_1_loss: 3.0807e-04 - model_2_loss: 9.4122e-05 - model_3_loss: 1.1881e-05 - model_4_loss: 1.6093e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.2016 - loss2: 6.6719 - val_loss: 10.2642 - val_model_loss: 2.6689 - val_model_1_loss: 0.9078 - val_model_2_loss: 1.6398 - val_model_3_loss: 2.0572 - val_model_4_loss: 1.3131 - val_model_accuracy: 0.4745 - val_model_1_accuracy: 0.6875 - val_model_2_accuracy: 0.5925 - val_model_3_accuracy: 0.7245 - val_model_4_accuracy: 0.7130 - val_loss1: 2.5258 - val_loss2: 8.2872\n","Epoch 279/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5827 - model_loss: 0.3192 - model_1_loss: 0.0125 - model_2_loss: 0.0252 - model_3_loss: 1.3061e-04 - model_4_loss: 2.9920e-05 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8076 - loss2: 6.4371 - val_loss: 11.1187 - val_model_loss: 3.4847 - val_model_1_loss: 0.9160 - val_model_2_loss: 1.6203 - val_model_3_loss: 2.0991 - val_model_4_loss: 1.3165 - val_model_accuracy: 0.4590 - val_model_1_accuracy: 0.6855 - val_model_2_accuracy: 0.5970 - val_model_3_accuracy: 0.7230 - val_model_4_accuracy: 0.7105 - val_loss1: 2.5379 - val_loss2: 8.2620\n","Epoch 280/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.0083 - model_loss: 0.5641 - model_1_loss: 0.0177 - model_2_loss: 0.0152 - model_3_loss: 6.1563e-05 - model_4_loss: 6.1049e-04 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.1498 - loss2: 6.7134 - val_loss: 10.8317 - val_model_loss: 3.2357 - val_model_1_loss: 0.9243 - val_model_2_loss: 1.5686 - val_model_3_loss: 2.1287 - val_model_4_loss: 1.3143 - val_model_accuracy: 0.4660 - val_model_1_accuracy: 0.6830 - val_model_2_accuracy: 0.6040 - val_model_3_accuracy: 0.7230 - val_model_4_accuracy: 0.7095 - val_loss1: 2.4958 - val_loss2: 8.2437\n","Epoch 281/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3088 - model_loss: 9.0676e-04 - model_1_loss: 0.0604 - model_2_loss: 0.0096 - model_3_loss: 0.0029 - model_4_loss: 0.0039 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7667 - loss2: 6.9547 - val_loss: 10.5691 - val_model_loss: 2.9961 - val_model_1_loss: 0.9379 - val_model_2_loss: 1.5171 - val_model_3_loss: 2.1596 - val_model_4_loss: 1.3165 - val_model_accuracy: 0.4755 - val_model_1_accuracy: 0.6830 - val_model_2_accuracy: 0.6100 - val_model_3_accuracy: 0.7225 - val_model_4_accuracy: 0.7080 - val_loss1: 2.4614 - val_loss2: 8.2244\n","Epoch 282/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.6423 - model_loss: 0.0031 - model_1_loss: 4.9592e-04 - model_2_loss: 0.0020 - model_3_loss: 8.3844e-05 - model_4_loss: 2.1458e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 2.5979 - loss2: 6.7514 - val_loss: 10.3242 - val_model_loss: 2.7782 - val_model_1_loss: 0.9512 - val_model_2_loss: 1.4625 - val_model_3_loss: 2.1887 - val_model_4_loss: 1.3184 - val_model_accuracy: 0.4820 - val_model_1_accuracy: 0.6825 - val_model_2_accuracy: 0.6260 - val_model_3_accuracy: 0.7225 - val_model_4_accuracy: 0.7070 - val_loss1: 2.4302 - val_loss2: 8.2005\n","Epoch 283/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.9582 - model_loss: 1.3500e-04 - model_1_loss: 0.0570 - model_2_loss: 0.4956 - model_3_loss: 1.0458 - model_4_loss: 5.8656e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.0652 - loss2: 6.5294 - val_loss: 9.5607 - val_model_loss: 2.5970 - val_model_1_loss: 0.9649 - val_model_2_loss: 1.2208 - val_model_3_loss: 1.8546 - val_model_4_loss: 1.3173 - val_model_accuracy: 0.4925 - val_model_1_accuracy: 0.6780 - val_model_2_accuracy: 0.6600 - val_model_3_accuracy: 0.7360 - val_model_4_accuracy: 0.7065 - val_loss1: 2.3914 - val_loss2: 8.2049\n","Epoch 284/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4893 - model_loss: 0.1195 - model_1_loss: 0.0115 - model_2_loss: 0.0298 - model_3_loss: 0.0301 - model_4_loss: 3.8613e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9421 - loss2: 6.5387 - val_loss: 8.6857 - val_model_loss: 2.1422 - val_model_1_loss: 0.9819 - val_model_2_loss: 1.0581 - val_model_3_loss: 1.5936 - val_model_4_loss: 1.3190 - val_model_accuracy: 0.5120 - val_model_1_accuracy: 0.6755 - val_model_2_accuracy: 0.6775 - val_model_3_accuracy: 0.7355 - val_model_4_accuracy: 0.7060 - val_loss1: 2.3612 - val_loss2: 8.2061\n","Epoch 285/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2829 - model_loss: 2.3202e-04 - model_1_loss: 0.0933 - model_2_loss: 3.7787e-05 - model_3_loss: 1.7683e-06 - model_4_loss: 0.0563 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.5934 - loss2: 6.7263 - val_loss: 8.1809 - val_model_loss: 1.7899 - val_model_1_loss: 0.9964 - val_model_2_loss: 1.0190 - val_model_3_loss: 1.4360 - val_model_4_loss: 1.3561 - val_model_accuracy: 0.5560 - val_model_1_accuracy: 0.6755 - val_model_2_accuracy: 0.6535 - val_model_3_accuracy: 0.7305 - val_model_4_accuracy: 0.7120 - val_loss1: 2.3475 - val_loss2: 8.1953\n","Epoch 286/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2965 - model_loss: 0.0091 - model_1_loss: 0.0020 - model_2_loss: 0.0018 - model_3_loss: 0.0617 - model_4_loss: 2.4008e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7879 - loss2: 6.5541 - val_loss: 7.9630 - val_model_loss: 1.5224 - val_model_1_loss: 1.0103 - val_model_2_loss: 1.0776 - val_model_3_loss: 1.3782 - val_model_4_loss: 1.3956 - val_model_accuracy: 0.5990 - val_model_1_accuracy: 0.6725 - val_model_2_accuracy: 0.6280 - val_model_3_accuracy: 0.7085 - val_model_4_accuracy: 0.7170 - val_loss1: 2.3401 - val_loss2: 8.1773\n","Epoch 287/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.1771 - model_loss: 1.2318e-06 - model_1_loss: 0.0016 - model_2_loss: 0.0028 - model_3_loss: 6.8062e-05 - model_4_loss: 0.0066 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6800 - loss2: 6.5206 - val_loss: 7.9514 - val_model_loss: 1.3448 - val_model_1_loss: 1.0241 - val_model_2_loss: 1.2028 - val_model_3_loss: 1.3704 - val_model_4_loss: 1.4321 - val_model_accuracy: 0.6335 - val_model_1_accuracy: 0.6695 - val_model_2_accuracy: 0.5995 - val_model_3_accuracy: 0.6675 - val_model_4_accuracy: 0.7240 - val_loss1: 2.3388 - val_loss2: 8.1572\n","Epoch 288/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2986 - model_loss: 3.3754e-05 - model_1_loss: 0.0015 - model_2_loss: 0.0023 - model_3_loss: 1.2318e-06 - model_4_loss: 2.3860e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9331 - loss2: 6.5577 - val_loss: 8.0825 - val_model_loss: 1.2279 - val_model_1_loss: 1.0362 - val_model_2_loss: 1.3614 - val_model_3_loss: 1.4059 - val_model_4_loss: 1.4735 - val_model_accuracy: 0.6535 - val_model_1_accuracy: 0.6695 - val_model_2_accuracy: 0.5750 - val_model_3_accuracy: 0.6265 - val_model_4_accuracy: 0.7270 - val_loss1: 2.3418 - val_loss2: 8.1356\n","Epoch 289/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3278 - model_loss: 9.4969e-06 - model_1_loss: 1.8768e-04 - model_2_loss: 0.0019 - model_3_loss: 2.1458e-06 - model_4_loss: 0.0406 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9229 - loss2: 6.4724 - val_loss: 8.2617 - val_model_loss: 1.1578 - val_model_1_loss: 1.0485 - val_model_2_loss: 1.5415 - val_model_3_loss: 1.4733 - val_model_4_loss: 1.4659 - val_model_accuracy: 0.6620 - val_model_1_accuracy: 0.6690 - val_model_2_accuracy: 0.5490 - val_model_3_accuracy: 0.5780 - val_model_4_accuracy: 0.7265 - val_loss1: 2.3378 - val_loss2: 8.1150\n","Epoch 290/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7278 - model_loss: 0.0143 - model_1_loss: 0.0083 - model_2_loss: 0.0036 - model_3_loss: 0.2271 - model_4_loss: 0.0055 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 2.2776 - loss2: 6.6058 - val_loss: 8.4015 - val_model_loss: 1.1141 - val_model_1_loss: 1.0604 - val_model_2_loss: 1.7274 - val_model_3_loss: 1.4636 - val_model_4_loss: 1.4638 - val_model_accuracy: 0.6770 - val_model_1_accuracy: 0.6685 - val_model_2_accuracy: 0.5265 - val_model_3_accuracy: 0.5770 - val_model_4_accuracy: 0.7250 - val_loss1: 2.3353 - val_loss2: 8.0927\n","Epoch 291/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2045 - model_loss: 0.0010 - model_1_loss: 4.1919e-05 - model_2_loss: 0.0012 - model_3_loss: 2.1060e-06 - model_4_loss: 1.7881e-07 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7601 - loss2: 6.4430 - val_loss: 8.5539 - val_model_loss: 1.0942 - val_model_1_loss: 1.0697 - val_model_2_loss: 1.8997 - val_model_3_loss: 1.4517 - val_model_4_loss: 1.4682 - val_model_accuracy: 0.6850 - val_model_1_accuracy: 0.6690 - val_model_2_accuracy: 0.5095 - val_model_3_accuracy: 0.5770 - val_model_4_accuracy: 0.7255 - val_loss1: 2.3335 - val_loss2: 8.0713\n","Epoch 292/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.5308 - model_loss: 1.6524e-04 - model_1_loss: 5.7378e-04 - model_2_loss: 0.2254 - model_3_loss: 0.0543 - model_4_loss: 4.8595e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8584 - loss2: 6.4217 - val_loss: 8.3833 - val_model_loss: 1.0924 - val_model_1_loss: 1.0804 - val_model_2_loss: 1.7451 - val_model_3_loss: 1.4301 - val_model_4_loss: 1.4714 - val_model_accuracy: 0.6960 - val_model_1_accuracy: 0.6665 - val_model_2_accuracy: 0.5180 - val_model_3_accuracy: 0.5855 - val_model_4_accuracy: 0.7255 - val_loss1: 2.3219 - val_loss2: 8.0577\n","Epoch 293/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2893 - model_loss: 9.8756e-05 - model_1_loss: 2.3322e-04 - model_2_loss: 7.7538e-05 - model_3_loss: 0.0036 - model_4_loss: 4.3169e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.9171 - loss2: 6.5334 - val_loss: 8.2486 - val_model_loss: 1.1019 - val_model_1_loss: 1.0899 - val_model_2_loss: 1.6157 - val_model_3_loss: 1.4070 - val_model_4_loss: 1.4770 - val_model_accuracy: 0.7030 - val_model_1_accuracy: 0.6645 - val_model_2_accuracy: 0.5240 - val_model_3_accuracy: 0.5975 - val_model_4_accuracy: 0.7265 - val_loss1: 2.3099 - val_loss2: 8.0424\n","Epoch 294/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.7795 - model_loss: 0.0016 - model_1_loss: 0.0014 - model_2_loss: 0.5160 - model_3_loss: 0.0172 - model_4_loss: 0.0210 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7765 - loss2: 6.6828 - val_loss: 7.9658 - val_model_loss: 1.1160 - val_model_1_loss: 1.1026 - val_model_2_loss: 1.3124 - val_model_3_loss: 1.3773 - val_model_4_loss: 1.5091 - val_model_accuracy: 0.7050 - val_model_1_accuracy: 0.6615 - val_model_2_accuracy: 0.5655 - val_model_3_accuracy: 0.6130 - val_model_4_accuracy: 0.7280 - val_loss1: 2.2935 - val_loss2: 8.0317\n","Epoch 295/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.1919 - model_loss: 1.0927e-05 - model_1_loss: 4.9348e-05 - model_2_loss: 2.5330e-05 - model_3_loss: 5.3270e-04 - model_4_loss: 6.7320e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7608 - loss2: 6.2167 - val_loss: 7.8893 - val_model_loss: 1.1349 - val_model_1_loss: 1.1122 - val_model_2_loss: 1.2097 - val_model_3_loss: 1.3468 - val_model_4_loss: 1.5453 - val_model_accuracy: 0.7065 - val_model_1_accuracy: 0.6585 - val_model_2_accuracy: 0.5940 - val_model_3_accuracy: 0.6365 - val_model_4_accuracy: 0.7335 - val_loss1: 2.2790 - val_loss2: 8.0184\n","Epoch 296/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.2596 - model_loss: 0.0032 - model_1_loss: 1.3510e-05 - model_2_loss: 3.4806e-05 - model_3_loss: 1.0494e-04 - model_4_loss: 8.0663e-06 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8710 - loss2: 6.4164 - val_loss: 7.9693 - val_model_loss: 1.1552 - val_model_1_loss: 1.1208 - val_model_2_loss: 1.2545 - val_model_3_loss: 1.3235 - val_model_4_loss: 1.5817 - val_model_accuracy: 0.7060 - val_model_1_accuracy: 0.6570 - val_model_2_accuracy: 0.6115 - val_model_3_accuracy: 0.6485 - val_model_4_accuracy: 0.7340 - val_loss1: 2.2667 - val_loss2: 8.0030\n","Epoch 297/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.3563 - model_loss: 2.2054e-06 - model_1_loss: 0.0063 - model_2_loss: 0.0018 - model_3_loss: 0.0976 - model_4_loss: 2.4635e-05 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.8633 - loss2: 6.3764 - val_loss: 8.1158 - val_model_loss: 1.1754 - val_model_1_loss: 1.1305 - val_model_2_loss: 1.3782 - val_model_3_loss: 1.2874 - val_model_4_loss: 1.6198 - val_model_accuracy: 0.7055 - val_model_1_accuracy: 0.6560 - val_model_2_accuracy: 0.6140 - val_model_3_accuracy: 0.6800 - val_model_4_accuracy: 0.7355 - val_loss1: 2.2507 - val_loss2: 7.9853\n","Epoch 298/300\n","1/1 [==============================] - 2s 2s/step - loss: 2.3514 - model_loss: 0.0024 - model_1_loss: 5.3895e-05 - model_2_loss: 3.2544e-04 - model_3_loss: 4.3023e-04 - model_4_loss: 1.0641 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 1.9438 - loss2: 6.2428 - val_loss: 7.9454 - val_model_loss: 1.1903 - val_model_1_loss: 1.1407 - val_model_2_loss: 1.5438 - val_model_3_loss: 1.2860 - val_model_4_loss: 1.2820 - val_model_accuracy: 0.7080 - val_model_1_accuracy: 0.6535 - val_model_2_accuracy: 0.6150 - val_model_3_accuracy: 0.7000 - val_model_4_accuracy: 0.6975 - val_loss1: 2.2013 - val_loss2: 8.0395\n","Epoch 299/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.1776 - model_loss: 3.3238e-05 - model_1_loss: 5.3875e-04 - model_2_loss: 1.6173e-05 - model_3_loss: 1.6444e-04 - model_4_loss: 6.1591e-07 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.7206 - loss2: 6.3315 - val_loss: 8.1358 - val_model_loss: 1.2054 - val_model_1_loss: 1.1506 - val_model_2_loss: 1.7264 - val_model_3_loss: 1.3106 - val_model_4_loss: 1.2606 - val_model_accuracy: 0.7120 - val_model_1_accuracy: 0.6550 - val_model_2_accuracy: 0.5980 - val_model_3_accuracy: 0.7155 - val_model_4_accuracy: 0.6185 - val_loss1: 2.1575 - val_loss2: 8.0706\n","Epoch 300/300\n","1/1 [==============================] - 2s 2s/step - loss: 1.4004 - model_loss: 1.2054e-04 - model_1_loss: 5.3541e-04 - model_2_loss: 0.2482 - model_3_loss: 3.5356e-04 - model_4_loss: 0.0025 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 1.6508 - loss2: 6.4649 - val_loss: 8.4357 - val_model_loss: 1.2177 - val_model_1_loss: 1.1606 - val_model_2_loss: 1.7515 - val_model_3_loss: 1.3522 - val_model_4_loss: 1.4907 - val_model_accuracy: 0.7120 - val_model_1_accuracy: 0.6530 - val_model_2_accuracy: 0.5940 - val_model_3_accuracy: 0.7195 - val_model_4_accuracy: 0.5340 - val_loss1: 2.1176 - val_loss2: 8.0847\n","Epoch 00268: early stopping and save the model\n"]}],"source":["#construct joint training for the five base models\n","input_size = (100, 100, 3)\n","model0 = create_AlexNet(input_shape=input_size, num_classes=2, random_seed=1)\n","model1 = create_AlexNet(input_shape=input_size, num_classes=2, random_seed=2)\n","model2 = create_AlexNet(input_shape=input_size, num_classes=2, random_seed=3)\n","model3 = create_AlexNet(input_shape=input_size, num_classes=2, random_seed=4)\n","model4 = create_AlexNet(input_shape=input_size, num_classes=2, random_seed=5)\n","allinputs = keras.Input(shape=input_size)\n","output0, feature_maps0 = model0(allinputs)\n","output1, feature_maps1 = model1(allinputs)\n","output2, feature_maps2 = model2(allinputs)\n","output3, feature_maps3 = model3(allinputs)\n","output4, feature_maps4 = model4(allinputs)\n","model_train = keras.Model(\n","    inputs=allinputs, outputs=[output0, output1, output2, output3, output4])\n","\n","#implement distance loss\n","loss1, loss2, loss = cosine_euclidean_sum_loss(x=[feature_maps0, feature_maps1, feature_maps2, feature_maps3, feature_maps4], \n","                                      cosine_weight=0.5, euclidean_weight=0.05, mask=True, max_norm=False)\n","\n","model_train.add_loss(loss)\n","model_train.add_metric(loss1, name=\"loss1\", aggregation='mean')\n","model_train.add_metric(loss2, name=\"loss2\", aggregation='mean')\n","\n","model_train.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                    loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'],\n","                    metrics=['accuracy'])\n","\n","#construct training and validation samples\n","train_sequence = KGTdata(x_train, y_train, batch_size=10, train=True)\n","validation_sequence = KGTdata(x_val, y_val, batch_size=10, train=False)\n","\n","#training\n","history = model_train.fit(\n","    train_sequence,\n","    epochs=300,\n","    validation_data=validation_sequence,\n","    #validation_steps=36,\n","    callbacks=CustomEarlyStoppingAndSave(\n","        save_path='100_samples_seed_fix.h5',\n","        patience=10))\n","frame = pd.DataFrame({\n","    'loss':\n","    history.history['loss'],\n","    'loss1':\n","    history.history['loss1'],\n","    'loss2':\n","    history.history['loss2'],\n","    'model_0_loss':\n","    history.history['model_loss'],\n","    'model_1_loss':\n","    history.history['model_1_loss'],\n","    'model_2_loss':\n","    history.history['model_2_loss'],\n","    'model_3_loss':\n","    history.history['model_3_loss'],\n","    'model_4_loss':\n","    history.history['model_4_loss'],\n","    'model_0_accuracy':\n","    history.history['model_accuracy'],\n","    'model_1_accuracy':\n","    history.history['model_1_accuracy'],\n","    'model_2_accuracy':\n","    history.history['model_2_accuracy'],\n","    'model_3_accuracy':\n","    history.history['model_3_accuracy'],\n","    'model_4_accuracy':\n","    history.history['model_4_accuracy'],\n","    'val_loss':\n","    history.history['val_loss'],\n","    'val_loss1':\n","    history.history['val_loss1'],\n","    'val_loss2':\n","    history.history['val_loss2'],\n","    'val_model_0_loss':\n","    history.history['val_model_loss'],\n","    'val_model_1_loss':\n","    history.history['val_model_1_loss'],\n","    'val_model_2_loss':\n","    history.history['val_model_2_loss'],\n","    'val_model_3_loss':\n","    history.history['val_model_3_loss'],\n","    'val_model_4_loss':\n","    history.history['val_model_4_loss'],\n","    'val_model_0_accuracy':\n","    history.history['val_model_accuracy'],\n","    'val_model_1_accuracy':\n","    history.history['val_model_1_accuracy'],\n","    'val_model_2_accuracy':\n","    history.history['val_model_2_accuracy'],\n","    'val_model_3_accuracy':\n","    history.history['val_model_3_accuracy'],\n","    'val_model_4_accuracy':\n","    history.history['val_model_4_accuracy'],\n","})\n","#frame.to_excel('table_{numsample}_samples_seed_{numseed}.xlsx'.format(numsample=100, numseed='fix'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8Q68bw0VAfd","executionInfo":{"status":"ok","timestamp":1651080072426,"user_tz":-120,"elapsed":7136,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"00ac575a-1076-40bd-d975-154cfeec7be2"},"outputs":[{"output_type":"stream","name":"stdout","text":["408/408 [==============================] - 7s 14ms/step - loss: 5.6514 - model_loss: 0.8802 - model_1_loss: 0.6576 - model_2_loss: 0.6181 - model_3_loss: 0.9143 - model_4_loss: 0.8411 - model_accuracy: 0.6849 - model_1_accuracy: 0.6766 - model_2_accuracy: 0.7407 - model_3_accuracy: 0.7824 - model_4_accuracy: 0.7682 - loss1: 2.6300 - loss2: 8.4899\n"]}],"source":["#evaluation of the five base models\n","evaluate = model_train.evaluate(x_test,[keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test)],batch_size=10)\n","evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p79zKgdTxTgO","executionInfo":{"status":"ok","timestamp":1651080076570,"user_tz":-120,"elapsed":4146,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"ec34798e-9dc7-4e3e-a708-bd0f45dcdb98"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7696463654223968"]},"metadata":{},"execution_count":12}],"source":["#soft voting ensemble\n","def SoftVotingEnsemble(model, x, y):\n","  data_size = x.shape[0]\n","  predictions = tf.argmax(tf.reduce_mean(model.predict(x), axis = 0),axis=1)\n","  accuracy = np.sum(\n","     predictions == y) / data_size\n","  return accuracy\n","SoftVotingEnsemble(model_train, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ML_FZOLCe79"},"outputs":[],"source":["class eCustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(eCustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_accuracy') \n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        #self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXwnG-CQCfbJ"},"outputs":[],"source":["class eKGTdata(keras.utils.Sequence):\n","    def __init__(self, data_x, data_y, batch_size, train):\n","      self.data_x = data_x\n","      self.data_y = data_y\n","      self.train = train\n","      self.batch_size = batch_size\n","\n","    def __len__(self):\n","      return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","      batch_x = self.data_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n","                            \n","      batch_y = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n","      if self.train == True:\n","          batch_x = Data_Aug(batch_x)\n","\n","      batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","      batch_y = keras.utils.to_categorical(batch_y, 2)\n","      return batch_x, batch_y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oql4eIoXC5mF","executionInfo":{"status":"ok","timestamp":1651081812201,"user_tz":-120,"elapsed":111933,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"eaffc4f9-127b-43a2-d7f9-d43000547feb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1/1 [==============================] - 4s 4s/step - loss: 0.6336 - accuracy: 0.5000 - val_loss: 5.5424 - val_accuracy: 0.5800\n","Epoch 2/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 7.3517 - val_accuracy: 0.6070\n","Epoch 3/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 7.1440 - val_accuracy: 0.6250\n","Epoch 4/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 6.4093 - val_accuracy: 0.6325\n","Epoch 5/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 5.4205 - val_accuracy: 0.6410\n","Epoch 6/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 5.1405 - val_accuracy: 0.6395\n","Epoch 7/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.7129 - val_accuracy: 0.6465\n","Epoch 8/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 4.6513 - val_accuracy: 0.6385\n","Epoch 9/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 4.4600 - val_accuracy: 0.6400\n","Epoch 10/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.1929 - val_accuracy: 0.6440\n","Epoch 11/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.8366 - val_accuracy: 0.6460\n","Epoch 12/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.2984 - accuracy: 0.8333 - val_loss: 3.7573 - val_accuracy: 0.6460\n","Epoch 13/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 3.5556 - val_accuracy: 0.6465\n","Epoch 14/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 3.3766 - val_accuracy: 0.6470\n","Epoch 15/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 3.2489 - val_accuracy: 0.6490\n","Epoch 16/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1165 - val_accuracy: 0.6490\n","Epoch 17/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.9763 - val_accuracy: 0.6495\n","Epoch 18/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.7945 - val_accuracy: 0.6540\n","Epoch 19/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.7135 - val_accuracy: 0.6560\n","Epoch 20/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.6310 - val_accuracy: 0.6575\n","Epoch 21/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.5524 - val_accuracy: 0.6605\n","Epoch 22/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.4807 - val_accuracy: 0.6615\n","Epoch 23/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 2.4278 - val_accuracy: 0.6685\n","Epoch 24/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.3737 - val_accuracy: 0.6720\n","Epoch 25/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3238 - val_accuracy: 0.6760\n","Epoch 26/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.2860 - val_accuracy: 0.6770\n","Epoch 27/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.2242 - val_accuracy: 0.6810\n","Epoch 28/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.1837 - val_accuracy: 0.6825\n","Epoch 29/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.1604 - val_accuracy: 0.6855\n","Epoch 30/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.1303 - val_accuracy: 0.6890\n","Epoch 31/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 2.1031 - val_accuracy: 0.6885\n","Epoch 32/50\n","1/1 [==============================] - 2s 2s/step - loss: 9.3564e-04 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.6935\n","Epoch 33/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.0571 - val_accuracy: 0.6940\n","Epoch 34/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 2.0346 - val_accuracy: 0.6970\n","Epoch 35/50\n","1/1 [==============================] - 2s 2s/step - loss: 6.8185e-04 - accuracy: 1.0000 - val_loss: 2.0143 - val_accuracy: 0.7005\n","Epoch 36/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.9800 - val_accuracy: 0.7020\n","Epoch 37/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.9547 - val_accuracy: 0.7035\n","Epoch 38/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.1061 - accuracy: 1.0000 - val_loss: 1.9222 - val_accuracy: 0.7065\n","Epoch 39/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.8927 - val_accuracy: 0.7100\n","Epoch 40/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.8683 - val_accuracy: 0.7110\n","Epoch 41/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.8421 - val_accuracy: 0.7135\n","Epoch 42/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.8135 - val_accuracy: 0.7160\n","Epoch 43/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7883 - val_accuracy: 0.7160\n","Epoch 44/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7690 - val_accuracy: 0.7190\n","Epoch 45/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.7511 - val_accuracy: 0.7225\n","Epoch 46/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 1.7339 - val_accuracy: 0.7235\n","Epoch 47/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.7245 - val_accuracy: 0.7265\n","Epoch 48/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.1299 - accuracy: 0.8333 - val_loss: 1.7069 - val_accuracy: 0.7275\n","Epoch 49/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6881 - val_accuracy: 0.7305\n","Epoch 50/50\n","1/1 [==============================] - 2s 2s/step - loss: 0.1495 - accuracy: 0.8333 - val_loss: 1.6803 - val_accuracy: 0.7300\n","Epoch 00049: early stopping and save the model\n","408/408 [==============================] - 4s 10ms/step - loss: 0.9848 - accuracy: 0.7657\n"]}],"source":["#feature fusion model\n","input_size = (100, 100, 3)\n","model_path = '100_samples_seed_fix.h5'\n","model = keras.models.load_model(model_path)\n","extractor_1 = keras.models.Model(inputs=model.layers[1].inputs,outputs=model.layers[1].layers[12].output)\n","extractor_2 = keras.models.Model(inputs=model.layers[2].inputs,outputs=model.layers[2].layers[12].output)\n","extractor_3 = keras.models.Model(inputs=model.layers[3].inputs,outputs=model.layers[3].layers[12].output)\n","extractor_4 = keras.models.Model(inputs=model.layers[4].inputs,outputs=model.layers[4].layers[12].output)\n","extractor_5 = keras.models.Model(inputs=model.layers[5].inputs,outputs=model.layers[5].layers[12].output)\n","extractor_1.trainable = False\n","extractor_2.trainable = False\n","extractor_3.trainable = False\n","extractor_4.trainable = False\n","extractor_5.trainable = False\n","inputs = keras.Input(shape = input_size)\n","features_1 = extractor_1(inputs, training = False)\n","features_2 = extractor_2(inputs, training = False)\n","features_3 = extractor_3(inputs, training = False)\n","features_4 = extractor_4(inputs, training = False)\n","features_5 = extractor_5(inputs, training = False)\n","\n","x = keras.layers.Concatenate(axis=-1)([features_1,features_2,features_3,features_4,features_5])\n","\n","x = keras.layers.Flatten()(x)\n","x = keras.layers.Dense(128,  name='dense_100')(x)\n","x = keras.layers.BatchNormalization()(x)\n","x = keras.layers.Activation('relu')(x)\n","x = keras.layers.Dropout(0.5)(x)\n","outputs = keras.layers.Dense(2, activation='softmax', name='dense_101')(x)\n","ensemble = keras.Model(inputs = inputs, outputs = outputs)\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","train_sequence = eKGTdata(x_train, y_train, batch_size=10, train=True)\n","validation_sequence = eKGTdata(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=50,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FH_Ry7tpC_G_","executionInfo":{"status":"ok","timestamp":1651081860688,"user_tz":-120,"elapsed":48498,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"142a9f59-3ddd-4154-fa55-4560b50115fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6991 - val_accuracy: 0.7280\n","Epoch 2/20\n","1/1 [==============================] - 2s 2s/step - loss: 5.6794e-04 - accuracy: 1.0000 - val_loss: 1.7030 - val_accuracy: 0.7270\n","Epoch 3/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.7001 - val_accuracy: 0.7265\n","Epoch 4/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6946 - val_accuracy: 0.7255\n","Epoch 5/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.6876 - val_accuracy: 0.7260\n","Epoch 6/20\n","1/1 [==============================] - 2s 2s/step - loss: 6.6520e-04 - accuracy: 1.0000 - val_loss: 1.6756 - val_accuracy: 0.7255\n","Epoch 7/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6623 - val_accuracy: 0.7240\n","Epoch 8/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 1.6455 - val_accuracy: 0.7205\n","Epoch 9/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6267 - val_accuracy: 0.7200\n","Epoch 10/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.6111 - val_accuracy: 0.7135\n","Epoch 11/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5935 - val_accuracy: 0.7120\n","Epoch 12/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5754 - val_accuracy: 0.7100\n","Epoch 13/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.5658 - val_accuracy: 0.7110\n","Epoch 14/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.5586 - val_accuracy: 0.7040\n","Epoch 15/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5499 - val_accuracy: 0.7020\n","Epoch 16/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.5436 - val_accuracy: 0.6975\n","Epoch 17/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.5391 - val_accuracy: 0.6970\n","Epoch 18/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.5334 - val_accuracy: 0.6940\n","Epoch 19/20\n","1/1 [==============================] - 2s 2s/step - loss: 7.5658e-04 - accuracy: 1.0000 - val_loss: 1.5291 - val_accuracy: 0.6940\n","Epoch 20/20\n","1/1 [==============================] - 2s 2s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5244 - val_accuracy: 0.6945\n","Epoch 00001: early stopping and save the model\n","408/408 [==============================] - 4s 10ms/step - loss: 1.0014 - accuracy: 0.7642\n"]}],"source":["#finetuning\n","extractor_1.trainable = True\n","extractor_2.trainable = True\n","extractor_3.trainable = True\n","extractor_4.trainable = True\n","extractor_5.trainable = True\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","#train_sequence = ecifar10data(sampled_x_train, sampled_y_train, batch_size=10, train=False)\n","#validation_sequence = ecifar10data(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=20,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"y1W3vPZQppO3","executionInfo":{"status":"ok","timestamp":1651081863975,"user_tz":-120,"elapsed":3289,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"03bd7f96-0728-4c35-aa04-488f19d95fbb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'              precision    recall  f1-score   support\\n\\n           0     0.7676    0.7698    0.7687      2072\\n           1     0.7608    0.7585    0.7596      2000\\n\\n    accuracy                         0.7642      4072\\n   macro avg     0.7642    0.7641    0.7642      4072\\nweighted avg     0.7642    0.7642    0.7642      4072\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}],"source":["#f1 score\n","predict = tf.argmax(ensemble.predict(x_test),axis=-1)\n","classification_report(y_test, predict,digits=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uglJj7xnC9Wm"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"BSDAlexNetEX.ipynb","provenance":[],"mount_file_id":"1WfvMxxFuCeSMgvvRqOO_5I6ApH1MBm9U","authorship_tag":"ABX9TyMiO5DttC+WfqQ4/tu38q2D"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}