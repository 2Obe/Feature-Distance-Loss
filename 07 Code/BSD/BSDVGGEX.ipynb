{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650974448577,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"},"user_tz":-120},"id":"tt00VOZ_d5dq","outputId":"fc5adbd5-a88b-45ee-eec4-08140f8e61c6"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n!unzip '/content/drive/MyDrive/KGT/KGT_validation.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/KGT_test.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/100_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/50_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/20_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/10_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/5_samples.zip' -d '/content'\\n!unzip '/content/drive/MyDrive/KGT/3_samples.zip' -d '/content'\\n\""]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["#unzip BSD dataset\n","!unzip '/content/drive/MyDrive/KGT/KGT_validation.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/KGT_test.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/100_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/50_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/20_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/10_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/5_samples.zip' -d '/content'\n","!unzip '/content/drive/MyDrive/KGT/3_samples.zip' -d '/content'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JlirJGkod7y0"},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","from tensorflow import keras\n","from sklearn import model_selection\n","from sklearn.metrics import classification_report\n","import imgaug.augmenters as iaa\n","import imgaug as ia\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TGGKlSyFBJn"},"outputs":[],"source":["ia.seed(1)\n","def Data_Aug(samples):\n","    randomaug = iaa.Sometimes(\n","        0.5,\n","        iaa.OneOf([\n","            iaa.Sequential([\n","                iaa.AllChannelsCLAHE(clip_limit=(1, 10)),\n","                iaa.Affine(rotate=(-5, 5))\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(translate_percent={\n","                    \"x\": (-0.2, 0.2),\n","                    \"y\": (-0.2, 0.2)\n","                }),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(rotate=(-10, 10)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.PerspectiveTransform(scale=(0, 0.15)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ])\n","        ]))\n","\n","\n","    return randomaug.augment_images(samples)\n","\n","def resize_images(imgs, hight, width):\n","    seq = iaa.Resize({\"height\": hight, \"width\": width})\n","    aug = seq.augment_images(imgs)\n","    return aug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RJ3uDY9FgNZ"},"outputs":[],"source":["#load BSD dataset\n","def load_data(dir_path, labels_dict):\n","  all_names = os.listdir(dir_path)\n","  data_x = []\n","  data_y = []\n","  for name in all_names:\n","    img = keras.preprocessing.image.load_img(os.path.join(dir_path, name), target_size=(100,100))\n","    img = keras.preprocessing.image.img_to_array(img,dtype='uint8')\n","    data_x.append(img)\n","    lab = labels_dict[name[:1]]\n","    data_y.append(lab)\n","  data_x = np.array(data_x)\n","  data_y = np.array(data_y)\n","  return data_x, data_y\n","class KGTdata(keras.utils.Sequence):\n","    def __init__(self, data_x, data_y, batch_size, train):\n","      self.data_x = data_x\n","      self.data_y = data_y\n","      self.train = train\n","      self.batch_size = batch_size\n","\n","    def __len__(self):\n","      return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","      batch_x = self.data_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n","                            \n","      batch_y = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n","      if self.train == True:\n","          batch_x = Data_Aug(batch_x)\n","\n","      batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","      batch_y = keras.utils.to_categorical(batch_y, 2)\n","      return batch_x, [batch_y, batch_y, batch_y, batch_y, batch_y]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4U_n_3bce9u4"},"outputs":[],"source":["#save the best model during training \n","class CustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(CustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_model_accuracy') + logs.get(\n","            'val_model_1_accuracy') + logs.get(\n","                'val_model_2_accuracy') \n","                #+ logs.get(\n","                 #   'val_model_3_accuracy') + logs.get('val_model_4_accuracy')\n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1BPrwTrBVE2"},"outputs":[],"source":["#Cosine&Euclidean distance loss\n","def descriptor(X, mask = False, max_norm = False):\n","  X = tf.reduce_mean(X, axis=3)\n","  if mask:\n","    mean_X = tf.reduce_mean(X, axis = [1,2], keepdims= True)\n","    X = tf.where(X > mean_X, X , tf.zeros_like(X, dtype=tf.float32))\n","  if max_norm:\n","    max_X=tf.reduce_max(X, axis = [1,2], keepdims= True)\n","    X = tf.math.divide_no_nan(X, max_X)\n","  return X \n","  \n","def compute_euclidean_sum(X, Y):\n","  L2_distance = tf.reduce_mean(tf.exp(-(X - Y)**2), axis= [1,2])\n","  return tf.reduce_mean(L2_distance)\n","\n","def compute_cosine_sum(X, Y):\n","  X = tf.reshape(X, [tf.shape(X)[0], -1])\n","  Y = tf.reshape(Y, [tf.shape(Y)[0], -1])\n","  loss = -keras.losses.cosine_similarity(X,Y,axis=-1)\n","  return tf.reduce_mean(loss)\n","\n","def cosine_euclidean_sum_loss(x, cosine_weight, euclidean_weight, mask, max_norm):\n","  descriptor0 = descriptor(x[0], mask=mask, max_norm=max_norm)\n","  descriptor1 = descriptor(x[1], mask=mask, max_norm=max_norm)\n","  descriptor2 = descriptor(x[2], mask=mask, max_norm=max_norm)\n","  descriptor3 = descriptor(x[3], mask=mask, max_norm=max_norm)\n","  descriptor4 = descriptor(x[4], mask=mask, max_norm=max_norm)\n","  cosine_sum = compute_cosine_sum(descriptor0, descriptor1)+compute_cosine_sum(descriptor0, descriptor2)+compute_cosine_sum(descriptor0, descriptor3)+compute_cosine_sum(descriptor0, descriptor4)+compute_cosine_sum(descriptor1, descriptor2)+compute_cosine_sum(descriptor1, descriptor3)+compute_cosine_sum(descriptor1, descriptor4)+compute_cosine_sum(descriptor2, descriptor3)+compute_cosine_sum(descriptor2, descriptor4)+compute_cosine_sum(descriptor3, descriptor4)\n","  euclidean_sum = compute_euclidean_sum(descriptor0, descriptor1)+compute_euclidean_sum(descriptor0, descriptor2)+compute_euclidean_sum(descriptor0, descriptor3)+compute_euclidean_sum(descriptor0, descriptor4)+compute_euclidean_sum(descriptor1, descriptor2)+compute_euclidean_sum(descriptor1, descriptor3)+compute_euclidean_sum(descriptor1, descriptor4)+compute_euclidean_sum(descriptor2, descriptor3)+compute_euclidean_sum(descriptor2, descriptor4)+compute_euclidean_sum(descriptor3, descriptor4)\n","  return cosine_sum, euclidean_sum, cosine_weight*cosine_sum+euclidean_weight*euclidean_sum  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMRptakCHOr_"},"outputs":[],"source":["#create single VGG model\n","def create_VGGNet(input_shape, num_classes,  random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  x = keras.layers.Conv2D(64, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(64, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.2)(x)\n","\n","  x = keras.layers.Conv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.3)(x)\n","  \n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.4)(x)\n","\n","\n","    \n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  p3 = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.5)(p3)\n","\n","\n"," \n","   \n","  '''  \n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.5)(x) \n","  '''\n","  \n"," \n","\n","  #x = keras.layers.GlobalAveragePooling2D()(x)\n","  x = keras.layers.Flatten()(x)\n","  x = keras.layers.Dense(128,  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Dropout(0.5)(x)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n","  return keras.Model(inputs=inputs, outputs=[outputs, p3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X8mni5GQeq_2"},"outputs":[],"source":["#load training, validation and testing images\n","training_data_path = '100_samples'\n","validation_data_path = 'KGT_validation'\n","test_data_path = 'KGT_test'\n","labels_dict = {'N': 0, 'P': 1}\n","x_train, y_train = load_data(training_data_path, labels_dict)\n","x_val, y_val = load_data(validation_data_path, labels_dict)\n","x_test, y_test = load_data(test_data_path, labels_dict)\n","_, x_val, _, y_val = model_selection.train_test_split(\n","    x_val,\n","    y_val,\n","    test_size=2000,\n","    random_state=0,\n","    stratify=y_val)\n","x_test = x_test/255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nf634qPVt_Mq","outputId":"666376d5-267d-44b0-f2c0-64ee404f1079"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/300\n","1/1 [==============================] - 18s 18s/step - loss: 5.8423 - model_loss: 1.3062 - model_1_loss: 0.7544 - model_2_loss: 1.3415 - model_3_loss: 1.0327 - model_4_loss: 1.4075 - model_accuracy: 0.3333 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.5000 - model_3_accuracy: 0.5000 - model_4_accuracy: 0.3333 - loss1: 8.1612 - loss2: 8.6382 - val_loss: 6.1463 - val_model_loss: 1.2788 - val_model_1_loss: 0.7739 - val_model_2_loss: 1.9419 - val_model_3_loss: 0.9599 - val_model_4_loss: 1.1918 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4775 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.5115 - val_model_4_accuracy: 0.5040 - val_loss1: 9.4448 - val_loss2: 9.8417\n","Epoch 2/300\n","1/1 [==============================] - 6s 6s/step - loss: 3.7640 - model_loss: 0.8167 - model_1_loss: 0.5443 - model_2_loss: 1.0370 - model_3_loss: 0.5156 - model_4_loss: 0.8504 - model_accuracy: 0.5000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.3333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.6667 - loss1: 7.9957 - loss2: 8.5593 - val_loss: 13.7092 - val_model_loss: 3.1637 - val_model_1_loss: 3.5275 - val_model_2_loss: 3.4873 - val_model_3_loss: 0.9185 - val_model_4_loss: 2.6122 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4670 - val_model_4_accuracy: 0.5040 - val_loss1: 9.4457 - val_loss2: 9.6208\n","Epoch 3/300\n","1/1 [==============================] - 6s 6s/step - loss: 4.6430 - model_loss: 0.3948 - model_1_loss: 1.8778 - model_2_loss: 1.2225 - model_3_loss: 0.3980 - model_4_loss: 0.7500 - model_accuracy: 1.0000 - model_1_accuracy: 0.1667 - model_2_accuracy: 0.1667 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.6667 - loss1: 7.7505 - loss2: 8.7676 - val_loss: 20.3722 - val_model_loss: 9.5650 - val_model_1_loss: 1.0706 - val_model_2_loss: 1.5661 - val_model_3_loss: 2.2890 - val_model_4_loss: 5.8816 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4825 - val_model_2_accuracy: 0.4665 - val_model_3_accuracy: 0.5065 - val_model_4_accuracy: 0.5040 - val_loss1: 9.5024 - val_loss2: 9.0793\n","Epoch 4/300\n","1/1 [==============================] - 5s 5s/step - loss: 2.3201 - model_loss: 0.8131 - model_1_loss: 0.1306 - model_2_loss: 0.8726 - model_3_loss: 0.2546 - model_4_loss: 0.2493 - model_accuracy: 0.6667 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 7.5430 - loss2: 8.4053 - val_loss: 44.1630 - val_model_loss: 20.1563 - val_model_1_loss: 2.1963 - val_model_2_loss: 2.3102 - val_model_3_loss: 7.8032 - val_model_4_loss: 11.6970 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4990 - val_model_2_accuracy: 0.4865 - val_model_3_accuracy: 0.5085 - val_model_4_accuracy: 0.5040 - val_loss1: 9.5799 - val_loss2: 8.2993\n","Epoch 5/300\n","1/1 [==============================] - 6s 6s/step - loss: 3.6462 - model_loss: 0.6183 - model_1_loss: 0.7167 - model_2_loss: 0.6309 - model_3_loss: 0.9832 - model_4_loss: 0.6972 - model_accuracy: 0.6667 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.8333 - loss1: 7.6110 - loss2: 8.5410 - val_loss: 73.4132 - val_model_loss: 36.4421 - val_model_1_loss: 7.3879 - val_model_2_loss: 3.1485 - val_model_3_loss: 13.3726 - val_model_4_loss: 13.0621 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5045 - val_model_2_accuracy: 0.4900 - val_model_3_accuracy: 0.5055 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6253 - val_loss2: 7.5989\n","Epoch 6/300\n","1/1 [==============================] - 6s 6s/step - loss: 2.9326 - model_loss: 0.2496 - model_1_loss: 0.6963 - model_2_loss: 1.2028 - model_3_loss: 0.4933 - model_4_loss: 0.2905 - model_accuracy: 0.8333 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.6667 - model_4_accuracy: 1.0000 - loss1: 6.9649 - loss2: 8.6815 - val_loss: 113.3486 - val_model_loss: 57.3723 - val_model_1_loss: 14.7256 - val_model_2_loss: 7.3599 - val_model_3_loss: 16.3744 - val_model_4_loss: 17.5165 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.4925 - val_model_3_accuracy: 0.5105 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6471 - val_loss2: 7.0067\n","Epoch 7/300\n","1/1 [==============================] - 6s 6s/step - loss: 2.1020 - model_loss: 0.1538 - model_1_loss: 1.2848 - model_2_loss: 0.1312 - model_3_loss: 0.1329 - model_4_loss: 0.3992 - model_accuracy: 1.0000 - model_1_accuracy: 0.6667 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 7.1128 - loss2: 8.4832 - val_loss: 180.3712 - val_model_loss: 84.3022 - val_model_1_loss: 34.2986 - val_model_2_loss: 12.8651 - val_model_3_loss: 21.2835 - val_model_4_loss: 27.6219 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.5140 - val_model_3_accuracy: 0.5080 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6517 - val_loss2: 6.6327\n","Epoch 8/300\n","1/1 [==============================] - 5s 5s/step - loss: 2.2698 - model_loss: 0.6999 - model_1_loss: 0.8743 - model_2_loss: 0.4898 - model_3_loss: 0.1556 - model_4_loss: 0.0502 - model_accuracy: 0.8333 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.5210 - loss2: 8.5472 - val_loss: 208.7715 - val_model_loss: 98.1128 - val_model_1_loss: 31.8692 - val_model_2_loss: 15.7511 - val_model_3_loss: 24.6735 - val_model_4_loss: 38.3649 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5045 - val_model_2_accuracy: 0.5090 - val_model_3_accuracy: 0.5095 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6552 - val_loss2: 6.2383\n","Epoch 9/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.8079 - model_loss: 0.1347 - model_1_loss: 0.3192 - model_2_loss: 0.2236 - model_3_loss: 0.0246 - model_4_loss: 0.1058 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.3013 - loss2: 8.7443 - val_loss: 232.4931 - val_model_loss: 102.9469 - val_model_1_loss: 27.1668 - val_model_2_loss: 20.3917 - val_model_3_loss: 28.8569 - val_model_4_loss: 53.1309 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5065 - val_model_2_accuracy: 0.5125 - val_model_3_accuracy: 0.5110 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6528 - val_loss2: 5.9625\n","Epoch 10/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.2913 - model_loss: 0.0146 - model_1_loss: 0.0848 - model_2_loss: 0.1556 - model_3_loss: 0.0188 - model_4_loss: 0.0176 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8324 - loss2: 8.8763 - val_loss: 265.2603 - val_model_loss: 108.1952 - val_model_1_loss: 27.6973 - val_model_2_loss: 29.3451 - val_model_3_loss: 33.9893 - val_model_4_loss: 66.0333 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5070 - val_model_2_accuracy: 0.5055 - val_model_3_accuracy: 0.5115 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6481 - val_loss2: 5.8585\n","Epoch 11/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.3104 - model_loss: 0.0645 - model_1_loss: 0.0415 - model_2_loss: 0.1556 - model_3_loss: 0.0406 - model_4_loss: 0.0083 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7668 - loss2: 8.7153 - val_loss: 298.2054 - val_model_loss: 112.5494 - val_model_1_loss: 28.9783 - val_model_2_loss: 36.5398 - val_model_3_loss: 41.3041 - val_model_4_loss: 78.8337 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5080 - val_model_2_accuracy: 0.5060 - val_model_3_accuracy: 0.5110 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6402 - val_loss2: 5.8057\n","Epoch 12/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.1957 - model_loss: 0.0149 - model_1_loss: 0.1019 - model_2_loss: 0.0105 - model_3_loss: 0.0304 - model_4_loss: 0.0380 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8757 - loss2: 8.9256 - val_loss: 324.4602 - val_model_loss: 112.0609 - val_model_1_loss: 30.6411 - val_model_2_loss: 40.1726 - val_model_3_loss: 49.9885 - val_model_4_loss: 91.5970 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5080 - val_model_2_accuracy: 0.5050 - val_model_3_accuracy: 0.5075 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6305 - val_loss2: 5.6837\n","Epoch 13/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.2892 - model_loss: 0.0848 - model_1_loss: 0.0200 - model_2_loss: 0.0374 - model_3_loss: 0.0121 - model_4_loss: 0.1348 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5080 - loss2: 9.1983 - val_loss: 340.8148 - val_model_loss: 108.9517 - val_model_1_loss: 31.8547 - val_model_2_loss: 44.5346 - val_model_3_loss: 56.8823 - val_model_4_loss: 98.5915 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5080 - val_model_2_accuracy: 0.5050 - val_model_3_accuracy: 0.5035 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6239 - val_loss2: 5.5754\n","Epoch 14/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.5010 - model_loss: 0.1670 - model_1_loss: 0.0090 - model_2_loss: 0.0072 - model_3_loss: 0.2832 - model_4_loss: 0.0346 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.6667 - model_4_accuracy: 1.0000 - loss1: 7.4662 - loss2: 8.8243 - val_loss: 370.6285 - val_model_loss: 110.1176 - val_model_1_loss: 32.1435 - val_model_2_loss: 47.6604 - val_model_3_loss: 74.5225 - val_model_4_loss: 106.1845 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5055 - val_model_2_accuracy: 0.5060 - val_model_3_accuracy: 0.5025 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6337 - val_loss2: 5.5466\n","Epoch 15/300\n","1/1 [==============================] - 6s 6s/step - loss: 1.4115 - model_loss: 0.2780 - model_1_loss: 0.1830 - model_2_loss: 0.1296 - model_3_loss: 0.2032 - model_4_loss: 0.6177 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.6667 - loss1: 7.9428 - loss2: 8.8793 - val_loss: 385.9071 - val_model_loss: 113.1371 - val_model_1_loss: 35.6232 - val_model_2_loss: 45.3663 - val_model_3_loss: 89.3006 - val_model_4_loss: 102.4798 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5070 - val_model_2_accuracy: 0.5085 - val_model_3_accuracy: 0.5020 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6269 - val_loss2: 5.3584\n","Epoch 16/300\n","1/1 [==============================] - 5s 5s/step - loss: 1.3471 - model_loss: 0.0953 - model_1_loss: 0.1992 - model_2_loss: 0.2729 - model_3_loss: 0.0948 - model_4_loss: 0.6848 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 7.5364 - loss2: 8.9470 - val_loss: 380.3981 - val_model_loss: 113.1512 - val_model_1_loss: 38.4442 - val_model_2_loss: 39.8131 - val_model_3_loss: 101.4856 - val_model_4_loss: 87.5039 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5070 - val_model_2_accuracy: 0.5095 - val_model_3_accuracy: 0.4975 - val_model_4_accuracy: 0.5040 - val_loss1: 9.6275 - val_loss2: 5.2701\n","Epoch 17/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.9603 - model_loss: 0.1315 - model_1_loss: 0.0314 - model_2_loss: 0.0136 - model_3_loss: 0.7400 - model_4_loss: 0.0439 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.7355 - loss2: 8.8884 - val_loss: 354.8757 - val_model_loss: 111.7926 - val_model_1_loss: 37.0231 - val_model_2_loss: 29.2387 - val_model_3_loss: 104.0910 - val_model_4_loss: 72.7302 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.5005 - val_model_2_accuracy: 0.5085 - val_model_3_accuracy: 0.4965 - val_model_4_accuracy: 0.5045 - val_loss1: 9.6290 - val_loss2: 5.2824\n","Epoch 18/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.1319 - model_loss: 0.0130 - model_1_loss: 0.0248 - model_2_loss: 0.0275 - model_3_loss: 0.0392 - model_4_loss: 0.0275 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6777 - loss2: 9.3270 - val_loss: 322.7631 - val_model_loss: 108.5201 - val_model_1_loss: 33.0349 - val_model_2_loss: 21.4438 - val_model_3_loss: 99.2272 - val_model_4_loss: 60.5370 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4890 - val_model_2_accuracy: 0.5045 - val_model_3_accuracy: 0.4970 - val_model_4_accuracy: 0.4990 - val_loss1: 9.6251 - val_loss2: 5.4618\n","Epoch 19/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.4430 - model_loss: 0.0855 - model_1_loss: 0.0133 - model_2_loss: 0.0471 - model_3_loss: 0.2792 - model_4_loss: 0.0178 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.7551 - loss2: 9.3506 - val_loss: 291.9280 - val_model_loss: 104.0003 - val_model_1_loss: 30.1522 - val_model_2_loss: 16.0194 - val_model_3_loss: 92.1421 - val_model_4_loss: 49.6141 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4720 - val_model_2_accuracy: 0.5125 - val_model_3_accuracy: 0.4960 - val_model_4_accuracy: 0.4825 - val_loss1: 9.6182 - val_loss2: 5.6792\n","Epoch 20/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.4077 - model_loss: 0.0049 - model_1_loss: 0.0169 - model_2_loss: 0.2761 - model_3_loss: 0.0265 - model_4_loss: 0.0832 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 9.0709 - loss2: 9.4978 - val_loss: 279.4031 - val_model_loss: 99.3065 - val_model_1_loss: 27.7687 - val_model_2_loss: 16.1803 - val_model_3_loss: 91.2299 - val_model_4_loss: 44.9177 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4610 - val_model_2_accuracy: 0.5025 - val_model_3_accuracy: 0.4945 - val_model_4_accuracy: 0.4775 - val_loss1: 9.6015 - val_loss2: 5.7613\n","Epoch 21/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0291 - model_loss: 0.0031 - model_1_loss: 0.0130 - model_2_loss: 0.0048 - model_3_loss: 0.0019 - model_4_loss: 0.0063 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.9561 - loss2: 9.3756 - val_loss: 268.1730 - val_model_loss: 95.6899 - val_model_1_loss: 27.5482 - val_model_2_loss: 15.1517 - val_model_3_loss: 88.8537 - val_model_4_loss: 40.9295 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4595 - val_model_2_accuracy: 0.4965 - val_model_3_accuracy: 0.4940 - val_model_4_accuracy: 0.4720 - val_loss1: 9.5786 - val_loss2: 5.9287\n","Epoch 22/300\n","1/1 [==============================] - 6s 6s/step - loss: 2.4604 - model_loss: 0.7839 - model_1_loss: 0.6651 - model_2_loss: 0.7936 - model_3_loss: 0.0604 - model_4_loss: 0.1575 - model_accuracy: 0.8333 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 9.0447 - loss2: 9.3550 - val_loss: 245.8383 - val_model_loss: 83.7957 - val_model_1_loss: 30.5947 - val_model_2_loss: 12.1072 - val_model_3_loss: 81.3695 - val_model_4_loss: 37.9712 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4620 - val_model_2_accuracy: 0.4970 - val_model_3_accuracy: 0.4930 - val_model_4_accuracy: 0.4700 - val_loss1: 9.5318 - val_loss2: 5.8465\n","Epoch 23/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0454 - model_loss: 0.0075 - model_1_loss: 0.0082 - model_2_loss: 0.0111 - model_3_loss: 0.0113 - model_4_loss: 0.0072 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2953 - loss2: 9.2308 - val_loss: 220.5435 - val_model_loss: 73.5096 - val_model_1_loss: 33.1116 - val_model_2_loss: 9.7894 - val_model_3_loss: 69.2958 - val_model_4_loss: 34.8372 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4635 - val_model_2_accuracy: 0.4940 - val_model_3_accuracy: 0.4930 - val_model_4_accuracy: 0.4685 - val_loss1: 9.4869 - val_loss2: 5.8273\n","Epoch 24/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0848 - model_loss: 0.0059 - model_1_loss: 0.0045 - model_2_loss: 0.0028 - model_3_loss: 0.0509 - model_4_loss: 0.0207 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6567 - loss2: 9.3855 - val_loss: 200.4025 - val_model_loss: 65.0770 - val_model_1_loss: 35.2524 - val_model_2_loss: 7.8990 - val_model_3_loss: 59.5522 - val_model_4_loss: 32.6218 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4585 - val_model_2_accuracy: 0.4830 - val_model_3_accuracy: 0.4930 - val_model_4_accuracy: 0.4675 - val_loss1: 9.4398 - val_loss2: 5.6259\n","Epoch 25/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.7520 - model_loss: 0.0227 - model_1_loss: 0.1035 - model_2_loss: 0.2149 - model_3_loss: 0.2074 - model_4_loss: 0.2034 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 7.8392 - loss2: 9.0058 - val_loss: 194.7077 - val_model_loss: 59.8666 - val_model_1_loss: 36.7079 - val_model_2_loss: 8.6863 - val_model_3_loss: 54.1042 - val_model_4_loss: 35.3428 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4535 - val_model_2_accuracy: 0.4710 - val_model_3_accuracy: 0.4930 - val_model_4_accuracy: 0.4665 - val_loss1: 9.4100 - val_loss2: 5.5106\n","Epoch 26/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1215 - model_loss: 0.0075 - model_1_loss: 0.0112 - model_2_loss: 0.0161 - model_3_loss: 0.0671 - model_4_loss: 0.0195 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9811 - loss2: 9.1489 - val_loss: 183.5376 - val_model_loss: 53.0983 - val_model_1_loss: 38.5312 - val_model_2_loss: 8.6366 - val_model_3_loss: 46.5694 - val_model_4_loss: 36.7020 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4505 - val_model_2_accuracy: 0.4750 - val_model_3_accuracy: 0.4935 - val_model_4_accuracy: 0.4685 - val_loss1: 9.3941 - val_loss2: 5.5761\n","Epoch 27/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.2010 - model_loss: 0.0145 - model_1_loss: 0.0349 - model_2_loss: 0.0231 - model_3_loss: 0.1210 - model_4_loss: 0.0074 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.7524 - loss2: 9.3402 - val_loss: 172.2419 - val_model_loss: 47.8485 - val_model_1_loss: 38.7020 - val_model_2_loss: 8.6564 - val_model_3_loss: 39.5398 - val_model_4_loss: 37.4952 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4420 - val_model_2_accuracy: 0.4885 - val_model_3_accuracy: 0.4895 - val_model_4_accuracy: 0.4705 - val_loss1: 9.3708 - val_loss2: 5.6827\n","Epoch 28/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.1318 - model_loss: 0.0021 - model_1_loss: 0.0077 - model_2_loss: 0.0129 - model_3_loss: 0.0133 - model_4_loss: 0.0958 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6483 - loss2: 9.3645 - val_loss: 163.2899 - val_model_loss: 42.4312 - val_model_1_loss: 39.2558 - val_model_2_loss: 8.5718 - val_model_3_loss: 34.0348 - val_model_4_loss: 38.9963 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4380 - val_model_2_accuracy: 0.4925 - val_model_3_accuracy: 0.4870 - val_model_4_accuracy: 0.4760 - val_loss1: 9.3435 - val_loss2: 5.7768\n","Epoch 29/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.6114 - model_loss: 0.0092 - model_1_loss: 0.0644 - model_2_loss: 0.0358 - model_3_loss: 0.4106 - model_4_loss: 0.0914 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.1514 - loss2: 9.1020 - val_loss: 154.8494 - val_model_loss: 38.3838 - val_model_1_loss: 39.7813 - val_model_2_loss: 8.8306 - val_model_3_loss: 27.6432 - val_model_4_loss: 40.2106 - val_model_accuracy: 0.5040 - val_model_1_accuracy: 0.4285 - val_model_2_accuracy: 0.4905 - val_model_3_accuracy: 0.4900 - val_model_4_accuracy: 0.4795 - val_loss1: 9.3129 - val_loss2: 5.8393\n","Epoch 30/300\n","1/1 [==============================] - 5s 5s/step - loss: 1.9371 - model_loss: 0.0695 - model_1_loss: 0.3195 - model_2_loss: 0.4370 - model_3_loss: 0.8194 - model_4_loss: 0.2917 - model_accuracy: 1.0000 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.5000 - model_4_accuracy: 0.8333 - loss1: 8.2168 - loss2: 8.9486 - val_loss: 155.7934 - val_model_loss: 35.3471 - val_model_1_loss: 48.0526 - val_model_2_loss: 9.0364 - val_model_3_loss: 22.3448 - val_model_4_loss: 41.0125 - val_model_accuracy: 0.5050 - val_model_1_accuracy: 0.4520 - val_model_2_accuracy: 0.4960 - val_model_3_accuracy: 0.4925 - val_model_4_accuracy: 0.4795 - val_loss1: 9.3059 - val_loss2: 5.8270\n","Epoch 31/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0988 - model_loss: 0.0204 - model_1_loss: 0.0414 - model_2_loss: 0.0051 - model_3_loss: 0.0117 - model_4_loss: 0.0203 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2437 - loss2: 9.1809 - val_loss: 149.3611 - val_model_loss: 31.7040 - val_model_1_loss: 50.6606 - val_model_2_loss: 9.0185 - val_model_3_loss: 17.2085 - val_model_4_loss: 40.7694 - val_model_accuracy: 0.5055 - val_model_1_accuracy: 0.4585 - val_model_2_accuracy: 0.4990 - val_model_3_accuracy: 0.4905 - val_model_4_accuracy: 0.4805 - val_loss1: 9.2866 - val_loss2: 5.7763\n","Epoch 32/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.4287 - model_loss: 0.0141 - model_1_loss: 0.2441 - model_2_loss: 0.0129 - model_3_loss: 0.0116 - model_4_loss: 0.1459 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.2000 - loss2: 9.1179 - val_loss: 142.4228 - val_model_loss: 28.8274 - val_model_1_loss: 50.9068 - val_model_2_loss: 9.1957 - val_model_3_loss: 13.3644 - val_model_4_loss: 40.1286 - val_model_accuracy: 0.5015 - val_model_1_accuracy: 0.4670 - val_model_2_accuracy: 0.4995 - val_model_3_accuracy: 0.4865 - val_model_4_accuracy: 0.4815 - val_loss1: 9.2639 - val_loss2: 5.7328\n","Epoch 33/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.6400 - model_loss: 0.0354 - model_1_loss: 0.1824 - model_2_loss: 0.3202 - model_3_loss: 0.0394 - model_4_loss: 0.0627 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0090 - loss2: 9.0969 - val_loss: 131.0658 - val_model_loss: 26.3208 - val_model_1_loss: 45.8951 - val_model_2_loss: 8.7171 - val_model_3_loss: 10.7181 - val_model_4_loss: 39.4147 - val_model_accuracy: 0.4980 - val_model_1_accuracy: 0.4675 - val_model_2_accuracy: 0.4955 - val_model_3_accuracy: 0.4765 - val_model_4_accuracy: 0.4820 - val_loss1: 9.2400 - val_loss2: 5.7891\n","Epoch 34/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1494 - model_loss: 0.0300 - model_1_loss: 0.0023 - model_2_loss: 0.0223 - model_3_loss: 0.0870 - model_4_loss: 0.0078 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.2474 - loss2: 8.7434 - val_loss: 120.8912 - val_model_loss: 24.4046 - val_model_1_loss: 40.7525 - val_model_2_loss: 8.5406 - val_model_3_loss: 8.6545 - val_model_4_loss: 38.5390 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.4615 - val_model_2_accuracy: 0.4915 - val_model_3_accuracy: 0.4735 - val_model_4_accuracy: 0.4825 - val_loss1: 9.2132 - val_loss2: 5.8611\n","Epoch 35/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0445 - model_loss: 0.0029 - model_1_loss: 0.0057 - model_2_loss: 0.0241 - model_3_loss: 0.0082 - model_4_loss: 0.0036 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0818 - loss2: 9.1364 - val_loss: 108.8615 - val_model_loss: 22.1798 - val_model_1_loss: 34.4654 - val_model_2_loss: 7.6820 - val_model_3_loss: 6.8168 - val_model_4_loss: 37.7175 - val_model_accuracy: 0.4895 - val_model_1_accuracy: 0.4515 - val_model_2_accuracy: 0.4895 - val_model_3_accuracy: 0.4690 - val_model_4_accuracy: 0.4830 - val_loss1: 9.1740 - val_loss2: 5.9297\n","Epoch 36/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.1598 - model_loss: 0.0370 - model_1_loss: 0.0205 - model_2_loss: 0.0429 - model_3_loss: 0.0565 - model_4_loss: 0.0030 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.5016 - loss2: 8.9647 - val_loss: 100.5961 - val_model_loss: 20.2692 - val_model_1_loss: 30.4056 - val_model_2_loss: 7.1843 - val_model_3_loss: 5.6441 - val_model_4_loss: 37.0929 - val_model_accuracy: 0.4870 - val_model_1_accuracy: 0.4425 - val_model_2_accuracy: 0.4945 - val_model_3_accuracy: 0.4595 - val_model_4_accuracy: 0.4825 - val_loss1: 9.1350 - val_loss2: 5.9946\n","Epoch 37/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1037 - model_loss: 0.0062 - model_1_loss: 0.0179 - model_2_loss: 0.0028 - model_3_loss: 0.0621 - model_4_loss: 0.0148 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1555 - loss2: 9.1521 - val_loss: 92.7797 - val_model_loss: 18.3414 - val_model_1_loss: 26.1873 - val_model_2_loss: 6.5080 - val_model_3_loss: 4.9891 - val_model_4_loss: 36.7541 - val_model_accuracy: 0.4905 - val_model_1_accuracy: 0.4445 - val_model_2_accuracy: 0.4995 - val_model_3_accuracy: 0.4695 - val_model_4_accuracy: 0.4825 - val_loss1: 9.0938 - val_loss2: 6.0640\n","Epoch 38/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0552 - model_loss: 0.0066 - model_1_loss: 0.0021 - model_2_loss: 0.0332 - model_3_loss: 0.0064 - model_4_loss: 0.0069 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8881 - loss2: 8.9580 - val_loss: 87.0050 - val_model_loss: 16.8691 - val_model_1_loss: 23.3844 - val_model_2_loss: 5.9747 - val_model_3_loss: 4.5948 - val_model_4_loss: 36.1820 - val_model_accuracy: 0.4920 - val_model_1_accuracy: 0.4450 - val_model_2_accuracy: 0.4930 - val_model_3_accuracy: 0.4765 - val_model_4_accuracy: 0.4835 - val_loss1: 9.0509 - val_loss2: 6.1439\n","Epoch 39/300\n","1/1 [==============================] - 6s 6s/step - loss: 8.7092 - model_loss: 1.9268 - model_1_loss: 1.1606 - model_2_loss: 1.3549 - model_3_loss: 0.9697 - model_4_loss: 3.2973 - model_accuracy: 0.6667 - model_1_accuracy: 0.6667 - model_2_accuracy: 0.6667 - model_3_accuracy: 0.6667 - model_4_accuracy: 0.6667 - loss1: 6.7379 - loss2: 8.5837 - val_loss: 101.8304 - val_model_loss: 21.3356 - val_model_1_loss: 29.4303 - val_model_2_loss: 6.8023 - val_model_3_loss: 5.3782 - val_model_4_loss: 38.8840 - val_model_accuracy: 0.4885 - val_model_1_accuracy: 0.4575 - val_model_2_accuracy: 0.4975 - val_model_3_accuracy: 0.4685 - val_model_4_accuracy: 0.4855 - val_loss1: 9.1487 - val_loss2: 6.0331\n","Epoch 40/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0213 - model_loss: 0.0050 - model_1_loss: 0.0038 - model_2_loss: 0.0089 - model_3_loss: 0.0023 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2260 - loss2: 9.0783 - val_loss: 114.1710 - val_model_loss: 25.4910 - val_model_1_loss: 34.3274 - val_model_2_loss: 7.3027 - val_model_3_loss: 6.1159 - val_model_4_loss: 40.9339 - val_model_accuracy: 0.4870 - val_model_1_accuracy: 0.4680 - val_model_2_accuracy: 0.4940 - val_model_3_accuracy: 0.4770 - val_model_4_accuracy: 0.4865 - val_loss1: 9.2152 - val_loss2: 5.9474\n","Epoch 41/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0186 - model_loss: 0.0014 - model_1_loss: 0.0025 - model_2_loss: 0.0049 - model_3_loss: 0.0067 - model_4_loss: 0.0030 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4021 - loss2: 9.2474 - val_loss: 124.3591 - val_model_loss: 29.2846 - val_model_1_loss: 38.2462 - val_model_2_loss: 7.6090 - val_model_3_loss: 6.6166 - val_model_4_loss: 42.6027 - val_model_accuracy: 0.4880 - val_model_1_accuracy: 0.4680 - val_model_2_accuracy: 0.4915 - val_model_3_accuracy: 0.4780 - val_model_4_accuracy: 0.4860 - val_loss1: 9.2583 - val_loss2: 5.8929\n","Epoch 42/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1369 - model_loss: 0.0040 - model_1_loss: 0.0905 - model_2_loss: 0.0070 - model_3_loss: 0.0237 - model_4_loss: 0.0117 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.3280 - loss2: 8.8690 - val_loss: 135.9742 - val_model_loss: 33.2696 - val_model_1_loss: 43.8350 - val_model_2_loss: 7.8986 - val_model_3_loss: 7.3298 - val_model_4_loss: 43.6411 - val_model_accuracy: 0.4885 - val_model_1_accuracy: 0.4700 - val_model_2_accuracy: 0.4905 - val_model_3_accuracy: 0.4800 - val_model_4_accuracy: 0.4865 - val_loss1: 9.2941 - val_loss2: 5.8345\n","Epoch 43/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.3614 - model_loss: 0.0715 - model_1_loss: 0.0365 - model_2_loss: 0.0534 - model_3_loss: 0.1605 - model_4_loss: 0.0395 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.6624 - loss2: 8.9705 - val_loss: 144.5560 - val_model_loss: 36.9957 - val_model_1_loss: 47.4960 - val_model_2_loss: 8.0094 - val_model_3_loss: 8.3427 - val_model_4_loss: 43.7121 - val_model_accuracy: 0.4890 - val_model_1_accuracy: 0.4715 - val_model_2_accuracy: 0.4895 - val_model_3_accuracy: 0.4725 - val_model_4_accuracy: 0.4865 - val_loss1: 9.3063 - val_loss2: 5.7993\n","Epoch 44/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.9957 - model_loss: 0.4021 - model_1_loss: 0.0097 - model_2_loss: 0.0110 - model_3_loss: 0.1978 - model_4_loss: 0.3752 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 8.4093 - loss2: 9.2339 - val_loss: 131.4846 - val_model_loss: 31.5443 - val_model_1_loss: 49.6667 - val_model_2_loss: 7.7188 - val_model_3_loss: 8.8444 - val_model_4_loss: 33.7103 - val_model_accuracy: 0.4880 - val_model_1_accuracy: 0.4720 - val_model_2_accuracy: 0.4905 - val_model_3_accuracy: 0.4620 - val_model_4_accuracy: 0.4870 - val_loss1: 9.3107 - val_loss2: 5.9267\n","Epoch 45/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1048 - model_loss: 0.0370 - model_1_loss: 0.0080 - model_2_loss: 0.0118 - model_3_loss: 0.0427 - model_4_loss: 0.0052 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.6839 - loss2: 8.9112 - val_loss: 122.1759 - val_model_loss: 27.0655 - val_model_1_loss: 51.8395 - val_model_2_loss: 7.6581 - val_model_3_loss: 9.5463 - val_model_4_loss: 26.0665 - val_model_accuracy: 0.4890 - val_model_1_accuracy: 0.4740 - val_model_2_accuracy: 0.4900 - val_model_3_accuracy: 0.4530 - val_model_4_accuracy: 0.4800 - val_loss1: 9.3067 - val_loss2: 6.1021\n","Epoch 46/300\n","1/1 [==============================] - 5s 5s/step - loss: 2.7866 - model_loss: 1.4235 - model_1_loss: 0.1867 - model_2_loss: 0.1065 - model_3_loss: 0.7343 - model_4_loss: 0.3356 - model_accuracy: 0.3333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 6.3419 - loss2: 8.5434 - val_loss: 107.2448 - val_model_loss: 16.4548 - val_model_1_loss: 52.5093 - val_model_2_loss: 7.8914 - val_model_3_loss: 10.7888 - val_model_4_loss: 19.6005 - val_model_accuracy: 0.4970 - val_model_1_accuracy: 0.4745 - val_model_2_accuracy: 0.4915 - val_model_3_accuracy: 0.4490 - val_model_4_accuracy: 0.4670 - val_loss1: 9.2745 - val_loss2: 6.2059\n","Epoch 47/300\n","1/1 [==============================] - 5s 5s/step - loss: 1.3550 - model_loss: 0.2724 - model_1_loss: 0.0157 - model_2_loss: 0.3799 - model_3_loss: 0.6552 - model_4_loss: 0.0319 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.1079 - loss2: 9.1363 - val_loss: 95.9971 - val_model_loss: 10.1551 - val_model_1_loss: 51.9827 - val_model_2_loss: 7.9279 - val_model_3_loss: 11.3641 - val_model_4_loss: 14.5675 - val_model_accuracy: 0.5120 - val_model_1_accuracy: 0.4715 - val_model_2_accuracy: 0.4885 - val_model_3_accuracy: 0.4465 - val_model_4_accuracy: 0.4610 - val_loss1: 9.2032 - val_loss2: 6.4673\n","Epoch 48/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.3607 - model_loss: 0.0017 - model_1_loss: 0.2403 - model_2_loss: 0.1037 - model_3_loss: 0.0120 - model_4_loss: 0.0031 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.1953 - loss2: 8.7338 - val_loss: 77.0647 - val_model_loss: 6.2584 - val_model_1_loss: 41.4509 - val_model_2_loss: 7.2664 - val_model_3_loss: 11.1813 - val_model_4_loss: 10.9077 - val_model_accuracy: 0.5110 - val_model_1_accuracy: 0.4635 - val_model_2_accuracy: 0.4900 - val_model_3_accuracy: 0.4445 - val_model_4_accuracy: 0.4475 - val_loss1: 9.0602 - val_loss2: 6.6401\n","Epoch 49/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0597 - model_loss: 0.0111 - model_1_loss: 0.0206 - model_2_loss: 0.0075 - model_3_loss: 0.0144 - model_4_loss: 0.0061 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7842 - loss2: 8.9680 - val_loss: 61.7122 - val_model_loss: 3.9663 - val_model_1_loss: 32.4452 - val_model_2_loss: 6.6180 - val_model_3_loss: 10.4647 - val_model_4_loss: 8.2180 - val_model_accuracy: 0.5050 - val_model_1_accuracy: 0.4600 - val_model_2_accuracy: 0.4905 - val_model_3_accuracy: 0.4395 - val_model_4_accuracy: 0.4340 - val_loss1: 8.7808 - val_loss2: 6.7716\n","Epoch 50/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.3798 - model_loss: 0.0795 - model_1_loss: 0.0044 - model_2_loss: 0.0070 - model_3_loss: 0.2545 - model_4_loss: 0.0344 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 6.9486 - loss2: 8.6536 - val_loss: 50.9524 - val_model_loss: 2.6655 - val_model_1_loss: 26.3633 - val_model_2_loss: 6.1259 - val_model_3_loss: 9.4082 - val_model_4_loss: 6.3895 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.4425 - val_model_2_accuracy: 0.4925 - val_model_3_accuracy: 0.4375 - val_model_4_accuracy: 0.4340 - val_loss1: 8.3217 - val_loss2: 6.8970\n","Epoch 51/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1444 - model_loss: 0.0486 - model_1_loss: 0.0056 - model_2_loss: 0.0250 - model_3_loss: 0.0358 - model_4_loss: 0.0293 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5835 - loss2: 9.3348 - val_loss: 42.4607 - val_model_loss: 1.9211 - val_model_1_loss: 21.2176 - val_model_2_loss: 5.5532 - val_model_3_loss: 8.5578 - val_model_4_loss: 5.2111 - val_model_accuracy: 0.4895 - val_model_1_accuracy: 0.4260 - val_model_2_accuracy: 0.4890 - val_model_3_accuracy: 0.4335 - val_model_4_accuracy: 0.4300 - val_loss1: 7.8858 - val_loss2: 7.0371\n","Epoch 52/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.4550 - model_loss: 0.0254 - model_1_loss: 0.0057 - model_2_loss: 0.0596 - model_3_loss: 0.2861 - model_4_loss: 0.0782 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.4273 - loss2: 9.2641 - val_loss: 37.1838 - val_model_loss: 1.5469 - val_model_1_loss: 17.8199 - val_model_2_loss: 5.0360 - val_model_3_loss: 8.3340 - val_model_4_loss: 4.4470 - val_model_accuracy: 0.4880 - val_model_1_accuracy: 0.4020 - val_model_2_accuracy: 0.4835 - val_model_3_accuracy: 0.4460 - val_model_4_accuracy: 0.4270 - val_loss1: 7.5164 - val_loss2: 7.1590\n","Epoch 53/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0282 - model_loss: 0.0052 - model_1_loss: 0.0017 - model_2_loss: 0.0057 - model_3_loss: 0.0103 - model_4_loss: 0.0053 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6461 - loss2: 9.3679 - val_loss: 32.4882 - val_model_loss: 1.3182 - val_model_1_loss: 15.0508 - val_model_2_loss: 4.5408 - val_model_3_loss: 7.7977 - val_model_4_loss: 3.7808 - val_model_accuracy: 0.5020 - val_model_1_accuracy: 0.4005 - val_model_2_accuracy: 0.4735 - val_model_3_accuracy: 0.4580 - val_model_4_accuracy: 0.4290 - val_loss1: 7.2048 - val_loss2: 7.2926\n","Epoch 54/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.4713 - model_loss: 0.1923 - model_1_loss: 0.0275 - model_2_loss: 0.1200 - model_3_loss: 0.0858 - model_4_loss: 0.0456 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5313 - loss2: 9.4048 - val_loss: 29.2591 - val_model_loss: 1.2105 - val_model_1_loss: 13.2093 - val_model_2_loss: 4.0213 - val_model_3_loss: 7.4245 - val_model_4_loss: 3.3936 - val_model_accuracy: 0.5425 - val_model_1_accuracy: 0.3965 - val_model_2_accuracy: 0.4590 - val_model_3_accuracy: 0.4640 - val_model_4_accuracy: 0.4485 - val_loss1: 6.9364 - val_loss2: 7.4317\n","Epoch 55/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0588 - model_loss: 0.0151 - model_1_loss: 0.0045 - model_2_loss: 0.0025 - model_3_loss: 0.0312 - model_4_loss: 0.0054 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.5560 - loss2: 8.9393 - val_loss: 26.5553 - val_model_loss: 1.1520 - val_model_1_loss: 11.6888 - val_model_2_loss: 3.6178 - val_model_3_loss: 7.0119 - val_model_4_loss: 3.0848 - val_model_accuracy: 0.5740 - val_model_1_accuracy: 0.3965 - val_model_2_accuracy: 0.4545 - val_model_3_accuracy: 0.4635 - val_model_4_accuracy: 0.4710 - val_loss1: 6.7279 - val_loss2: 7.5544\n","Epoch 56/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0860 - model_loss: 0.0288 - model_1_loss: 0.0051 - model_2_loss: 0.0040 - model_3_loss: 0.0146 - model_4_loss: 0.0336 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7592 - loss2: 9.1923 - val_loss: 24.3047 - val_model_loss: 1.1185 - val_model_1_loss: 10.5024 - val_model_2_loss: 3.2855 - val_model_3_loss: 6.5291 - val_model_4_loss: 2.8692 - val_model_accuracy: 0.5875 - val_model_1_accuracy: 0.3990 - val_model_2_accuracy: 0.4420 - val_model_3_accuracy: 0.4660 - val_model_4_accuracy: 0.4865 - val_loss1: 6.5477 - val_loss2: 7.6734\n","Epoch 57/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0345 - model_loss: 0.0051 - model_1_loss: 0.0018 - model_2_loss: 0.0215 - model_3_loss: 0.0045 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5915 - loss2: 9.3244 - val_loss: 22.4499 - val_model_loss: 1.0959 - val_model_1_loss: 9.5491 - val_model_2_loss: 3.0166 - val_model_3_loss: 6.0819 - val_model_4_loss: 2.7064 - val_model_accuracy: 0.5895 - val_model_1_accuracy: 0.4000 - val_model_2_accuracy: 0.4365 - val_model_3_accuracy: 0.4675 - val_model_4_accuracy: 0.4970 - val_loss1: 6.4009 - val_loss2: 7.7793\n","Epoch 58/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0473 - model_loss: 0.0109 - model_1_loss: 0.0076 - model_2_loss: 0.0118 - model_3_loss: 0.0123 - model_4_loss: 0.0047 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.6673 - loss2: 8.4878 - val_loss: 21.1739 - val_model_loss: 1.0953 - val_model_1_loss: 8.9085 - val_model_2_loss: 2.8609 - val_model_3_loss: 5.6958 - val_model_4_loss: 2.6134 - val_model_accuracy: 0.5935 - val_model_1_accuracy: 0.3940 - val_model_2_accuracy: 0.4365 - val_model_3_accuracy: 0.4670 - val_model_4_accuracy: 0.4975 - val_loss1: 6.2549 - val_loss2: 7.8694\n","Epoch 59/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0305 - model_loss: 0.0117 - model_1_loss: 0.0029 - model_2_loss: 0.0033 - model_3_loss: 0.0100 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3097 - loss2: 9.2892 - val_loss: 19.9778 - val_model_loss: 1.0882 - val_model_1_loss: 8.2923 - val_model_2_loss: 2.7379 - val_model_3_loss: 5.3228 - val_model_4_loss: 2.5367 - val_model_accuracy: 0.6020 - val_model_1_accuracy: 0.3880 - val_model_2_accuracy: 0.4175 - val_model_3_accuracy: 0.4655 - val_model_4_accuracy: 0.4960 - val_loss1: 6.1076 - val_loss2: 7.9611\n","Epoch 60/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.5156 - model_loss: 0.3497 - model_1_loss: 0.0062 - model_2_loss: 0.0346 - model_3_loss: 0.0085 - model_4_loss: 0.1165 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6059 - loss2: 9.2314 - val_loss: 18.9188 - val_model_loss: 1.0920 - val_model_1_loss: 7.7125 - val_model_2_loss: 2.6631 - val_model_3_loss: 4.9765 - val_model_4_loss: 2.4746 - val_model_accuracy: 0.6040 - val_model_1_accuracy: 0.3875 - val_model_2_accuracy: 0.4015 - val_model_3_accuracy: 0.4630 - val_model_4_accuracy: 0.4960 - val_loss1: 5.9619 - val_loss2: 8.0514\n","Epoch 61/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0940 - model_loss: 0.0031 - model_1_loss: 0.0105 - model_2_loss: 0.0227 - model_3_loss: 0.0492 - model_4_loss: 0.0085 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8250 - loss2: 9.0883 - val_loss: 18.1266 - val_model_loss: 1.1070 - val_model_1_loss: 7.2759 - val_model_2_loss: 2.6301 - val_model_3_loss: 4.6457 - val_model_4_loss: 2.4679 - val_model_accuracy: 0.6125 - val_model_1_accuracy: 0.3910 - val_model_2_accuracy: 0.3850 - val_model_3_accuracy: 0.4575 - val_model_4_accuracy: 0.5020 - val_loss1: 5.8181 - val_loss2: 8.1341\n","Epoch 62/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0450 - model_loss: 0.0146 - model_1_loss: 0.0047 - model_2_loss: 0.0059 - model_3_loss: 0.0101 - model_4_loss: 0.0099 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3837 - loss2: 9.3240 - val_loss: 17.3904 - val_model_loss: 1.1214 - val_model_1_loss: 6.8498 - val_model_2_loss: 2.5974 - val_model_3_loss: 4.3457 - val_model_4_loss: 2.4761 - val_model_accuracy: 0.6250 - val_model_1_accuracy: 0.3920 - val_model_2_accuracy: 0.3660 - val_model_3_accuracy: 0.4495 - val_model_4_accuracy: 0.5050 - val_loss1: 5.7032 - val_loss2: 8.2101\n","Epoch 63/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0139 - model_loss: 0.0027 - model_1_loss: 0.0016 - model_2_loss: 0.0011 - model_3_loss: 0.0052 - model_4_loss: 0.0034 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4497 - loss2: 9.3278 - val_loss: 16.7944 - val_model_loss: 1.1402 - val_model_1_loss: 6.4724 - val_model_2_loss: 2.5951 - val_model_3_loss: 4.0700 - val_model_4_loss: 2.5167 - val_model_accuracy: 0.6210 - val_model_1_accuracy: 0.3865 - val_model_2_accuracy: 0.3460 - val_model_3_accuracy: 0.4375 - val_model_4_accuracy: 0.5055 - val_loss1: 5.6067 - val_loss2: 8.2837\n","Epoch 64/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.4728 - model_loss: 0.1725 - model_1_loss: 0.1782 - model_2_loss: 0.0061 - model_3_loss: 0.1053 - model_4_loss: 0.0107 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8789 - loss2: 9.1881 - val_loss: 16.4211 - val_model_loss: 1.1326 - val_model_1_loss: 6.2832 - val_model_2_loss: 2.6066 - val_model_3_loss: 3.8287 - val_model_4_loss: 2.5700 - val_model_accuracy: 0.5955 - val_model_1_accuracy: 0.3890 - val_model_2_accuracy: 0.3370 - val_model_3_accuracy: 0.4295 - val_model_4_accuracy: 0.5025 - val_loss1: 5.6102 - val_loss2: 8.3284\n","Epoch 65/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0386 - model_loss: 0.0035 - model_1_loss: 0.0018 - model_2_loss: 0.0026 - model_3_loss: 0.0226 - model_4_loss: 0.0081 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8942 - loss2: 9.1105 - val_loss: 16.1575 - val_model_loss: 1.1447 - val_model_1_loss: 6.1276 - val_model_2_loss: 2.6348 - val_model_3_loss: 3.6306 - val_model_4_loss: 2.6199 - val_model_accuracy: 0.5500 - val_model_1_accuracy: 0.3915 - val_model_2_accuracy: 0.3305 - val_model_3_accuracy: 0.4235 - val_model_4_accuracy: 0.5070 - val_loss1: 5.6060 - val_loss2: 8.3703\n","Epoch 66/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.2572 - model_loss: 0.0184 - model_1_loss: 0.0131 - model_2_loss: 0.2052 - model_3_loss: 0.0104 - model_4_loss: 0.0101 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2045 - loss2: 9.1558 - val_loss: 15.9465 - val_model_loss: 1.1726 - val_model_1_loss: 5.9839 - val_model_2_loss: 2.6584 - val_model_3_loss: 3.4511 - val_model_4_loss: 2.6804 - val_model_accuracy: 0.5150 - val_model_1_accuracy: 0.3910 - val_model_2_accuracy: 0.3235 - val_model_3_accuracy: 0.4170 - val_model_4_accuracy: 0.5095 - val_loss1: 5.6011 - val_loss2: 8.4129\n","Epoch 67/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1619 - model_loss: 0.0238 - model_1_loss: 0.0047 - model_2_loss: 0.0219 - model_3_loss: 0.0230 - model_4_loss: 0.0884 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0737 - loss2: 9.0192 - val_loss: 15.7924 - val_model_loss: 1.2117 - val_model_1_loss: 5.8614 - val_model_2_loss: 2.6762 - val_model_3_loss: 3.2944 - val_model_4_loss: 2.7487 - val_model_accuracy: 0.4875 - val_model_1_accuracy: 0.3875 - val_model_2_accuracy: 0.3215 - val_model_3_accuracy: 0.4085 - val_model_4_accuracy: 0.5115 - val_loss1: 5.6083 - val_loss2: 8.4550\n","Epoch 68/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.8143 - model_loss: 0.0971 - model_1_loss: 0.0040 - model_2_loss: 0.0090 - model_3_loss: 0.6999 - model_4_loss: 0.0043 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.7042 - loss2: 9.0833 - val_loss: 15.9079 - val_model_loss: 1.2440 - val_model_1_loss: 5.7737 - val_model_2_loss: 2.6835 - val_model_3_loss: 3.3949 - val_model_4_loss: 2.8118 - val_model_accuracy: 0.4780 - val_model_1_accuracy: 0.3890 - val_model_2_accuracy: 0.3170 - val_model_3_accuracy: 0.4110 - val_model_4_accuracy: 0.5075 - val_loss1: 5.5468 - val_loss2: 8.4715\n","Epoch 69/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1785 - model_loss: 0.0340 - model_1_loss: 0.0042 - model_2_loss: 0.0052 - model_3_loss: 0.0280 - model_4_loss: 0.1070 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3408 - loss2: 9.2410 - val_loss: 15.9125 - val_model_loss: 1.2895 - val_model_1_loss: 5.6416 - val_model_2_loss: 2.6880 - val_model_3_loss: 3.4397 - val_model_4_loss: 2.8537 - val_model_accuracy: 0.4595 - val_model_1_accuracy: 0.3885 - val_model_2_accuracy: 0.3160 - val_model_3_accuracy: 0.4180 - val_model_4_accuracy: 0.5025 - val_loss1: 5.5044 - val_loss2: 8.4941\n","Epoch 70/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0377 - model_loss: 0.0140 - model_1_loss: 0.0029 - model_2_loss: 0.0047 - model_3_loss: 0.0063 - model_4_loss: 0.0097 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0195 - loss2: 9.2410 - val_loss: 15.8740 - val_model_loss: 1.3346 - val_model_1_loss: 5.5278 - val_model_2_loss: 2.6830 - val_model_3_loss: 3.4452 - val_model_4_loss: 2.8833 - val_model_accuracy: 0.4525 - val_model_1_accuracy: 0.3855 - val_model_2_accuracy: 0.3145 - val_model_3_accuracy: 0.4235 - val_model_4_accuracy: 0.4900 - val_loss1: 5.4699 - val_loss2: 8.5184\n","Epoch 71/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0110 - model_loss: 9.7287e-04 - model_1_loss: 0.0016 - model_2_loss: 0.0013 - model_3_loss: 0.0051 - model_4_loss: 0.0020 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.7353 - loss2: 9.4165 - val_loss: 15.7918 - val_model_loss: 1.3844 - val_model_1_loss: 5.4105 - val_model_2_loss: 2.6855 - val_model_3_loss: 3.4218 - val_model_4_loss: 2.8896 - val_model_accuracy: 0.4530 - val_model_1_accuracy: 0.3895 - val_model_2_accuracy: 0.3180 - val_model_3_accuracy: 0.4265 - val_model_4_accuracy: 0.4815 - val_loss1: 5.4373 - val_loss2: 8.5454\n","Epoch 72/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.5439 - model_loss: 0.0442 - model_1_loss: 0.0059 - model_2_loss: 0.2105 - model_3_loss: 0.0679 - model_4_loss: 0.2154 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.4725 - loss2: 9.3612 - val_loss: 15.6619 - val_model_loss: 1.4187 - val_model_1_loss: 5.3159 - val_model_2_loss: 2.6272 - val_model_3_loss: 3.4629 - val_model_4_loss: 2.8371 - val_model_accuracy: 0.4520 - val_model_1_accuracy: 0.3860 - val_model_2_accuracy: 0.3135 - val_model_3_accuracy: 0.4285 - val_model_4_accuracy: 0.4600 - val_loss1: 5.4041 - val_loss2: 8.5645\n","Epoch 73/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0210 - model_loss: 0.0059 - model_1_loss: 0.0066 - model_2_loss: 0.0029 - model_3_loss: 0.0020 - model_4_loss: 0.0036 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5466 - loss2: 9.4141 - val_loss: 15.5068 - val_model_loss: 1.4626 - val_model_1_loss: 5.2207 - val_model_2_loss: 2.6053 - val_model_3_loss: 3.4657 - val_model_4_loss: 2.7524 - val_model_accuracy: 0.4525 - val_model_1_accuracy: 0.3845 - val_model_2_accuracy: 0.3180 - val_model_3_accuracy: 0.4285 - val_model_4_accuracy: 0.3935 - val_loss1: 5.4195 - val_loss2: 8.5943\n","Epoch 74/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0717 - model_loss: 0.0354 - model_1_loss: 0.0016 - model_2_loss: 0.0090 - model_3_loss: 0.0194 - model_4_loss: 0.0062 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.7940 - loss2: 9.4077 - val_loss: 15.4842 - val_model_loss: 1.5042 - val_model_1_loss: 5.1555 - val_model_2_loss: 2.5914 - val_model_3_loss: 3.5019 - val_model_4_loss: 2.7312 - val_model_accuracy: 0.4565 - val_model_1_accuracy: 0.3855 - val_model_2_accuracy: 0.3215 - val_model_3_accuracy: 0.4290 - val_model_4_accuracy: 0.3175 - val_loss1: 5.5085 - val_loss2: 8.6253\n","Epoch 75/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.3015 - model_loss: 0.0132 - model_1_loss: 0.0806 - model_2_loss: 0.0724 - model_3_loss: 0.1291 - model_4_loss: 0.0061 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8113 - loss2: 9.0187 - val_loss: 15.6917 - val_model_loss: 1.5368 - val_model_1_loss: 5.1903 - val_model_2_loss: 2.5978 - val_model_3_loss: 3.5751 - val_model_4_loss: 2.7917 - val_model_accuracy: 0.4630 - val_model_1_accuracy: 0.3855 - val_model_2_accuracy: 0.3275 - val_model_3_accuracy: 0.4300 - val_model_4_accuracy: 0.2865 - val_loss1: 5.6847 - val_loss2: 8.6408\n","Epoch 76/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0140 - model_loss: 0.0032 - model_1_loss: 8.5082e-04 - model_2_loss: 0.0056 - model_3_loss: 0.0038 - model_4_loss: 5.6111e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.8081 - loss2: 9.4317 - val_loss: 15.8369 - val_model_loss: 1.5672 - val_model_1_loss: 5.1778 - val_model_2_loss: 2.5968 - val_model_3_loss: 3.5997 - val_model_4_loss: 2.8955 - val_model_accuracy: 0.4690 - val_model_1_accuracy: 0.3860 - val_model_2_accuracy: 0.3400 - val_model_3_accuracy: 0.4310 - val_model_4_accuracy: 0.2870 - val_loss1: 5.8845 - val_loss2: 8.6710\n","Epoch 77/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0592 - model_loss: 0.0040 - model_1_loss: 0.0010 - model_2_loss: 0.0098 - model_3_loss: 0.0402 - model_4_loss: 0.0041 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6634 - loss2: 9.3708 - val_loss: 16.1070 - val_model_loss: 1.5992 - val_model_1_loss: 5.1602 - val_model_2_loss: 2.6106 - val_model_3_loss: 3.6966 - val_model_4_loss: 3.0403 - val_model_accuracy: 0.4705 - val_model_1_accuracy: 0.3875 - val_model_2_accuracy: 0.3545 - val_model_3_accuracy: 0.4315 - val_model_4_accuracy: 0.3120 - val_loss1: 6.0813 - val_loss2: 8.6950\n","Epoch 78/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0159 - model_loss: 0.0030 - model_1_loss: 0.0015 - model_2_loss: 0.0010 - model_3_loss: 0.0086 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1962 - loss2: 9.2295 - val_loss: 16.3718 - val_model_loss: 1.6325 - val_model_1_loss: 5.1371 - val_model_2_loss: 2.6326 - val_model_3_loss: 3.7738 - val_model_4_loss: 3.1958 - val_model_accuracy: 0.4720 - val_model_1_accuracy: 0.3865 - val_model_2_accuracy: 0.3690 - val_model_3_accuracy: 0.4325 - val_model_4_accuracy: 0.3270 - val_loss1: 6.2252 - val_loss2: 8.7184\n","Epoch 79/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0324 - model_loss: 0.0082 - model_1_loss: 0.0025 - model_2_loss: 0.0099 - model_3_loss: 0.0065 - model_4_loss: 0.0053 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6158 - loss2: 9.3859 - val_loss: 16.5786 - val_model_loss: 1.6576 - val_model_1_loss: 5.1100 - val_model_2_loss: 2.6485 - val_model_3_loss: 3.8169 - val_model_4_loss: 3.3456 - val_model_accuracy: 0.4735 - val_model_1_accuracy: 0.3855 - val_model_2_accuracy: 0.3810 - val_model_3_accuracy: 0.4315 - val_model_4_accuracy: 0.3495 - val_loss1: 6.3306 - val_loss2: 8.7438\n","Epoch 80/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0203 - model_loss: 0.0036 - model_1_loss: 0.0022 - model_2_loss: 0.0033 - model_3_loss: 0.0075 - model_4_loss: 0.0036 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5655 - loss2: 9.2524 - val_loss: 16.8196 - val_model_loss: 1.6827 - val_model_1_loss: 5.0791 - val_model_2_loss: 2.6787 - val_model_3_loss: 3.8856 - val_model_4_loss: 3.4936 - val_model_accuracy: 0.4750 - val_model_1_accuracy: 0.3840 - val_model_2_accuracy: 0.3905 - val_model_3_accuracy: 0.4320 - val_model_4_accuracy: 0.3675 - val_loss1: 6.4147 - val_loss2: 8.7642\n","Epoch 81/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0951 - model_loss: 0.0037 - model_1_loss: 0.0133 - model_2_loss: 0.0111 - model_3_loss: 0.0608 - model_4_loss: 0.0061 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8770 - loss2: 9.0397 - val_loss: 17.0201 - val_model_loss: 1.7025 - val_model_1_loss: 5.0363 - val_model_2_loss: 2.7056 - val_model_3_loss: 3.9417 - val_model_4_loss: 3.6340 - val_model_accuracy: 0.4760 - val_model_1_accuracy: 0.3835 - val_model_2_accuracy: 0.3970 - val_model_3_accuracy: 0.4315 - val_model_4_accuracy: 0.3790 - val_loss1: 6.4835 - val_loss2: 8.7873\n","Epoch 82/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1373 - model_loss: 0.0021 - model_1_loss: 0.0066 - model_2_loss: 0.0053 - model_3_loss: 0.0962 - model_4_loss: 0.0271 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9997 - loss2: 9.1514 - val_loss: 17.1252 - val_model_loss: 1.7215 - val_model_1_loss: 4.9737 - val_model_2_loss: 2.7246 - val_model_3_loss: 3.9693 - val_model_4_loss: 3.7360 - val_model_accuracy: 0.4765 - val_model_1_accuracy: 0.3820 - val_model_2_accuracy: 0.4025 - val_model_3_accuracy: 0.4330 - val_model_4_accuracy: 0.3865 - val_loss1: 6.5409 - val_loss2: 8.8181\n","Epoch 83/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.2012 - model_loss: 0.0038 - model_1_loss: 0.1268 - model_2_loss: 0.0302 - model_3_loss: 0.0358 - model_4_loss: 0.0045 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0070 - loss2: 9.0770 - val_loss: 17.3097 - val_model_loss: 1.7314 - val_model_1_loss: 4.9218 - val_model_2_loss: 2.7489 - val_model_3_loss: 4.0714 - val_model_4_loss: 3.8362 - val_model_accuracy: 0.4770 - val_model_1_accuracy: 0.3715 - val_model_2_accuracy: 0.4020 - val_model_3_accuracy: 0.4340 - val_model_4_accuracy: 0.3890 - val_loss1: 6.5880 - val_loss2: 8.8760\n","Epoch 84/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0604 - model_loss: 0.0064 - model_1_loss: 0.0070 - model_2_loss: 0.0131 - model_3_loss: 0.0060 - model_4_loss: 0.0278 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5172 - loss2: 9.1605 - val_loss: 17.5214 - val_model_loss: 1.7506 - val_model_1_loss: 4.8782 - val_model_2_loss: 2.7697 - val_model_3_loss: 4.1962 - val_model_4_loss: 3.9266 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.3640 - val_model_2_accuracy: 0.4035 - val_model_3_accuracy: 0.4335 - val_model_4_accuracy: 0.3935 - val_loss1: 6.6242 - val_loss2: 8.9212\n","Epoch 85/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.4657 - model_loss: 0.0750 - model_1_loss: 0.1400 - model_2_loss: 0.0060 - model_3_loss: 0.2055 - model_4_loss: 0.0392 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.8487 - loss2: 8.9469 - val_loss: 17.6563 - val_model_loss: 1.7649 - val_model_1_loss: 4.8691 - val_model_2_loss: 2.7864 - val_model_3_loss: 4.2534 - val_model_4_loss: 3.9825 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.3545 - val_model_2_accuracy: 0.4020 - val_model_3_accuracy: 0.4340 - val_model_4_accuracy: 0.3975 - val_loss1: 6.6237 - val_loss2: 8.9620\n","Epoch 86/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0873 - model_loss: 0.0145 - model_1_loss: 0.0042 - model_2_loss: 0.0131 - model_3_loss: 0.0143 - model_4_loss: 0.0412 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3187 - loss2: 9.2184 - val_loss: 17.7430 - val_model_loss: 1.7816 - val_model_1_loss: 4.8581 - val_model_2_loss: 2.8016 - val_model_3_loss: 4.2910 - val_model_4_loss: 4.0107 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.3530 - val_model_2_accuracy: 0.4035 - val_model_3_accuracy: 0.4365 - val_model_4_accuracy: 0.4015 - val_loss1: 6.6284 - val_loss2: 8.9923\n","Epoch 87/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0199 - model_loss: 0.0043 - model_1_loss: 0.0032 - model_2_loss: 0.0024 - model_3_loss: 0.0068 - model_4_loss: 0.0032 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4415 - loss2: 9.3658 - val_loss: 17.7371 - val_model_loss: 1.7951 - val_model_1_loss: 4.8442 - val_model_2_loss: 2.8067 - val_model_3_loss: 4.2884 - val_model_4_loss: 4.0027 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.3535 - val_model_2_accuracy: 0.4040 - val_model_3_accuracy: 0.4370 - val_model_4_accuracy: 0.4020 - val_loss1: 6.6320 - val_loss2: 9.0149\n","Epoch 88/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0766 - model_loss: 0.0094 - model_1_loss: 0.0011 - model_2_loss: 0.0015 - model_3_loss: 0.0536 - model_4_loss: 0.0109 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0405 - loss2: 9.1083 - val_loss: 17.7891 - val_model_loss: 1.8049 - val_model_1_loss: 4.8301 - val_model_2_loss: 2.8148 - val_model_3_loss: 4.3208 - val_model_4_loss: 4.0186 - val_model_accuracy: 0.4810 - val_model_1_accuracy: 0.3570 - val_model_2_accuracy: 0.4030 - val_model_3_accuracy: 0.4365 - val_model_4_accuracy: 0.4015 - val_loss1: 6.6343 - val_loss2: 9.0268\n","Epoch 89/300\n","1/1 [==============================] - 5s 5s/step - loss: 1.2336 - model_loss: 0.0088 - model_1_loss: 0.0296 - model_2_loss: 0.1670 - model_3_loss: 1.0252 - model_4_loss: 0.0030 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.6667 - model_4_accuracy: 1.0000 - loss1: 6.8885 - loss2: 8.7018 - val_loss: 19.5007 - val_model_loss: 1.8121 - val_model_1_loss: 4.8324 - val_model_2_loss: 2.8011 - val_model_3_loss: 6.0220 - val_model_4_loss: 4.0331 - val_model_accuracy: 0.4820 - val_model_1_accuracy: 0.3515 - val_model_2_accuracy: 0.4075 - val_model_3_accuracy: 0.4490 - val_model_4_accuracy: 0.4025 - val_loss1: 6.6753 - val_loss2: 8.8511\n","Epoch 90/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0262 - model_loss: 0.0022 - model_1_loss: 0.0094 - model_2_loss: 0.0025 - model_3_loss: 0.0058 - model_4_loss: 0.0063 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8583 - loss2: 9.1906 - val_loss: 21.6744 - val_model_loss: 1.8216 - val_model_1_loss: 4.8243 - val_model_2_loss: 2.7758 - val_model_3_loss: 8.2314 - val_model_4_loss: 4.0214 - val_model_accuracy: 0.4820 - val_model_1_accuracy: 0.3530 - val_model_2_accuracy: 0.4100 - val_model_3_accuracy: 0.4505 - val_model_4_accuracy: 0.4040 - val_loss1: 6.6823 - val_loss2: 8.5828\n","Epoch 91/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0257 - model_loss: 0.0078 - model_1_loss: 0.0060 - model_2_loss: 0.0018 - model_3_loss: 0.0077 - model_4_loss: 0.0023 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5158 - loss2: 9.3796 - val_loss: 23.8041 - val_model_loss: 1.8318 - val_model_1_loss: 4.8079 - val_model_2_loss: 2.7537 - val_model_3_loss: 10.4212 - val_model_4_loss: 3.9895 - val_model_accuracy: 0.4820 - val_model_1_accuracy: 0.3505 - val_model_2_accuracy: 0.4110 - val_model_3_accuracy: 0.4675 - val_model_4_accuracy: 0.4060 - val_loss1: 6.6892 - val_loss2: 8.3800\n","Epoch 92/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0211 - model_loss: 0.0013 - model_1_loss: 0.0013 - model_2_loss: 7.5675e-04 - model_3_loss: 0.0136 - model_4_loss: 0.0042 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4208 - loss2: 9.2708 - val_loss: 25.6313 - val_model_loss: 1.8401 - val_model_1_loss: 4.7890 - val_model_2_loss: 2.7340 - val_model_3_loss: 12.3189 - val_model_4_loss: 3.9493 - val_model_accuracy: 0.4820 - val_model_1_accuracy: 0.3480 - val_model_2_accuracy: 0.4135 - val_model_3_accuracy: 0.4860 - val_model_4_accuracy: 0.4075 - val_loss1: 6.6757 - val_loss2: 8.2491\n","Epoch 93/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.6213 - model_loss: 0.1845 - model_1_loss: 0.0065 - model_2_loss: 0.1658 - model_3_loss: 0.2364 - model_4_loss: 0.0280 - model_accuracy: 0.8333 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.0284 - loss2: 9.0015 - val_loss: 27.8376 - val_model_loss: 1.8729 - val_model_1_loss: 4.7715 - val_model_2_loss: 2.7891 - val_model_3_loss: 14.4920 - val_model_4_loss: 3.9120 - val_model_accuracy: 0.4810 - val_model_1_accuracy: 0.3475 - val_model_2_accuracy: 0.4230 - val_model_3_accuracy: 0.5025 - val_model_4_accuracy: 0.4105 - val_loss1: 6.7498 - val_loss2: 8.1535\n","Epoch 94/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0301 - model_loss: 0.0101 - model_1_loss: 0.0015 - model_2_loss: 0.0045 - model_3_loss: 0.0068 - model_4_loss: 0.0073 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8753 - loss2: 9.1072 - val_loss: 29.8712 - val_model_loss: 1.8936 - val_model_1_loss: 4.7519 - val_model_2_loss: 2.8739 - val_model_3_loss: 16.4866 - val_model_4_loss: 3.8652 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.3450 - val_model_2_accuracy: 0.4305 - val_model_3_accuracy: 0.5125 - val_model_4_accuracy: 0.4130 - val_loss1: 6.7449 - val_loss2: 8.0680\n","Epoch 95/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0546 - model_loss: 0.0013 - model_1_loss: 0.0011 - model_2_loss: 7.7725e-04 - model_3_loss: 0.0263 - model_4_loss: 0.0252 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.4836 - loss2: 8.9867 - val_loss: 31.1311 - val_model_loss: 1.9171 - val_model_1_loss: 4.7437 - val_model_2_loss: 2.9811 - val_model_3_loss: 17.6482 - val_model_4_loss: 3.8411 - val_model_accuracy: 0.4775 - val_model_1_accuracy: 0.3445 - val_model_2_accuracy: 0.4365 - val_model_3_accuracy: 0.5130 - val_model_4_accuracy: 0.4145 - val_loss1: 6.7023 - val_loss2: 8.0177\n","Epoch 96/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0330 - model_loss: 0.0128 - model_1_loss: 0.0031 - model_2_loss: 0.0072 - model_3_loss: 0.0077 - model_4_loss: 0.0023 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8971 - loss2: 9.0409 - val_loss: 31.9266 - val_model_loss: 1.9365 - val_model_1_loss: 4.7199 - val_model_2_loss: 3.0806 - val_model_3_loss: 18.3813 - val_model_4_loss: 3.8082 - val_model_accuracy: 0.4780 - val_model_1_accuracy: 0.3430 - val_model_2_accuracy: 0.4360 - val_model_3_accuracy: 0.5115 - val_model_4_accuracy: 0.4135 - val_loss1: 6.6422 - val_loss2: 7.9742\n","Epoch 97/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0180 - model_loss: 0.0029 - model_1_loss: 9.2654e-04 - model_2_loss: 0.0085 - model_3_loss: 0.0039 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.6004 - loss2: 8.7388 - val_loss: 32.6542 - val_model_loss: 1.9606 - val_model_1_loss: 4.7187 - val_model_2_loss: 3.1574 - val_model_3_loss: 19.0423 - val_model_4_loss: 3.7752 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.3440 - val_model_2_accuracy: 0.4360 - val_model_3_accuracy: 0.5100 - val_model_4_accuracy: 0.4110 - val_loss1: 6.5677 - val_loss2: 7.9297\n","Epoch 98/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.4990 - model_loss: 0.0747 - model_1_loss: 0.0045 - model_2_loss: 0.0122 - model_3_loss: 0.3982 - model_4_loss: 0.0093 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.2666 - loss2: 8.6400 - val_loss: 31.4016 - val_model_loss: 1.9533 - val_model_1_loss: 4.7017 - val_model_2_loss: 3.2346 - val_model_3_loss: 17.7495 - val_model_4_loss: 3.7626 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.3435 - val_model_2_accuracy: 0.4470 - val_model_3_accuracy: 0.5100 - val_model_4_accuracy: 0.4105 - val_loss1: 6.5244 - val_loss2: 7.9448\n","Epoch 99/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1260 - model_loss: 0.0770 - model_1_loss: 5.1358e-04 - model_2_loss: 0.0235 - model_3_loss: 0.0088 - model_4_loss: 0.0162 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.8993 - loss2: 8.6183 - val_loss: 30.1593 - val_model_loss: 1.9500 - val_model_1_loss: 4.6759 - val_model_2_loss: 3.3136 - val_model_3_loss: 16.4815 - val_model_4_loss: 3.7383 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.3445 - val_model_2_accuracy: 0.4575 - val_model_3_accuracy: 0.4995 - val_model_4_accuracy: 0.4120 - val_loss1: 6.4589 - val_loss2: 7.9579\n","Epoch 100/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0366 - model_loss: 0.0213 - model_1_loss: 0.0016 - model_2_loss: 0.0028 - model_3_loss: 0.0067 - model_4_loss: 0.0042 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9577 - loss2: 9.1601 - val_loss: 29.0172 - val_model_loss: 1.9522 - val_model_1_loss: 4.6542 - val_model_2_loss: 3.3884 - val_model_3_loss: 15.3171 - val_model_4_loss: 3.7052 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.3430 - val_model_2_accuracy: 0.4635 - val_model_3_accuracy: 0.4810 - val_model_4_accuracy: 0.4130 - val_loss1: 6.3984 - val_loss2: 7.9739\n","Epoch 101/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0258 - model_loss: 0.0050 - model_1_loss: 8.7806e-04 - model_2_loss: 0.0132 - model_3_loss: 0.0021 - model_4_loss: 0.0046 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0953 - loss2: 9.1610 - val_loss: 27.9940 - val_model_loss: 1.9546 - val_model_1_loss: 4.6207 - val_model_2_loss: 3.4721 - val_model_3_loss: 14.2779 - val_model_4_loss: 3.6686 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.3410 - val_model_2_accuracy: 0.4670 - val_model_3_accuracy: 0.4750 - val_model_4_accuracy: 0.4130 - val_loss1: 6.3429 - val_loss2: 7.9879\n","Epoch 102/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.4163 - model_loss: 0.0496 - model_1_loss: 0.0059 - model_2_loss: 0.2251 - model_3_loss: 0.1296 - model_4_loss: 0.0060 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.9872 - loss2: 9.0171 - val_loss: 25.5174 - val_model_loss: 1.9641 - val_model_1_loss: 4.6009 - val_model_2_loss: 3.2256 - val_model_3_loss: 12.0908 - val_model_4_loss: 3.6360 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.3395 - val_model_2_accuracy: 0.4695 - val_model_3_accuracy: 0.4670 - val_model_4_accuracy: 0.4145 - val_loss1: 6.2134 - val_loss2: 8.1012\n","Epoch 103/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.3637 - model_loss: 0.0015 - model_1_loss: 0.0175 - model_2_loss: 0.0069 - model_3_loss: 0.3260 - model_4_loss: 0.0118 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.9558 - loss2: 9.1432 - val_loss: 21.8046 - val_model_loss: 1.9804 - val_model_1_loss: 4.5659 - val_model_2_loss: 3.0486 - val_model_3_loss: 8.6108 - val_model_4_loss: 3.5990 - val_model_accuracy: 0.4810 - val_model_1_accuracy: 0.3400 - val_model_2_accuracy: 0.4685 - val_model_3_accuracy: 0.4485 - val_model_4_accuracy: 0.4160 - val_loss1: 5.9669 - val_loss2: 8.3123\n","Epoch 104/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.2152 - model_loss: 0.0013 - model_1_loss: 0.0019 - model_2_loss: 0.0315 - model_3_loss: 0.1762 - model_4_loss: 0.0042 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 7.4456 - loss2: 8.9083 - val_loss: 18.3413 - val_model_loss: 1.9934 - val_model_1_loss: 4.5357 - val_model_2_loss: 2.9262 - val_model_3_loss: 5.3220 - val_model_4_loss: 3.5640 - val_model_accuracy: 0.4800 - val_model_1_accuracy: 0.3340 - val_model_2_accuracy: 0.4530 - val_model_3_accuracy: 0.4230 - val_model_4_accuracy: 0.4150 - val_loss1: 5.6008 - val_loss2: 8.6441\n","Epoch 105/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0209 - model_loss: 0.0099 - model_1_loss: 0.0013 - model_2_loss: 0.0048 - model_3_loss: 0.0019 - model_4_loss: 0.0030 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7088 - loss2: 9.1056 - val_loss: 16.8910 - val_model_loss: 2.0119 - val_model_1_loss: 4.4986 - val_model_2_loss: 2.8502 - val_model_3_loss: 4.0052 - val_model_4_loss: 3.5250 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.3330 - val_model_2_accuracy: 0.4260 - val_model_3_accuracy: 0.4295 - val_model_4_accuracy: 0.4150 - val_loss1: 5.2978 - val_loss2: 8.7786\n","Epoch 106/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0272 - model_loss: 0.0057 - model_1_loss: 0.0025 - model_2_loss: 0.0093 - model_3_loss: 0.0066 - model_4_loss: 0.0031 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1301 - loss2: 9.3318 - val_loss: 16.6315 - val_model_loss: 2.0214 - val_model_1_loss: 4.4615 - val_model_2_loss: 2.8003 - val_model_3_loss: 3.8677 - val_model_4_loss: 3.4806 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.3280 - val_model_2_accuracy: 0.3990 - val_model_3_accuracy: 0.4755 - val_model_4_accuracy: 0.4150 - val_loss1: 5.1405 - val_loss2: 8.7701\n","Epoch 107/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0343 - model_loss: 0.0034 - model_1_loss: 0.0129 - model_2_loss: 0.0122 - model_3_loss: 0.0040 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2647 - loss2: 9.2756 - val_loss: 16.7349 - val_model_loss: 2.0371 - val_model_1_loss: 4.4233 - val_model_2_loss: 2.7756 - val_model_3_loss: 4.0586 - val_model_4_loss: 3.4402 - val_model_accuracy: 0.4785 - val_model_1_accuracy: 0.3285 - val_model_2_accuracy: 0.3920 - val_model_3_accuracy: 0.4920 - val_model_4_accuracy: 0.4155 - val_loss1: 5.1029 - val_loss2: 8.7524\n","Epoch 108/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0480 - model_loss: 0.0023 - model_1_loss: 7.4712e-04 - model_2_loss: 0.0046 - model_3_loss: 0.0389 - model_4_loss: 0.0015 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9804 - loss2: 9.2005 - val_loss: 16.8159 - val_model_loss: 2.0499 - val_model_1_loss: 4.3894 - val_model_2_loss: 2.7515 - val_model_3_loss: 4.2202 - val_model_4_loss: 3.4048 - val_model_accuracy: 0.4780 - val_model_1_accuracy: 0.3310 - val_model_2_accuracy: 0.3700 - val_model_3_accuracy: 0.5040 - val_model_4_accuracy: 0.4130 - val_loss1: 5.1438 - val_loss2: 8.7465\n","Epoch 109/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0763 - model_loss: 0.0061 - model_1_loss: 0.0041 - model_2_loss: 0.0121 - model_3_loss: 0.0045 - model_4_loss: 0.0494 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6232 - loss2: 9.3670 - val_loss: 16.8153 - val_model_loss: 2.0637 - val_model_1_loss: 4.3560 - val_model_2_loss: 2.7402 - val_model_3_loss: 4.3142 - val_model_4_loss: 3.3411 - val_model_accuracy: 0.4775 - val_model_1_accuracy: 0.3310 - val_model_2_accuracy: 0.3455 - val_model_3_accuracy: 0.5075 - val_model_4_accuracy: 0.4115 - val_loss1: 5.1965 - val_loss2: 8.7537\n","Epoch 110/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0227 - model_loss: 0.0027 - model_1_loss: 0.0023 - model_2_loss: 0.0119 - model_3_loss: 0.0053 - model_4_loss: 4.0685e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6349 - loss2: 9.4366 - val_loss: 16.7650 - val_model_loss: 2.0740 - val_model_1_loss: 4.3135 - val_model_2_loss: 2.7296 - val_model_3_loss: 4.3735 - val_model_4_loss: 3.2744 - val_model_accuracy: 0.4760 - val_model_1_accuracy: 0.3310 - val_model_2_accuracy: 0.3415 - val_model_3_accuracy: 0.5150 - val_model_4_accuracy: 0.4090 - val_loss1: 5.2589 - val_loss2: 8.7648\n","Epoch 111/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0172 - model_loss: 0.0031 - model_1_loss: 3.3381e-04 - model_2_loss: 0.0012 - model_3_loss: 0.0119 - model_4_loss: 6.6939e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2368 - loss2: 9.3349 - val_loss: 16.7348 - val_model_loss: 2.0862 - val_model_1_loss: 4.2733 - val_model_2_loss: 2.7293 - val_model_3_loss: 4.4305 - val_model_4_loss: 3.2156 - val_model_accuracy: 0.4755 - val_model_1_accuracy: 0.3305 - val_model_2_accuracy: 0.3440 - val_model_3_accuracy: 0.5210 - val_model_4_accuracy: 0.4100 - val_loss1: 5.3132 - val_loss2: 8.7733\n","Epoch 112/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1205 - model_loss: 0.0451 - model_1_loss: 0.0104 - model_2_loss: 0.0090 - model_3_loss: 0.0514 - model_4_loss: 0.0046 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4898 - loss2: 9.2801 - val_loss: 16.7069 - val_model_loss: 2.0843 - val_model_1_loss: 4.2434 - val_model_2_loss: 2.7456 - val_model_3_loss: 4.4523 - val_model_4_loss: 3.1813 - val_model_accuracy: 0.4740 - val_model_1_accuracy: 0.3310 - val_model_2_accuracy: 0.3495 - val_model_3_accuracy: 0.5270 - val_model_4_accuracy: 0.4065 - val_loss1: 5.3456 - val_loss2: 8.7785\n","Epoch 113/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0070 - model_loss: 0.0017 - model_1_loss: 7.6763e-04 - model_2_loss: 8.0001e-04 - model_3_loss: 0.0025 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2900 - loss2: 9.2657 - val_loss: 16.6898 - val_model_loss: 2.0897 - val_model_1_loss: 4.2210 - val_model_2_loss: 2.7574 - val_model_3_loss: 4.4768 - val_model_4_loss: 3.1449 - val_model_accuracy: 0.4735 - val_model_1_accuracy: 0.3330 - val_model_2_accuracy: 0.3565 - val_model_3_accuracy: 0.5275 - val_model_4_accuracy: 0.4015 - val_loss1: 5.3687 - val_loss2: 8.7843\n","Epoch 114/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0694 - model_loss: 6.4697e-04 - model_1_loss: 4.7570e-04 - model_2_loss: 0.0070 - model_3_loss: 0.0572 - model_4_loss: 0.0041 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2302 - loss2: 9.3441 - val_loss: 16.6420 - val_model_loss: 2.0924 - val_model_1_loss: 4.1897 - val_model_2_loss: 2.7688 - val_model_3_loss: 4.4770 - val_model_4_loss: 3.1141 - val_model_accuracy: 0.4730 - val_model_1_accuracy: 0.3345 - val_model_2_accuracy: 0.3640 - val_model_3_accuracy: 0.5280 - val_model_4_accuracy: 0.4005 - val_loss1: 5.3643 - val_loss2: 8.7861\n","Epoch 115/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.5648 - model_loss: 0.0440 - model_1_loss: 0.0047 - model_2_loss: 0.2183 - model_3_loss: 0.2909 - model_4_loss: 0.0069 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.3626 - loss2: 9.1606 - val_loss: 16.5631 - val_model_loss: 2.0908 - val_model_1_loss: 4.1660 - val_model_2_loss: 2.8286 - val_model_3_loss: 4.3872 - val_model_4_loss: 3.0906 - val_model_accuracy: 0.4660 - val_model_1_accuracy: 0.3370 - val_model_2_accuracy: 0.3335 - val_model_3_accuracy: 0.5300 - val_model_4_accuracy: 0.3960 - val_loss1: 5.2796 - val_loss2: 8.7935\n","Epoch 116/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0315 - model_loss: 0.0016 - model_1_loss: 0.0023 - model_2_loss: 0.0060 - model_3_loss: 0.0200 - model_4_loss: 0.0017 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9376 - loss2: 9.2739 - val_loss: 16.4767 - val_model_loss: 2.0929 - val_model_1_loss: 4.1460 - val_model_2_loss: 2.8762 - val_model_3_loss: 4.2928 - val_model_4_loss: 3.0689 - val_model_accuracy: 0.4645 - val_model_1_accuracy: 0.3380 - val_model_2_accuracy: 0.3155 - val_model_3_accuracy: 0.5285 - val_model_4_accuracy: 0.3945 - val_loss1: 5.2379 - val_loss2: 8.8028\n","Epoch 117/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0277 - model_loss: 0.0106 - model_1_loss: 0.0019 - model_2_loss: 9.8819e-04 - model_3_loss: 0.0120 - model_4_loss: 0.0022 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2024 - loss2: 9.2769 - val_loss: 16.3503 - val_model_loss: 2.0938 - val_model_1_loss: 4.1223 - val_model_2_loss: 2.8942 - val_model_3_loss: 4.1953 - val_model_4_loss: 3.0448 - val_model_accuracy: 0.4610 - val_model_1_accuracy: 0.3365 - val_model_2_accuracy: 0.3390 - val_model_3_accuracy: 0.5280 - val_model_4_accuracy: 0.3930 - val_loss1: 5.2418 - val_loss2: 8.8180\n","Epoch 118/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.2594 - model_loss: 0.0911 - model_1_loss: 0.0016 - model_2_loss: 0.0619 - model_3_loss: 0.0966 - model_4_loss: 0.0083 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0221 - loss2: 9.2622 - val_loss: 16.2064 - val_model_loss: 2.1119 - val_model_1_loss: 4.0863 - val_model_2_loss: 2.9079 - val_model_3_loss: 4.0696 - val_model_4_loss: 3.0307 - val_model_accuracy: 0.4665 - val_model_1_accuracy: 0.3365 - val_model_2_accuracy: 0.3640 - val_model_3_accuracy: 0.5275 - val_model_4_accuracy: 0.3915 - val_loss1: 5.2333 - val_loss2: 8.8367\n","Epoch 119/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0392 - model_loss: 0.0137 - model_1_loss: 0.0041 - model_2_loss: 0.0066 - model_3_loss: 0.0068 - model_4_loss: 0.0081 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8143 - loss2: 9.2552 - val_loss: 16.0950 - val_model_loss: 2.1352 - val_model_1_loss: 4.0622 - val_model_2_loss: 2.9259 - val_model_3_loss: 3.9500 - val_model_4_loss: 3.0216 - val_model_accuracy: 0.4680 - val_model_1_accuracy: 0.3380 - val_model_2_accuracy: 0.3755 - val_model_3_accuracy: 0.5235 - val_model_4_accuracy: 0.3880 - val_loss1: 5.2122 - val_loss2: 8.8545\n","Epoch 120/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0510 - model_loss: 0.0088 - model_1_loss: 0.0120 - model_2_loss: 0.0247 - model_3_loss: 0.0039 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2890 - loss2: 9.4031 - val_loss: 16.0010 - val_model_loss: 2.1557 - val_model_1_loss: 4.0360 - val_model_2_loss: 2.9537 - val_model_3_loss: 3.8485 - val_model_4_loss: 3.0070 - val_model_accuracy: 0.4715 - val_model_1_accuracy: 0.3380 - val_model_2_accuracy: 0.3790 - val_model_3_accuracy: 0.5175 - val_model_4_accuracy: 0.3840 - val_loss1: 5.1883 - val_loss2: 8.8714\n","Epoch 121/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.3738 - model_loss: 0.0501 - model_1_loss: 0.0035 - model_2_loss: 0.1079 - model_3_loss: 0.2105 - model_4_loss: 0.0019 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.1900 - loss2: 9.2027 - val_loss: 15.9002 - val_model_loss: 2.1689 - val_model_1_loss: 4.0052 - val_model_2_loss: 3.0024 - val_model_3_loss: 3.7303 - val_model_4_loss: 2.9934 - val_model_accuracy: 0.4710 - val_model_1_accuracy: 0.3370 - val_model_2_accuracy: 0.3890 - val_model_3_accuracy: 0.5145 - val_model_4_accuracy: 0.3830 - val_loss1: 5.1699 - val_loss2: 8.8876\n","Epoch 122/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0174 - model_loss: 0.0084 - model_1_loss: 2.9343e-04 - model_2_loss: 0.0022 - model_3_loss: 0.0061 - model_4_loss: 4.6001e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7676 - loss2: 9.2558 - val_loss: 15.8244 - val_model_loss: 2.1825 - val_model_1_loss: 3.9783 - val_model_2_loss: 3.0552 - val_model_3_loss: 3.6176 - val_model_4_loss: 2.9908 - val_model_accuracy: 0.4705 - val_model_1_accuracy: 0.3380 - val_model_2_accuracy: 0.3970 - val_model_3_accuracy: 0.5095 - val_model_4_accuracy: 0.3810 - val_loss1: 5.1612 - val_loss2: 8.8975\n","Epoch 123/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0442 - model_loss: 0.0099 - model_1_loss: 0.0030 - model_2_loss: 0.0014 - model_3_loss: 0.0228 - model_4_loss: 0.0071 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1163 - loss2: 9.2744 - val_loss: 15.7520 - val_model_loss: 2.1943 - val_model_1_loss: 3.9523 - val_model_2_loss: 3.1027 - val_model_3_loss: 3.5185 - val_model_4_loss: 2.9842 - val_model_accuracy: 0.4710 - val_model_1_accuracy: 0.3360 - val_model_2_accuracy: 0.4040 - val_model_3_accuracy: 0.5065 - val_model_4_accuracy: 0.3765 - val_loss1: 5.1757 - val_loss2: 8.9055\n","Epoch 124/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0399 - model_loss: 8.7903e-04 - model_1_loss: 0.0027 - model_2_loss: 0.0024 - model_3_loss: 0.0296 - model_4_loss: 0.0043 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9677 - loss2: 9.2341 - val_loss: 15.6813 - val_model_loss: 2.2057 - val_model_1_loss: 3.9242 - val_model_2_loss: 3.1416 - val_model_3_loss: 3.4324 - val_model_4_loss: 2.9774 - val_model_accuracy: 0.4725 - val_model_1_accuracy: 0.3350 - val_model_2_accuracy: 0.4085 - val_model_3_accuracy: 0.5030 - val_model_4_accuracy: 0.3750 - val_loss1: 5.1891 - val_loss2: 8.9111\n","Epoch 125/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.2883 - model_loss: 0.0086 - model_1_loss: 0.0950 - model_2_loss: 0.1607 - model_3_loss: 0.0050 - model_4_loss: 0.0191 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 0.8333 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9966 - loss2: 9.2263 - val_loss: 15.5671 - val_model_loss: 2.2224 - val_model_1_loss: 3.8364 - val_model_2_loss: 3.1683 - val_model_3_loss: 3.3666 - val_model_4_loss: 2.9733 - val_model_accuracy: 0.4735 - val_model_1_accuracy: 0.3325 - val_model_2_accuracy: 0.4200 - val_model_3_accuracy: 0.4955 - val_model_4_accuracy: 0.3715 - val_loss1: 5.2129 - val_loss2: 8.9114\n","Epoch 126/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0475 - model_loss: 0.0019 - model_1_loss: 0.0097 - model_2_loss: 0.0067 - model_3_loss: 0.0081 - model_4_loss: 0.0211 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0395 - loss2: 9.2836 - val_loss: 15.4491 - val_model_loss: 2.2337 - val_model_1_loss: 3.7571 - val_model_2_loss: 3.1891 - val_model_3_loss: 3.3055 - val_model_4_loss: 2.9637 - val_model_accuracy: 0.4740 - val_model_1_accuracy: 0.3310 - val_model_2_accuracy: 0.4310 - val_model_3_accuracy: 0.4870 - val_model_4_accuracy: 0.3695 - val_loss1: 5.2275 - val_loss2: 8.9113\n","Epoch 127/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0143 - model_loss: 0.0023 - model_1_loss: 0.0011 - model_2_loss: 0.0040 - model_3_loss: 0.0062 - model_4_loss: 7.5031e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0441 - loss2: 9.2659 - val_loss: 15.3492 - val_model_loss: 2.2507 - val_model_1_loss: 3.6769 - val_model_2_loss: 3.2097 - val_model_3_loss: 3.2590 - val_model_4_loss: 2.9529 - val_model_accuracy: 0.4750 - val_model_1_accuracy: 0.3325 - val_model_2_accuracy: 0.4405 - val_model_3_accuracy: 0.4785 - val_model_4_accuracy: 0.3685 - val_loss1: 5.2514 - val_loss2: 8.9121\n","Epoch 128/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0897 - model_loss: 0.0017 - model_1_loss: 0.0438 - model_2_loss: 0.0243 - model_3_loss: 0.0106 - model_4_loss: 0.0092 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1491 - loss2: 9.2609 - val_loss: 15.2037 - val_model_loss: 2.2626 - val_model_1_loss: 3.5496 - val_model_2_loss: 3.2245 - val_model_3_loss: 3.2203 - val_model_4_loss: 2.9468 - val_model_accuracy: 0.4745 - val_model_1_accuracy: 0.3340 - val_model_2_accuracy: 0.4440 - val_model_3_accuracy: 0.4705 - val_model_4_accuracy: 0.3690 - val_loss1: 5.2785 - val_loss2: 8.9123\n","Epoch 129/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0083 - model_loss: 0.0030 - model_1_loss: 4.5587e-04 - model_2_loss: 0.0014 - model_3_loss: 0.0024 - model_4_loss: 0.0010 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2744 - loss2: 9.3359 - val_loss: 15.0418 - val_model_loss: 2.2712 - val_model_1_loss: 3.4285 - val_model_2_loss: 3.2294 - val_model_3_loss: 3.1763 - val_model_4_loss: 2.9364 - val_model_accuracy: 0.4745 - val_model_1_accuracy: 0.3425 - val_model_2_accuracy: 0.4550 - val_model_3_accuracy: 0.4615 - val_model_4_accuracy: 0.3690 - val_loss1: 5.3117 - val_loss2: 8.9143\n","Epoch 130/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0361 - model_loss: 0.0066 - model_1_loss: 8.5765e-04 - model_2_loss: 0.0102 - model_3_loss: 0.0074 - model_4_loss: 0.0111 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2531 - loss2: 9.3145 - val_loss: 14.9323 - val_model_loss: 2.2797 - val_model_1_loss: 3.3324 - val_model_2_loss: 3.2455 - val_model_3_loss: 3.1465 - val_model_4_loss: 2.9281 - val_model_accuracy: 0.4750 - val_model_1_accuracy: 0.3495 - val_model_2_accuracy: 0.4610 - val_model_3_accuracy: 0.4515 - val_model_4_accuracy: 0.3700 - val_loss1: 5.3428 - val_loss2: 8.9153\n","Epoch 131/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0176 - model_loss: 0.0041 - model_1_loss: 0.0016 - model_2_loss: 0.0047 - model_3_loss: 0.0053 - model_4_loss: 0.0019 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.4691 - loss2: 9.1970 - val_loss: 14.8624 - val_model_loss: 2.2893 - val_model_1_loss: 3.2643 - val_model_2_loss: 3.2626 - val_model_3_loss: 3.1132 - val_model_4_loss: 2.9329 - val_model_accuracy: 0.4750 - val_model_1_accuracy: 0.3570 - val_model_2_accuracy: 0.4715 - val_model_3_accuracy: 0.4440 - val_model_4_accuracy: 0.3695 - val_loss1: 5.3646 - val_loss2: 8.9112\n","Epoch 132/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1956 - model_loss: 0.0040 - model_1_loss: 0.0087 - model_2_loss: 0.1696 - model_3_loss: 0.0098 - model_4_loss: 0.0035 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0486 - loss2: 9.2195 - val_loss: 14.7275 - val_model_loss: 2.3017 - val_model_1_loss: 3.2048 - val_model_2_loss: 3.1922 - val_model_3_loss: 3.0968 - val_model_4_loss: 2.9320 - val_model_accuracy: 0.4755 - val_model_1_accuracy: 0.3645 - val_model_2_accuracy: 0.4475 - val_model_3_accuracy: 0.4345 - val_model_4_accuracy: 0.3670 - val_loss1: 5.3886 - val_loss2: 8.9474\n","Epoch 133/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0187 - model_loss: 0.0019 - model_1_loss: 0.0013 - model_2_loss: 9.6240e-04 - model_3_loss: 0.0088 - model_4_loss: 0.0057 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4417 - loss2: 9.3840 - val_loss: 14.6084 - val_model_loss: 2.3087 - val_model_1_loss: 3.1460 - val_model_2_loss: 3.1571 - val_model_3_loss: 3.0717 - val_model_4_loss: 2.9249 - val_model_accuracy: 0.4795 - val_model_1_accuracy: 0.3730 - val_model_2_accuracy: 0.4455 - val_model_3_accuracy: 0.4290 - val_model_4_accuracy: 0.3650 - val_loss1: 5.3965 - val_loss2: 8.9656\n","Epoch 134/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0251 - model_loss: 0.0096 - model_1_loss: 0.0012 - model_2_loss: 0.0025 - model_3_loss: 0.0102 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1938 - loss2: 9.3001 - val_loss: 14.5522 - val_model_loss: 2.3159 - val_model_1_loss: 3.0976 - val_model_2_loss: 3.1600 - val_model_3_loss: 3.0581 - val_model_4_loss: 2.9205 - val_model_accuracy: 0.4790 - val_model_1_accuracy: 0.3800 - val_model_2_accuracy: 0.4365 - val_model_3_accuracy: 0.4195 - val_model_4_accuracy: 0.3650 - val_loss1: 5.3877 - val_loss2: 8.9711\n","Epoch 135/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0191 - model_loss: 0.0020 - model_1_loss: 0.0037 - model_2_loss: 0.0055 - model_3_loss: 0.0046 - model_4_loss: 0.0032 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9673 - loss2: 9.2953 - val_loss: 14.5422 - val_model_loss: 2.3283 - val_model_1_loss: 3.0636 - val_model_2_loss: 3.1822 - val_model_3_loss: 3.0508 - val_model_4_loss: 2.9173 - val_model_accuracy: 0.4820 - val_model_1_accuracy: 0.3905 - val_model_2_accuracy: 0.4415 - val_model_3_accuracy: 0.4135 - val_model_4_accuracy: 0.3620 - val_loss1: 5.4018 - val_loss2: 8.9693\n","Epoch 136/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0271 - model_loss: 0.0032 - model_1_loss: 0.0029 - model_2_loss: 0.0134 - model_3_loss: 0.0057 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5016 - loss2: 9.3838 - val_loss: 14.5414 - val_model_loss: 2.3375 - val_model_1_loss: 3.0378 - val_model_2_loss: 3.2143 - val_model_3_loss: 3.0374 - val_model_4_loss: 2.9143 - val_model_accuracy: 0.4830 - val_model_1_accuracy: 0.3980 - val_model_2_accuracy: 0.4495 - val_model_3_accuracy: 0.4110 - val_model_4_accuracy: 0.3635 - val_loss1: 5.4089 - val_loss2: 8.9633\n","Epoch 137/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0965 - model_loss: 0.0290 - model_1_loss: 0.0122 - model_2_loss: 0.0070 - model_3_loss: 0.0304 - model_4_loss: 0.0179 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9347 - loss2: 9.2039 - val_loss: 14.5788 - val_model_loss: 2.3573 - val_model_1_loss: 3.0283 - val_model_2_loss: 3.2392 - val_model_3_loss: 3.0433 - val_model_4_loss: 2.9106 - val_model_accuracy: 0.4875 - val_model_1_accuracy: 0.4150 - val_model_2_accuracy: 0.4740 - val_model_3_accuracy: 0.4145 - val_model_4_accuracy: 0.3645 - val_loss1: 5.4283 - val_loss2: 8.9660\n","Epoch 138/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0269 - model_loss: 0.0018 - model_1_loss: 0.0054 - model_2_loss: 0.0031 - model_3_loss: 0.0153 - model_4_loss: 0.0013 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0805 - loss2: 9.2691 - val_loss: 14.5981 - val_model_loss: 2.3768 - val_model_1_loss: 3.0150 - val_model_2_loss: 3.2615 - val_model_3_loss: 3.0445 - val_model_4_loss: 2.9003 - val_model_accuracy: 0.4885 - val_model_1_accuracy: 0.4225 - val_model_2_accuracy: 0.4950 - val_model_3_accuracy: 0.4180 - val_model_4_accuracy: 0.3590 - val_loss1: 5.4421 - val_loss2: 8.9701\n","Epoch 139/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0137 - model_loss: 0.0013 - model_1_loss: 0.0021 - model_2_loss: 0.0016 - model_3_loss: 0.0059 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9464 - loss2: 9.2974 - val_loss: 14.6119 - val_model_loss: 2.3916 - val_model_1_loss: 3.0065 - val_model_2_loss: 3.2813 - val_model_3_loss: 3.0380 - val_model_4_loss: 2.8944 - val_model_accuracy: 0.4905 - val_model_1_accuracy: 0.4365 - val_model_2_accuracy: 0.5215 - val_model_3_accuracy: 0.4220 - val_model_4_accuracy: 0.3545 - val_loss1: 5.4647 - val_loss2: 8.9721\n","Epoch 140/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0176 - model_loss: 0.0049 - model_1_loss: 6.9875e-04 - model_2_loss: 0.0060 - model_3_loss: 0.0043 - model_4_loss: 0.0017 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4903 - loss2: 9.4239 - val_loss: 14.6225 - val_model_loss: 2.4043 - val_model_1_loss: 3.0007 - val_model_2_loss: 3.2998 - val_model_3_loss: 3.0292 - val_model_4_loss: 2.8884 - val_model_accuracy: 0.4910 - val_model_1_accuracy: 0.4415 - val_model_2_accuracy: 0.5305 - val_model_3_accuracy: 0.4270 - val_model_4_accuracy: 0.3545 - val_loss1: 5.4850 - val_loss2: 8.9733\n","Epoch 141/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0286 - model_loss: 7.0596e-04 - model_1_loss: 0.0030 - model_2_loss: 0.0119 - model_3_loss: 0.0088 - model_4_loss: 0.0043 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9902 - loss2: 9.1960 - val_loss: 14.6137 - val_model_loss: 2.4109 - val_model_1_loss: 2.9948 - val_model_2_loss: 3.3137 - val_model_3_loss: 3.0092 - val_model_4_loss: 2.8851 - val_model_accuracy: 0.4925 - val_model_1_accuracy: 0.4485 - val_model_2_accuracy: 0.5325 - val_model_3_accuracy: 0.4310 - val_model_4_accuracy: 0.3540 - val_loss1: 5.5013 - val_loss2: 8.9732\n","Epoch 142/300\n","1/1 [==============================] - 5s 5s/step - loss: 1.2067 - model_loss: 0.0370 - model_1_loss: 0.1386 - model_2_loss: 0.5061 - model_3_loss: 0.4104 - model_4_loss: 0.1146 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 0.8333 - model_3_accuracy: 0.8333 - model_4_accuracy: 1.0000 - loss1: 8.4546 - loss2: 9.2598 - val_loss: 14.4188 - val_model_loss: 2.4244 - val_model_1_loss: 2.9485 - val_model_2_loss: 3.2702 - val_model_3_loss: 2.8653 - val_model_4_loss: 2.9104 - val_model_accuracy: 0.4920 - val_model_1_accuracy: 0.4330 - val_model_2_accuracy: 0.5380 - val_model_3_accuracy: 0.4240 - val_model_4_accuracy: 0.3570 - val_loss1: 5.4572 - val_loss2: 8.9450\n","Epoch 143/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0081 - model_loss: 8.0102e-04 - model_1_loss: 7.6897e-04 - model_2_loss: 0.0046 - model_3_loss: 0.0016 - model_4_loss: 3.3079e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4755 - loss2: 9.4074 - val_loss: 14.2180 - val_model_loss: 2.4218 - val_model_1_loss: 2.9051 - val_model_2_loss: 3.2109 - val_model_3_loss: 2.7397 - val_model_4_loss: 2.9406 - val_model_accuracy: 0.4925 - val_model_1_accuracy: 0.4235 - val_model_2_accuracy: 0.5410 - val_model_3_accuracy: 0.4240 - val_model_4_accuracy: 0.3620 - val_loss1: 5.4034 - val_loss2: 8.9113\n","Epoch 144/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0823 - model_loss: 0.0026 - model_1_loss: 0.0020 - model_2_loss: 0.0640 - model_3_loss: 0.0101 - model_4_loss: 0.0037 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0690 - loss2: 9.3042 - val_loss: 14.0829 - val_model_loss: 2.4197 - val_model_1_loss: 2.8694 - val_model_2_loss: 3.1521 - val_model_3_loss: 2.6564 - val_model_4_loss: 2.9854 - val_model_accuracy: 0.4920 - val_model_1_accuracy: 0.4140 - val_model_2_accuracy: 0.5510 - val_model_3_accuracy: 0.4255 - val_model_4_accuracy: 0.3625 - val_loss1: 5.3580 - val_loss2: 8.8741\n","Epoch 145/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1005 - model_loss: 0.0036 - model_1_loss: 0.0284 - model_2_loss: 0.0591 - model_3_loss: 0.0078 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8799 - loss2: 9.2552 - val_loss: 13.9699 - val_model_loss: 2.4216 - val_model_1_loss: 2.8409 - val_model_2_loss: 3.0700 - val_model_3_loss: 2.5930 - val_model_4_loss: 3.0444 - val_model_accuracy: 0.4930 - val_model_1_accuracy: 0.4095 - val_model_2_accuracy: 0.5505 - val_model_3_accuracy: 0.4275 - val_model_4_accuracy: 0.3695 - val_loss1: 5.3307 - val_loss2: 8.8521\n","Epoch 146/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1129 - model_loss: 0.0735 - model_1_loss: 0.0070 - model_2_loss: 0.0192 - model_3_loss: 0.0085 - model_4_loss: 0.0046 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4269 - loss2: 9.3295 - val_loss: 13.9505 - val_model_loss: 2.4263 - val_model_1_loss: 2.8318 - val_model_2_loss: 3.0128 - val_model_3_loss: 2.5635 - val_model_4_loss: 3.1161 - val_model_accuracy: 0.4915 - val_model_1_accuracy: 0.4035 - val_model_2_accuracy: 0.5425 - val_model_3_accuracy: 0.4280 - val_model_4_accuracy: 0.3785 - val_loss1: 5.3060 - val_loss2: 8.8337\n","Epoch 147/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1840 - model_loss: 0.0033 - model_1_loss: 0.0160 - model_2_loss: 0.0217 - model_3_loss: 0.0459 - model_4_loss: 0.0971 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7990 - loss2: 9.2880 - val_loss: 13.7575 - val_model_loss: 2.4200 - val_model_1_loss: 2.8158 - val_model_2_loss: 2.9470 - val_model_3_loss: 2.5289 - val_model_4_loss: 3.0458 - val_model_accuracy: 0.4910 - val_model_1_accuracy: 0.4020 - val_model_2_accuracy: 0.5350 - val_model_3_accuracy: 0.4290 - val_model_4_accuracy: 0.3750 - val_loss1: 5.3295 - val_loss2: 8.8547\n","Epoch 148/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1734 - model_loss: 0.0017 - model_1_loss: 0.0610 - model_2_loss: 0.0260 - model_3_loss: 0.0548 - model_4_loss: 0.0300 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8217 - loss2: 9.3151 - val_loss: 13.6744 - val_model_loss: 2.4203 - val_model_1_loss: 2.8347 - val_model_2_loss: 2.8893 - val_model_3_loss: 2.5236 - val_model_4_loss: 3.0066 - val_model_accuracy: 0.4900 - val_model_1_accuracy: 0.3690 - val_model_2_accuracy: 0.5265 - val_model_3_accuracy: 0.4365 - val_model_4_accuracy: 0.3715 - val_loss1: 5.3504 - val_loss2: 8.8711\n","Epoch 149/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1325 - model_loss: 0.0035 - model_1_loss: 0.0011 - model_2_loss: 0.1030 - model_3_loss: 0.0167 - model_4_loss: 0.0082 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0090 - loss2: 9.1066 - val_loss: 13.6096 - val_model_loss: 2.4166 - val_model_1_loss: 2.8627 - val_model_2_loss: 2.8460 - val_model_3_loss: 2.5275 - val_model_4_loss: 2.9568 - val_model_accuracy: 0.4895 - val_model_1_accuracy: 0.3595 - val_model_2_accuracy: 0.5215 - val_model_3_accuracy: 0.4385 - val_model_4_accuracy: 0.3665 - val_loss1: 5.3836 - val_loss2: 8.8904\n","Epoch 150/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0057 - model_loss: 0.0029 - model_1_loss: 8.5989e-04 - model_2_loss: 4.8373e-04 - model_3_loss: 4.1994e-04 - model_4_loss: 0.0010 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3841 - loss2: 9.2907 - val_loss: 13.5436 - val_model_loss: 2.4115 - val_model_1_loss: 2.8941 - val_model_2_loss: 2.7961 - val_model_3_loss: 2.5310 - val_model_4_loss: 2.9108 - val_model_accuracy: 0.4895 - val_model_1_accuracy: 0.3600 - val_model_2_accuracy: 0.5210 - val_model_3_accuracy: 0.4430 - val_model_4_accuracy: 0.3660 - val_loss1: 5.4227 - val_loss2: 8.9076\n","Epoch 151/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0174 - model_loss: 0.0026 - model_1_loss: 6.5066e-04 - model_2_loss: 0.0085 - model_3_loss: 0.0045 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2158 - loss2: 9.2046 - val_loss: 13.5202 - val_model_loss: 2.4155 - val_model_1_loss: 2.9338 - val_model_2_loss: 2.7633 - val_model_3_loss: 2.5408 - val_model_4_loss: 2.8669 - val_model_accuracy: 0.4880 - val_model_1_accuracy: 0.3570 - val_model_2_accuracy: 0.5190 - val_model_3_accuracy: 0.4450 - val_model_4_accuracy: 0.3630 - val_loss1: 5.4712 - val_loss2: 8.9223\n","Epoch 152/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0255 - model_loss: 0.0020 - model_1_loss: 0.0071 - model_2_loss: 0.0074 - model_3_loss: 0.0063 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3935 - loss2: 9.2711 - val_loss: 13.4874 - val_model_loss: 2.4065 - val_model_1_loss: 2.9824 - val_model_2_loss: 2.7186 - val_model_3_loss: 2.5499 - val_model_4_loss: 2.8300 - val_model_accuracy: 0.4885 - val_model_1_accuracy: 0.3640 - val_model_2_accuracy: 0.5170 - val_model_3_accuracy: 0.4510 - val_model_4_accuracy: 0.3695 - val_loss1: 5.5045 - val_loss2: 8.9297\n","Epoch 153/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0542 - model_loss: 6.2278e-04 - model_1_loss: 0.0018 - model_2_loss: 0.0291 - model_3_loss: 0.0051 - model_4_loss: 0.0177 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2271 - loss2: 9.2361 - val_loss: 13.5003 - val_model_loss: 2.4046 - val_model_1_loss: 3.0378 - val_model_2_loss: 2.7024 - val_model_3_loss: 2.5602 - val_model_4_loss: 2.7953 - val_model_accuracy: 0.4880 - val_model_1_accuracy: 0.3680 - val_model_2_accuracy: 0.5145 - val_model_3_accuracy: 0.4565 - val_model_4_accuracy: 0.3680 - val_loss1: 5.5103 - val_loss2: 8.9312\n","Epoch 154/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0098 - model_loss: 8.2351e-04 - model_1_loss: 0.0013 - model_2_loss: 0.0046 - model_3_loss: 0.0027 - model_4_loss: 3.9927e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5302 - loss2: 9.3036 - val_loss: 13.5052 - val_model_loss: 2.3998 - val_model_1_loss: 3.0923 - val_model_2_loss: 2.6788 - val_model_3_loss: 2.5673 - val_model_4_loss: 2.7669 - val_model_accuracy: 0.4880 - val_model_1_accuracy: 0.3745 - val_model_2_accuracy: 0.5150 - val_model_3_accuracy: 0.4595 - val_model_4_accuracy: 0.3710 - val_loss1: 5.5115 - val_loss2: 8.9287\n","Epoch 155/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0465 - model_loss: 0.0063 - model_1_loss: 0.0024 - model_2_loss: 0.0149 - model_3_loss: 0.0212 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.6682 - loss2: 9.1112 - val_loss: 13.5647 - val_model_loss: 2.4045 - val_model_1_loss: 3.1638 - val_model_2_loss: 2.6642 - val_model_3_loss: 2.5837 - val_model_4_loss: 2.7485 - val_model_accuracy: 0.4880 - val_model_1_accuracy: 0.3785 - val_model_2_accuracy: 0.5175 - val_model_3_accuracy: 0.4670 - val_model_4_accuracy: 0.3685 - val_loss1: 5.5088 - val_loss2: 8.9183\n","Epoch 156/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0303 - model_loss: 0.0040 - model_1_loss: 0.0044 - model_2_loss: 0.0062 - model_3_loss: 0.0058 - model_4_loss: 0.0099 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8881 - loss2: 9.1418 - val_loss: 13.5937 - val_model_loss: 2.4011 - val_model_1_loss: 3.2256 - val_model_2_loss: 2.6343 - val_model_3_loss: 2.5973 - val_model_4_loss: 2.7355 - val_model_accuracy: 0.4885 - val_model_1_accuracy: 0.3820 - val_model_2_accuracy: 0.5215 - val_model_3_accuracy: 0.4735 - val_model_4_accuracy: 0.3705 - val_loss1: 5.4973 - val_loss2: 8.9004\n","Epoch 157/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0228 - model_loss: 0.0037 - model_1_loss: 0.0018 - model_2_loss: 0.0021 - model_3_loss: 0.0117 - model_4_loss: 0.0035 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2324 - loss2: 9.1486 - val_loss: 13.6101 - val_model_loss: 2.3971 - val_model_1_loss: 3.2782 - val_model_2_loss: 2.6060 - val_model_3_loss: 2.6065 - val_model_4_loss: 2.7223 - val_model_accuracy: 0.4885 - val_model_1_accuracy: 0.3815 - val_model_2_accuracy: 0.5250 - val_model_3_accuracy: 0.4785 - val_model_4_accuracy: 0.3700 - val_loss1: 5.4899 - val_loss2: 8.8861\n","Epoch 158/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0216 - model_loss: 5.5992e-04 - model_1_loss: 0.0016 - model_2_loss: 0.0085 - model_3_loss: 0.0089 - model_4_loss: 0.0021 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7227 - loss2: 9.1162 - val_loss: 13.6331 - val_model_loss: 2.3947 - val_model_1_loss: 3.3279 - val_model_2_loss: 2.5891 - val_model_3_loss: 2.6154 - val_model_4_loss: 2.7061 - val_model_accuracy: 0.4885 - val_model_1_accuracy: 0.3790 - val_model_2_accuracy: 0.5270 - val_model_3_accuracy: 0.4845 - val_model_4_accuracy: 0.3710 - val_loss1: 5.4855 - val_loss2: 8.8759\n","Epoch 159/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0167 - model_loss: 0.0021 - model_1_loss: 4.2794e-04 - model_2_loss: 5.1373e-04 - model_3_loss: 0.0086 - model_4_loss: 0.0051 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3457 - loss2: 9.2111 - val_loss: 13.6227 - val_model_loss: 2.3893 - val_model_1_loss: 3.3629 - val_model_2_loss: 2.5572 - val_model_3_loss: 2.6226 - val_model_4_loss: 2.6907 - val_model_accuracy: 0.4890 - val_model_1_accuracy: 0.3815 - val_model_2_accuracy: 0.5310 - val_model_3_accuracy: 0.4870 - val_model_4_accuracy: 0.3695 - val_loss1: 5.4826 - val_loss2: 8.8665\n","Epoch 160/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0349 - model_loss: 0.0022 - model_1_loss: 0.0097 - model_2_loss: 0.0045 - model_3_loss: 0.0056 - model_4_loss: 0.0129 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1883 - loss2: 9.0460 - val_loss: 13.6827 - val_model_loss: 2.3951 - val_model_1_loss: 3.4175 - val_model_2_loss: 2.5557 - val_model_3_loss: 2.6298 - val_model_4_loss: 2.6846 - val_model_accuracy: 0.4890 - val_model_1_accuracy: 0.3790 - val_model_2_accuracy: 0.5280 - val_model_3_accuracy: 0.4925 - val_model_4_accuracy: 0.3690 - val_loss1: 5.4825 - val_loss2: 8.8605\n","Epoch 161/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0060 - model_loss: 0.0015 - model_1_loss: 0.0016 - model_2_loss: 7.0764e-04 - model_3_loss: 0.0019 - model_4_loss: 3.3326e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3202 - loss2: 9.1366 - val_loss: 13.6730 - val_model_loss: 2.3883 - val_model_1_loss: 3.4554 - val_model_2_loss: 2.5225 - val_model_3_loss: 2.6279 - val_model_4_loss: 2.6789 - val_model_accuracy: 0.4890 - val_model_1_accuracy: 0.3800 - val_model_2_accuracy: 0.5325 - val_model_3_accuracy: 0.4975 - val_model_4_accuracy: 0.3690 - val_loss1: 5.4802 - val_loss2: 8.8510\n","Epoch 162/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0303 - model_loss: 0.0049 - model_1_loss: 0.0089 - model_2_loss: 0.0084 - model_3_loss: 0.0025 - model_4_loss: 0.0056 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8094 - loss2: 9.1142 - val_loss: 13.6549 - val_model_loss: 2.3849 - val_model_1_loss: 3.4750 - val_model_2_loss: 2.4911 - val_model_3_loss: 2.6324 - val_model_4_loss: 2.6714 - val_model_accuracy: 0.4900 - val_model_1_accuracy: 0.3800 - val_model_2_accuracy: 0.5385 - val_model_3_accuracy: 0.5030 - val_model_4_accuracy: 0.3715 - val_loss1: 5.4762 - val_loss2: 8.8445\n","Epoch 163/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0086 - model_loss: 0.0025 - model_1_loss: 0.0014 - model_2_loss: 0.0035 - model_3_loss: 4.1785e-04 - model_4_loss: 6.5915e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3711 - loss2: 9.1643 - val_loss: 13.6092 - val_model_loss: 2.3804 - val_model_1_loss: 3.4802 - val_model_2_loss: 2.4595 - val_model_3_loss: 2.6285 - val_model_4_loss: 2.6607 - val_model_accuracy: 0.4920 - val_model_1_accuracy: 0.3815 - val_model_2_accuracy: 0.5425 - val_model_3_accuracy: 0.5055 - val_model_4_accuracy: 0.3665 - val_loss1: 5.4809 - val_loss2: 8.8463\n","Epoch 164/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0183 - model_loss: 0.0064 - model_1_loss: 0.0047 - model_2_loss: 5.4907e-04 - model_3_loss: 0.0053 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9105 - loss2: 9.1181 - val_loss: 13.5837 - val_model_loss: 2.3810 - val_model_1_loss: 3.4883 - val_model_2_loss: 2.4317 - val_model_3_loss: 2.6305 - val_model_4_loss: 2.6522 - val_model_accuracy: 0.4930 - val_model_1_accuracy: 0.3825 - val_model_2_accuracy: 0.5455 - val_model_3_accuracy: 0.5070 - val_model_4_accuracy: 0.3710 - val_loss1: 5.4842 - val_loss2: 8.8480\n","Epoch 165/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0142 - model_loss: 0.0035 - model_1_loss: 0.0017 - model_2_loss: 0.0041 - model_3_loss: 0.0043 - model_4_loss: 5.7372e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7256 - loss2: 9.0165 - val_loss: 13.5866 - val_model_loss: 2.3894 - val_model_1_loss: 3.4970 - val_model_2_loss: 2.4229 - val_model_3_loss: 2.6337 - val_model_4_loss: 2.6436 - val_model_accuracy: 0.4935 - val_model_1_accuracy: 0.3810 - val_model_2_accuracy: 0.5445 - val_model_3_accuracy: 0.5105 - val_model_4_accuracy: 0.3720 - val_loss1: 5.4926 - val_loss2: 8.8530\n","Epoch 166/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.3211 - model_loss: 0.0060 - model_1_loss: 0.0015 - model_2_loss: 0.0063 - model_3_loss: 0.0732 - model_4_loss: 0.2342 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 7.3723 - loss2: 8.9185 - val_loss: 13.8931 - val_model_loss: 2.3819 - val_model_1_loss: 3.5038 - val_model_2_loss: 2.3886 - val_model_3_loss: 2.6278 - val_model_4_loss: 2.9910 - val_model_accuracy: 0.4960 - val_model_1_accuracy: 0.3825 - val_model_2_accuracy: 0.5485 - val_model_3_accuracy: 0.5095 - val_model_4_accuracy: 0.3935 - val_loss1: 5.3590 - val_loss2: 8.7518\n","Epoch 167/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0069 - model_loss: 7.9473e-04 - model_1_loss: 0.0020 - model_2_loss: 0.0012 - model_3_loss: 9.5368e-04 - model_4_loss: 0.0020 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9750 - loss2: 9.0068 - val_loss: 14.3580 - val_model_loss: 2.3836 - val_model_1_loss: 3.5108 - val_model_2_loss: 2.3713 - val_model_3_loss: 2.6144 - val_model_4_loss: 3.4779 - val_model_accuracy: 0.4955 - val_model_1_accuracy: 0.3810 - val_model_2_accuracy: 0.5495 - val_model_3_accuracy: 0.5050 - val_model_4_accuracy: 0.4340 - val_loss1: 5.2567 - val_loss2: 8.6156\n","Epoch 168/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0161 - model_loss: 0.0030 - model_1_loss: 0.0035 - model_2_loss: 0.0072 - model_3_loss: 0.0020 - model_4_loss: 4.7205e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3198 - loss2: 9.1064 - val_loss: 14.8704 - val_model_loss: 2.3796 - val_model_1_loss: 3.4972 - val_model_2_loss: 2.3403 - val_model_3_loss: 2.5994 - val_model_4_loss: 4.0539 - val_model_accuracy: 0.4965 - val_model_1_accuracy: 0.3825 - val_model_2_accuracy: 0.5515 - val_model_3_accuracy: 0.5045 - val_model_4_accuracy: 0.4595 - val_loss1: 5.1919 - val_loss2: 8.4707\n","Epoch 169/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0180 - model_loss: 0.0012 - model_1_loss: 0.0096 - model_2_loss: 0.0029 - model_3_loss: 0.0022 - model_4_loss: 0.0021 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1942 - loss2: 9.2100 - val_loss: 15.4301 - val_model_loss: 2.3791 - val_model_1_loss: 3.4763 - val_model_2_loss: 2.3163 - val_model_3_loss: 2.5887 - val_model_4_loss: 4.6697 - val_model_accuracy: 0.4980 - val_model_1_accuracy: 0.3815 - val_model_2_accuracy: 0.5545 - val_model_3_accuracy: 0.5040 - val_model_4_accuracy: 0.4810 - val_loss1: 5.1490 - val_loss2: 8.3398\n","Epoch 170/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0294 - model_loss: 0.0107 - model_1_loss: 0.0095 - model_2_loss: 0.0019 - model_3_loss: 0.0028 - model_4_loss: 0.0046 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7408 - loss2: 9.0873 - val_loss: 15.9968 - val_model_loss: 2.3815 - val_model_1_loss: 3.4494 - val_model_2_loss: 2.2929 - val_model_3_loss: 2.5819 - val_model_4_loss: 5.2910 - val_model_accuracy: 0.4985 - val_model_1_accuracy: 0.3830 - val_model_2_accuracy: 0.5595 - val_model_3_accuracy: 0.5060 - val_model_4_accuracy: 0.4885 - val_loss1: 5.1180 - val_loss2: 8.2303\n","Epoch 171/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.2485 - model_loss: 0.0035 - model_1_loss: 6.4684e-04 - model_2_loss: 0.0017 - model_3_loss: 0.0088 - model_4_loss: 0.2339 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 7.1752 - loss2: 8.6623 - val_loss: 16.3457 - val_model_loss: 2.3845 - val_model_1_loss: 3.4334 - val_model_2_loss: 2.2884 - val_model_3_loss: 2.5814 - val_model_4_loss: 5.6579 - val_model_accuracy: 0.4985 - val_model_1_accuracy: 0.3825 - val_model_2_accuracy: 0.5580 - val_model_3_accuracy: 0.5050 - val_model_4_accuracy: 0.4860 - val_loss1: 5.1063 - val_loss2: 8.1746\n","Epoch 172/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0100 - model_loss: 0.0018 - model_1_loss: 7.9437e-04 - model_2_loss: 0.0033 - model_3_loss: 0.0030 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 6.7990 - loss2: 8.8461 - val_loss: 16.5913 - val_model_loss: 2.3799 - val_model_1_loss: 3.4055 - val_model_2_loss: 2.2597 - val_model_3_loss: 2.5815 - val_model_4_loss: 5.9646 - val_model_accuracy: 0.5020 - val_model_1_accuracy: 0.3840 - val_model_2_accuracy: 0.5640 - val_model_3_accuracy: 0.5075 - val_model_4_accuracy: 0.4850 - val_loss1: 5.0970 - val_loss2: 8.1313\n","Epoch 173/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.2213 - model_loss: 9.3410e-04 - model_1_loss: 0.0691 - model_2_loss: 0.0022 - model_3_loss: 0.0461 - model_4_loss: 0.1030 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1264 - loss2: 9.1004 - val_loss: 16.5424 - val_model_loss: 2.3721 - val_model_1_loss: 3.3485 - val_model_2_loss: 2.2364 - val_model_3_loss: 2.5743 - val_model_4_loss: 6.0111 - val_model_accuracy: 0.5030 - val_model_1_accuracy: 0.3700 - val_model_2_accuracy: 0.5660 - val_model_3_accuracy: 0.5090 - val_model_4_accuracy: 0.4805 - val_loss1: 5.1144 - val_loss2: 8.1470\n","Epoch 174/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0075 - model_loss: 0.0012 - model_1_loss: 5.9766e-04 - model_2_loss: 3.5604e-04 - model_3_loss: 0.0034 - model_4_loss: 0.0020 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1439 - loss2: 9.1639 - val_loss: 16.4764 - val_model_loss: 2.3673 - val_model_1_loss: 3.3177 - val_model_2_loss: 2.2111 - val_model_3_loss: 2.5656 - val_model_4_loss: 6.0146 - val_model_accuracy: 0.5060 - val_model_1_accuracy: 0.3695 - val_model_2_accuracy: 0.5690 - val_model_3_accuracy: 0.5120 - val_model_4_accuracy: 0.4785 - val_loss1: 5.1530 - val_loss2: 8.1641\n","Epoch 175/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0080 - model_loss: 0.0020 - model_1_loss: 2.7196e-04 - model_2_loss: 2.8734e-04 - model_3_loss: 0.0036 - model_4_loss: 0.0019 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0024 - loss2: 9.1467 - val_loss: 16.4171 - val_model_loss: 2.3653 - val_model_1_loss: 3.3155 - val_model_2_loss: 2.1893 - val_model_3_loss: 2.5574 - val_model_4_loss: 5.9897 - val_model_accuracy: 0.5055 - val_model_1_accuracy: 0.3630 - val_model_2_accuracy: 0.5705 - val_model_3_accuracy: 0.5165 - val_model_4_accuracy: 0.4775 - val_loss1: 5.1913 - val_loss2: 8.1820\n","Epoch 176/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0389 - model_loss: 6.4069e-04 - model_1_loss: 0.0182 - model_2_loss: 0.0039 - model_3_loss: 0.0154 - model_4_loss: 8.8793e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.3865 - loss2: 8.9834 - val_loss: 16.3560 - val_model_loss: 2.3669 - val_model_1_loss: 3.3218 - val_model_2_loss: 2.1752 - val_model_3_loss: 2.5492 - val_model_4_loss: 5.9428 - val_model_accuracy: 0.5065 - val_model_1_accuracy: 0.3695 - val_model_2_accuracy: 0.5725 - val_model_3_accuracy: 0.5170 - val_model_4_accuracy: 0.4775 - val_loss1: 5.2477 - val_loss2: 8.2020\n","Epoch 177/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0117 - model_loss: 0.0011 - model_1_loss: 0.0054 - model_2_loss: 0.0016 - model_3_loss: 0.0027 - model_4_loss: 8.8672e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.4637 - loss2: 9.0159 - val_loss: 16.2552 - val_model_loss: 2.3641 - val_model_1_loss: 3.3404 - val_model_2_loss: 2.1502 - val_model_3_loss: 2.5385 - val_model_4_loss: 5.8620 - val_model_accuracy: 0.5090 - val_model_1_accuracy: 0.3825 - val_model_2_accuracy: 0.5755 - val_model_3_accuracy: 0.5175 - val_model_4_accuracy: 0.4810 - val_loss1: 5.3018 - val_loss2: 8.2229\n","Epoch 178/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0150 - model_loss: 6.5702e-04 - model_1_loss: 2.2914e-04 - model_2_loss: 0.0099 - model_3_loss: 0.0014 - model_4_loss: 0.0029 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8707 - loss2: 9.0788 - val_loss: 16.1240 - val_model_loss: 2.3587 - val_model_1_loss: 3.3639 - val_model_2_loss: 2.1147 - val_model_3_loss: 2.5243 - val_model_4_loss: 5.7625 - val_model_accuracy: 0.5090 - val_model_1_accuracy: 0.3990 - val_model_2_accuracy: 0.5810 - val_model_3_accuracy: 0.5195 - val_model_4_accuracy: 0.4945 - val_loss1: 5.3457 - val_loss2: 8.2420\n","Epoch 179/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0143 - model_loss: 4.6606e-04 - model_1_loss: 0.0032 - model_2_loss: 0.0027 - model_3_loss: 0.0034 - model_4_loss: 0.0045 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9990 - loss2: 9.1305 - val_loss: 16.0540 - val_model_loss: 2.3592 - val_model_1_loss: 3.3960 - val_model_2_loss: 2.0883 - val_model_3_loss: 2.5132 - val_model_4_loss: 5.6973 - val_model_accuracy: 0.5105 - val_model_1_accuracy: 0.4225 - val_model_2_accuracy: 0.5830 - val_model_3_accuracy: 0.5200 - val_model_4_accuracy: 0.5045 - val_loss1: 5.3809 - val_loss2: 8.2564\n","Epoch 180/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0125 - model_loss: 0.0016 - model_1_loss: 4.2784e-04 - model_2_loss: 0.0029 - model_3_loss: 0.0053 - model_4_loss: 0.0023 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1450 - loss2: 9.1453 - val_loss: 15.9681 - val_model_loss: 2.3560 - val_model_1_loss: 3.4217 - val_model_2_loss: 2.0601 - val_model_3_loss: 2.5004 - val_model_4_loss: 5.6299 - val_model_accuracy: 0.5125 - val_model_1_accuracy: 0.4450 - val_model_2_accuracy: 0.5870 - val_model_3_accuracy: 0.5210 - val_model_4_accuracy: 0.5085 - val_loss1: 5.4140 - val_loss2: 8.2698\n","Epoch 181/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0166 - model_loss: 9.1546e-04 - model_1_loss: 0.0027 - model_2_loss: 0.0056 - model_3_loss: 0.0015 - model_4_loss: 0.0058 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0522 - loss2: 9.1422 - val_loss: 15.8903 - val_model_loss: 2.3533 - val_model_1_loss: 3.4522 - val_model_2_loss: 2.0324 - val_model_3_loss: 2.4888 - val_model_4_loss: 5.5636 - val_model_accuracy: 0.5155 - val_model_1_accuracy: 0.4535 - val_model_2_accuracy: 0.5930 - val_model_3_accuracy: 0.5220 - val_model_4_accuracy: 0.5105 - val_loss1: 5.4415 - val_loss2: 8.2802\n","Epoch 182/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.2470 - model_loss: 0.0063 - model_1_loss: 0.0130 - model_2_loss: 0.0055 - model_3_loss: 0.0222 - model_4_loss: 0.2000 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.2111 - loss2: 9.2126 - val_loss: 15.3484 - val_model_loss: 2.3522 - val_model_1_loss: 3.4974 - val_model_2_loss: 2.0116 - val_model_3_loss: 2.4885 - val_model_4_loss: 4.9986 - val_model_accuracy: 0.5180 - val_model_1_accuracy: 0.4670 - val_model_2_accuracy: 0.5935 - val_model_3_accuracy: 0.5240 - val_model_4_accuracy: 0.5085 - val_loss1: 5.5036 - val_loss2: 8.3354\n","Epoch 183/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0196 - model_loss: 2.6971e-04 - model_1_loss: 0.0016 - model_2_loss: 0.0064 - model_3_loss: 0.0055 - model_4_loss: 0.0058 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4360 - loss2: 9.2621 - val_loss: 14.8916 - val_model_loss: 2.3463 - val_model_1_loss: 3.5225 - val_model_2_loss: 1.9809 - val_model_3_loss: 2.4794 - val_model_4_loss: 4.5625 - val_model_accuracy: 0.5200 - val_model_1_accuracy: 0.4780 - val_model_2_accuracy: 0.5960 - val_model_3_accuracy: 0.5270 - val_model_4_accuracy: 0.5090 - val_loss1: 5.5669 - val_loss2: 8.3814\n","Epoch 184/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0584 - model_loss: 0.0010 - model_1_loss: 0.0016 - model_2_loss: 0.0076 - model_3_loss: 0.0013 - model_4_loss: 0.0469 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1359 - loss2: 9.1745 - val_loss: 14.6129 - val_model_loss: 2.3414 - val_model_1_loss: 3.5422 - val_model_2_loss: 1.9579 - val_model_3_loss: 2.4729 - val_model_4_loss: 4.2986 - val_model_accuracy: 0.5215 - val_model_1_accuracy: 0.4845 - val_model_2_accuracy: 0.6020 - val_model_3_accuracy: 0.5290 - val_model_4_accuracy: 0.5220 - val_loss1: 5.6275 - val_loss2: 8.4202\n","Epoch 185/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.5203 - model_loss: 0.0045 - model_1_loss: 0.0234 - model_2_loss: 0.0136 - model_3_loss: 0.0067 - model_4_loss: 0.4722 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.3646 - loss2: 9.2607 - val_loss: 13.8997 - val_model_loss: 2.3430 - val_model_1_loss: 3.5842 - val_model_2_loss: 1.9556 - val_model_3_loss: 2.4736 - val_model_4_loss: 3.5434 - val_model_accuracy: 0.5225 - val_model_1_accuracy: 0.4945 - val_model_2_accuracy: 0.6020 - val_model_3_accuracy: 0.5305 - val_model_4_accuracy: 0.5055 - val_loss1: 5.7345 - val_loss2: 8.5157\n","Epoch 186/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0498 - model_loss: 6.6859e-04 - model_1_loss: 6.0573e-04 - model_2_loss: 0.0021 - model_3_loss: 0.0048 - model_4_loss: 0.0417 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7592 - loss2: 9.1265 - val_loss: 13.4616 - val_model_loss: 2.3449 - val_model_1_loss: 3.5966 - val_model_2_loss: 1.9498 - val_model_3_loss: 2.4734 - val_model_4_loss: 3.0970 - val_model_accuracy: 0.5225 - val_model_1_accuracy: 0.4980 - val_model_2_accuracy: 0.6090 - val_model_3_accuracy: 0.5300 - val_model_4_accuracy: 0.4890 - val_loss1: 5.8218 - val_loss2: 8.5894\n","Epoch 187/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0055 - model_loss: 4.7526e-04 - model_1_loss: 2.8846e-04 - model_2_loss: 6.2688e-04 - model_3_loss: 0.0015 - model_4_loss: 0.0025 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5333 - loss2: 9.3129 - val_loss: 13.1929 - val_model_loss: 2.3407 - val_model_1_loss: 3.5789 - val_model_2_loss: 1.9356 - val_model_3_loss: 2.4615 - val_model_4_loss: 2.8761 - val_model_accuracy: 0.5240 - val_model_1_accuracy: 0.4995 - val_model_2_accuracy: 0.6105 - val_model_3_accuracy: 0.5325 - val_model_4_accuracy: 0.4940 - val_loss1: 5.9054 - val_loss2: 8.6439\n","Epoch 188/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0184 - model_loss: 0.0013 - model_1_loss: 0.0016 - model_2_loss: 8.3472e-04 - model_3_loss: 9.8258e-04 - model_4_loss: 0.0138 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6095 - loss2: 9.3162 - val_loss: 13.0748 - val_model_loss: 2.3362 - val_model_1_loss: 3.5534 - val_model_2_loss: 1.9215 - val_model_3_loss: 2.4489 - val_model_4_loss: 2.8148 - val_model_accuracy: 0.5270 - val_model_1_accuracy: 0.5005 - val_model_2_accuracy: 0.6155 - val_model_3_accuracy: 0.5340 - val_model_4_accuracy: 0.5005 - val_loss1: 5.9714 - val_loss2: 8.6795\n","Epoch 189/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0233 - model_loss: 0.0104 - model_1_loss: 4.1593e-04 - model_2_loss: 0.0014 - model_3_loss: 0.0099 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3414 - loss2: 9.2903 - val_loss: 13.0849 - val_model_loss: 2.3349 - val_model_1_loss: 3.5332 - val_model_2_loss: 1.9167 - val_model_3_loss: 2.4402 - val_model_4_loss: 2.8600 - val_model_accuracy: 0.5270 - val_model_1_accuracy: 0.5015 - val_model_2_accuracy: 0.6130 - val_model_3_accuracy: 0.5355 - val_model_4_accuracy: 0.5215 - val_loss1: 6.0178 - val_loss2: 8.7023\n","Epoch 190/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0098 - model_loss: 0.0015 - model_1_loss: 2.9279e-04 - model_2_loss: 0.0028 - model_3_loss: 0.0025 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2265 - loss2: 9.2236 - val_loss: 13.1791 - val_model_loss: 2.3343 - val_model_1_loss: 3.5176 - val_model_2_loss: 1.9143 - val_model_3_loss: 2.4377 - val_model_4_loss: 2.9752 - val_model_accuracy: 0.5280 - val_model_1_accuracy: 0.5005 - val_model_2_accuracy: 0.6130 - val_model_3_accuracy: 0.5350 - val_model_4_accuracy: 0.5430 - val_loss1: 6.0513 - val_loss2: 8.7126\n","Epoch 191/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0116 - model_loss: 0.0016 - model_1_loss: 0.0060 - model_2_loss: 0.0012 - model_3_loss: 0.0019 - model_4_loss: 8.7869e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.7791 - loss2: 9.3830 - val_loss: 13.2631 - val_model_loss: 2.3291 - val_model_1_loss: 3.4939 - val_model_2_loss: 1.8993 - val_model_3_loss: 2.4244 - val_model_4_loss: 3.1164 - val_model_accuracy: 0.5275 - val_model_1_accuracy: 0.5000 - val_model_2_accuracy: 0.6170 - val_model_3_accuracy: 0.5355 - val_model_4_accuracy: 0.5545 - val_loss1: 6.0885 - val_loss2: 8.7195\n","Epoch 192/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0077 - model_loss: 5.7393e-04 - model_1_loss: 0.0015 - model_2_loss: 9.8757e-04 - model_3_loss: 0.0012 - model_4_loss: 0.0034 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5936 - loss2: 9.3503 - val_loss: 13.3715 - val_model_loss: 2.3269 - val_model_1_loss: 3.4717 - val_model_2_loss: 1.8911 - val_model_3_loss: 2.4133 - val_model_4_loss: 3.2684 - val_model_accuracy: 0.5280 - val_model_1_accuracy: 0.5015 - val_model_2_accuracy: 0.6185 - val_model_3_accuracy: 0.5370 - val_model_4_accuracy: 0.5660 - val_loss1: 6.1155 - val_loss2: 8.7230\n","Epoch 193/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0146 - model_loss: 0.0040 - model_1_loss: 0.0013 - model_2_loss: 0.0021 - model_3_loss: 0.0069 - model_4_loss: 2.9904e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9364 - loss2: 9.2247 - val_loss: 13.5100 - val_model_loss: 2.3292 - val_model_1_loss: 3.4616 - val_model_2_loss: 1.8883 - val_model_3_loss: 2.4129 - val_model_4_loss: 3.4180 - val_model_accuracy: 0.5285 - val_model_1_accuracy: 0.5005 - val_model_2_accuracy: 0.6220 - val_model_3_accuracy: 0.5375 - val_model_4_accuracy: 0.5785 - val_loss1: 6.1375 - val_loss2: 8.7213\n","Epoch 194/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0629 - model_loss: 7.3876e-04 - model_1_loss: 6.9135e-04 - model_2_loss: 0.0022 - model_3_loss: 0.0060 - model_4_loss: 0.0532 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9707 - loss2: 9.1681 - val_loss: 13.4931 - val_model_loss: 2.3256 - val_model_1_loss: 3.4456 - val_model_2_loss: 1.8791 - val_model_3_loss: 2.4038 - val_model_4_loss: 3.4391 - val_model_accuracy: 0.5290 - val_model_1_accuracy: 0.4985 - val_model_2_accuracy: 0.6235 - val_model_3_accuracy: 0.5385 - val_model_4_accuracy: 0.5760 - val_loss1: 6.1553 - val_loss2: 8.7331\n","Epoch 195/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.3060 - model_loss: 0.0015 - model_1_loss: 0.0010 - model_2_loss: 4.0623e-04 - model_3_loss: 0.0033 - model_4_loss: 0.2998 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 7.8266 - loss2: 9.2480 - val_loss: 13.2501 - val_model_loss: 2.3203 - val_model_1_loss: 3.4237 - val_model_2_loss: 1.8598 - val_model_3_loss: 2.3866 - val_model_4_loss: 3.2597 - val_model_accuracy: 0.5305 - val_model_1_accuracy: 0.5005 - val_model_2_accuracy: 0.6315 - val_model_3_accuracy: 0.5385 - val_model_4_accuracy: 0.5780 - val_loss1: 6.1621 - val_loss2: 8.7524\n","Epoch 196/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0060 - model_loss: 0.0037 - model_1_loss: 3.5922e-04 - model_2_loss: 3.0688e-04 - model_3_loss: 7.3690e-04 - model_4_loss: 8.9586e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5748 - loss2: 9.3602 - val_loss: 13.0170 - val_model_loss: 2.3136 - val_model_1_loss: 3.3999 - val_model_2_loss: 1.8389 - val_model_3_loss: 2.3680 - val_model_4_loss: 3.0966 - val_model_accuracy: 0.5325 - val_model_1_accuracy: 0.4985 - val_model_2_accuracy: 0.6370 - val_model_3_accuracy: 0.5405 - val_model_4_accuracy: 0.5800 - val_loss1: 6.1780 - val_loss2: 8.7800\n","Epoch 197/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0135 - model_loss: 0.0013 - model_1_loss: 0.0040 - model_2_loss: 6.8286e-04 - model_3_loss: 0.0048 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1896 - loss2: 9.2751 - val_loss: 12.8195 - val_model_loss: 2.3092 - val_model_1_loss: 3.3818 - val_model_2_loss: 1.8231 - val_model_3_loss: 2.3575 - val_model_4_loss: 2.9478 - val_model_accuracy: 0.5355 - val_model_1_accuracy: 0.5015 - val_model_2_accuracy: 0.6405 - val_model_3_accuracy: 0.5415 - val_model_4_accuracy: 0.5750 - val_loss1: 6.1928 - val_loss2: 8.8107\n","Epoch 198/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0233 - model_loss: 0.0012 - model_1_loss: 0.0060 - model_2_loss: 0.0012 - model_3_loss: 0.0010 - model_4_loss: 0.0138 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3180 - loss2: 9.2881 - val_loss: 12.6129 - val_model_loss: 2.2997 - val_model_1_loss: 3.3604 - val_model_2_loss: 1.8001 - val_model_3_loss: 2.3374 - val_model_4_loss: 2.8154 - val_model_accuracy: 0.5360 - val_model_1_accuracy: 0.5025 - val_model_2_accuracy: 0.6460 - val_model_3_accuracy: 0.5430 - val_model_4_accuracy: 0.5765 - val_loss1: 6.2032 - val_loss2: 8.8385\n","Epoch 199/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1280 - model_loss: 0.0024 - model_1_loss: 0.0013 - model_2_loss: 0.0013 - model_3_loss: 9.4465e-04 - model_4_loss: 0.1219 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.0675 - loss2: 9.2602 - val_loss: 12.5035 - val_model_loss: 2.3000 - val_model_1_loss: 3.3477 - val_model_2_loss: 1.7922 - val_model_3_loss: 2.3336 - val_model_4_loss: 2.7299 - val_model_accuracy: 0.5350 - val_model_1_accuracy: 0.5030 - val_model_2_accuracy: 0.6465 - val_model_3_accuracy: 0.5430 - val_model_4_accuracy: 0.5720 - val_loss1: 6.2153 - val_loss2: 8.8580\n","Epoch 200/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0138 - model_loss: 0.0013 - model_1_loss: 5.9292e-04 - model_2_loss: 9.8164e-04 - model_3_loss: 0.0094 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9411 - loss2: 9.2939 - val_loss: 12.3663 - val_model_loss: 2.2954 - val_model_1_loss: 3.3296 - val_model_2_loss: 1.7729 - val_model_3_loss: 2.3203 - val_model_4_loss: 2.6481 - val_model_accuracy: 0.5355 - val_model_1_accuracy: 0.5030 - val_model_2_accuracy: 0.6485 - val_model_3_accuracy: 0.5455 - val_model_4_accuracy: 0.5735 - val_loss1: 6.2300 - val_loss2: 8.8778\n","Epoch 201/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0091 - model_loss: 0.0028 - model_1_loss: 8.9722e-04 - model_2_loss: 0.0014 - model_3_loss: 0.0022 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.9563 - loss2: 9.4275 - val_loss: 12.2523 - val_model_loss: 2.2921 - val_model_1_loss: 3.3143 - val_model_2_loss: 1.7635 - val_model_3_loss: 2.3077 - val_model_4_loss: 2.5746 - val_model_accuracy: 0.5365 - val_model_1_accuracy: 0.5025 - val_model_2_accuracy: 0.6500 - val_model_3_accuracy: 0.5455 - val_model_4_accuracy: 0.5675 - val_loss1: 6.2472 - val_loss2: 8.9042\n","Epoch 202/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0050 - model_loss: 0.0012 - model_1_loss: 0.0016 - model_2_loss: 0.0012 - model_3_loss: 3.9712e-04 - model_4_loss: 6.5793e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0858 - loss2: 9.2110 - val_loss: 12.1577 - val_model_loss: 2.2896 - val_model_1_loss: 3.3008 - val_model_2_loss: 1.7525 - val_model_3_loss: 2.2985 - val_model_4_loss: 2.5164 - val_model_accuracy: 0.5360 - val_model_1_accuracy: 0.5030 - val_model_2_accuracy: 0.6515 - val_model_3_accuracy: 0.5460 - val_model_4_accuracy: 0.5645 - val_loss1: 6.2619 - val_loss2: 8.9249\n","Epoch 203/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0095 - model_loss: 0.0013 - model_1_loss: 0.0033 - model_2_loss: 0.0012 - model_3_loss: 6.1712e-04 - model_4_loss: 0.0031 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.7933 - loss2: 9.4079 - val_loss: 12.0386 - val_model_loss: 2.2841 - val_model_1_loss: 3.2823 - val_model_2_loss: 1.7380 - val_model_3_loss: 2.2803 - val_model_4_loss: 2.4539 - val_model_accuracy: 0.5375 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.6510 - val_model_3_accuracy: 0.5470 - val_model_4_accuracy: 0.5585 - val_loss1: 6.2790 - val_loss2: 8.9504\n","Epoch 204/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0427 - model_loss: 3.5021e-04 - model_1_loss: 0.0011 - model_2_loss: 0.0155 - model_3_loss: 0.0209 - model_4_loss: 0.0047 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8001 - loss2: 9.2610 - val_loss: 11.9420 - val_model_loss: 2.2838 - val_model_1_loss: 3.2675 - val_model_2_loss: 1.7265 - val_model_3_loss: 2.2623 - val_model_4_loss: 2.4019 - val_model_accuracy: 0.5385 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.6525 - val_model_3_accuracy: 0.5430 - val_model_4_accuracy: 0.5530 - val_loss1: 6.2895 - val_loss2: 8.9779\n","Epoch 205/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0530 - model_loss: 7.1854e-04 - model_1_loss: 0.0025 - model_2_loss: 0.0302 - model_3_loss: 0.0180 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5538 - loss2: 9.2962 - val_loss: 11.9077 - val_model_loss: 2.2861 - val_model_1_loss: 3.2665 - val_model_2_loss: 1.7347 - val_model_3_loss: 2.2550 - val_model_4_loss: 2.3655 - val_model_accuracy: 0.5390 - val_model_1_accuracy: 0.5050 - val_model_2_accuracy: 0.6525 - val_model_3_accuracy: 0.5440 - val_model_4_accuracy: 0.5450 - val_loss1: 6.2969 - val_loss2: 9.0066\n","Epoch 206/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0083 - model_loss: 0.0028 - model_1_loss: 8.3503e-04 - model_2_loss: 6.7852e-04 - model_3_loss: 0.0024 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3493 - loss2: 9.3463 - val_loss: 11.8379 - val_model_loss: 2.2801 - val_model_1_loss: 3.2576 - val_model_2_loss: 1.7326 - val_model_3_loss: 2.2389 - val_model_4_loss: 2.3287 - val_model_accuracy: 0.5385 - val_model_1_accuracy: 0.5050 - val_model_2_accuracy: 0.6525 - val_model_3_accuracy: 0.5415 - val_model_4_accuracy: 0.5355 - val_loss1: 6.3077 - val_loss2: 9.0334\n","Epoch 207/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0822 - model_loss: 0.0037 - model_1_loss: 6.0596e-04 - model_2_loss: 0.0072 - model_3_loss: 0.0107 - model_4_loss: 0.0599 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4064 - loss2: 9.3224 - val_loss: 11.7811 - val_model_loss: 2.2779 - val_model_1_loss: 3.2510 - val_model_2_loss: 1.7274 - val_model_3_loss: 2.2297 - val_model_4_loss: 2.2950 - val_model_accuracy: 0.5405 - val_model_1_accuracy: 0.5055 - val_model_2_accuracy: 0.6525 - val_model_3_accuracy: 0.5380 - val_model_4_accuracy: 0.5255 - val_loss1: 6.3226 - val_loss2: 9.0774\n","Epoch 208/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0338 - model_loss: 0.0012 - model_1_loss: 0.0188 - model_2_loss: 0.0058 - model_3_loss: 0.0065 - model_4_loss: 0.0013 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.7936 - loss2: 9.4268 - val_loss: 11.7520 - val_model_loss: 2.2758 - val_model_1_loss: 3.2652 - val_model_2_loss: 1.7207 - val_model_3_loss: 2.2168 - val_model_4_loss: 2.2736 - val_model_accuracy: 0.5405 - val_model_1_accuracy: 0.5025 - val_model_2_accuracy: 0.6515 - val_model_3_accuracy: 0.5340 - val_model_4_accuracy: 0.5205 - val_loss1: 6.3184 - val_loss2: 9.1122\n","Epoch 209/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0091 - model_loss: 0.0010 - model_1_loss: 7.0615e-04 - model_2_loss: 0.0022 - model_3_loss: 0.0022 - model_4_loss: 0.0030 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1143 - loss2: 9.3435 - val_loss: 11.7174 - val_model_loss: 2.2714 - val_model_1_loss: 3.2713 - val_model_2_loss: 1.7089 - val_model_3_loss: 2.2038 - val_model_4_loss: 2.2620 - val_model_accuracy: 0.5400 - val_model_1_accuracy: 0.5005 - val_model_2_accuracy: 0.6520 - val_model_3_accuracy: 0.5335 - val_model_4_accuracy: 0.5150 - val_loss1: 6.3179 - val_loss2: 9.1410\n","Epoch 210/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0277 - model_loss: 0.0028 - model_1_loss: 0.0043 - model_2_loss: 0.0022 - model_3_loss: 0.0046 - model_4_loss: 0.0137 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1760 - loss2: 9.2228 - val_loss: 11.7662 - val_model_loss: 2.2756 - val_model_1_loss: 3.2945 - val_model_2_loss: 1.7130 - val_model_3_loss: 2.2085 - val_model_4_loss: 2.2747 - val_model_accuracy: 0.5405 - val_model_1_accuracy: 0.4990 - val_model_2_accuracy: 0.6530 - val_model_3_accuracy: 0.5305 - val_model_4_accuracy: 0.5175 - val_loss1: 6.3065 - val_loss2: 9.1645\n","Epoch 211/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0125 - model_loss: 0.0013 - model_1_loss: 8.3950e-04 - model_2_loss: 0.0045 - model_3_loss: 0.0053 - model_4_loss: 5.6817e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1483 - loss2: 9.1572 - val_loss: 11.7780 - val_model_loss: 2.2681 - val_model_1_loss: 3.3079 - val_model_2_loss: 1.7132 - val_model_3_loss: 2.2047 - val_model_4_loss: 2.2841 - val_model_accuracy: 0.5400 - val_model_1_accuracy: 0.4980 - val_model_2_accuracy: 0.6510 - val_model_3_accuracy: 0.5290 - val_model_4_accuracy: 0.5175 - val_loss1: 6.2959 - val_loss2: 9.1828\n","Epoch 212/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0198 - model_loss: 0.0042 - model_1_loss: 0.0025 - model_2_loss: 0.0016 - model_3_loss: 0.0085 - model_4_loss: 0.0030 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4832 - loss2: 9.3529 - val_loss: 11.7678 - val_model_loss: 2.2613 - val_model_1_loss: 3.3105 - val_model_2_loss: 1.7028 - val_model_3_loss: 2.1964 - val_model_4_loss: 2.2968 - val_model_accuracy: 0.5410 - val_model_1_accuracy: 0.4980 - val_model_2_accuracy: 0.6535 - val_model_3_accuracy: 0.5270 - val_model_4_accuracy: 0.5155 - val_loss1: 6.2928 - val_loss2: 9.1970\n","Epoch 213/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0455 - model_loss: 0.0234 - model_1_loss: 5.4513e-04 - model_2_loss: 0.0012 - model_3_loss: 0.0012 - model_4_loss: 0.0191 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3490 - loss2: 9.3283 - val_loss: 11.7903 - val_model_loss: 2.2667 - val_model_1_loss: 3.3120 - val_model_2_loss: 1.6988 - val_model_3_loss: 2.1947 - val_model_4_loss: 2.3181 - val_model_accuracy: 0.5415 - val_model_1_accuracy: 0.4960 - val_model_2_accuracy: 0.6525 - val_model_3_accuracy: 0.5290 - val_model_4_accuracy: 0.5170 - val_loss1: 6.2875 - val_loss2: 9.2090\n","Epoch 214/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0203 - model_loss: 0.0012 - model_1_loss: 0.0104 - model_2_loss: 0.0017 - model_3_loss: 0.0027 - model_4_loss: 0.0044 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6187 - loss2: 9.3813 - val_loss: 11.7962 - val_model_loss: 2.2662 - val_model_1_loss: 3.3153 - val_model_2_loss: 1.6888 - val_model_3_loss: 2.1874 - val_model_4_loss: 2.3385 - val_model_accuracy: 0.5435 - val_model_1_accuracy: 0.4945 - val_model_2_accuracy: 0.6535 - val_model_3_accuracy: 0.5290 - val_model_4_accuracy: 0.5185 - val_loss1: 6.2798 - val_loss2: 9.2169\n","Epoch 215/300\n","1/1 [==============================] - 6s 6s/step - loss: 1.0074 - model_loss: 0.0533 - model_1_loss: 0.4978 - model_2_loss: 0.0795 - model_3_loss: 0.1332 - model_4_loss: 0.2435 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.8333 - loss1: 8.0145 - loss2: 9.2338 - val_loss: 11.6169 - val_model_loss: 2.2515 - val_model_1_loss: 3.3151 - val_model_2_loss: 1.6228 - val_model_3_loss: 2.1182 - val_model_4_loss: 2.3093 - val_model_accuracy: 0.5435 - val_model_1_accuracy: 0.4955 - val_model_2_accuracy: 0.6550 - val_model_3_accuracy: 0.5300 - val_model_4_accuracy: 0.5075 - val_loss1: 6.1660 - val_loss2: 9.2042\n","Epoch 216/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0066 - model_loss: 0.0012 - model_1_loss: 0.0016 - model_2_loss: 1.6900e-04 - model_3_loss: 5.2579e-04 - model_4_loss: 0.0032 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.8102 - loss2: 9.4041 - val_loss: 11.3257 - val_model_loss: 2.2357 - val_model_1_loss: 3.2037 - val_model_2_loss: 1.5587 - val_model_3_loss: 2.0475 - val_model_4_loss: 2.2802 - val_model_accuracy: 0.5440 - val_model_1_accuracy: 0.4870 - val_model_2_accuracy: 0.6605 - val_model_3_accuracy: 0.5290 - val_model_4_accuracy: 0.4960 - val_loss1: 5.9921 - val_loss2: 9.1761\n","Epoch 217/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0233 - model_loss: 0.0044 - model_1_loss: 0.0026 - model_2_loss: 0.0027 - model_3_loss: 0.0100 - model_4_loss: 0.0036 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3350 - loss2: 9.3470 - val_loss: 10.9796 - val_model_loss: 2.2288 - val_model_1_loss: 2.9707 - val_model_2_loss: 1.5123 - val_model_3_loss: 1.9980 - val_model_4_loss: 2.2698 - val_model_accuracy: 0.5455 - val_model_1_accuracy: 0.4535 - val_model_2_accuracy: 0.6585 - val_model_3_accuracy: 0.5265 - val_model_4_accuracy: 0.4780 - val_loss1: 5.8628 - val_loss2: 9.1431\n","Epoch 218/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0288 - model_loss: 0.0015 - model_1_loss: 5.4600e-04 - model_2_loss: 0.0238 - model_3_loss: 4.4692e-04 - model_4_loss: 0.0025 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6534 - loss2: 9.3431 - val_loss: 10.6628 - val_model_loss: 2.2138 - val_model_1_loss: 2.7796 - val_model_2_loss: 1.4674 - val_model_3_loss: 1.9433 - val_model_4_loss: 2.2588 - val_model_accuracy: 0.5465 - val_model_1_accuracy: 0.4020 - val_model_2_accuracy: 0.6615 - val_model_3_accuracy: 0.5220 - val_model_4_accuracy: 0.4620 - val_loss1: 5.7437 - val_loss2: 9.0942\n","Epoch 219/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0383 - model_loss: 0.0042 - model_1_loss: 0.0028 - model_2_loss: 5.1380e-04 - model_3_loss: 0.0018 - model_4_loss: 0.0291 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1133 - loss2: 9.2095 - val_loss: 10.5408 - val_model_loss: 2.2064 - val_model_1_loss: 2.7313 - val_model_2_loss: 1.4400 - val_model_3_loss: 1.9107 - val_model_4_loss: 2.2524 - val_model_accuracy: 0.5485 - val_model_1_accuracy: 0.4145 - val_model_2_accuracy: 0.6645 - val_model_3_accuracy: 0.5110 - val_model_4_accuracy: 0.4605 - val_loss1: 5.6365 - val_loss2: 9.0304\n","Epoch 220/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0098 - model_loss: 9.5458e-04 - model_1_loss: 0.0014 - model_2_loss: 9.0545e-04 - model_3_loss: 0.0024 - model_4_loss: 0.0042 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1556 - loss2: 9.2122 - val_loss: 10.4806 - val_model_loss: 2.1944 - val_model_1_loss: 2.7480 - val_model_2_loss: 1.4162 - val_model_3_loss: 1.8766 - val_model_4_loss: 2.2454 - val_model_accuracy: 0.5485 - val_model_1_accuracy: 0.4165 - val_model_2_accuracy: 0.6620 - val_model_3_accuracy: 0.5030 - val_model_4_accuracy: 0.4530 - val_loss1: 5.5974 - val_loss2: 8.9658\n","Epoch 221/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0193 - model_loss: 0.0012 - model_1_loss: 0.0034 - model_2_loss: 8.6458e-04 - model_3_loss: 0.0015 - model_4_loss: 0.0123 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4061 - loss2: 9.2591 - val_loss: 10.5109 - val_model_loss: 2.1851 - val_model_1_loss: 2.8101 - val_model_2_loss: 1.4045 - val_model_3_loss: 1.8554 - val_model_4_loss: 2.2558 - val_model_accuracy: 0.5490 - val_model_1_accuracy: 0.4160 - val_model_2_accuracy: 0.6540 - val_model_3_accuracy: 0.4940 - val_model_4_accuracy: 0.4495 - val_loss1: 5.5913 - val_loss2: 8.9027\n","Epoch 222/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0061 - model_loss: 0.0018 - model_1_loss: 8.9400e-04 - model_2_loss: 7.3483e-04 - model_3_loss: 7.1397e-04 - model_4_loss: 0.0020 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0823 - loss2: 9.1396 - val_loss: 10.5664 - val_model_loss: 2.1771 - val_model_1_loss: 2.8851 - val_model_2_loss: 1.3945 - val_model_3_loss: 1.8391 - val_model_4_loss: 2.2707 - val_model_accuracy: 0.5495 - val_model_1_accuracy: 0.4225 - val_model_2_accuracy: 0.6540 - val_model_3_accuracy: 0.4850 - val_model_4_accuracy: 0.4420 - val_loss1: 5.5979 - val_loss2: 8.8438\n","Epoch 223/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0104 - model_loss: 0.0026 - model_1_loss: 0.0014 - model_2_loss: 2.3201e-04 - model_3_loss: 4.4170e-04 - model_4_loss: 0.0057 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.4746 - loss2: 8.9797 - val_loss: 10.6493 - val_model_loss: 2.1729 - val_model_1_loss: 2.9585 - val_model_2_loss: 1.3901 - val_model_3_loss: 1.8318 - val_model_4_loss: 2.2960 - val_model_accuracy: 0.5495 - val_model_1_accuracy: 0.4280 - val_model_2_accuracy: 0.6505 - val_model_3_accuracy: 0.4800 - val_model_4_accuracy: 0.4345 - val_loss1: 5.6129 - val_loss2: 8.7932\n","Epoch 224/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0174 - model_loss: 0.0021 - model_1_loss: 5.9906e-04 - model_2_loss: 0.0105 - model_3_loss: 0.0016 - model_4_loss: 0.0026 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4403 - loss2: 9.2812 - val_loss: 10.6528 - val_model_loss: 2.1557 - val_model_1_loss: 3.0026 - val_model_2_loss: 1.3788 - val_model_3_loss: 1.8086 - val_model_4_loss: 2.3070 - val_model_accuracy: 0.5495 - val_model_1_accuracy: 0.4365 - val_model_2_accuracy: 0.6495 - val_model_3_accuracy: 0.4730 - val_model_4_accuracy: 0.4355 - val_loss1: 5.6356 - val_loss2: 8.7533\n","Epoch 225/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0073 - model_loss: 7.6437e-04 - model_1_loss: 5.1525e-04 - model_2_loss: 6.6321e-04 - model_3_loss: 0.0031 - model_4_loss: 0.0022 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5712 - loss2: 9.3515 - val_loss: 10.6900 - val_model_loss: 2.1427 - val_model_1_loss: 3.0541 - val_model_2_loss: 1.3717 - val_model_3_loss: 1.7930 - val_model_4_loss: 2.3284 - val_model_accuracy: 0.5495 - val_model_1_accuracy: 0.4380 - val_model_2_accuracy: 0.6475 - val_model_3_accuracy: 0.4670 - val_model_4_accuracy: 0.4355 - val_loss1: 5.6618 - val_loss2: 8.7174\n","Epoch 226/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0073 - model_loss: 6.2256e-04 - model_1_loss: 0.0019 - model_2_loss: 0.0018 - model_3_loss: 0.0013 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1910 - loss2: 9.2929 - val_loss: 10.7189 - val_model_loss: 2.1314 - val_model_1_loss: 3.0877 - val_model_2_loss: 1.3672 - val_model_3_loss: 1.7807 - val_model_4_loss: 2.3519 - val_model_accuracy: 0.5490 - val_model_1_accuracy: 0.4405 - val_model_2_accuracy: 0.6480 - val_model_3_accuracy: 0.4640 - val_model_4_accuracy: 0.4390 - val_loss1: 5.6852 - val_loss2: 8.6909\n","Epoch 227/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0488 - model_loss: 0.0012 - model_1_loss: 0.0148 - model_2_loss: 0.0033 - model_3_loss: 0.0037 - model_4_loss: 0.0257 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9346 - loss2: 9.1472 - val_loss: 10.7544 - val_model_loss: 2.1214 - val_model_1_loss: 3.1211 - val_model_2_loss: 1.3670 - val_model_3_loss: 1.7740 - val_model_4_loss: 2.3709 - val_model_accuracy: 0.5500 - val_model_1_accuracy: 0.4400 - val_model_2_accuracy: 0.6460 - val_model_3_accuracy: 0.4635 - val_model_4_accuracy: 0.4415 - val_loss1: 5.7124 - val_loss2: 8.6748\n","Epoch 228/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0045 - model_loss: 5.6934e-04 - model_1_loss: 7.6945e-04 - model_2_loss: 7.9974e-04 - model_3_loss: 8.3140e-04 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0445 - loss2: 9.1591 - val_loss: 10.7485 - val_model_loss: 2.1088 - val_model_1_loss: 3.1307 - val_model_2_loss: 1.3643 - val_model_3_loss: 1.7621 - val_model_4_loss: 2.3825 - val_model_accuracy: 0.5530 - val_model_1_accuracy: 0.4405 - val_model_2_accuracy: 0.6465 - val_model_3_accuracy: 0.4625 - val_model_4_accuracy: 0.4440 - val_loss1: 5.7398 - val_loss2: 8.6668\n","Epoch 229/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0060 - model_loss: 0.0021 - model_1_loss: 6.2347e-04 - model_2_loss: 7.7209e-04 - model_3_loss: 0.0013 - model_4_loss: 0.0012 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9006 - loss2: 9.1364 - val_loss: 10.7514 - val_model_loss: 2.0998 - val_model_1_loss: 3.1381 - val_model_2_loss: 1.3650 - val_model_3_loss: 1.7537 - val_model_4_loss: 2.3947 - val_model_accuracy: 0.5525 - val_model_1_accuracy: 0.4410 - val_model_2_accuracy: 0.6430 - val_model_3_accuracy: 0.4580 - val_model_4_accuracy: 0.4465 - val_loss1: 5.7623 - val_loss2: 8.6618\n","Epoch 230/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0089 - model_loss: 0.0014 - model_1_loss: 7.4942e-04 - model_2_loss: 0.0039 - model_3_loss: 0.0013 - model_4_loss: 0.0015 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9890 - loss2: 9.1131 - val_loss: 10.7347 - val_model_loss: 2.0841 - val_model_1_loss: 3.1432 - val_model_2_loss: 1.3617 - val_model_3_loss: 1.7400 - val_model_4_loss: 2.4058 - val_model_accuracy: 0.5545 - val_model_1_accuracy: 0.4415 - val_model_2_accuracy: 0.6395 - val_model_3_accuracy: 0.4540 - val_model_4_accuracy: 0.4470 - val_loss1: 5.7824 - val_loss2: 8.6574\n","Epoch 231/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0095 - model_loss: 0.0014 - model_1_loss: 0.0015 - model_2_loss: 0.0026 - model_3_loss: 7.0515e-04 - model_4_loss: 0.0034 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0674 - loss2: 9.1646 - val_loss: 10.7071 - val_model_loss: 2.0725 - val_model_1_loss: 3.1354 - val_model_2_loss: 1.3598 - val_model_3_loss: 1.7262 - val_model_4_loss: 2.4133 - val_model_accuracy: 0.5545 - val_model_1_accuracy: 0.4425 - val_model_2_accuracy: 0.6400 - val_model_3_accuracy: 0.4515 - val_model_4_accuracy: 0.4460 - val_loss1: 5.8030 - val_loss2: 8.6589\n","Epoch 232/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0188 - model_loss: 0.0019 - model_1_loss: 0.0036 - model_2_loss: 0.0043 - model_3_loss: 0.0025 - model_4_loss: 0.0065 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7787 - loss2: 9.0279 - val_loss: 10.7366 - val_model_loss: 2.0696 - val_model_1_loss: 3.1436 - val_model_2_loss: 1.3654 - val_model_3_loss: 1.7255 - val_model_4_loss: 2.4324 - val_model_accuracy: 0.5545 - val_model_1_accuracy: 0.4435 - val_model_2_accuracy: 0.6370 - val_model_3_accuracy: 0.4490 - val_model_4_accuracy: 0.4465 - val_loss1: 5.8252 - val_loss2: 8.6605\n","Epoch 233/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0098 - model_loss: 0.0043 - model_1_loss: 0.0019 - model_2_loss: 2.1708e-04 - model_3_loss: 6.0839e-04 - model_4_loss: 0.0028 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4645 - loss2: 9.2194 - val_loss: 10.7102 - val_model_loss: 2.0579 - val_model_1_loss: 3.1308 - val_model_2_loss: 1.3652 - val_model_3_loss: 1.7120 - val_model_4_loss: 2.4443 - val_model_accuracy: 0.5550 - val_model_1_accuracy: 0.4445 - val_model_2_accuracy: 0.6345 - val_model_3_accuracy: 0.4490 - val_model_4_accuracy: 0.4435 - val_loss1: 5.8456 - val_loss2: 8.6647\n","Epoch 234/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0265 - model_loss: 0.0023 - model_1_loss: 0.0151 - model_2_loss: 0.0029 - model_3_loss: 0.0026 - model_4_loss: 0.0037 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8995 - loss2: 9.1038 - val_loss: 10.6132 - val_model_loss: 2.0424 - val_model_1_loss: 3.0637 - val_model_2_loss: 1.3607 - val_model_3_loss: 1.6972 - val_model_4_loss: 2.4492 - val_model_accuracy: 0.5570 - val_model_1_accuracy: 0.4455 - val_model_2_accuracy: 0.6370 - val_model_3_accuracy: 0.4520 - val_model_4_accuracy: 0.4445 - val_loss1: 5.8567 - val_loss2: 8.6841\n","Epoch 235/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0118 - model_loss: 0.0039 - model_1_loss: 0.0030 - model_2_loss: 0.0013 - model_3_loss: 0.0022 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2587 - loss2: 9.2652 - val_loss: 10.5430 - val_model_loss: 2.0302 - val_model_1_loss: 3.0086 - val_model_2_loss: 1.3613 - val_model_3_loss: 1.6846 - val_model_4_loss: 2.4584 - val_model_accuracy: 0.5580 - val_model_1_accuracy: 0.4460 - val_model_2_accuracy: 0.6360 - val_model_3_accuracy: 0.4520 - val_model_4_accuracy: 0.4435 - val_loss1: 5.8757 - val_loss2: 8.7053\n","Epoch 236/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0265 - model_loss: 0.0034 - model_1_loss: 7.1620e-04 - model_2_loss: 0.0185 - model_3_loss: 0.0016 - model_4_loss: 0.0022 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.3653 - loss2: 8.9389 - val_loss: 10.5203 - val_model_loss: 2.0278 - val_model_1_loss: 2.9630 - val_model_2_loss: 1.3766 - val_model_3_loss: 1.6823 - val_model_4_loss: 2.4706 - val_model_accuracy: 0.5585 - val_model_1_accuracy: 0.4445 - val_model_2_accuracy: 0.6335 - val_model_3_accuracy: 0.4525 - val_model_4_accuracy: 0.4435 - val_loss1: 5.9168 - val_loss2: 8.7319\n","Epoch 237/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0129 - model_loss: 9.2474e-04 - model_1_loss: 0.0030 - model_2_loss: 0.0014 - model_3_loss: 0.0068 - model_4_loss: 8.6696e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8189 - loss2: 9.0055 - val_loss: 10.5048 - val_model_loss: 2.0272 - val_model_1_loss: 2.9216 - val_model_2_loss: 1.3910 - val_model_3_loss: 1.6813 - val_model_4_loss: 2.4837 - val_model_accuracy: 0.5585 - val_model_1_accuracy: 0.4430 - val_model_2_accuracy: 0.6325 - val_model_3_accuracy: 0.4545 - val_model_4_accuracy: 0.4410 - val_loss1: 5.9546 - val_loss2: 8.7588\n","Epoch 238/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.2831 - model_loss: 0.0013 - model_1_loss: 0.1497 - model_2_loss: 0.0098 - model_3_loss: 0.0045 - model_4_loss: 0.1177 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7193 - loss2: 9.0107 - val_loss: 10.2374 - val_model_loss: 2.0148 - val_model_1_loss: 2.7723 - val_model_2_loss: 1.3988 - val_model_3_loss: 1.6598 - val_model_4_loss: 2.3917 - val_model_accuracy: 0.5575 - val_model_1_accuracy: 0.4695 - val_model_2_accuracy: 0.6315 - val_model_3_accuracy: 0.4575 - val_model_4_accuracy: 0.4705 - val_loss1: 6.0895 - val_loss2: 8.7710\n","Epoch 239/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0505 - model_loss: 0.0032 - model_1_loss: 0.0021 - model_2_loss: 1.4738e-04 - model_3_loss: 0.0346 - model_4_loss: 0.0105 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8963 - loss2: 9.1310 - val_loss: 10.1082 - val_model_loss: 2.0145 - val_model_1_loss: 2.6972 - val_model_2_loss: 1.4120 - val_model_3_loss: 1.6302 - val_model_4_loss: 2.3543 - val_model_accuracy: 0.5580 - val_model_1_accuracy: 0.4800 - val_model_2_accuracy: 0.6295 - val_model_3_accuracy: 0.4685 - val_model_4_accuracy: 0.4820 - val_loss1: 6.2599 - val_loss2: 8.7940\n","Epoch 240/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0041 - model_loss: 1.5507e-04 - model_1_loss: 0.0014 - model_2_loss: 8.3727e-04 - model_3_loss: 8.0731e-04 - model_4_loss: 8.8884e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.9394 - loss2: 9.1345 - val_loss: 10.0035 - val_model_loss: 2.0004 - val_model_1_loss: 2.6550 - val_model_2_loss: 1.4191 - val_model_3_loss: 1.5905 - val_model_4_loss: 2.3384 - val_model_accuracy: 0.5585 - val_model_1_accuracy: 0.4915 - val_model_2_accuracy: 0.6290 - val_model_3_accuracy: 0.4775 - val_model_4_accuracy: 0.4875 - val_loss1: 6.4147 - val_loss2: 8.8139\n","Epoch 241/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0076 - model_loss: 0.0021 - model_1_loss: 0.0027 - model_2_loss: 0.0012 - model_3_loss: 0.0014 - model_4_loss: 2.8393e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.8482 - loss2: 9.4053 - val_loss: 9.9583 - val_model_loss: 1.9871 - val_model_1_loss: 2.6445 - val_model_2_loss: 1.4257 - val_model_3_loss: 1.5543 - val_model_4_loss: 2.3466 - val_model_accuracy: 0.5605 - val_model_1_accuracy: 0.5040 - val_model_2_accuracy: 0.6275 - val_model_3_accuracy: 0.4795 - val_model_4_accuracy: 0.4860 - val_loss1: 6.5493 - val_loss2: 8.8276\n","Epoch 242/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0029 - model_loss: 1.6204e-04 - model_1_loss: 9.8364e-04 - model_2_loss: 6.0681e-04 - model_3_loss: 6.2159e-04 - model_4_loss: 5.6205e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.8308 - loss2: 9.4183 - val_loss: 9.9549 - val_model_loss: 1.9744 - val_model_1_loss: 2.6591 - val_model_2_loss: 1.4347 - val_model_3_loss: 1.5213 - val_model_4_loss: 2.3653 - val_model_accuracy: 0.5620 - val_model_1_accuracy: 0.5165 - val_model_2_accuracy: 0.6275 - val_model_3_accuracy: 0.4860 - val_model_4_accuracy: 0.4855 - val_loss1: 6.6548 - val_loss2: 8.8313\n","Epoch 243/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0679 - model_loss: 0.0018 - model_1_loss: 0.0410 - model_2_loss: 0.0210 - model_3_loss: 0.0017 - model_4_loss: 0.0024 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7137 - loss2: 9.1483 - val_loss: 9.9885 - val_model_loss: 1.9654 - val_model_1_loss: 2.6907 - val_model_2_loss: 1.4419 - val_model_3_loss: 1.4998 - val_model_4_loss: 2.3907 - val_model_accuracy: 0.5630 - val_model_1_accuracy: 0.5180 - val_model_2_accuracy: 0.6275 - val_model_3_accuracy: 0.4915 - val_model_4_accuracy: 0.4900 - val_loss1: 6.7078 - val_loss2: 8.8177\n","Epoch 244/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0234 - model_loss: 0.0021 - model_1_loss: 0.0156 - model_2_loss: 4.8921e-04 - model_3_loss: 0.0045 - model_4_loss: 6.5386e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.8647 - loss2: 9.0862 - val_loss: 10.0147 - val_model_loss: 1.9641 - val_model_1_loss: 2.6901 - val_model_2_loss: 1.4521 - val_model_3_loss: 1.4866 - val_model_4_loss: 2.4218 - val_model_accuracy: 0.5630 - val_model_1_accuracy: 0.5165 - val_model_2_accuracy: 0.6255 - val_model_3_accuracy: 0.4970 - val_model_4_accuracy: 0.4940 - val_loss1: 6.7621 - val_loss2: 8.8169\n","Epoch 245/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0322 - model_loss: 0.0062 - model_1_loss: 0.0143 - model_2_loss: 0.0017 - model_3_loss: 0.0073 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3447 - loss2: 9.2962 - val_loss: 9.9661 - val_model_loss: 1.9520 - val_model_1_loss: 2.6629 - val_model_2_loss: 1.4518 - val_model_3_loss: 1.4584 - val_model_4_loss: 2.4410 - val_model_accuracy: 0.5645 - val_model_1_accuracy: 0.5220 - val_model_2_accuracy: 0.6290 - val_model_3_accuracy: 0.5000 - val_model_4_accuracy: 0.4980 - val_loss1: 6.8099 - val_loss2: 8.8226\n","Epoch 246/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0058 - model_loss: 6.7454e-04 - model_1_loss: 7.1542e-04 - model_2_loss: 9.2370e-04 - model_3_loss: 0.0024 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.9572 - loss2: 9.4140 - val_loss: 9.9200 - val_model_loss: 1.9384 - val_model_1_loss: 2.6404 - val_model_2_loss: 1.4524 - val_model_3_loss: 1.4286 - val_model_4_loss: 2.4603 - val_model_accuracy: 0.5650 - val_model_1_accuracy: 0.5200 - val_model_2_accuracy: 0.6315 - val_model_3_accuracy: 0.5090 - val_model_4_accuracy: 0.5040 - val_loss1: 6.8611 - val_loss2: 8.8270\n","Epoch 247/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0468 - model_loss: 0.0032 - model_1_loss: 0.0369 - model_2_loss: 5.7412e-04 - model_3_loss: 0.0035 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 9.0945 - loss2: 9.4322 - val_loss: 9.8941 - val_model_loss: 1.9302 - val_model_1_loss: 2.6222 - val_model_2_loss: 1.4551 - val_model_3_loss: 1.4055 - val_model_4_loss: 2.4811 - val_model_accuracy: 0.5665 - val_model_1_accuracy: 0.5210 - val_model_2_accuracy: 0.6325 - val_model_3_accuracy: 0.5150 - val_model_4_accuracy: 0.5125 - val_loss1: 6.9047 - val_loss2: 8.8339\n","Epoch 248/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0092 - model_loss: 0.0029 - model_1_loss: 0.0017 - model_2_loss: 0.0024 - model_3_loss: 6.8967e-04 - model_4_loss: 0.0015 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.7292 - loss2: 9.3336 - val_loss: 9.8206 - val_model_loss: 1.9113 - val_model_1_loss: 2.5963 - val_model_2_loss: 1.4488 - val_model_3_loss: 1.3750 - val_model_4_loss: 2.4892 - val_model_accuracy: 0.5665 - val_model_1_accuracy: 0.5265 - val_model_2_accuracy: 0.6375 - val_model_3_accuracy: 0.5255 - val_model_4_accuracy: 0.5215 - val_loss1: 6.9457 - val_loss2: 8.8424\n","Epoch 249/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0627 - model_loss: 0.0030 - model_1_loss: 0.0438 - model_2_loss: 0.0081 - model_3_loss: 0.0069 - model_4_loss: 9.7418e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.7913 - loss2: 9.0446 - val_loss: 9.8046 - val_model_loss: 1.9079 - val_model_1_loss: 2.5732 - val_model_2_loss: 1.4494 - val_model_3_loss: 1.3618 - val_model_4_loss: 2.5124 - val_model_accuracy: 0.5670 - val_model_1_accuracy: 0.5280 - val_model_2_accuracy: 0.6365 - val_model_3_accuracy: 0.5325 - val_model_4_accuracy: 0.5275 - val_loss1: 6.9733 - val_loss2: 8.8485\n","Epoch 250/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.4862 - model_loss: 0.0214 - model_1_loss: 0.4286 - model_2_loss: 0.0132 - model_3_loss: 0.0113 - model_4_loss: 0.0117 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 7.2726 - loss2: 8.9831 - val_loss: 9.5301 - val_model_loss: 1.9052 - val_model_1_loss: 2.3281 - val_model_2_loss: 1.4378 - val_model_3_loss: 1.3392 - val_model_4_loss: 2.5198 - val_model_accuracy: 0.5715 - val_model_1_accuracy: 0.5465 - val_model_2_accuracy: 0.6410 - val_model_3_accuracy: 0.5380 - val_model_4_accuracy: 0.5295 - val_loss1: 7.1086 - val_loss2: 8.9549\n","Epoch 251/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0182 - model_loss: 0.0014 - model_1_loss: 8.0035e-04 - model_2_loss: 0.0018 - model_3_loss: 9.8120e-04 - model_4_loss: 0.0133 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4845 - loss2: 9.3814 - val_loss: 9.4498 - val_model_loss: 1.9143 - val_model_1_loss: 2.2598 - val_model_2_loss: 1.4272 - val_model_3_loss: 1.3284 - val_model_4_loss: 2.5201 - val_model_accuracy: 0.5710 - val_model_1_accuracy: 0.5850 - val_model_2_accuracy: 0.6400 - val_model_3_accuracy: 0.5420 - val_model_4_accuracy: 0.5335 - val_loss1: 7.2177 - val_loss2: 9.0271\n","Epoch 252/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0132 - model_loss: 5.4910e-04 - model_1_loss: 0.0099 - model_2_loss: 6.9848e-04 - model_3_loss: 0.0015 - model_4_loss: 6.3155e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 9.1152 - loss2: 9.4609 - val_loss: 9.4739 - val_model_loss: 1.9056 - val_model_1_loss: 2.3453 - val_model_2_loss: 1.4117 - val_model_3_loss: 1.3045 - val_model_4_loss: 2.5068 - val_model_accuracy: 0.5715 - val_model_1_accuracy: 0.6200 - val_model_2_accuracy: 0.6455 - val_model_3_accuracy: 0.5500 - val_model_4_accuracy: 0.5370 - val_loss1: 7.3000 - val_loss2: 9.0657\n","Epoch 253/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0079 - model_loss: 6.6770e-04 - model_1_loss: 0.0016 - model_2_loss: 0.0021 - model_3_loss: 0.0029 - model_4_loss: 6.4890e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3315 - loss2: 9.3366 - val_loss: 9.5798 - val_model_loss: 1.8934 - val_model_1_loss: 2.5029 - val_model_2_loss: 1.3992 - val_model_3_loss: 1.2816 - val_model_4_loss: 2.5026 - val_model_accuracy: 0.5735 - val_model_1_accuracy: 0.6405 - val_model_2_accuracy: 0.6495 - val_model_3_accuracy: 0.5600 - val_model_4_accuracy: 0.5410 - val_loss1: 7.3683 - val_loss2: 9.0777\n","Epoch 254/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0083 - model_loss: 7.4017e-04 - model_1_loss: 3.0112e-04 - model_2_loss: 6.4817e-04 - model_3_loss: 0.0053 - model_4_loss: 0.0013 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.8086 - loss2: 9.4501 - val_loss: 9.6982 - val_model_loss: 1.8901 - val_model_1_loss: 2.6664 - val_model_2_loss: 1.3857 - val_model_3_loss: 1.2671 - val_model_4_loss: 2.4890 - val_model_accuracy: 0.5770 - val_model_1_accuracy: 0.6400 - val_model_2_accuracy: 0.6520 - val_model_3_accuracy: 0.5710 - val_model_4_accuracy: 0.5410 - val_loss1: 7.4044 - val_loss2: 9.0778\n","Epoch 255/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0062 - model_loss: 0.0012 - model_1_loss: 0.0014 - model_2_loss: 3.0437e-04 - model_3_loss: 9.5124e-04 - model_4_loss: 0.0023 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4378 - loss2: 9.3088 - val_loss: 9.7940 - val_model_loss: 1.8788 - val_model_1_loss: 2.8178 - val_model_2_loss: 1.3735 - val_model_3_loss: 1.2479 - val_model_4_loss: 2.4760 - val_model_accuracy: 0.5805 - val_model_1_accuracy: 0.6445 - val_model_2_accuracy: 0.6560 - val_model_3_accuracy: 0.5785 - val_model_4_accuracy: 0.5435 - val_loss1: 7.4375 - val_loss2: 9.0677\n","Epoch 256/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0237 - model_loss: 8.2088e-04 - model_1_loss: 0.0196 - model_2_loss: 2.2470e-04 - model_3_loss: 0.0016 - model_4_loss: 0.0015 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.9332 - loss2: 9.4798 - val_loss: 9.8752 - val_model_loss: 1.8733 - val_model_1_loss: 2.9425 - val_model_2_loss: 1.3633 - val_model_3_loss: 1.2355 - val_model_4_loss: 2.4606 - val_model_accuracy: 0.5815 - val_model_1_accuracy: 0.6450 - val_model_2_accuracy: 0.6565 - val_model_3_accuracy: 0.5860 - val_model_4_accuracy: 0.5480 - val_loss1: 7.4467 - val_loss2: 9.0554\n","Epoch 257/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0698 - model_loss: 0.0034 - model_1_loss: 0.0417 - model_2_loss: 6.0936e-04 - model_3_loss: 0.0075 - model_4_loss: 0.0167 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6362 - loss2: 9.4860 - val_loss: 9.9100 - val_model_loss: 1.8585 - val_model_1_loss: 3.0417 - val_model_2_loss: 1.3519 - val_model_3_loss: 1.2172 - val_model_4_loss: 2.4407 - val_model_accuracy: 0.5835 - val_model_1_accuracy: 0.6490 - val_model_2_accuracy: 0.6585 - val_model_3_accuracy: 0.5955 - val_model_4_accuracy: 0.5500 - val_loss1: 7.4534 - val_loss2: 9.0393\n","Epoch 258/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0235 - model_loss: 0.0015 - model_1_loss: 0.0032 - model_2_loss: 0.0104 - model_3_loss: 0.0019 - model_4_loss: 0.0065 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6757 - loss2: 9.3887 - val_loss: 9.9615 - val_model_loss: 1.8547 - val_model_1_loss: 3.1348 - val_model_2_loss: 1.3398 - val_model_3_loss: 1.2090 - val_model_4_loss: 2.4231 - val_model_accuracy: 0.5885 - val_model_1_accuracy: 0.6520 - val_model_2_accuracy: 0.6630 - val_model_3_accuracy: 0.6040 - val_model_4_accuracy: 0.5520 - val_loss1: 7.4379 - val_loss2: 9.0213\n","Epoch 259/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0211 - model_loss: 0.0031 - model_1_loss: 0.0108 - model_2_loss: 0.0039 - model_3_loss: 0.0022 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 9.2285 - loss2: 9.5494 - val_loss: 9.9757 - val_model_loss: 1.8387 - val_model_1_loss: 3.2152 - val_model_2_loss: 1.3288 - val_model_3_loss: 1.1932 - val_model_4_loss: 2.3998 - val_model_accuracy: 0.5895 - val_model_1_accuracy: 0.6585 - val_model_2_accuracy: 0.6640 - val_model_3_accuracy: 0.6120 - val_model_4_accuracy: 0.5565 - val_loss1: 7.4311 - val_loss2: 9.0055\n","Epoch 260/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0117 - model_loss: 6.0339e-04 - model_1_loss: 0.0025 - model_2_loss: 0.0022 - model_3_loss: 0.0037 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.8684 - loss2: 9.4840 - val_loss: 9.9987 - val_model_loss: 1.8277 - val_model_1_loss: 3.2832 - val_model_2_loss: 1.3222 - val_model_3_loss: 1.1848 - val_model_4_loss: 2.3808 - val_model_accuracy: 0.5905 - val_model_1_accuracy: 0.6620 - val_model_2_accuracy: 0.6675 - val_model_3_accuracy: 0.6185 - val_model_4_accuracy: 0.5585 - val_loss1: 7.4144 - val_loss2: 8.9882\n","Epoch 261/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0582 - model_loss: 0.0048 - model_1_loss: 0.0046 - model_2_loss: 0.0089 - model_3_loss: 0.0032 - model_4_loss: 0.0367 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4327 - loss2: 9.4387 - val_loss: 9.9733 - val_model_loss: 1.8137 - val_model_1_loss: 3.3341 - val_model_2_loss: 1.3114 - val_model_3_loss: 1.1763 - val_model_4_loss: 2.3378 - val_model_accuracy: 0.5925 - val_model_1_accuracy: 0.6670 - val_model_2_accuracy: 0.6695 - val_model_3_accuracy: 0.6250 - val_model_4_accuracy: 0.5605 - val_loss1: 7.4057 - val_loss2: 8.9778\n","Epoch 262/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0151 - model_loss: 9.1794e-04 - model_1_loss: 0.0037 - model_2_loss: 0.0055 - model_3_loss: 0.0039 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.8213 - loss2: 9.4554 - val_loss: 9.9446 - val_model_loss: 1.8028 - val_model_1_loss: 3.3712 - val_model_2_loss: 1.3025 - val_model_3_loss: 1.1685 - val_model_4_loss: 2.2995 - val_model_accuracy: 0.5940 - val_model_1_accuracy: 0.6700 - val_model_2_accuracy: 0.6700 - val_model_3_accuracy: 0.6285 - val_model_4_accuracy: 0.5625 - val_loss1: 7.3908 - val_loss2: 8.9732\n","Epoch 263/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0815 - model_loss: 0.0066 - model_1_loss: 0.0612 - model_2_loss: 2.9745e-04 - model_3_loss: 0.0011 - model_4_loss: 0.0123 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6037 - loss2: 9.3847 - val_loss: 9.9273 - val_model_loss: 1.7963 - val_model_1_loss: 3.4012 - val_model_2_loss: 1.2940 - val_model_3_loss: 1.1634 - val_model_4_loss: 2.2723 - val_model_accuracy: 0.5980 - val_model_1_accuracy: 0.6600 - val_model_2_accuracy: 0.6710 - val_model_3_accuracy: 0.6320 - val_model_4_accuracy: 0.5610 - val_loss1: 7.3859 - val_loss2: 8.9821\n","Epoch 264/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0086 - model_loss: 0.0026 - model_1_loss: 0.0029 - model_2_loss: 8.5409e-04 - model_3_loss: 6.8834e-04 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 9.0894 - loss2: 9.5007 - val_loss: 9.8731 - val_model_loss: 1.7785 - val_model_1_loss: 3.4145 - val_model_2_loss: 1.2844 - val_model_3_loss: 1.1510 - val_model_4_loss: 2.2447 - val_model_accuracy: 0.6005 - val_model_1_accuracy: 0.6535 - val_model_2_accuracy: 0.6710 - val_model_3_accuracy: 0.6360 - val_model_4_accuracy: 0.5615 - val_loss1: 7.3833 - val_loss2: 8.9922\n","Epoch 265/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0169 - model_loss: 0.0011 - model_1_loss: 0.0057 - model_2_loss: 0.0042 - model_3_loss: 0.0046 - model_4_loss: 0.0014 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6390 - loss2: 9.4264 - val_loss: 9.8518 - val_model_loss: 1.7749 - val_model_1_loss: 3.4179 - val_model_2_loss: 1.2814 - val_model_3_loss: 1.1501 - val_model_4_loss: 2.2274 - val_model_accuracy: 0.6000 - val_model_1_accuracy: 0.6495 - val_model_2_accuracy: 0.6710 - val_model_3_accuracy: 0.6420 - val_model_4_accuracy: 0.5610 - val_loss1: 7.3645 - val_loss2: 9.0031\n","Epoch 266/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0360 - model_loss: 0.0022 - model_1_loss: 0.0187 - model_2_loss: 0.0095 - model_3_loss: 3.9802e-04 - model_4_loss: 0.0051 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.8836 - loss2: 9.5103 - val_loss: 9.8209 - val_model_loss: 1.7633 - val_model_1_loss: 3.4302 - val_model_2_loss: 1.2777 - val_model_3_loss: 1.1431 - val_model_4_loss: 2.2066 - val_model_accuracy: 0.6015 - val_model_1_accuracy: 0.6420 - val_model_2_accuracy: 0.6715 - val_model_3_accuracy: 0.6490 - val_model_4_accuracy: 0.5625 - val_loss1: 7.3512 - val_loss2: 9.0154\n","Epoch 267/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0157 - model_loss: 4.7270e-04 - model_1_loss: 0.0082 - model_2_loss: 0.0029 - model_3_loss: 0.0015 - model_4_loss: 0.0026 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6267 - loss2: 9.3505 - val_loss: 9.8007 - val_model_loss: 1.7589 - val_model_1_loss: 3.4365 - val_model_2_loss: 1.2762 - val_model_3_loss: 1.1416 - val_model_4_loss: 2.1875 - val_model_accuracy: 0.6025 - val_model_1_accuracy: 0.6340 - val_model_2_accuracy: 0.6700 - val_model_3_accuracy: 0.6525 - val_model_4_accuracy: 0.5610 - val_loss1: 7.3341 - val_loss2: 9.0300\n","Epoch 268/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0034 - model_loss: 0.0010 - model_1_loss: 0.0010 - model_2_loss: 3.2016e-04 - model_3_loss: 2.1423e-04 - model_4_loss: 7.2593e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 9.1591 - loss2: 9.5373 - val_loss: 9.7328 - val_model_loss: 1.7403 - val_model_1_loss: 3.4273 - val_model_2_loss: 1.2704 - val_model_3_loss: 1.1312 - val_model_4_loss: 2.1635 - val_model_accuracy: 0.6035 - val_model_1_accuracy: 0.6275 - val_model_2_accuracy: 0.6695 - val_model_3_accuracy: 0.6600 - val_model_4_accuracy: 0.5630 - val_loss1: 7.3222 - val_loss2: 9.0423\n","Epoch 269/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0098 - model_loss: 4.7370e-04 - model_1_loss: 0.0047 - model_2_loss: 4.5082e-04 - model_3_loss: 0.0027 - model_4_loss: 0.0015 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2768 - loss2: 9.1923 - val_loss: 9.7234 - val_model_loss: 1.7381 - val_model_1_loss: 3.4369 - val_model_2_loss: 1.2694 - val_model_3_loss: 1.1309 - val_model_4_loss: 2.1481 - val_model_accuracy: 0.6035 - val_model_1_accuracy: 0.6230 - val_model_2_accuracy: 0.6715 - val_model_3_accuracy: 0.6635 - val_model_4_accuracy: 0.5615 - val_loss1: 7.2918 - val_loss2: 9.0513\n","Epoch 270/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0080 - model_loss: 0.0014 - model_1_loss: 0.0035 - model_2_loss: 6.4690e-04 - model_3_loss: 0.0015 - model_4_loss: 8.0639e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5289 - loss2: 9.4376 - val_loss: 9.6865 - val_model_loss: 1.7302 - val_model_1_loss: 3.4253 - val_model_2_loss: 1.2688 - val_model_3_loss: 1.1273 - val_model_4_loss: 2.1349 - val_model_accuracy: 0.6035 - val_model_1_accuracy: 0.6135 - val_model_2_accuracy: 0.6725 - val_model_3_accuracy: 0.6680 - val_model_4_accuracy: 0.5610 - val_loss1: 7.2653 - val_loss2: 9.0603\n","Epoch 271/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0731 - model_loss: 0.0040 - model_1_loss: 0.0617 - model_2_loss: 0.0011 - model_3_loss: 0.0026 - model_4_loss: 0.0037 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6656 - loss2: 9.4664 - val_loss: 9.6286 - val_model_loss: 1.7186 - val_model_1_loss: 3.4010 - val_model_2_loss: 1.2680 - val_model_3_loss: 1.1230 - val_model_4_loss: 2.1181 - val_model_accuracy: 0.6065 - val_model_1_accuracy: 0.6140 - val_model_2_accuracy: 0.6715 - val_model_3_accuracy: 0.6705 - val_model_4_accuracy: 0.5610 - val_loss1: 7.2477 - val_loss2: 9.0724\n","Epoch 272/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0060 - model_loss: 0.0027 - model_1_loss: 4.2156e-04 - model_2_loss: 4.8909e-04 - model_3_loss: 0.0021 - model_4_loss: 3.4145e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 9.3616 - loss2: 9.5988 - val_loss: 9.5564 - val_model_loss: 1.7047 - val_model_1_loss: 3.3746 - val_model_2_loss: 1.2634 - val_model_3_loss: 1.1161 - val_model_4_loss: 2.0976 - val_model_accuracy: 0.6065 - val_model_1_accuracy: 0.6125 - val_model_2_accuracy: 0.6740 - val_model_3_accuracy: 0.6735 - val_model_4_accuracy: 0.5615 - val_loss1: 7.2331 - val_loss2: 9.0832\n","Epoch 273/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.1200 - model_loss: 0.0010 - model_1_loss: 0.0061 - model_2_loss: 8.4671e-04 - model_3_loss: 0.0033 - model_4_loss: 0.1087 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0513 - loss2: 9.3450 - val_loss: 9.4955 - val_model_loss: 1.6985 - val_model_1_loss: 3.3642 - val_model_2_loss: 1.2618 - val_model_3_loss: 1.1149 - val_model_4_loss: 2.0561 - val_model_accuracy: 0.6075 - val_model_1_accuracy: 0.6105 - val_model_2_accuracy: 0.6750 - val_model_3_accuracy: 0.6800 - val_model_4_accuracy: 0.5690 - val_loss1: 7.2590 - val_loss2: 9.1182\n","Epoch 274/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0309 - model_loss: 6.6997e-04 - model_1_loss: 0.0036 - model_2_loss: 4.0002e-04 - model_3_loss: 6.4925e-04 - model_4_loss: 0.0256 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5553 - loss2: 9.4359 - val_loss: 9.4421 - val_model_loss: 1.6861 - val_model_1_loss: 3.3551 - val_model_2_loss: 1.2613 - val_model_3_loss: 1.1110 - val_model_4_loss: 2.0286 - val_model_accuracy: 0.6080 - val_model_1_accuracy: 0.6090 - val_model_2_accuracy: 0.6725 - val_model_3_accuracy: 0.6820 - val_model_4_accuracy: 0.5775 - val_loss1: 7.2869 - val_loss2: 9.1466\n","Epoch 275/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0070 - model_loss: 7.9295e-04 - model_1_loss: 0.0011 - model_2_loss: 9.5525e-04 - model_3_loss: 0.0030 - model_4_loss: 0.0011 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.7262 - loss2: 9.4805 - val_loss: 9.3665 - val_model_loss: 1.6700 - val_model_1_loss: 3.3340 - val_model_2_loss: 1.2563 - val_model_3_loss: 1.1048 - val_model_4_loss: 2.0013 - val_model_accuracy: 0.6115 - val_model_1_accuracy: 0.6080 - val_model_2_accuracy: 0.6740 - val_model_3_accuracy: 0.6865 - val_model_4_accuracy: 0.5855 - val_loss1: 7.3126 - val_loss2: 9.1717\n","Epoch 276/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.2636 - model_loss: 7.2741e-04 - model_1_loss: 0.2542 - model_2_loss: 0.0020 - model_3_loss: 6.7496e-04 - model_4_loss: 0.0060 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2732 - loss2: 9.2851 - val_loss: 9.2384 - val_model_loss: 1.6686 - val_model_1_loss: 3.2202 - val_model_2_loss: 1.2579 - val_model_3_loss: 1.1058 - val_model_4_loss: 1.9859 - val_model_accuracy: 0.6120 - val_model_1_accuracy: 0.6155 - val_model_2_accuracy: 0.6745 - val_model_3_accuracy: 0.6875 - val_model_4_accuracy: 0.5955 - val_loss1: 7.3458 - val_loss2: 9.1919\n","Epoch 277/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0541 - model_loss: 0.0070 - model_1_loss: 0.0023 - model_2_loss: 0.0051 - model_3_loss: 0.0016 - model_4_loss: 0.0380 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.7812 - loss2: 9.4436 - val_loss: 9.0590 - val_model_loss: 1.6608 - val_model_1_loss: 3.0965 - val_model_2_loss: 1.2557 - val_model_3_loss: 1.1043 - val_model_4_loss: 1.9416 - val_model_accuracy: 0.6125 - val_model_1_accuracy: 0.6235 - val_model_2_accuracy: 0.6765 - val_model_3_accuracy: 0.6890 - val_model_4_accuracy: 0.5960 - val_loss1: 7.3586 - val_loss2: 9.2143\n","Epoch 278/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0202 - model_loss: 3.7290e-04 - model_1_loss: 0.0054 - model_2_loss: 4.2490e-04 - model_3_loss: 3.0142e-04 - model_4_loss: 0.0138 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.8788 - loss2: 9.5162 - val_loss: 8.8387 - val_model_loss: 1.6391 - val_model_1_loss: 2.9591 - val_model_2_loss: 1.2484 - val_model_3_loss: 1.0968 - val_model_4_loss: 1.8952 - val_model_accuracy: 0.6150 - val_model_1_accuracy: 0.6305 - val_model_2_accuracy: 0.6775 - val_model_3_accuracy: 0.6945 - val_model_4_accuracy: 0.6010 - val_loss1: 7.3795 - val_loss2: 9.2368\n","Epoch 279/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0478 - model_loss: 0.0264 - model_1_loss: 0.0029 - model_2_loss: 0.0016 - model_3_loss: 0.0036 - model_4_loss: 0.0133 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5596 - loss2: 9.5028 - val_loss: 8.6495 - val_model_loss: 1.6227 - val_model_1_loss: 2.8293 - val_model_2_loss: 1.2465 - val_model_3_loss: 1.0931 - val_model_4_loss: 1.8579 - val_model_accuracy: 0.6200 - val_model_1_accuracy: 0.6380 - val_model_2_accuracy: 0.6760 - val_model_3_accuracy: 0.7000 - val_model_4_accuracy: 0.6025 - val_loss1: 7.3903 - val_loss2: 9.2570\n","Epoch 280/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0367 - model_loss: 0.0058 - model_1_loss: 0.0051 - model_2_loss: 0.0047 - model_3_loss: 0.0149 - model_4_loss: 0.0062 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4510 - loss2: 9.4268 - val_loss: 8.5157 - val_model_loss: 1.6200 - val_model_1_loss: 2.7222 - val_model_2_loss: 1.2468 - val_model_3_loss: 1.0938 - val_model_4_loss: 1.8329 - val_model_accuracy: 0.6220 - val_model_1_accuracy: 0.6415 - val_model_2_accuracy: 0.6760 - val_model_3_accuracy: 0.7075 - val_model_4_accuracy: 0.6025 - val_loss1: 7.3894 - val_loss2: 9.2753\n","Epoch 281/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0148 - model_loss: 0.0027 - model_1_loss: 0.0022 - model_2_loss: 0.0011 - model_3_loss: 0.0025 - model_4_loss: 0.0062 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.8250 - loss2: 9.5375 - val_loss: 8.3720 - val_model_loss: 1.6130 - val_model_1_loss: 2.6169 - val_model_2_loss: 1.2433 - val_model_3_loss: 1.0922 - val_model_4_loss: 1.8066 - val_model_accuracy: 0.6235 - val_model_1_accuracy: 0.6425 - val_model_2_accuracy: 0.6760 - val_model_3_accuracy: 0.7105 - val_model_4_accuracy: 0.5970 - val_loss1: 7.3920 - val_loss2: 9.2915\n","Epoch 282/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0066 - model_loss: 0.0015 - model_1_loss: 0.0015 - model_2_loss: 8.2794e-04 - model_3_loss: 0.0012 - model_4_loss: 0.0016 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.7599 - loss2: 9.4665 - val_loss: 8.2472 - val_model_loss: 1.6067 - val_model_1_loss: 2.5217 - val_model_2_loss: 1.2425 - val_model_3_loss: 1.0904 - val_model_4_loss: 1.7859 - val_model_accuracy: 0.6240 - val_model_1_accuracy: 0.6400 - val_model_2_accuracy: 0.6765 - val_model_3_accuracy: 0.7125 - val_model_4_accuracy: 0.5960 - val_loss1: 7.3787 - val_loss2: 9.3039\n","Epoch 283/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0112 - model_loss: 8.0026e-04 - model_1_loss: 0.0031 - model_2_loss: 0.0043 - model_3_loss: 0.0011 - model_4_loss: 0.0020 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6324 - loss2: 9.3530 - val_loss: 8.1578 - val_model_loss: 1.6076 - val_model_1_loss: 2.4431 - val_model_2_loss: 1.2432 - val_model_3_loss: 1.0904 - val_model_4_loss: 1.7734 - val_model_accuracy: 0.6210 - val_model_1_accuracy: 0.6400 - val_model_2_accuracy: 0.6735 - val_model_3_accuracy: 0.7130 - val_model_4_accuracy: 0.5905 - val_loss1: 7.3596 - val_loss2: 9.3144\n","Epoch 284/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0081 - model_loss: 8.5814e-04 - model_1_loss: 8.5616e-04 - model_2_loss: 0.0015 - model_3_loss: 0.0012 - model_4_loss: 0.0036 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.9389 - loss2: 9.4842 - val_loss: 8.0534 - val_model_loss: 1.5975 - val_model_1_loss: 2.3694 - val_model_2_loss: 1.2398 - val_model_3_loss: 1.0880 - val_model_4_loss: 1.7587 - val_model_accuracy: 0.6245 - val_model_1_accuracy: 0.6335 - val_model_2_accuracy: 0.6735 - val_model_3_accuracy: 0.7145 - val_model_4_accuracy: 0.5900 - val_loss1: 7.3503 - val_loss2: 9.3201\n","Epoch 285/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0195 - model_loss: 5.5461e-04 - model_1_loss: 0.0141 - model_2_loss: 6.1248e-04 - model_3_loss: 0.0024 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.0354 - loss2: 9.3495 - val_loss: 7.9606 - val_model_loss: 1.5859 - val_model_1_loss: 2.3057 - val_model_2_loss: 1.2381 - val_model_3_loss: 1.0864 - val_model_4_loss: 1.7445 - val_model_accuracy: 0.6280 - val_model_1_accuracy: 0.6310 - val_model_2_accuracy: 0.6735 - val_model_3_accuracy: 0.7155 - val_model_4_accuracy: 0.5930 - val_loss1: 7.3458 - val_loss2: 9.3264\n","Epoch 286/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0220 - model_loss: 5.6329e-04 - model_1_loss: 0.0197 - model_2_loss: 4.8823e-04 - model_3_loss: 6.7903e-04 - model_4_loss: 6.5927e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4918 - loss2: 9.3640 - val_loss: 7.8697 - val_model_loss: 1.5696 - val_model_1_loss: 2.2572 - val_model_2_loss: 1.2316 - val_model_3_loss: 1.0824 - val_model_4_loss: 1.7289 - val_model_accuracy: 0.6310 - val_model_1_accuracy: 0.6280 - val_model_2_accuracy: 0.6755 - val_model_3_accuracy: 0.7205 - val_model_4_accuracy: 0.5955 - val_loss1: 7.3458 - val_loss2: 9.3315\n","Epoch 287/300\n","1/1 [==============================] - 6s 6s/step - loss: 3.4462 - model_loss: 0.7363 - model_1_loss: 1.7745 - model_2_loss: 0.0537 - model_3_loss: 0.5429 - model_4_loss: 0.3388 - model_accuracy: 0.8333 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 8.5994 - loss2: 9.3371 - val_loss: 8.2959 - val_model_loss: 1.6271 - val_model_1_loss: 2.4015 - val_model_2_loss: 1.2775 - val_model_3_loss: 1.1787 - val_model_4_loss: 1.8112 - val_model_accuracy: 0.6435 - val_model_1_accuracy: 0.6325 - val_model_2_accuracy: 0.6460 - val_model_3_accuracy: 0.7245 - val_model_4_accuracy: 0.5640 - val_loss1: 7.0620 - val_loss2: 9.2065\n","Epoch 288/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0050 - model_loss: 0.0010 - model_1_loss: 7.4487e-04 - model_2_loss: 3.5181e-04 - model_3_loss: 1.8329e-04 - model_4_loss: 0.0027 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6855 - loss2: 9.4047 - val_loss: 8.8363 - val_model_loss: 1.6813 - val_model_1_loss: 2.5665 - val_model_2_loss: 1.3463 - val_model_3_loss: 1.2646 - val_model_4_loss: 1.9776 - val_model_accuracy: 0.6550 - val_model_1_accuracy: 0.6110 - val_model_2_accuracy: 0.6240 - val_model_3_accuracy: 0.7125 - val_model_4_accuracy: 0.5390 - val_loss1: 6.7897 - val_loss2: 9.0777\n","Epoch 289/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0247 - model_loss: 0.0026 - model_1_loss: 0.0173 - model_2_loss: 3.4867e-04 - model_3_loss: 0.0013 - model_4_loss: 0.0031 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.9750 - loss2: 9.3972 - val_loss: 9.4714 - val_model_loss: 1.7364 - val_model_1_loss: 2.7527 - val_model_2_loss: 1.4466 - val_model_3_loss: 1.3302 - val_model_4_loss: 2.2054 - val_model_accuracy: 0.6620 - val_model_1_accuracy: 0.5705 - val_model_2_accuracy: 0.6040 - val_model_3_accuracy: 0.6980 - val_model_4_accuracy: 0.5250 - val_loss1: 6.5602 - val_loss2: 8.9654\n","Epoch 290/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.1039 - model_loss: 0.0056 - model_1_loss: 0.0754 - model_2_loss: 5.0360e-04 - model_3_loss: 0.0205 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.4116 - loss2: 9.3080 - val_loss: 10.1279 - val_model_loss: 1.7892 - val_model_1_loss: 2.8612 - val_model_2_loss: 1.5740 - val_model_3_loss: 1.3953 - val_model_4_loss: 2.5082 - val_model_accuracy: 0.6635 - val_model_1_accuracy: 0.5490 - val_model_2_accuracy: 0.5855 - val_model_3_accuracy: 0.6650 - val_model_4_accuracy: 0.5050 - val_loss1: 6.3810 - val_loss2: 8.8543\n","Epoch 291/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0085 - model_loss: 1.4123e-04 - model_1_loss: 0.0025 - model_2_loss: 0.0021 - model_3_loss: 0.0020 - model_4_loss: 0.0018 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1157 - loss2: 9.1942 - val_loss: 10.8010 - val_model_loss: 1.8321 - val_model_1_loss: 2.9417 - val_model_2_loss: 1.7031 - val_model_3_loss: 1.4716 - val_model_4_loss: 2.8525 - val_model_accuracy: 0.6670 - val_model_1_accuracy: 0.5330 - val_model_2_accuracy: 0.5700 - val_model_3_accuracy: 0.6395 - val_model_4_accuracy: 0.4940 - val_loss1: 6.2313 - val_loss2: 8.7553\n","Epoch 292/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0267 - model_loss: 0.0027 - model_1_loss: 0.0118 - model_2_loss: 8.1634e-04 - model_3_loss: 0.0018 - model_4_loss: 0.0096 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6260 - loss2: 9.2375 - val_loss: 11.4784 - val_model_loss: 1.8694 - val_model_1_loss: 2.9867 - val_model_2_loss: 1.8277 - val_model_3_loss: 1.5617 - val_model_4_loss: 3.2329 - val_model_accuracy: 0.6680 - val_model_1_accuracy: 0.5300 - val_model_2_accuracy: 0.5565 - val_model_3_accuracy: 0.6235 - val_model_4_accuracy: 0.4790 - val_loss1: 6.1007 - val_loss2: 8.6665\n","Epoch 293/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0221 - model_loss: 7.4099e-04 - model_1_loss: 0.0182 - model_2_loss: 0.0013 - model_3_loss: 0.0011 - model_4_loss: 6.9665e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3834 - loss2: 9.2102 - val_loss: 12.1398 - val_model_loss: 1.8988 - val_model_1_loss: 2.9962 - val_model_2_loss: 1.9473 - val_model_3_loss: 1.6666 - val_model_4_loss: 3.6309 - val_model_accuracy: 0.6710 - val_model_1_accuracy: 0.5245 - val_model_2_accuracy: 0.5530 - val_model_3_accuracy: 0.6075 - val_model_4_accuracy: 0.4660 - val_loss1: 5.9509 - val_loss2: 8.5799\n","Epoch 294/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.5828 - model_loss: 0.0014 - model_1_loss: 0.0127 - model_2_loss: 0.0098 - model_3_loss: 0.2838 - model_4_loss: 0.2751 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 7.5560 - loss2: 8.9869 - val_loss: 11.5070 - val_model_loss: 1.9321 - val_model_1_loss: 2.9939 - val_model_2_loss: 1.9693 - val_model_3_loss: 1.6005 - val_model_4_loss: 3.0112 - val_model_accuracy: 0.6675 - val_model_1_accuracy: 0.5145 - val_model_2_accuracy: 0.5495 - val_model_3_accuracy: 0.6860 - val_model_4_accuracy: 0.4545 - val_loss1: 6.0609 - val_loss2: 8.7028\n","Epoch 295/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0058 - model_loss: 0.0035 - model_1_loss: 0.0011 - model_2_loss: 1.8682e-04 - model_3_loss: 5.8238e-04 - model_4_loss: 4.7091e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.6290 - loss2: 9.2810 - val_loss: 11.4308 - val_model_loss: 1.9553 - val_model_1_loss: 2.9650 - val_model_2_loss: 1.9837 - val_model_3_loss: 1.8924 - val_model_4_loss: 2.6343 - val_model_accuracy: 0.6660 - val_model_1_accuracy: 0.4945 - val_model_2_accuracy: 0.5380 - val_model_3_accuracy: 0.7255 - val_model_4_accuracy: 0.4790 - val_loss1: 6.0889 - val_loss2: 8.6534\n","Epoch 296/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0122 - model_loss: 0.0028 - model_1_loss: 0.0058 - model_2_loss: 1.1953e-04 - model_3_loss: 0.0025 - model_4_loss: 9.3736e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.2313 - loss2: 9.1749 - val_loss: 11.7620 - val_model_loss: 1.9730 - val_model_1_loss: 2.9381 - val_model_2_loss: 2.0055 - val_model_3_loss: 2.2982 - val_model_4_loss: 2.5472 - val_model_accuracy: 0.6535 - val_model_1_accuracy: 0.4520 - val_model_2_accuracy: 0.5330 - val_model_3_accuracy: 0.7295 - val_model_4_accuracy: 0.5140 - val_loss1: 6.1103 - val_loss2: 8.5243\n","Epoch 297/300\n","1/1 [==============================] - 5s 5s/step - loss: 0.0574 - model_loss: 5.6584e-04 - model_1_loss: 0.0024 - model_2_loss: 0.0379 - model_3_loss: 0.0037 - model_4_loss: 0.0129 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.5134 - loss2: 9.2942 - val_loss: 11.9973 - val_model_loss: 1.9887 - val_model_1_loss: 2.9340 - val_model_2_loss: 1.7645 - val_model_3_loss: 2.6779 - val_model_4_loss: 2.6323 - val_model_accuracy: 0.6370 - val_model_1_accuracy: 0.4325 - val_model_2_accuracy: 0.5400 - val_model_3_accuracy: 0.7255 - val_model_4_accuracy: 0.5385 - val_loss1: 6.2113 - val_loss2: 8.4279\n","Epoch 298/300\n","1/1 [==============================] - 5s 5s/step - loss: 2.2412 - model_loss: 0.0846 - model_1_loss: 1.2306 - model_2_loss: 0.0048 - model_3_loss: 0.1318 - model_4_loss: 0.7895 - model_accuracy: 1.0000 - model_1_accuracy: 0.8333 - model_2_accuracy: 1.0000 - model_3_accuracy: 0.8333 - model_4_accuracy: 0.8333 - loss1: 8.0843 - loss2: 9.0424 - val_loss: 11.8508 - val_model_loss: 1.8823 - val_model_1_loss: 2.8822 - val_model_2_loss: 1.6432 - val_model_3_loss: 2.9079 - val_model_4_loss: 2.5352 - val_model_accuracy: 0.6060 - val_model_1_accuracy: 0.4570 - val_model_2_accuracy: 0.5530 - val_model_3_accuracy: 0.6725 - val_model_4_accuracy: 0.5590 - val_loss1: 6.1420 - val_loss2: 8.3742\n","Epoch 299/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0936 - model_loss: 0.0162 - model_1_loss: 0.0729 - model_2_loss: 5.4991e-04 - model_3_loss: 0.0030 - model_4_loss: 0.0010 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.1150 - loss2: 9.1747 - val_loss: 11.9252 - val_model_loss: 1.8063 - val_model_1_loss: 2.9435 - val_model_2_loss: 1.6190 - val_model_3_loss: 3.1169 - val_model_4_loss: 2.4394 - val_model_accuracy: 0.5920 - val_model_1_accuracy: 0.5010 - val_model_2_accuracy: 0.5710 - val_model_3_accuracy: 0.6350 - val_model_4_accuracy: 0.5625 - val_loss1: 6.0118 - val_loss2: 8.2864\n","Epoch 300/300\n","1/1 [==============================] - 6s 6s/step - loss: 0.0110 - model_loss: 0.0014 - model_1_loss: 0.0076 - model_2_loss: 4.9013e-04 - model_3_loss: 0.0011 - model_4_loss: 3.7904e-04 - model_accuracy: 1.0000 - model_1_accuracy: 1.0000 - model_2_accuracy: 1.0000 - model_3_accuracy: 1.0000 - model_4_accuracy: 1.0000 - loss1: 8.3878 - loss2: 9.2468 - val_loss: 12.1495 - val_model_loss: 1.7570 - val_model_1_loss: 3.0970 - val_model_2_loss: 1.6492 - val_model_3_loss: 3.2915 - val_model_4_loss: 2.3548 - val_model_accuracy: 0.5850 - val_model_1_accuracy: 0.5325 - val_model_2_accuracy: 0.5740 - val_model_3_accuracy: 0.6150 - val_model_4_accuracy: 0.5640 - val_loss1: 5.9676 - val_loss2: 8.1905\n","Epoch 00281: early stopping and save the model\n"]}],"source":["#construct joint training for the five base models\n","input_size = (100, 100, 3)\n","model0 = create_VGGNet(input_shape=input_size, num_classes=2,  random_seed=1)\n","model1 = create_VGGNet(input_shape=input_size, num_classes=2,  random_seed=2)\n","model2 = create_VGGNet(input_shape=input_size, num_classes=2,  random_seed=3)\n","model3 = create_VGGNet(input_shape=input_size, num_classes=2,  random_seed=4)\n","model4 = create_VGGNet(input_shape=input_size, num_classes=2,  random_seed=5)\n","allinputs = keras.Input(shape=input_size)\n","output0, feature_maps0 = model0(allinputs)\n","output1, feature_maps1 = model1(allinputs)\n","output2, feature_maps2 = model2(allinputs)\n","output3, feature_maps3 = model3(allinputs)\n","output4, feature_maps4 = model4(allinputs)\n","model_train = keras.Model(\n","    inputs=allinputs, outputs=[output0, output1, output2, output3, output4])\n","\n","#implement distance loss\n","loss1, loss2, loss = cosine_euclidean_sum_loss(x=[feature_maps0, feature_maps1, feature_maps2, feature_maps3, feature_maps4], \n","                                      cosine_weight=1, euclidean_weight=10, mask=True, max_norm=False)\n","\n","model_train.add_loss(loss)\n","model_train.add_metric(loss1, name=\"loss1\", aggregation='mean')\n","model_train.add_metric(loss2, name=\"loss2\", aggregation='mean')\n","\n","model_train.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","                    loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'],\n","                    metrics=['accuracy'])\n","\n","#construct training and validation samples\n","train_sequence = KGTdata(x_train, y_train, batch_size=10, train=True)\n","validation_sequence = KGTdata(x_val, y_val, batch_size=10, train=False)\n","\n","#training\n","history = model_train.fit(\n","    train_sequence,\n","    epochs=300,\n","    validation_data=validation_sequence,\n","    callbacks=CustomEarlyStoppingAndSave(\n","        save_path='100_samples_seed_fix.h5',\n","        patience=10))\n","frame = pd.DataFrame({\n","    'loss':\n","    history.history['loss'],\n","    'loss1':\n","    history.history['loss1'],\n","    'loss2':\n","    history.history['loss2'],\n","    'model_0_loss':\n","    history.history['model_loss'],\n","    'model_1_loss':\n","    history.history['model_1_loss'],\n","    'model_2_loss':\n","    history.history['model_2_loss'],\n","    'model_3_loss':\n","    history.history['model_3_loss'],\n","    'model_4_loss':\n","    history.history['model_4_loss'],\n","    'model_0_accuracy':\n","    history.history['model_accuracy'],\n","    'model_1_accuracy':\n","    history.history['model_1_accuracy'],\n","    'model_2_accuracy':\n","    history.history['model_2_accuracy'],\n","    'model_3_accuracy':\n","    history.history['model_3_accuracy'],\n","    'model_4_accuracy':\n","    history.history['model_4_accuracy'],\n","    'val_loss':\n","    history.history['val_loss'],\n","    'val_loss1':\n","    history.history['val_loss1'],\n","    'val_loss2':\n","    history.history['val_loss2'],\n","    'val_model_0_loss':\n","    history.history['val_model_loss'],\n","    'val_model_1_loss':\n","    history.history['val_model_1_loss'],\n","    'val_model_2_loss':\n","    history.history['val_model_2_loss'],\n","    'val_model_3_loss':\n","    history.history['val_model_3_loss'],\n","    'val_model_4_loss':\n","    history.history['val_model_4_loss'],\n","    'val_model_0_accuracy':\n","    history.history['val_model_accuracy'],\n","    'val_model_1_accuracy':\n","    history.history['val_model_1_accuracy'],\n","    'val_model_2_accuracy':\n","    history.history['val_model_2_accuracy'],\n","    'val_model_3_accuracy':\n","    history.history['val_model_3_accuracy'],\n","    'val_model_4_accuracy':\n","    history.history['val_model_4_accuracy'],\n","})\n","#frame.to_excel('table_{numsample}_samples_seed_{numseed}.xlsx'.format(numsample=100, numseed='fix'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"D8Q68bw0VAfd","outputId":"4105d574-646f-4983-bbd2-9e2dad43f4a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["408/408 [==============================] - 15s 33ms/step - loss: 7.7294 - model_loss: 1.5233 - model_1_loss: 2.4701 - model_2_loss: 1.1801 - model_3_loss: 0.9089 - model_4_loss: 1.6471 - model_accuracy: 0.6213 - model_1_accuracy: 0.6171 - model_2_accuracy: 0.6483 - model_3_accuracy: 0.6938 - model_4_accuracy: 0.5734 - loss1: 7.1230 - loss2: 9.3095\n"]}],"source":["#evaluation of the five base models\n","evaluate = model_train.evaluate(x_test,[keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test)],batch_size=10)\n","evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"p79zKgdTxTgO","outputId":"c06f2c5e-2187-4f67-dc59-4d5a2c104d65"},"outputs":[{"data":{"text/plain":["0.6414538310412574"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["#soft voting ensemble\n","def SoftVotingEnsemble(model, x, y):\n","  data_size = x.shape[0]\n","  predictions = tf.argmax(tf.reduce_mean(model.predict(x), axis = 0),axis=1)\n","  accuracy = np.sum(\n","     predictions == y) / data_size\n","  return accuracy\n","SoftVotingEnsemble(model_train, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6ML_FZOLCe79"},"outputs":[],"source":["class eCustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(eCustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_accuracy') \n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        #self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rXwnG-CQCfbJ"},"outputs":[],"source":["class eKGTdata(keras.utils.Sequence):\n","    def __init__(self, data_x, data_y, batch_size, train):\n","      self.data_x = data_x\n","      self.data_y = data_y\n","      self.train = train\n","      self.batch_size = batch_size\n","\n","    def __len__(self):\n","      return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","      batch_x = self.data_x[idx * self.batch_size:(idx + 1) * self.batch_size]\n","                            \n","      batch_y = self.data_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n","      if self.train == True:\n","          batch_x = Data_Aug(batch_x)\n","\n","      batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","      batch_y = keras.utils.to_categorical(batch_y, 2)\n","      return batch_x, batch_y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oql4eIoXC5mF","executionInfo":{"status":"ok","timestamp":1650985179595,"user_tz":-120,"elapsed":279976,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"c414c301-5bf3-4010-c137-cb2b08b86fc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1/1 [==============================] - 9s 9s/step - loss: 1.1986 - accuracy: 0.5000 - val_loss: 1.3916 - val_accuracy: 0.4960\n","Epoch 2/50\n","1/1 [==============================] - 5s 5s/step - loss: 1.2623 - accuracy: 0.5000 - val_loss: 1.2374 - val_accuracy: 0.5045\n","Epoch 3/50\n","1/1 [==============================] - 5s 5s/step - loss: 1.1642 - accuracy: 0.5000 - val_loss: 1.1248 - val_accuracy: 0.5190\n","Epoch 4/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.2435 - accuracy: 1.0000 - val_loss: 1.0831 - val_accuracy: 0.5470\n","Epoch 5/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.7891 - accuracy: 0.6667 - val_loss: 1.0917 - val_accuracy: 0.5530\n","Epoch 6/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.3685 - accuracy: 0.8333 - val_loss: 1.1338 - val_accuracy: 0.5670\n","Epoch 7/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.6449 - accuracy: 0.6667 - val_loss: 1.1848 - val_accuracy: 0.5850\n","Epoch 8/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.1845 - accuracy: 0.8333 - val_loss: 1.2377 - val_accuracy: 0.5885\n","Epoch 9/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.4692 - accuracy: 0.8333 - val_loss: 1.2945 - val_accuracy: 0.6030\n","Epoch 10/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.4352 - accuracy: 0.8333 - val_loss: 1.3398 - val_accuracy: 0.6085\n","Epoch 11/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 1.3799 - val_accuracy: 0.6145\n","Epoch 12/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.5111 - accuracy: 0.8333 - val_loss: 1.4165 - val_accuracy: 0.6215\n","Epoch 13/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.4404 - accuracy: 0.8333 - val_loss: 1.4421 - val_accuracy: 0.6260\n","Epoch 14/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.2091 - accuracy: 0.8333 - val_loss: 1.4670 - val_accuracy: 0.6305\n","Epoch 15/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 1.4910 - val_accuracy: 0.6330\n","Epoch 16/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.1886 - accuracy: 0.8333 - val_loss: 1.5112 - val_accuracy: 0.6345\n","Epoch 17/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.1437 - accuracy: 1.0000 - val_loss: 1.5342 - val_accuracy: 0.6360\n","Epoch 18/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.5502 - val_accuracy: 0.6365\n","Epoch 19/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 1.5668 - val_accuracy: 0.6375\n","Epoch 20/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 1.5848 - val_accuracy: 0.6395\n","Epoch 21/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.5973 - val_accuracy: 0.6365\n","Epoch 22/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 1.6080 - val_accuracy: 0.6375\n","Epoch 23/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.1270 - accuracy: 1.0000 - val_loss: 1.6131 - val_accuracy: 0.6380\n","Epoch 24/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.6166 - val_accuracy: 0.6385\n","Epoch 25/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.6174 - val_accuracy: 0.6405\n","Epoch 26/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 1.6241 - val_accuracy: 0.6405\n","Epoch 27/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0965 - accuracy: 1.0000 - val_loss: 1.6289 - val_accuracy: 0.6385\n","Epoch 28/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0921 - accuracy: 1.0000 - val_loss: 1.6297 - val_accuracy: 0.6415\n","Epoch 29/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.6285 - val_accuracy: 0.6400\n","Epoch 30/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 1.6316 - val_accuracy: 0.6415\n","Epoch 31/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.6298 - val_accuracy: 0.6420\n","Epoch 32/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.6267 - val_accuracy: 0.6420\n","Epoch 33/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 1.6218 - val_accuracy: 0.6435\n","Epoch 34/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0792 - accuracy: 1.0000 - val_loss: 1.6228 - val_accuracy: 0.6420\n","Epoch 35/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 1.6200 - val_accuracy: 0.6430\n","Epoch 36/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.6105 - val_accuracy: 0.6435\n","Epoch 37/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.6047 - val_accuracy: 0.6430\n","Epoch 38/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 1.5971 - val_accuracy: 0.6430\n","Epoch 39/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 1.5951 - val_accuracy: 0.6450\n","Epoch 40/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.5907 - val_accuracy: 0.6450\n","Epoch 41/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.5867 - val_accuracy: 0.6455\n","Epoch 42/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 1.5816 - val_accuracy: 0.6470\n","Epoch 43/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5764 - val_accuracy: 0.6470\n","Epoch 44/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.5726 - val_accuracy: 0.6470\n","Epoch 45/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.5715 - val_accuracy: 0.6465\n","Epoch 46/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.5697 - val_accuracy: 0.6465\n","Epoch 47/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.5702 - val_accuracy: 0.6460\n","Epoch 48/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.5619 - val_accuracy: 0.6470\n","Epoch 49/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.5589 - val_accuracy: 0.6480\n","Epoch 50/50\n","1/1 [==============================] - 5s 5s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5555 - val_accuracy: 0.6475\n","Epoch 00049: early stopping and save the model\n","408/408 [==============================] - 12s 27ms/step - loss: 1.4047 - accuracy: 0.6144\n"]}],"source":["#feature fusion model\n","input_size = (100, 100, 3)\n","model_path = '100_samples_seed_fix.h5'\n","model = keras.models.load_model(model_path)\n","extractor_1 = keras.models.Model(inputs=model.layers[1].inputs,outputs=model.layers[1].layers[38].output)\n","extractor_2 = keras.models.Model(inputs=model.layers[2].inputs,outputs=model.layers[2].layers[38].output)\n","extractor_3 = keras.models.Model(inputs=model.layers[3].inputs,outputs=model.layers[3].layers[38].output)\n","extractor_4 = keras.models.Model(inputs=model.layers[4].inputs,outputs=model.layers[4].layers[38].output)\n","extractor_5 = keras.models.Model(inputs=model.layers[5].inputs,outputs=model.layers[5].layers[38].output)\n","extractor_1.trainable = False\n","extractor_2.trainable = False\n","extractor_3.trainable = False\n","extractor_4.trainable = False\n","extractor_5.trainable = False\n","inputs = keras.Input(shape = input_size)\n","features_1 = extractor_1(inputs, training = False)\n","features_2 = extractor_2(inputs, training = False)\n","features_3 = extractor_3(inputs, training = False)\n","features_4 = extractor_4(inputs, training = False)\n","features_5 = extractor_5(inputs, training = False)\n","\n","x = keras.layers.Concatenate(axis=-1)([features_1,features_2,features_3,features_4,features_5])\n","\n","x = keras.layers.Flatten()(x)\n","x = keras.layers.Dense(128,  name='dense_100')(x)\n","x = keras.layers.BatchNormalization()(x)\n","x = keras.layers.Activation('relu')(x)\n","x = keras.layers.Dropout(0.5)(x)\n","outputs = keras.layers.Dense(2, activation='softmax', name='dense_101')(x)\n","ensemble = keras.Model(inputs = inputs, outputs = outputs)\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","train_sequence = eKGTdata(x_train, y_train, batch_size=10, train=True)\n","validation_sequence = eKGTdata(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=50,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FH_Ry7tpC_G_","executionInfo":{"status":"ok","timestamp":1650985300616,"user_tz":-120,"elapsed":121026,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"69288029-5e34-4796-8898-2b36bc427381"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1/1 [==============================] - 11s 11s/step - loss: 0.1317 - accuracy: 0.8333 - val_loss: 1.5843 - val_accuracy: 0.6365\n","Epoch 2/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.6117 - val_accuracy: 0.6265\n","Epoch 3/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 1.6103 - val_accuracy: 0.6190\n","Epoch 4/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6101 - val_accuracy: 0.6135\n","Epoch 5/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.6042 - val_accuracy: 0.6090\n","Epoch 6/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 1.5785 - val_accuracy: 0.6075\n","Epoch 7/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 1.5563 - val_accuracy: 0.6100\n","Epoch 8/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.5351 - val_accuracy: 0.6095\n","Epoch 9/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.5135 - val_accuracy: 0.6120\n","Epoch 10/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.4966 - val_accuracy: 0.6150\n","Epoch 11/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4844 - val_accuracy: 0.6170\n","Epoch 12/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.4777 - val_accuracy: 0.6190\n","Epoch 13/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.1008 - accuracy: 1.0000 - val_loss: 1.4760 - val_accuracy: 0.6305\n","Epoch 14/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 1.4764 - val_accuracy: 0.6375\n","Epoch 15/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.4725 - val_accuracy: 0.6430\n","Epoch 16/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.4661 - val_accuracy: 0.6480\n","Epoch 17/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 1.4662 - val_accuracy: 0.6545\n","Epoch 18/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4698 - val_accuracy: 0.6600\n","Epoch 19/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.4689 - val_accuracy: 0.6665\n","Epoch 20/20\n","1/1 [==============================] - 5s 5s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.4688 - val_accuracy: 0.6710\n","Epoch 00020: early stopping and save the model\n","408/408 [==============================] - 12s 27ms/step - loss: 1.2403 - accuracy: 0.6410\n"]}],"source":["#finetuning\n","extractor_1.trainable = True\n","extractor_2.trainable = True\n","extractor_3.trainable = True\n","extractor_4.trainable = True\n","extractor_5.trainable = True\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","#train_sequence = ecifar10data(sampled_x_train, sampled_y_train, batch_size=10, train=False)\n","#validation_sequence = ecifar10data(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=20,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"y1W3vPZQppO3","executionInfo":{"status":"ok","timestamp":1650985308172,"user_tz":-120,"elapsed":7561,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"a717821a-bcda-4c6a-a908-2fce7a637ccb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'              precision    recall  f1-score   support\\n\\n           0     0.6604    0.6062    0.6321      2072\\n           1     0.6240    0.6770    0.6494      2000\\n\\n    accuracy                         0.6410      4072\\n   macro avg     0.6422    0.6416    0.6408      4072\\nweighted avg     0.6425    0.6410    0.6406      4072\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}],"source":["#f1 score\n","predict = tf.argmax(ensemble.predict(x_test),axis=-1)\n","classification_report(y_test, predict,digits=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uglJj7xnC9Wm"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"BSDVGGEX.ipynb","provenance":[],"mount_file_id":"1bi_1j88kIX6qX9Wn29Ly889FI2FYiS2a","authorship_tag":"ABX9TyP3dLeIkuJjbiVwIH2jvP11"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}