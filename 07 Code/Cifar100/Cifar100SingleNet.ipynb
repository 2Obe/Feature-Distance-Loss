{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Jew0M5MHK1tq"},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","from tensorflow import keras\n","from sklearn import model_selection\n","import imgaug.augmenters as iaa\n","import imgaug as ia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gaUmcnZwK5Z5"},"outputs":[],"source":["ia.seed(1)\n","def Data_Aug(samples):\n","    randomaug = iaa.Sometimes(\n","        0.5,\n","        iaa.OneOf([\n","            iaa.Sequential([\n","                iaa.AllChannelsCLAHE(clip_limit=(1, 10)),\n","                iaa.Affine(rotate=(-5, 5))\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(translate_percent={\n","                    \"x\": (-0.2, 0.2),\n","                    \"y\": (-0.2, 0.2)\n","                }),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(rotate=(-10, 10)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.PerspectiveTransform(scale=(0, 0.15)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ])\n","        ]))\n","\n","\n","    return randomaug.augment_images(samples)\n","\n","def resize_images(imgs, hight, width):\n","    seq = iaa.Resize({\"height\": hight, \"width\": width})\n","    aug = seq.augment_images(imgs)\n","    return aug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RJ3uDY9FgNZ"},"outputs":[],"source":["class cifar100data(keras.utils.Sequence):\n","    '''\n","    generate data batch of cifar10\n","    10 classes\n","    '''\n","    def __init__(self, data_x, data_y, batch_size, train):\n","        self.data_x = data_x\n","        self.data_y = data_y\n","        self.train = train\n","        self.batch_size = batch_size\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","\n","        batch_x = self.data_x[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        batch_y = self.data_y[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        if self.train == True:\n","            batch_x = Data_Aug(batch_x)\n","\n","        batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","        batch_y = keras.utils.to_categorical(np.array(batch_y), 100)\n","        return batch_x, batch_y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unA7GJ9ofGEv"},"outputs":[],"source":["class CustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(CustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_accuracy') \n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QieLj9eTLmZZ"},"outputs":[],"source":["#create single ResNet model\n","def creat_ResNet(input_shape, num_classes=100, num_filters = 64, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x)\n","\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(2*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(4*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  last_acti = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  '''  \n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(8*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  last_acti = keras.layers.MaxPooling2D((2,2))(x) \n","  '''\n","\n","  x = keras.layers.GlobalAveragePooling2D()(last_acti)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  model = keras.Model(inputs=inputs, outputs=[outputs,last_acti])\n","  return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57au-gFlNLBl"},"outputs":[],"source":["def create_AlexNet(input_shape, num_classes=100, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  x = keras.layers.Conv2D(96, (3,3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","  \n","  x = keras.layers.Conv2D(256, (3,3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x) \n","  x = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","  \n","  x = keras.layers.Conv2D(384, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x) \n","  x = keras.layers.Conv2D(384, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x) \n","  x = keras.layers.Conv2D(256, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  feature_maps = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","  x = keras.layers.Flatten()(feature_maps)\n","  #x = keras.layers.Dense(1024,activation='relu')(x)\n","  #x = keras.layers.Dropout(0.5)(x)\n","  x = keras.layers.Dense(512,activation='relu')(x)\n","  x = keras.layers.Dropout(0.5)(x)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n","  model = keras.Model(inputs=inputs, outputs=outputs)\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYABb0H70IEc"},"outputs":[],"source":["def create_VGGNet(input_shape, num_classes=100, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  x = keras.layers.Conv2D(64, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(64, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.2)(x)\n","\n","  x = keras.layers.Conv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.3)(x)\n","\n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.4)(x)\n","\n","\n","    \n","  '''x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.5)(x)'''\n","\n","\n"," \n","  #x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  #x = keras.layers.BatchNormalization()(x)\n","  #x = keras.layers.Activation('relu')(x)\n","  #x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  #x = keras.layers.BatchNormalization()(x)\n","  #x = keras.layers.Activation('relu')(x)\n","  #x = keras.layers.Conv2D(512, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  #x = keras.layers.BatchNormalization()(x)\n","  #x = keras.layers.Activation('relu')(x)\n","  #x = keras.layers.MaxPooling2D((2, 2))(x)\n","  #x = keras.layers.Dropout(0.5)(x) \n"," \n","\n","  #x = keras.layers.GlobalAveragePooling2D()(x)\n","  x = keras.layers.Flatten()(x)\n","  x = keras.layers.Dense(512,  kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Dropout(0.5)(x)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n","  return keras.Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":709},"id":"b4a5P5V5OKw8","outputId":"79b12ee0-e12a-40fb-fe94-10cf60b8c951","executionInfo":{"status":"error","timestamp":1647249677562,"user_tz":-60,"elapsed":214598,"user":{"displayName":"shiro Ma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqFsTeoRso-cMy8IuKSTujNwFXnHJ61j6jonsl=s64","userId":"15301478031333934447"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169009152/169001437 [==============================] - 11s 0us/step\n","169017344/169001437 [==============================] - 11s 0us/step\n","Epoch 1/100\n","1000/1000 [==============================] - 32s 22ms/step - loss: 4.6349 - accuracy: 0.0069 - val_loss: 4.6052 - val_accuracy: 0.0100\n","Epoch 2/100\n","1000/1000 [==============================] - 22s 22ms/step - loss: 4.6067 - accuracy: 0.0065 - val_loss: 4.6052 - val_accuracy: 0.0100\n","Epoch 3/100\n","1000/1000 [==============================] - 22s 22ms/step - loss: 4.6067 - accuracy: 0.0070 - val_loss: 4.6052 - val_accuracy: 0.0100\n","Epoch 4/100\n","1000/1000 [==============================] - 22s 22ms/step - loss: 4.6067 - accuracy: 0.0084 - val_loss: 4.6052 - val_accuracy: 0.0100\n","Epoch 5/100\n","1000/1000 [==============================] - 22s 22ms/step - loss: 4.6067 - accuracy: 0.0074 - val_loss: 4.6052 - val_accuracy: 0.0100\n","Epoch 6/100\n","1000/1000 [==============================] - 22s 22ms/step - loss: 4.6066 - accuracy: 0.0069 - val_loss: 4.6052 - val_accuracy: 0.0100\n","Epoch 7/100\n","1000/1000 [==============================] - 22s 22ms/step - loss: 4.6066 - accuracy: 0.0069 - val_loss: 4.6052 - val_accuracy: 0.0100\n","Epoch 8/100\n"," 164/1000 [===>..........................] - ETA: 17s - loss: 4.6056 - accuracy: 0.0122"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-8e4f21000e6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         save_path='{numsample}_samples_seed_{numseed}.h5'.format(\n\u001b[1;32m     45\u001b[0m             numsample=100, numseed='fix'),\n\u001b[0;32m---> 46\u001b[0;31m         patience=10))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["input_size= (32,32,3)\n","model = create_AlexNet(input_shape=input_size, num_classes=100, random_seed=1)\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                    loss=['categorical_crossentropy'],\n","                    metrics=['accuracy'])\n","\n","(x_origin_train, y_origin_train), (x_test,y_test) = keras.datasets.cifar100.load_data()\n","y_origin_train = y_origin_train.reshape(-1,)\n","y_test = y_test.reshape(-1,)\n","x_test = x_test/255.0\n","\n","x_train, x_val, y_train, y_val = model_selection.train_test_split(\n","    x_origin_train,\n","    y_origin_train,\n","    test_size=10000,\n","    random_state=0,\n","    stratify=y_origin_train)\n","_, x_val, _, y_val = model_selection.train_test_split(\n","    x_val,\n","    y_val,\n","    test_size=2000,\n","    random_state=0,\n","    stratify=y_val)\n","\n","train_index = []\n","random.seed(0)\n","for i in range(100):\n","    train_index += (random.sample(list(np.where(y_train == i)[0]), 100))\n","random.shuffle(train_index)\n","sampled_x_train = x_train[train_index]\n","sampled_y_train = y_train[train_index]\n","del train_index\n","\n","train_sequence = cifar100data(sampled_x_train, sampled_y_train, batch_size=10, train=True)\n","validation_sequence = cifar100data(x_val, y_val, batch_size=10, train=False)\n","\n","history = model.fit(\n","    train_sequence,\n","    epochs=100,\n","    validation_data=validation_sequence,\n","    callbacks=CustomEarlyStoppingAndSave(\n","        save_path='{numsample}_samples_seed_{numseed}.h5'.format(\n","            numsample=100, numseed='fix'),\n","        patience=10))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_LxZ8TyPmMN"},"outputs":[],"source":["evaluate1 = model.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)\n","evaluate1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jawc89TTOjoy"},"outputs":[],"source":["model_train = keras.models.load_model('100_samples_seed_fix.h5')\n","evaluate2 = model_train.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)\n","evaluate2"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Cifar100SingleNet.ipynb","provenance":[],"authorship_tag":"ABX9TyMCYavfP/RNeH3ZjfMrUd/a"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}