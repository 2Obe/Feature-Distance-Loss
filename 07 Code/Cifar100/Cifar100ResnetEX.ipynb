{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"CEyUcTGlE5YL"},"outputs":[],"source":["import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","from tensorflow import keras\n","from sklearn import model_selection\n","from sklearn.metrics import classification_report\n","import imgaug.augmenters as iaa\n","import imgaug as ia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TGGKlSyFBJn"},"outputs":[],"source":["#image augmentation methods\n","ia.seed(1)\n","def Data_Aug(samples):\n","    randomaug = iaa.Sometimes(\n","        0.5,\n","        iaa.OneOf([\n","            iaa.Sequential([\n","                iaa.AllChannelsCLAHE(clip_limit=(1, 10)),\n","                iaa.Affine(rotate=(-5, 5))\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(translate_percent={\n","                    \"x\": (-0.2, 0.2),\n","                    \"y\": (-0.2, 0.2)\n","                }),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(rotate=(-10, 10)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.PerspectiveTransform(scale=(0, 0.15)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ])\n","        ]))\n","\n","\n","    return randomaug.augment_images(samples)\n","\n","def resize_images(imgs, hight, width):\n","    seq = iaa.Resize({\"height\": hight, \"width\": width})\n","    aug = seq.augment_images(imgs)\n","    return aug"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RJ3uDY9FgNZ"},"outputs":[],"source":["class cifar100data(keras.utils.Sequence):\n","    '''\n","    generate data batch of cifar10\n","    10 classes\n","    '''\n","    def __init__(self, data_x, data_y, batch_size, train):\n","        self.data_x = data_x\n","        self.data_y = data_y\n","        self.train = train\n","        self.batch_size = batch_size\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","\n","        batch_x = self.data_x[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        batch_y = self.data_y[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        if self.train == True:\n","            batch_x = Data_Aug(batch_x)\n","\n","        batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","        batch_y = keras.utils.to_categorical(np.array(batch_y), 100)\n","        return batch_x, [batch_y, batch_y, batch_y, batch_y, batch_y]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4U_n_3bce9u4"},"outputs":[],"source":["#callback for saving best model\n","class CustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(CustomEarlyStoppingAndSave, self).__init__()\n","        self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_model_accuracy') + logs.get(\n","            'val_model_1_accuracy') + logs.get(\n","                'val_model_2_accuracy') + logs.get(\n","                    'val_model_3_accuracy') + logs.get('val_model_4_accuracy')\n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch > 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1BPrwTrBVE2"},"outputs":[],"source":["#Cosine&Euclidean distance loss\n","def descriptor(X, mask = False, max_norm = False):\n","  X = tf.reduce_mean(X, axis=-1)\n","  if mask:\n","    mean_X = tf.reduce_mean(X, axis = [1,2], keepdims= True)\n","    X = tf.where(X > mean_X, X , tf.zeros_like(X, dtype=tf.float32))\n","  if max_norm:\n","    max_X = tf.reduce_max(X, axis = [1,2], keepdims= True)\n","    X = tf.math.divide_no_nan(X, max_X)\n","  return X \n","  \n","def compute_euclidean_sum(X, Y):\n","  L2_distance = tf.reduce_mean(tf.exp(-(X - Y)**2), axis= [1,2])\n","  return tf.reduce_mean(L2_distance)\n","\n","def compute_cosine_sum(X, Y):\n","  X = tf.reshape(X, [tf.shape(X)[0], -1])\n","  Y = tf.reshape(Y, [tf.shape(Y)[0], -1])\n","  loss = -keras.losses.cosine_similarity(X,Y,axis=-1)\n","  return tf.reduce_mean(loss)\n","\n","def cosine_euclidean_sum_loss(x, cosine_weight, euclidean_weight, mask, max_norm):\n","  descriptor0 = descriptor(x[0], mask=mask, max_norm=max_norm)\n","  descriptor1 = descriptor(x[1], mask=mask, max_norm=max_norm)\n","  descriptor2 = descriptor(x[2], mask=mask, max_norm=max_norm)\n","  descriptor3 = descriptor(x[3], mask=mask, max_norm=max_norm)\n","  descriptor4 = descriptor(x[4], mask=mask, max_norm=max_norm)\n","  cosine_sum = compute_cosine_sum(descriptor0, descriptor1)+compute_cosine_sum(descriptor0, descriptor2)+compute_cosine_sum(descriptor0, descriptor3)+compute_cosine_sum(descriptor0, descriptor4)+compute_cosine_sum(descriptor1, descriptor2)+compute_cosine_sum(descriptor1, descriptor3)+compute_cosine_sum(descriptor1, descriptor4)+compute_cosine_sum(descriptor2, descriptor3)+compute_cosine_sum(descriptor2, descriptor4)+compute_cosine_sum(descriptor3, descriptor4)\n","  euclidean_sum = compute_euclidean_sum(descriptor0, descriptor1)+compute_euclidean_sum(descriptor0, descriptor2)+compute_euclidean_sum(descriptor0, descriptor3)+compute_euclidean_sum(descriptor0, descriptor4)+compute_euclidean_sum(descriptor1, descriptor2)+compute_euclidean_sum(descriptor1, descriptor3)+compute_euclidean_sum(descriptor1, descriptor4)+compute_euclidean_sum(descriptor2, descriptor3)+compute_euclidean_sum(descriptor2, descriptor4)+compute_euclidean_sum(descriptor3, descriptor4)\n","  return cosine_sum, euclidean_sum, cosine_weight*cosine_sum+euclidean_weight*euclidean_sum  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZMRptakCHOr_"},"outputs":[],"source":["#create single ResNet model\n","def creat_ResNet(input_shape, num_classes=100, num_filters = 64, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x)\n","\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(2*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(4*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  last_acti = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  '''  \n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(8*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  last_acti = keras.layers.MaxPooling2D((2,2))(x) \n","  '''\n","\n","  x = keras.layers.GlobalAveragePooling2D()(last_acti)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  model = keras.Model(inputs=inputs, outputs=[outputs,last_acti])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nf634qPVt_Mq","outputId":"17073188-80aa-49b6-ca04-86a74042cb9a","executionInfo":{"status":"ok","timestamp":1650056329305,"user_tz":-120,"elapsed":1444825,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/300\n","30/30 [==============================] - 28s 211ms/step - loss: 83.9790 - model_loss: 5.9373 - model_1_loss: 6.2301 - model_2_loss: 6.2126 - model_3_loss: 6.1664 - model_4_loss: 6.3492 - model_accuracy: 0.0033 - model_1_accuracy: 0.0000e+00 - model_2_accuracy: 0.0033 - model_3_accuracy: 0.0167 - model_4_accuracy: 0.0033 - loss1: 2.9638 - loss2: 5.0120 - val_loss: 99.8942 - val_model_loss: 6.8230 - val_model_1_loss: 6.1913 - val_model_2_loss: 15.0424 - val_model_3_loss: 5.0919 - val_model_4_loss: 23.3291 - val_model_accuracy: 0.0150 - val_model_1_accuracy: 0.0110 - val_model_2_accuracy: 0.0100 - val_model_3_accuracy: 0.0115 - val_model_4_accuracy: 0.0100 - val_loss1: 2.1869 - val_loss2: 4.1230\n","Epoch 2/300\n","30/30 [==============================] - 4s 143ms/step - loss: 69.1531 - model_loss: 4.5995 - model_1_loss: 4.7017 - model_2_loss: 4.6248 - model_3_loss: 4.6901 - model_4_loss: 4.7299 - model_accuracy: 0.0300 - model_1_accuracy: 0.0200 - model_2_accuracy: 0.0500 - model_3_accuracy: 0.0267 - model_4_accuracy: 0.0267 - loss1: 2.0429 - loss2: 4.3764 - val_loss: 77.0018 - val_model_loss: 6.3618 - val_model_1_loss: 5.2042 - val_model_2_loss: 7.1215 - val_model_3_loss: 4.7348 - val_model_4_loss: 6.0204 - val_model_accuracy: 0.0150 - val_model_1_accuracy: 0.0180 - val_model_2_accuracy: 0.0095 - val_model_3_accuracy: 0.0200 - val_model_4_accuracy: 0.0140 - val_loss1: 1.5188 - val_loss2: 4.6040\n","Epoch 3/300\n","30/30 [==============================] - 4s 150ms/step - loss: 65.4985 - model_loss: 4.3283 - model_1_loss: 4.2351 - model_2_loss: 4.1992 - model_3_loss: 4.3432 - model_4_loss: 4.1520 - model_accuracy: 0.0567 - model_1_accuracy: 0.0467 - model_2_accuracy: 0.0700 - model_3_accuracy: 0.0400 - model_4_accuracy: 0.0600 - loss1: 1.9635 - loss2: 4.2277 - val_loss: 76.2802 - val_model_loss: 5.3870 - val_model_1_loss: 5.2337 - val_model_2_loss: 5.1988 - val_model_3_loss: 4.6430 - val_model_4_loss: 5.2110 - val_model_accuracy: 0.0190 - val_model_1_accuracy: 0.0175 - val_model_2_accuracy: 0.0170 - val_model_3_accuracy: 0.0310 - val_model_4_accuracy: 0.0255 - val_loss1: 1.4929 - val_loss2: 4.9114\n","Epoch 4/300\n","30/30 [==============================] - 4s 147ms/step - loss: 64.3288 - model_loss: 4.1779 - model_1_loss: 4.0618 - model_2_loss: 4.0398 - model_3_loss: 4.2466 - model_4_loss: 3.9693 - model_accuracy: 0.0567 - model_1_accuracy: 0.0867 - model_2_accuracy: 0.0667 - model_3_accuracy: 0.0567 - model_4_accuracy: 0.0833 - loss1: 1.8841 - loss2: 4.1949 - val_loss: 72.2404 - val_model_loss: 4.8055 - val_model_1_loss: 5.0460 - val_model_2_loss: 5.1317 - val_model_3_loss: 4.5697 - val_model_4_loss: 5.2190 - val_model_accuracy: 0.0245 - val_model_1_accuracy: 0.0195 - val_model_2_accuracy: 0.0260 - val_model_3_accuracy: 0.0300 - val_model_4_accuracy: 0.0355 - val_loss1: 1.6410 - val_loss2: 4.5827\n","Epoch 5/300\n","30/30 [==============================] - 4s 144ms/step - loss: 62.4391 - model_loss: 4.0206 - model_1_loss: 3.8302 - model_2_loss: 3.7861 - model_3_loss: 4.0362 - model_4_loss: 3.6381 - model_accuracy: 0.0833 - model_1_accuracy: 0.1200 - model_2_accuracy: 0.1100 - model_3_accuracy: 0.0900 - model_4_accuracy: 0.1667 - loss1: 1.8684 - loss2: 4.1260 - val_loss: 70.3859 - val_model_loss: 5.1110 - val_model_1_loss: 4.8731 - val_model_2_loss: 4.9639 - val_model_3_loss: 4.6671 - val_model_4_loss: 5.3342 - val_model_accuracy: 0.0340 - val_model_1_accuracy: 0.0310 - val_model_2_accuracy: 0.0260 - val_model_3_accuracy: 0.0305 - val_model_4_accuracy: 0.0185 - val_loss1: 1.7919 - val_loss2: 4.3645\n","Epoch 6/300\n","30/30 [==============================] - 4s 146ms/step - loss: 60.3769 - model_loss: 3.6480 - model_1_loss: 3.4540 - model_2_loss: 3.3304 - model_3_loss: 3.7477 - model_4_loss: 3.2766 - model_accuracy: 0.1300 - model_1_accuracy: 0.2000 - model_2_accuracy: 0.2100 - model_3_accuracy: 0.1133 - model_4_accuracy: 0.2367 - loss1: 1.8097 - loss2: 4.1111 - val_loss: 70.3027 - val_model_loss: 5.0732 - val_model_1_loss: 4.8247 - val_model_2_loss: 5.0746 - val_model_3_loss: 4.7787 - val_model_4_loss: 5.6974 - val_model_accuracy: 0.0385 - val_model_1_accuracy: 0.0390 - val_model_2_accuracy: 0.0275 - val_model_3_accuracy: 0.0325 - val_model_4_accuracy: 0.0170 - val_loss1: 1.7170 - val_loss2: 4.3137\n","Epoch 7/300\n","30/30 [==============================] - 5s 155ms/step - loss: 58.9386 - model_loss: 3.5015 - model_1_loss: 3.1405 - model_2_loss: 3.0444 - model_3_loss: 3.5892 - model_4_loss: 2.9154 - model_accuracy: 0.1500 - model_1_accuracy: 0.2533 - model_2_accuracy: 0.2633 - model_3_accuracy: 0.1667 - model_4_accuracy: 0.3067 - loss1: 1.7802 - loss2: 4.0967 - val_loss: 69.4690 - val_model_loss: 5.2904 - val_model_1_loss: 4.9958 - val_model_2_loss: 4.9249 - val_model_3_loss: 4.8346 - val_model_4_loss: 5.3305 - val_model_accuracy: 0.0365 - val_model_1_accuracy: 0.0355 - val_model_2_accuracy: 0.0395 - val_model_3_accuracy: 0.0350 - val_model_4_accuracy: 0.0290 - val_loss1: 1.6719 - val_loss2: 4.2421\n","Epoch 8/300\n","30/30 [==============================] - 4s 150ms/step - loss: 58.5079 - model_loss: 3.3697 - model_1_loss: 2.9899 - model_2_loss: 2.9679 - model_3_loss: 3.4293 - model_4_loss: 2.8199 - model_accuracy: 0.1667 - model_1_accuracy: 0.2700 - model_2_accuracy: 0.2900 - model_3_accuracy: 0.1767 - model_4_accuracy: 0.3367 - loss1: 1.7243 - loss2: 4.1207 - val_loss: 70.4547 - val_model_loss: 5.4728 - val_model_1_loss: 4.9430 - val_model_2_loss: 5.1123 - val_model_3_loss: 4.9308 - val_model_4_loss: 5.0097 - val_model_accuracy: 0.0400 - val_model_1_accuracy: 0.0515 - val_model_2_accuracy: 0.0445 - val_model_3_accuracy: 0.0415 - val_model_4_accuracy: 0.0470 - val_loss1: 1.6613 - val_loss2: 4.3325\n","Epoch 9/300\n","30/30 [==============================] - 4s 145ms/step - loss: 56.3111 - model_loss: 3.0778 - model_1_loss: 2.6369 - model_2_loss: 2.6051 - model_3_loss: 3.1594 - model_4_loss: 2.3780 - model_accuracy: 0.2267 - model_1_accuracy: 0.3533 - model_2_accuracy: 0.3500 - model_3_accuracy: 0.2200 - model_4_accuracy: 0.4400 - loss1: 1.7714 - loss2: 4.0682 - val_loss: 70.4217 - val_model_loss: 5.5031 - val_model_1_loss: 4.9382 - val_model_2_loss: 5.2327 - val_model_3_loss: 4.9180 - val_model_4_loss: 5.4629 - val_model_accuracy: 0.0455 - val_model_1_accuracy: 0.0415 - val_model_2_accuracy: 0.0390 - val_model_3_accuracy: 0.0525 - val_model_4_accuracy: 0.0315 - val_loss1: 1.7005 - val_loss2: 4.2666\n","Epoch 10/300\n","30/30 [==============================] - 5s 155ms/step - loss: 55.9249 - model_loss: 3.0007 - model_1_loss: 2.5612 - model_2_loss: 2.6256 - model_3_loss: 3.1706 - model_4_loss: 2.3707 - model_accuracy: 0.2500 - model_1_accuracy: 0.3600 - model_2_accuracy: 0.3667 - model_3_accuracy: 0.2233 - model_4_accuracy: 0.4667 - loss1: 1.7604 - loss2: 4.0436 - val_loss: 69.5726 - val_model_loss: 5.5212 - val_model_1_loss: 5.2496 - val_model_2_loss: 5.1587 - val_model_3_loss: 5.2539 - val_model_4_loss: 5.5249 - val_model_accuracy: 0.0530 - val_model_1_accuracy: 0.0555 - val_model_2_accuracy: 0.0395 - val_model_3_accuracy: 0.0495 - val_model_4_accuracy: 0.0505 - val_loss1: 1.6576 - val_loss2: 4.1207\n","Epoch 11/300\n","30/30 [==============================] - 4s 147ms/step - loss: 54.7915 - model_loss: 2.8096 - model_1_loss: 2.3847 - model_2_loss: 2.3638 - model_3_loss: 2.9408 - model_4_loss: 2.2336 - model_accuracy: 0.3033 - model_1_accuracy: 0.4233 - model_2_accuracy: 0.4233 - model_3_accuracy: 0.2300 - model_4_accuracy: 0.4700 - loss1: 1.7627 - loss2: 4.0296 - val_loss: 70.7669 - val_model_loss: 6.2677 - val_model_1_loss: 5.0626 - val_model_2_loss: 5.0440 - val_model_3_loss: 5.7342 - val_model_4_loss: 5.3406 - val_model_accuracy: 0.0370 - val_model_1_accuracy: 0.0605 - val_model_2_accuracy: 0.0475 - val_model_3_accuracy: 0.0545 - val_model_4_accuracy: 0.0595 - val_loss1: 1.7254 - val_loss2: 4.1592\n","Epoch 12/300\n","30/30 [==============================] - 4s 147ms/step - loss: 53.5942 - model_loss: 2.7268 - model_1_loss: 2.0884 - model_2_loss: 2.1174 - model_3_loss: 2.8243 - model_4_loss: 1.9178 - model_accuracy: 0.2967 - model_1_accuracy: 0.5167 - model_2_accuracy: 0.5100 - model_3_accuracy: 0.2533 - model_4_accuracy: 0.5467 - loss1: 1.7498 - loss2: 4.0170 - val_loss: 69.7942 - val_model_loss: 5.6339 - val_model_1_loss: 5.0121 - val_model_2_loss: 5.3507 - val_model_3_loss: 5.4863 - val_model_4_loss: 5.7271 - val_model_accuracy: 0.0445 - val_model_1_accuracy: 0.0600 - val_model_2_accuracy: 0.0630 - val_model_3_accuracy: 0.0515 - val_model_4_accuracy: 0.0445 - val_loss1: 1.7469 - val_loss2: 4.0837\n","Epoch 13/300\n","30/30 [==============================] - 4s 147ms/step - loss: 51.3650 - model_loss: 2.2582 - model_1_loss: 1.7175 - model_2_loss: 1.7935 - model_3_loss: 2.4423 - model_4_loss: 1.5311 - model_accuracy: 0.4333 - model_1_accuracy: 0.6433 - model_2_accuracy: 0.6167 - model_3_accuracy: 0.4100 - model_4_accuracy: 0.6800 - loss1: 1.7978 - loss2: 3.9825 - val_loss: 68.7352 - val_model_loss: 5.3537 - val_model_1_loss: 5.0521 - val_model_2_loss: 4.9992 - val_model_3_loss: 5.0447 - val_model_4_loss: 5.0001 - val_model_accuracy: 0.0675 - val_model_1_accuracy: 0.0580 - val_model_2_accuracy: 0.0505 - val_model_3_accuracy: 0.0665 - val_model_4_accuracy: 0.0655 - val_loss1: 1.7375 - val_loss2: 4.1548\n","Epoch 14/300\n","30/30 [==============================] - 4s 150ms/step - loss: 50.6376 - model_loss: 2.0513 - model_1_loss: 1.6162 - model_2_loss: 1.6676 - model_3_loss: 2.2247 - model_4_loss: 1.4103 - model_accuracy: 0.5133 - model_1_accuracy: 0.6200 - model_2_accuracy: 0.6133 - model_3_accuracy: 0.4533 - model_4_accuracy: 0.7033 - loss1: 1.7817 - loss2: 3.9886 - val_loss: 68.9152 - val_model_loss: 5.4022 - val_model_1_loss: 4.9902 - val_model_2_loss: 5.1071 - val_model_3_loss: 5.2881 - val_model_4_loss: 5.0539 - val_model_accuracy: 0.0600 - val_model_1_accuracy: 0.0685 - val_model_2_accuracy: 0.0730 - val_model_3_accuracy: 0.0635 - val_model_4_accuracy: 0.0600 - val_loss1: 1.6712 - val_loss2: 4.1402\n","Epoch 15/300\n","30/30 [==============================] - 4s 144ms/step - loss: 50.1801 - model_loss: 1.9362 - model_1_loss: 1.5271 - model_2_loss: 1.5714 - model_3_loss: 2.1474 - model_4_loss: 1.4657 - model_accuracy: 0.5333 - model_1_accuracy: 0.6767 - model_2_accuracy: 0.6633 - model_3_accuracy: 0.4667 - model_4_accuracy: 0.6700 - loss1: 1.7917 - loss2: 3.9741 - val_loss: 69.9625 - val_model_loss: 5.4273 - val_model_1_loss: 5.3171 - val_model_2_loss: 5.2971 - val_model_3_loss: 5.5995 - val_model_4_loss: 5.3402 - val_model_accuracy: 0.0695 - val_model_1_accuracy: 0.0590 - val_model_2_accuracy: 0.0545 - val_model_3_accuracy: 0.0600 - val_model_4_accuracy: 0.0710 - val_loss1: 1.7219 - val_loss2: 4.1259\n","Epoch 16/300\n","30/30 [==============================] - 4s 151ms/step - loss: 49.9335 - model_loss: 1.8436 - model_1_loss: 1.5270 - model_2_loss: 1.5239 - model_3_loss: 2.0201 - model_4_loss: 1.3572 - model_accuracy: 0.5233 - model_1_accuracy: 0.6500 - model_2_accuracy: 0.6733 - model_3_accuracy: 0.4967 - model_4_accuracy: 0.6933 - loss1: 1.7567 - loss2: 3.9905 - val_loss: 69.8475 - val_model_loss: 5.9203 - val_model_1_loss: 5.3258 - val_model_2_loss: 5.1820 - val_model_3_loss: 5.8119 - val_model_4_loss: 5.4744 - val_model_accuracy: 0.0560 - val_model_1_accuracy: 0.0650 - val_model_2_accuracy: 0.0550 - val_model_3_accuracy: 0.0620 - val_model_4_accuracy: 0.0630 - val_loss1: 1.7427 - val_loss2: 4.0390\n","Epoch 17/300\n","30/30 [==============================] - 4s 150ms/step - loss: 48.6150 - model_loss: 1.6134 - model_1_loss: 1.2779 - model_2_loss: 1.2682 - model_3_loss: 1.8114 - model_4_loss: 1.1508 - model_accuracy: 0.6333 - model_1_accuracy: 0.7167 - model_2_accuracy: 0.7200 - model_3_accuracy: 0.5700 - model_4_accuracy: 0.7700 - loss1: 1.7755 - loss2: 3.9718 - val_loss: 70.3029 - val_model_loss: 6.0381 - val_model_1_loss: 5.6243 - val_model_2_loss: 5.5887 - val_model_3_loss: 5.3129 - val_model_4_loss: 5.5125 - val_model_accuracy: 0.0570 - val_model_1_accuracy: 0.0740 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0635 - val_model_4_accuracy: 0.0655 - val_loss1: 1.7650 - val_loss2: 4.0461\n","Epoch 18/300\n","30/30 [==============================] - 4s 149ms/step - loss: 47.7412 - model_loss: 1.4587 - model_1_loss: 1.1136 - model_2_loss: 1.1459 - model_3_loss: 1.5238 - model_4_loss: 0.9665 - model_accuracy: 0.6933 - model_1_accuracy: 0.7833 - model_2_accuracy: 0.7733 - model_3_accuracy: 0.6533 - model_4_accuracy: 0.8033 - loss1: 1.7366 - loss2: 3.9796 - val_loss: 69.9081 - val_model_loss: 6.1471 - val_model_1_loss: 5.2716 - val_model_2_loss: 5.3309 - val_model_3_loss: 5.6272 - val_model_4_loss: 5.1928 - val_model_accuracy: 0.0565 - val_model_1_accuracy: 0.0730 - val_model_2_accuracy: 0.0670 - val_model_3_accuracy: 0.0735 - val_model_4_accuracy: 0.0680 - val_loss1: 1.7173 - val_loss2: 4.0621\n","Epoch 19/300\n","30/30 [==============================] - 4s 148ms/step - loss: 47.5651 - model_loss: 1.5065 - model_1_loss: 1.1293 - model_2_loss: 1.1742 - model_3_loss: 1.5786 - model_4_loss: 1.0467 - model_accuracy: 0.6467 - model_1_accuracy: 0.7800 - model_2_accuracy: 0.7467 - model_3_accuracy: 0.6167 - model_4_accuracy: 0.7600 - loss1: 1.7506 - loss2: 3.9379 - val_loss: 71.2978 - val_model_loss: 6.2453 - val_model_1_loss: 5.4477 - val_model_2_loss: 5.4683 - val_model_3_loss: 6.1272 - val_model_4_loss: 5.5346 - val_model_accuracy: 0.0610 - val_model_1_accuracy: 0.0730 - val_model_2_accuracy: 0.0610 - val_model_3_accuracy: 0.0605 - val_model_4_accuracy: 0.0740 - val_loss1: 1.7683 - val_loss2: 4.0706\n","Epoch 20/300\n","30/30 [==============================] - 4s 149ms/step - loss: 47.8752 - model_loss: 1.4267 - model_1_loss: 1.2470 - model_2_loss: 1.1813 - model_3_loss: 1.5343 - model_4_loss: 1.0880 - model_accuracy: 0.6700 - model_1_accuracy: 0.7000 - model_2_accuracy: 0.7567 - model_3_accuracy: 0.6367 - model_4_accuracy: 0.7633 - loss1: 1.7339 - loss2: 3.9664 - val_loss: 71.4580 - val_model_loss: 6.3795 - val_model_1_loss: 5.9257 - val_model_2_loss: 5.8025 - val_model_3_loss: 5.7230 - val_model_4_loss: 5.9240 - val_model_accuracy: 0.0455 - val_model_1_accuracy: 0.0615 - val_model_2_accuracy: 0.0495 - val_model_3_accuracy: 0.0640 - val_model_4_accuracy: 0.0560 - val_loss1: 1.7645 - val_loss2: 3.9939\n","Epoch 21/300\n","30/30 [==============================] - 5s 164ms/step - loss: 46.8580 - model_loss: 1.2237 - model_1_loss: 1.0915 - model_2_loss: 1.1811 - model_3_loss: 1.2631 - model_4_loss: 0.9983 - model_accuracy: 0.7233 - model_1_accuracy: 0.7633 - model_2_accuracy: 0.7533 - model_3_accuracy: 0.6967 - model_4_accuracy: 0.7800 - loss1: 1.7368 - loss2: 3.9364 - val_loss: 70.5838 - val_model_loss: 6.0325 - val_model_1_loss: 5.5187 - val_model_2_loss: 5.8510 - val_model_3_loss: 5.9507 - val_model_4_loss: 5.7141 - val_model_accuracy: 0.0655 - val_model_1_accuracy: 0.0755 - val_model_2_accuracy: 0.0655 - val_model_3_accuracy: 0.0585 - val_model_4_accuracy: 0.0645 - val_loss1: 1.7492 - val_loss2: 3.9768\n","Epoch 22/300\n","30/30 [==============================] - 4s 150ms/step - loss: 46.7446 - model_loss: 1.2127 - model_1_loss: 1.0679 - model_2_loss: 1.1154 - model_3_loss: 1.2831 - model_4_loss: 1.0342 - model_accuracy: 0.7033 - model_1_accuracy: 0.7600 - model_2_accuracy: 0.7200 - model_3_accuracy: 0.7000 - model_4_accuracy: 0.7633 - loss1: 1.7300 - loss2: 3.9301 - val_loss: 72.1153 - val_model_loss: 6.2810 - val_model_1_loss: 5.4738 - val_model_2_loss: 6.1369 - val_model_3_loss: 6.6607 - val_model_4_loss: 5.9341 - val_model_accuracy: 0.0620 - val_model_1_accuracy: 0.0735 - val_model_2_accuracy: 0.0625 - val_model_3_accuracy: 0.0565 - val_model_4_accuracy: 0.0630 - val_loss1: 1.6820 - val_loss2: 3.9947\n","Epoch 23/300\n","30/30 [==============================] - 4s 151ms/step - loss: 45.9281 - model_loss: 1.0027 - model_1_loss: 0.9262 - model_2_loss: 0.9628 - model_3_loss: 1.1819 - model_4_loss: 0.8356 - model_accuracy: 0.7967 - model_1_accuracy: 0.7867 - model_2_accuracy: 0.7667 - model_3_accuracy: 0.7167 - model_4_accuracy: 0.8300 - loss1: 1.7043 - loss2: 3.9315 - val_loss: 71.8596 - val_model_loss: 6.4347 - val_model_1_loss: 5.7072 - val_model_2_loss: 6.0536 - val_model_3_loss: 6.5199 - val_model_4_loss: 5.9683 - val_model_accuracy: 0.0655 - val_model_1_accuracy: 0.0700 - val_model_2_accuracy: 0.0660 - val_model_3_accuracy: 0.0630 - val_model_4_accuracy: 0.0770 - val_loss1: 1.7589 - val_loss2: 3.9417\n","Epoch 24/300\n","30/30 [==============================] - 4s 148ms/step - loss: 45.6374 - model_loss: 0.9300 - model_1_loss: 0.8700 - model_2_loss: 0.8933 - model_3_loss: 1.0284 - model_4_loss: 0.7687 - model_accuracy: 0.7767 - model_1_accuracy: 0.8067 - model_2_accuracy: 0.8133 - model_3_accuracy: 0.7667 - model_4_accuracy: 0.8200 - loss1: 1.7115 - loss2: 3.9435 - val_loss: 71.5655 - val_model_loss: 5.9439 - val_model_1_loss: 5.8332 - val_model_2_loss: 5.5504 - val_model_3_loss: 5.9783 - val_model_4_loss: 5.9364 - val_model_accuracy: 0.0615 - val_model_1_accuracy: 0.0805 - val_model_2_accuracy: 0.0700 - val_model_3_accuracy: 0.0815 - val_model_4_accuracy: 0.0650 - val_loss1: 1.5916 - val_loss2: 4.0732\n","Epoch 25/300\n","30/30 [==============================] - 4s 147ms/step - loss: 45.5311 - model_loss: 0.9079 - model_1_loss: 0.8392 - model_2_loss: 0.8798 - model_3_loss: 1.1444 - model_4_loss: 0.7897 - model_accuracy: 0.8100 - model_1_accuracy: 0.8167 - model_2_accuracy: 0.8100 - model_3_accuracy: 0.7267 - model_4_accuracy: 0.8433 - loss1: 1.6867 - loss2: 3.9284 - val_loss: 72.1135 - val_model_loss: 6.2822 - val_model_1_loss: 5.9037 - val_model_2_loss: 6.2423 - val_model_3_loss: 6.0578 - val_model_4_loss: 6.0993 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0690 - val_model_2_accuracy: 0.0590 - val_model_3_accuracy: 0.0695 - val_model_4_accuracy: 0.0660 - val_loss1: 1.7549 - val_loss2: 3.9773\n","Epoch 26/300\n","30/30 [==============================] - 4s 145ms/step - loss: 45.1733 - model_loss: 0.8741 - model_1_loss: 0.7913 - model_2_loss: 0.8492 - model_3_loss: 0.9729 - model_4_loss: 0.7885 - model_accuracy: 0.8067 - model_1_accuracy: 0.8500 - model_2_accuracy: 0.8033 - model_3_accuracy: 0.7833 - model_4_accuracy: 0.8233 - loss1: 1.6981 - loss2: 3.9199 - val_loss: 72.0606 - val_model_loss: 6.3347 - val_model_1_loss: 6.0797 - val_model_2_loss: 6.0547 - val_model_3_loss: 6.0771 - val_model_4_loss: 6.0191 - val_model_accuracy: 0.0625 - val_model_1_accuracy: 0.0725 - val_model_2_accuracy: 0.0765 - val_model_3_accuracy: 0.0690 - val_model_4_accuracy: 0.0750 - val_loss1: 1.6718 - val_loss2: 3.9824\n","Epoch 27/300\n","30/30 [==============================] - 4s 149ms/step - loss: 45.1984 - model_loss: 0.8657 - model_1_loss: 0.7941 - model_2_loss: 0.7364 - model_3_loss: 0.9951 - model_4_loss: 0.7831 - model_accuracy: 0.8033 - model_1_accuracy: 0.8567 - model_2_accuracy: 0.8133 - model_3_accuracy: 0.7700 - model_4_accuracy: 0.8200 - loss1: 1.6807 - loss2: 3.9343 - val_loss: 73.0786 - val_model_loss: 6.8042 - val_model_1_loss: 6.4800 - val_model_2_loss: 5.6445 - val_model_3_loss: 6.0005 - val_model_4_loss: 6.3815 - val_model_accuracy: 0.0600 - val_model_1_accuracy: 0.0635 - val_model_2_accuracy: 0.0695 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0625 - val_loss1: 1.7129 - val_loss2: 4.0055\n","Epoch 28/300\n","30/30 [==============================] - 4s 148ms/step - loss: 45.0652 - model_loss: 0.9177 - model_1_loss: 0.8132 - model_2_loss: 0.7092 - model_3_loss: 0.9438 - model_4_loss: 0.7032 - model_accuracy: 0.7700 - model_1_accuracy: 0.8067 - model_2_accuracy: 0.8467 - model_3_accuracy: 0.7533 - model_4_accuracy: 0.8200 - loss1: 1.6791 - loss2: 3.9299 - val_loss: 72.2107 - val_model_loss: 6.6721 - val_model_1_loss: 6.3051 - val_model_2_loss: 5.8936 - val_model_3_loss: 6.2123 - val_model_4_loss: 5.6723 - val_model_accuracy: 0.0615 - val_model_1_accuracy: 0.0710 - val_model_2_accuracy: 0.0685 - val_model_3_accuracy: 0.0685 - val_model_4_accuracy: 0.0675 - val_loss1: 1.6766 - val_loss2: 3.9779\n","Epoch 29/300\n","30/30 [==============================] - 4s 149ms/step - loss: 43.6232 - model_loss: 0.6704 - model_1_loss: 0.5602 - model_2_loss: 0.5647 - model_3_loss: 0.7020 - model_4_loss: 0.4888 - model_accuracy: 0.8367 - model_1_accuracy: 0.8833 - model_2_accuracy: 0.8667 - model_3_accuracy: 0.8533 - model_4_accuracy: 0.9133 - loss1: 1.6709 - loss2: 3.8966 - val_loss: 72.5273 - val_model_loss: 6.6762 - val_model_1_loss: 6.0324 - val_model_2_loss: 6.0662 - val_model_3_loss: 6.0943 - val_model_4_loss: 5.9750 - val_model_accuracy: 0.0710 - val_model_1_accuracy: 0.0880 - val_model_2_accuracy: 0.0780 - val_model_3_accuracy: 0.0870 - val_model_4_accuracy: 0.0730 - val_loss1: 1.6323 - val_loss2: 4.0051\n","Epoch 30/300\n","30/30 [==============================] - 4s 145ms/step - loss: 44.4769 - model_loss: 0.6648 - model_1_loss: 0.6250 - model_2_loss: 0.7779 - model_3_loss: 0.6383 - model_4_loss: 0.6241 - model_accuracy: 0.8467 - model_1_accuracy: 0.8667 - model_2_accuracy: 0.7967 - model_3_accuracy: 0.8567 - model_4_accuracy: 0.8367 - loss1: 1.6372 - loss2: 3.9510 - val_loss: 74.2592 - val_model_loss: 7.2427 - val_model_1_loss: 6.4170 - val_model_2_loss: 6.2346 - val_model_3_loss: 6.5661 - val_model_4_loss: 6.3780 - val_model_accuracy: 0.0630 - val_model_1_accuracy: 0.0625 - val_model_2_accuracy: 0.0550 - val_model_3_accuracy: 0.0635 - val_model_4_accuracy: 0.0680 - val_loss1: 1.6753 - val_loss2: 3.9745\n","Epoch 31/300\n","30/30 [==============================] - 4s 148ms/step - loss: 44.6807 - model_loss: 0.7083 - model_1_loss: 0.8444 - model_2_loss: 0.7661 - model_3_loss: 0.8631 - model_4_loss: 0.6461 - model_accuracy: 0.8467 - model_1_accuracy: 0.7833 - model_2_accuracy: 0.7933 - model_3_accuracy: 0.7767 - model_4_accuracy: 0.8667 - loss1: 1.6335 - loss2: 3.9219 - val_loss: 73.1398 - val_model_loss: 6.6156 - val_model_1_loss: 6.2733 - val_model_2_loss: 5.9277 - val_model_3_loss: 6.9628 - val_model_4_loss: 5.8832 - val_model_accuracy: 0.0730 - val_model_1_accuracy: 0.0800 - val_model_2_accuracy: 0.0675 - val_model_3_accuracy: 0.0635 - val_model_4_accuracy: 0.0860 - val_loss1: 1.6230 - val_loss2: 3.9854\n","Epoch 32/300\n","30/30 [==============================] - 4s 147ms/step - loss: 44.1383 - model_loss: 0.5942 - model_1_loss: 0.7603 - model_2_loss: 0.6205 - model_3_loss: 0.7267 - model_4_loss: 0.6346 - model_accuracy: 0.8833 - model_1_accuracy: 0.8200 - model_2_accuracy: 0.8500 - model_3_accuracy: 0.8433 - model_4_accuracy: 0.8467 - loss1: 1.6364 - loss2: 3.9166 - val_loss: 74.0610 - val_model_loss: 6.6564 - val_model_1_loss: 6.3822 - val_model_2_loss: 6.2897 - val_model_3_loss: 6.7170 - val_model_4_loss: 6.6103 - val_model_accuracy: 0.0625 - val_model_1_accuracy: 0.0760 - val_model_2_accuracy: 0.0790 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0675 - val_loss1: 1.5876 - val_loss2: 3.9818\n","Epoch 33/300\n","30/30 [==============================] - 4s 147ms/step - loss: 44.5577 - model_loss: 0.7562 - model_1_loss: 0.7968 - model_2_loss: 0.6778 - model_3_loss: 0.8140 - model_4_loss: 0.6758 - model_accuracy: 0.8067 - model_1_accuracy: 0.7933 - model_2_accuracy: 0.8433 - model_3_accuracy: 0.7800 - model_4_accuracy: 0.8533 - loss1: 1.6272 - loss2: 3.9210 - val_loss: 74.7567 - val_model_loss: 6.9008 - val_model_1_loss: 6.4045 - val_model_2_loss: 6.3533 - val_model_3_loss: 6.8022 - val_model_4_loss: 6.8390 - val_model_accuracy: 0.0655 - val_model_1_accuracy: 0.0680 - val_model_2_accuracy: 0.0575 - val_model_3_accuracy: 0.0660 - val_model_4_accuracy: 0.0600 - val_loss1: 1.6422 - val_loss2: 3.9815\n","Epoch 34/300\n","30/30 [==============================] - 4s 146ms/step - loss: 43.9060 - model_loss: 0.6208 - model_1_loss: 0.5779 - model_2_loss: 0.5638 - model_3_loss: 0.6351 - model_4_loss: 0.5695 - model_accuracy: 0.8600 - model_1_accuracy: 0.8900 - model_2_accuracy: 0.8800 - model_3_accuracy: 0.8633 - model_4_accuracy: 0.8567 - loss1: 1.6133 - loss2: 3.9326 - val_loss: 74.4226 - val_model_loss: 7.0404 - val_model_1_loss: 6.1621 - val_model_2_loss: 6.4313 - val_model_3_loss: 6.5641 - val_model_4_loss: 6.7417 - val_model_accuracy: 0.0660 - val_model_1_accuracy: 0.0695 - val_model_2_accuracy: 0.0735 - val_model_3_accuracy: 0.0740 - val_model_4_accuracy: 0.0660 - val_loss1: 1.6006 - val_loss2: 3.9882\n","Epoch 35/300\n","30/30 [==============================] - 4s 149ms/step - loss: 43.7716 - model_loss: 0.5559 - model_1_loss: 0.6034 - model_2_loss: 0.5902 - model_3_loss: 0.5694 - model_4_loss: 0.5560 - model_accuracy: 0.8833 - model_1_accuracy: 0.8533 - model_2_accuracy: 0.8400 - model_3_accuracy: 0.8867 - model_4_accuracy: 0.8833 - loss1: 1.6028 - loss2: 3.9294 - val_loss: 74.5404 - val_model_loss: 6.7152 - val_model_1_loss: 6.5381 - val_model_2_loss: 6.4521 - val_model_3_loss: 6.6981 - val_model_4_loss: 6.3951 - val_model_accuracy: 0.0630 - val_model_1_accuracy: 0.0670 - val_model_2_accuracy: 0.0635 - val_model_3_accuracy: 0.0710 - val_model_4_accuracy: 0.0735 - val_loss1: 1.6268 - val_loss2: 4.0115\n","Epoch 36/300\n","30/30 [==============================] - 4s 150ms/step - loss: 43.7309 - model_loss: 0.5255 - model_1_loss: 0.6698 - model_2_loss: 0.5601 - model_3_loss: 0.5511 - model_4_loss: 0.6069 - model_accuracy: 0.8867 - model_1_accuracy: 0.8133 - model_2_accuracy: 0.8700 - model_3_accuracy: 0.8767 - model_4_accuracy: 0.8367 - loss1: 1.6012 - loss2: 3.9216 - val_loss: 74.9098 - val_model_loss: 6.6346 - val_model_1_loss: 6.4085 - val_model_2_loss: 6.2457 - val_model_3_loss: 6.9436 - val_model_4_loss: 7.0650 - val_model_accuracy: 0.0680 - val_model_1_accuracy: 0.0795 - val_model_2_accuracy: 0.0845 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0655 - val_loss1: 1.5726 - val_loss2: 4.0040\n","Epoch 37/300\n","30/30 [==============================] - 4s 148ms/step - loss: 44.0106 - model_loss: 0.5515 - model_1_loss: 0.5734 - model_2_loss: 0.5550 - model_3_loss: 0.6261 - model_4_loss: 0.6690 - model_accuracy: 0.8767 - model_1_accuracy: 0.8767 - model_2_accuracy: 0.8733 - model_3_accuracy: 0.8533 - model_4_accuracy: 0.8267 - loss1: 1.5985 - loss2: 3.9437 - val_loss: 73.8460 - val_model_loss: 6.8665 - val_model_1_loss: 6.3922 - val_model_2_loss: 6.3616 - val_model_3_loss: 6.5438 - val_model_4_loss: 6.2773 - val_model_accuracy: 0.0665 - val_model_1_accuracy: 0.0750 - val_model_2_accuracy: 0.0785 - val_model_3_accuracy: 0.0765 - val_model_4_accuracy: 0.0775 - val_loss1: 1.5828 - val_loss2: 3.9822\n","Epoch 38/300\n","30/30 [==============================] - 4s 149ms/step - loss: 43.7728 - model_loss: 0.5386 - model_1_loss: 0.5392 - model_2_loss: 0.6489 - model_3_loss: 0.6019 - model_4_loss: 0.5803 - model_accuracy: 0.8733 - model_1_accuracy: 0.8767 - model_2_accuracy: 0.8433 - model_3_accuracy: 0.8667 - model_4_accuracy: 0.8433 - loss1: 1.5954 - loss2: 3.9268 - val_loss: 75.6395 - val_model_loss: 7.0048 - val_model_1_loss: 6.6392 - val_model_2_loss: 7.1039 - val_model_3_loss: 6.9893 - val_model_4_loss: 6.6185 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0680 - val_model_2_accuracy: 0.0600 - val_model_3_accuracy: 0.0710 - val_model_4_accuracy: 0.0795 - val_loss1: 1.6036 - val_loss2: 3.9680\n","Epoch 39/300\n","30/30 [==============================] - 4s 151ms/step - loss: 43.1467 - model_loss: 0.4085 - model_1_loss: 0.4635 - model_2_loss: 0.5124 - model_3_loss: 0.5488 - model_4_loss: 0.4086 - model_accuracy: 0.9133 - model_1_accuracy: 0.8933 - model_2_accuracy: 0.8833 - model_3_accuracy: 0.8733 - model_4_accuracy: 0.9233 - loss1: 1.5717 - loss2: 3.9233 - val_loss: 74.3445 - val_model_loss: 6.6763 - val_model_1_loss: 6.7498 - val_model_2_loss: 6.3248 - val_model_3_loss: 6.6224 - val_model_4_loss: 6.4018 - val_model_accuracy: 0.0710 - val_model_1_accuracy: 0.0635 - val_model_2_accuracy: 0.0840 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0790 - val_loss1: 1.5167 - val_loss2: 4.0053\n","Epoch 40/300\n","30/30 [==============================] - 4s 149ms/step - loss: 43.6278 - model_loss: 0.5132 - model_1_loss: 0.5767 - model_2_loss: 0.6639 - model_3_loss: 0.6088 - model_4_loss: 0.4595 - model_accuracy: 0.8800 - model_1_accuracy: 0.8800 - model_2_accuracy: 0.8167 - model_3_accuracy: 0.8567 - model_4_accuracy: 0.9033 - loss1: 1.5676 - loss2: 3.9238 - val_loss: 77.5791 - val_model_loss: 7.3763 - val_model_1_loss: 7.1004 - val_model_2_loss: 7.3148 - val_model_3_loss: 7.2272 - val_model_4_loss: 7.5307 - val_model_accuracy: 0.0685 - val_model_1_accuracy: 0.0630 - val_model_2_accuracy: 0.0615 - val_model_3_accuracy: 0.0625 - val_model_4_accuracy: 0.0725 - val_loss1: 1.6146 - val_loss2: 3.9415\n","Epoch 41/300\n","30/30 [==============================] - 4s 150ms/step - loss: 42.9898 - model_loss: 0.3965 - model_1_loss: 0.3749 - model_2_loss: 0.4905 - model_3_loss: 0.4774 - model_4_loss: 0.3621 - model_accuracy: 0.9133 - model_1_accuracy: 0.9367 - model_2_accuracy: 0.8900 - model_3_accuracy: 0.8867 - model_4_accuracy: 0.9133 - loss1: 1.5476 - loss2: 3.9341 - val_loss: 75.8452 - val_model_loss: 7.0795 - val_model_1_loss: 6.4519 - val_model_2_loss: 7.1560 - val_model_3_loss: 6.5845 - val_model_4_loss: 7.0413 - val_model_accuracy: 0.0715 - val_model_1_accuracy: 0.0715 - val_model_2_accuracy: 0.0715 - val_model_3_accuracy: 0.0790 - val_model_4_accuracy: 0.0720 - val_loss1: 1.5413 - val_loss2: 3.9991\n","Epoch 42/300\n","30/30 [==============================] - 4s 150ms/step - loss: 42.7683 - model_loss: 0.3439 - model_1_loss: 0.3317 - model_2_loss: 0.3695 - model_3_loss: 0.4009 - model_4_loss: 0.3155 - model_accuracy: 0.9300 - model_1_accuracy: 0.9367 - model_2_accuracy: 0.9100 - model_3_accuracy: 0.9233 - model_4_accuracy: 0.9300 - loss1: 1.5238 - loss2: 3.9483 - val_loss: 75.1289 - val_model_loss: 7.1060 - val_model_1_loss: 6.4732 - val_model_2_loss: 6.6092 - val_model_3_loss: 6.7963 - val_model_4_loss: 6.3083 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0710 - val_model_2_accuracy: 0.0735 - val_model_3_accuracy: 0.0685 - val_model_4_accuracy: 0.0815 - val_loss1: 1.5154 - val_loss2: 4.0320\n","Epoch 43/300\n","30/30 [==============================] - 4s 151ms/step - loss: 42.9243 - model_loss: 0.4436 - model_1_loss: 0.4194 - model_2_loss: 0.4423 - model_3_loss: 0.4374 - model_4_loss: 0.3848 - model_accuracy: 0.9033 - model_1_accuracy: 0.9267 - model_2_accuracy: 0.9033 - model_3_accuracy: 0.9033 - model_4_accuracy: 0.9067 - loss1: 1.5220 - loss2: 3.9275 - val_loss: 74.7610 - val_model_loss: 6.8760 - val_model_1_loss: 6.2255 - val_model_2_loss: 6.9196 - val_model_3_loss: 7.0385 - val_model_4_loss: 6.4928 - val_model_accuracy: 0.0775 - val_model_1_accuracy: 0.0855 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0785 - val_model_4_accuracy: 0.0700 - val_loss1: 1.5195 - val_loss2: 3.9689\n","Epoch 44/300\n","30/30 [==============================] - 4s 150ms/step - loss: 42.6856 - model_loss: 0.4544 - model_1_loss: 0.3410 - model_2_loss: 0.4051 - model_3_loss: 0.3813 - model_4_loss: 0.2959 - model_accuracy: 0.9067 - model_1_accuracy: 0.9133 - model_2_accuracy: 0.9033 - model_3_accuracy: 0.9167 - model_4_accuracy: 0.9433 - loss1: 1.5188 - loss2: 3.9289 - val_loss: 75.3347 - val_model_loss: 7.4744 - val_model_1_loss: 6.2474 - val_model_2_loss: 6.5312 - val_model_3_loss: 6.9825 - val_model_4_loss: 6.2058 - val_model_accuracy: 0.0645 - val_model_1_accuracy: 0.0825 - val_model_2_accuracy: 0.0620 - val_model_3_accuracy: 0.0660 - val_model_4_accuracy: 0.0685 - val_loss1: 1.4602 - val_loss2: 4.0433\n","Epoch 45/300\n","30/30 [==============================] - 5s 158ms/step - loss: 42.7272 - model_loss: 0.3302 - model_1_loss: 0.3446 - model_2_loss: 0.3659 - model_3_loss: 0.3581 - model_4_loss: 0.3637 - model_accuracy: 0.9300 - model_1_accuracy: 0.9267 - model_2_accuracy: 0.9167 - model_3_accuracy: 0.9300 - model_4_accuracy: 0.9033 - loss1: 1.4929 - loss2: 3.9472 - val_loss: 75.5532 - val_model_loss: 6.9137 - val_model_1_loss: 6.2786 - val_model_2_loss: 7.0650 - val_model_3_loss: 6.9759 - val_model_4_loss: 6.8085 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0755 - val_model_2_accuracy: 0.0655 - val_model_3_accuracy: 0.0700 - val_model_4_accuracy: 0.0800 - val_loss1: 1.5041 - val_loss2: 4.0007\n","Epoch 46/300\n","30/30 [==============================] - 4s 147ms/step - loss: 43.0740 - model_loss: 0.3387 - model_1_loss: 0.4248 - model_2_loss: 0.4063 - model_3_loss: 0.4174 - model_4_loss: 0.3886 - model_accuracy: 0.9067 - model_1_accuracy: 0.8967 - model_2_accuracy: 0.9067 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9200 - loss1: 1.4715 - loss2: 3.9627 - val_loss: 74.9813 - val_model_loss: 7.1647 - val_model_1_loss: 6.2664 - val_model_2_loss: 6.2770 - val_model_3_loss: 6.8925 - val_model_4_loss: 6.4755 - val_model_accuracy: 0.0640 - val_model_1_accuracy: 0.0810 - val_model_2_accuracy: 0.0780 - val_model_3_accuracy: 0.0800 - val_model_4_accuracy: 0.0760 - val_loss1: 1.4483 - val_loss2: 4.0457\n","Epoch 47/300\n","30/30 [==============================] - 4s 146ms/step - loss: 43.6899 - model_loss: 0.4867 - model_1_loss: 0.4656 - model_2_loss: 0.5474 - model_3_loss: 0.5514 - model_4_loss: 0.4897 - model_accuracy: 0.8833 - model_1_accuracy: 0.8700 - model_2_accuracy: 0.8700 - model_3_accuracy: 0.8533 - model_4_accuracy: 0.8767 - loss1: 1.4948 - loss2: 3.9654 - val_loss: 77.1462 - val_model_loss: 7.1837 - val_model_1_loss: 6.8655 - val_model_2_loss: 6.8268 - val_model_3_loss: 7.5438 - val_model_4_loss: 6.9418 - val_model_accuracy: 0.0745 - val_model_1_accuracy: 0.0850 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0595 - val_model_4_accuracy: 0.0705 - val_loss1: 1.5603 - val_loss2: 4.0224\n","Epoch 48/300\n","30/30 [==============================] - 4s 147ms/step - loss: 43.1700 - model_loss: 0.4101 - model_1_loss: 0.3997 - model_2_loss: 0.4376 - model_3_loss: 0.4251 - model_4_loss: 0.3840 - model_accuracy: 0.8733 - model_1_accuracy: 0.9100 - model_2_accuracy: 0.8833 - model_3_accuracy: 0.9067 - model_4_accuracy: 0.9167 - loss1: 1.4910 - loss2: 3.9622 - val_loss: 77.7467 - val_model_loss: 7.4012 - val_model_1_loss: 6.6552 - val_model_2_loss: 6.7732 - val_model_3_loss: 7.4733 - val_model_4_loss: 7.5493 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0745 - val_model_2_accuracy: 0.0725 - val_model_3_accuracy: 0.0560 - val_model_4_accuracy: 0.0570 - val_loss1: 1.4520 - val_loss2: 4.0442\n","Epoch 49/300\n","30/30 [==============================] - 4s 150ms/step - loss: 43.0675 - model_loss: 0.3467 - model_1_loss: 0.4008 - model_2_loss: 0.3489 - model_3_loss: 0.3626 - model_4_loss: 0.4303 - model_accuracy: 0.9167 - model_1_accuracy: 0.9033 - model_2_accuracy: 0.9167 - model_3_accuracy: 0.9067 - model_4_accuracy: 0.8900 - loss1: 1.4538 - loss2: 3.9725 - val_loss: 77.1836 - val_model_loss: 7.2067 - val_model_1_loss: 7.0399 - val_model_2_loss: 6.8504 - val_model_3_loss: 7.3319 - val_model_4_loss: 7.0310 - val_model_accuracy: 0.0675 - val_model_1_accuracy: 0.0690 - val_model_2_accuracy: 0.0695 - val_model_3_accuracy: 0.0765 - val_model_4_accuracy: 0.0855 - val_loss1: 1.4798 - val_loss2: 4.0244\n","Epoch 50/300\n","30/30 [==============================] - 4s 151ms/step - loss: 42.6572 - model_loss: 0.3127 - model_1_loss: 0.3346 - model_2_loss: 0.2801 - model_3_loss: 0.2960 - model_4_loss: 0.2707 - model_accuracy: 0.9200 - model_1_accuracy: 0.9167 - model_2_accuracy: 0.9400 - model_3_accuracy: 0.9267 - model_4_accuracy: 0.9433 - loss1: 1.4542 - loss2: 3.9709 - val_loss: 76.8507 - val_model_loss: 7.1574 - val_model_1_loss: 6.9393 - val_model_2_loss: 6.5106 - val_model_3_loss: 7.1507 - val_model_4_loss: 6.7543 - val_model_accuracy: 0.0790 - val_model_1_accuracy: 0.0755 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0720 - val_model_4_accuracy: 0.0715 - val_loss1: 1.4226 - val_loss2: 4.0916\n","Epoch 51/300\n","30/30 [==============================] - 4s 147ms/step - loss: 42.1975 - model_loss: 0.2464 - model_1_loss: 0.2609 - model_2_loss: 0.2014 - model_3_loss: 0.2045 - model_4_loss: 0.2090 - model_accuracy: 0.9267 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9633 - loss1: 1.4427 - loss2: 3.9633 - val_loss: 75.8414 - val_model_loss: 7.2362 - val_model_1_loss: 6.6985 - val_model_2_loss: 6.3971 - val_model_3_loss: 6.9997 - val_model_4_loss: 6.6125 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0750 - val_model_2_accuracy: 0.0825 - val_model_3_accuracy: 0.0790 - val_model_4_accuracy: 0.0805 - val_loss1: 1.3862 - val_loss2: 4.0511\n","Epoch 52/300\n","30/30 [==============================] - 4s 145ms/step - loss: 42.5080 - model_loss: 0.2431 - model_1_loss: 0.2825 - model_2_loss: 0.2152 - model_3_loss: 0.2209 - model_4_loss: 0.2372 - model_accuracy: 0.9400 - model_1_accuracy: 0.9233 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9400 - loss1: 1.3878 - loss2: 3.9921 - val_loss: 77.5678 - val_model_loss: 7.3132 - val_model_1_loss: 6.8603 - val_model_2_loss: 6.4351 - val_model_3_loss: 7.0950 - val_model_4_loss: 6.9562 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0695 - val_model_2_accuracy: 0.0780 - val_model_3_accuracy: 0.0710 - val_model_4_accuracy: 0.0845 - val_loss1: 1.3200 - val_loss2: 4.1588\n","Epoch 53/300\n","30/30 [==============================] - 4s 150ms/step - loss: 43.4184 - model_loss: 0.3415 - model_1_loss: 0.3773 - model_2_loss: 0.3515 - model_3_loss: 0.2883 - model_4_loss: 0.3184 - model_accuracy: 0.9133 - model_1_accuracy: 0.9067 - model_2_accuracy: 0.9033 - model_3_accuracy: 0.9467 - model_4_accuracy: 0.9267 - loss1: 1.3733 - loss2: 4.0368 - val_loss: 77.8000 - val_model_loss: 7.5531 - val_model_1_loss: 6.9326 - val_model_2_loss: 6.8374 - val_model_3_loss: 6.9185 - val_model_4_loss: 7.1108 - val_model_accuracy: 0.0585 - val_model_1_accuracy: 0.0665 - val_model_2_accuracy: 0.0630 - val_model_3_accuracy: 0.0585 - val_model_4_accuracy: 0.0690 - val_loss1: 1.3763 - val_loss2: 4.1071\n","Epoch 54/300\n","30/30 [==============================] - 4s 147ms/step - loss: 43.3581 - model_loss: 0.3851 - model_1_loss: 0.4403 - model_2_loss: 0.4440 - model_3_loss: 0.3073 - model_4_loss: 0.3467 - model_accuracy: 0.9067 - model_1_accuracy: 0.8767 - model_2_accuracy: 0.8933 - model_3_accuracy: 0.9133 - model_4_accuracy: 0.9100 - loss1: 1.3920 - loss2: 4.0043 - val_loss: 79.0481 - val_model_loss: 7.6914 - val_model_1_loss: 7.0547 - val_model_2_loss: 7.7626 - val_model_3_loss: 7.1157 - val_model_4_loss: 7.3515 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0740 - val_model_2_accuracy: 0.0530 - val_model_3_accuracy: 0.0720 - val_model_4_accuracy: 0.0740 - val_loss1: 1.3855 - val_loss2: 4.0687\n","Epoch 55/300\n","30/30 [==============================] - 4s 148ms/step - loss: 43.4687 - model_loss: 0.3626 - model_1_loss: 0.4017 - model_2_loss: 0.4230 - model_3_loss: 0.2909 - model_4_loss: 0.3175 - model_accuracy: 0.9067 - model_1_accuracy: 0.9167 - model_2_accuracy: 0.8833 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9167 - loss1: 1.3846 - loss2: 4.0289 - val_loss: 81.7827 - val_model_loss: 8.1096 - val_model_1_loss: 7.3309 - val_model_2_loss: 7.3404 - val_model_3_loss: 8.1393 - val_model_4_loss: 7.9405 - val_model_accuracy: 0.0685 - val_model_1_accuracy: 0.0695 - val_model_2_accuracy: 0.0605 - val_model_3_accuracy: 0.0620 - val_model_4_accuracy: 0.0645 - val_loss1: 1.3667 - val_loss2: 4.1555\n","Epoch 56/300\n","30/30 [==============================] - 5s 154ms/step - loss: 43.7005 - model_loss: 0.3764 - model_1_loss: 0.3954 - model_2_loss: 0.4024 - model_3_loss: 0.2899 - model_4_loss: 0.3384 - model_accuracy: 0.9100 - model_1_accuracy: 0.9067 - model_2_accuracy: 0.9167 - model_3_accuracy: 0.9433 - model_4_accuracy: 0.9100 - loss1: 1.3861 - loss2: 4.0512 - val_loss: 79.7227 - val_model_loss: 7.4016 - val_model_1_loss: 7.0237 - val_model_2_loss: 7.4767 - val_model_3_loss: 7.3434 - val_model_4_loss: 8.0573 - val_model_accuracy: 0.0760 - val_model_1_accuracy: 0.0740 - val_model_2_accuracy: 0.0645 - val_model_3_accuracy: 0.0720 - val_model_4_accuracy: 0.0555 - val_loss1: 1.3902 - val_loss2: 4.1030\n","Epoch 57/300\n","30/30 [==============================] - 4s 149ms/step - loss: 43.1244 - model_loss: 0.2998 - model_1_loss: 0.3055 - model_2_loss: 0.3006 - model_3_loss: 0.3970 - model_4_loss: 0.3378 - model_accuracy: 0.9333 - model_1_accuracy: 0.9400 - model_2_accuracy: 0.9300 - model_3_accuracy: 0.8800 - model_4_accuracy: 0.9267 - loss1: 1.3844 - loss2: 4.0099 - val_loss: 77.8001 - val_model_loss: 7.2792 - val_model_1_loss: 6.7819 - val_model_2_loss: 6.8946 - val_model_3_loss: 7.4019 - val_model_4_loss: 7.1440 - val_model_accuracy: 0.0570 - val_model_1_accuracy: 0.0695 - val_model_2_accuracy: 0.0670 - val_model_3_accuracy: 0.0650 - val_model_4_accuracy: 0.0675 - val_loss1: 1.3580 - val_loss2: 4.0940\n","Epoch 58/300\n","30/30 [==============================] - 4s 148ms/step - loss: 43.1863 - model_loss: 0.2148 - model_1_loss: 0.2662 - model_2_loss: 0.3794 - model_3_loss: 0.2298 - model_4_loss: 0.3355 - model_accuracy: 0.9467 - model_1_accuracy: 0.9367 - model_2_accuracy: 0.8867 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9200 - loss1: 1.3768 - loss2: 4.0384 - val_loss: 79.1579 - val_model_loss: 7.8084 - val_model_1_loss: 6.9719 - val_model_2_loss: 6.9605 - val_model_3_loss: 7.4772 - val_model_4_loss: 7.0835 - val_model_accuracy: 0.0650 - val_model_1_accuracy: 0.0850 - val_model_2_accuracy: 0.0780 - val_model_3_accuracy: 0.0700 - val_model_4_accuracy: 0.0755 - val_loss1: 1.3474 - val_loss2: 4.1509\n","Epoch 59/300\n","30/30 [==============================] - 4s 149ms/step - loss: 43.6612 - model_loss: 0.2726 - model_1_loss: 0.3013 - model_2_loss: 0.3749 - model_3_loss: 0.2836 - model_4_loss: 0.2911 - model_accuracy: 0.9400 - model_1_accuracy: 0.9233 - model_2_accuracy: 0.9133 - model_3_accuracy: 0.9433 - model_4_accuracy: 0.9167 - loss1: 1.3510 - loss2: 4.0787 - val_loss: 80.4009 - val_model_loss: 7.5209 - val_model_1_loss: 7.1579 - val_model_2_loss: 7.1615 - val_model_3_loss: 7.6758 - val_model_4_loss: 7.8361 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0690 - val_model_2_accuracy: 0.0675 - val_model_3_accuracy: 0.0640 - val_model_4_accuracy: 0.0695 - val_loss1: 1.2797 - val_loss2: 4.1769\n","Epoch 60/300\n","30/30 [==============================] - 4s 152ms/step - loss: 43.7907 - model_loss: 0.2537 - model_1_loss: 0.4000 - model_2_loss: 0.3844 - model_3_loss: 0.3763 - model_4_loss: 0.2678 - model_accuracy: 0.9433 - model_1_accuracy: 0.9200 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9200 - model_4_accuracy: 0.9367 - loss1: 1.3342 - loss2: 4.0774 - val_loss: 80.9632 - val_model_loss: 8.0961 - val_model_1_loss: 7.3690 - val_model_2_loss: 7.3363 - val_model_3_loss: 7.5164 - val_model_4_loss: 7.2302 - val_model_accuracy: 0.0700 - val_model_1_accuracy: 0.0800 - val_model_2_accuracy: 0.0745 - val_model_3_accuracy: 0.0810 - val_model_4_accuracy: 0.0935 - val_loss1: 1.3126 - val_loss2: 4.2103\n","Epoch 61/300\n","30/30 [==============================] - 4s 148ms/step - loss: 44.2608 - model_loss: 0.3437 - model_1_loss: 0.2982 - model_2_loss: 0.2980 - model_3_loss: 0.3187 - model_4_loss: 0.2568 - model_accuracy: 0.9133 - model_1_accuracy: 0.9400 - model_2_accuracy: 0.9167 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9233 - loss1: 1.2995 - loss2: 4.1446 - val_loss: 81.3142 - val_model_loss: 7.9432 - val_model_1_loss: 7.2657 - val_model_2_loss: 7.1452 - val_model_3_loss: 7.7578 - val_model_4_loss: 7.1957 - val_model_accuracy: 0.0615 - val_model_1_accuracy: 0.0740 - val_model_2_accuracy: 0.0680 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0815 - val_loss1: 1.2190 - val_loss2: 4.2788\n","Epoch 62/300\n","30/30 [==============================] - 4s 147ms/step - loss: 46.0650 - model_loss: 0.2092 - model_1_loss: 0.2976 - model_2_loss: 0.3042 - model_3_loss: 0.2450 - model_4_loss: 0.3070 - model_accuracy: 0.9567 - model_1_accuracy: 0.9233 - model_2_accuracy: 0.9267 - model_3_accuracy: 0.9467 - model_4_accuracy: 0.9133 - loss1: 1.1256 - loss2: 4.3577 - val_loss: 81.8598 - val_model_loss: 7.6235 - val_model_1_loss: 6.9566 - val_model_2_loss: 6.9037 - val_model_3_loss: 7.2842 - val_model_4_loss: 8.0052 - val_model_accuracy: 0.0770 - val_model_1_accuracy: 0.0785 - val_model_2_accuracy: 0.0815 - val_model_3_accuracy: 0.0830 - val_model_4_accuracy: 0.0665 - val_loss1: 1.1713 - val_loss2: 4.3915\n","Epoch 63/300\n","30/30 [==============================] - 5s 154ms/step - loss: 46.0999 - model_loss: 0.2770 - model_1_loss: 0.3350 - model_2_loss: 0.2741 - model_3_loss: 0.2280 - model_4_loss: 0.3384 - model_accuracy: 0.9300 - model_1_accuracy: 0.9100 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9467 - model_4_accuracy: 0.9200 - loss1: 1.1587 - loss2: 4.3489 - val_loss: 82.7777 - val_model_loss: 7.7252 - val_model_1_loss: 7.4103 - val_model_2_loss: 7.4533 - val_model_3_loss: 7.4770 - val_model_4_loss: 7.9100 - val_model_accuracy: 0.0660 - val_model_1_accuracy: 0.0675 - val_model_2_accuracy: 0.0580 - val_model_3_accuracy: 0.0695 - val_model_4_accuracy: 0.0535 - val_loss1: 1.2008 - val_loss2: 4.3601\n","Epoch 64/300\n","30/30 [==============================] - 5s 155ms/step - loss: 44.3780 - model_loss: 0.2130 - model_1_loss: 0.2164 - model_2_loss: 0.2628 - model_3_loss: 0.2623 - model_4_loss: 0.2143 - model_accuracy: 0.9500 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9267 - model_4_accuracy: 0.9567 - loss1: 1.2433 - loss2: 4.1966 - val_loss: 80.1356 - val_model_loss: 7.3499 - val_model_1_loss: 7.4980 - val_model_2_loss: 6.9096 - val_model_3_loss: 7.3835 - val_model_4_loss: 7.3384 - val_model_accuracy: 0.0810 - val_model_1_accuracy: 0.0775 - val_model_2_accuracy: 0.0895 - val_model_3_accuracy: 0.0845 - val_model_4_accuracy: 0.0800 - val_loss1: 1.2347 - val_loss2: 4.2421\n","Epoch 65/300\n","30/30 [==============================] - 4s 150ms/step - loss: 44.3214 - model_loss: 0.2216 - model_1_loss: 0.2862 - model_2_loss: 0.2599 - model_3_loss: 0.3187 - model_4_loss: 0.1998 - model_accuracy: 0.9367 - model_1_accuracy: 0.9367 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9100 - model_4_accuracy: 0.9533 - loss1: 1.2541 - loss2: 4.1781 - val_loss: 79.3932 - val_model_loss: 7.2608 - val_model_1_loss: 7.2153 - val_model_2_loss: 6.7843 - val_model_3_loss: 7.4058 - val_model_4_loss: 7.3455 - val_model_accuracy: 0.0860 - val_model_1_accuracy: 0.0810 - val_model_2_accuracy: 0.0890 - val_model_3_accuracy: 0.0805 - val_model_4_accuracy: 0.0815 - val_loss1: 1.2922 - val_loss2: 4.2089\n","Epoch 66/300\n","30/30 [==============================] - 4s 147ms/step - loss: 45.1044 - model_loss: 0.2013 - model_1_loss: 0.3115 - model_2_loss: 0.2382 - model_3_loss: 0.2804 - model_4_loss: 0.2370 - model_accuracy: 0.9567 - model_1_accuracy: 0.9167 - model_2_accuracy: 0.9400 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9400 - loss1: 1.1829 - loss2: 4.2653 - val_loss: 78.7938 - val_model_loss: 6.8386 - val_model_1_loss: 6.9654 - val_model_2_loss: 6.6193 - val_model_3_loss: 7.4847 - val_model_4_loss: 6.9116 - val_model_accuracy: 0.0790 - val_model_1_accuracy: 0.0735 - val_model_2_accuracy: 0.0830 - val_model_3_accuracy: 0.0810 - val_model_4_accuracy: 0.0865 - val_loss1: 1.2278 - val_loss2: 4.2747\n","Epoch 67/300\n","30/30 [==============================] - 4s 148ms/step - loss: 45.4270 - model_loss: 0.1591 - model_1_loss: 0.3065 - model_2_loss: 0.2448 - model_3_loss: 0.2868 - model_4_loss: 0.2754 - model_accuracy: 0.9667 - model_1_accuracy: 0.9233 - model_2_accuracy: 0.9467 - model_3_accuracy: 0.9133 - model_4_accuracy: 0.9200 - loss1: 1.1660 - loss2: 4.2988 - val_loss: 82.3477 - val_model_loss: 7.2745 - val_model_1_loss: 6.9563 - val_model_2_loss: 6.7394 - val_model_3_loss: 8.0022 - val_model_4_loss: 8.3725 - val_model_accuracy: 0.0760 - val_model_1_accuracy: 0.0840 - val_model_2_accuracy: 0.0795 - val_model_3_accuracy: 0.0750 - val_model_4_accuracy: 0.0620 - val_loss1: 1.1586 - val_loss2: 4.3844\n","Epoch 68/300\n","30/30 [==============================] - 5s 163ms/step - loss: 45.9011 - model_loss: 0.1267 - model_1_loss: 0.2573 - model_2_loss: 0.2619 - model_3_loss: 0.2003 - model_4_loss: 0.2749 - model_accuracy: 0.9733 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9533 - model_4_accuracy: 0.9300 - loss1: 1.1040 - loss2: 4.3676 - val_loss: 83.5074 - val_model_loss: 7.3014 - val_model_1_loss: 7.1220 - val_model_2_loss: 7.0390 - val_model_3_loss: 8.0928 - val_model_4_loss: 7.8714 - val_model_accuracy: 0.0820 - val_model_1_accuracy: 0.0815 - val_model_2_accuracy: 0.0700 - val_model_3_accuracy: 0.0680 - val_model_4_accuracy: 0.0595 - val_loss1: 1.0769 - val_loss2: 4.5004\n","Epoch 69/300\n","30/30 [==============================] - 4s 150ms/step - loss: 45.8974 - model_loss: 0.1867 - model_1_loss: 0.2440 - model_2_loss: 0.2589 - model_3_loss: 0.2866 - model_4_loss: 0.2969 - model_accuracy: 0.9633 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9433 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9133 - loss1: 1.1294 - loss2: 4.3495 - val_loss: 83.2762 - val_model_loss: 7.7876 - val_model_1_loss: 7.3079 - val_model_2_loss: 7.2843 - val_model_3_loss: 8.0302 - val_model_4_loss: 7.7117 - val_model_accuracy: 0.0660 - val_model_1_accuracy: 0.0780 - val_model_2_accuracy: 0.0725 - val_model_3_accuracy: 0.0750 - val_model_4_accuracy: 0.0735 - val_loss1: 1.1072 - val_loss2: 4.4047\n","Epoch 70/300\n","30/30 [==============================] - 4s 152ms/step - loss: 45.9387 - model_loss: 0.2585 - model_1_loss: 0.3161 - model_2_loss: 0.2683 - model_3_loss: 0.4159 - model_4_loss: 0.3097 - model_accuracy: 0.9467 - model_1_accuracy: 0.9300 - model_2_accuracy: 0.9300 - model_3_accuracy: 0.8900 - model_4_accuracy: 0.9333 - loss1: 1.1392 - loss2: 4.3231 - val_loss: 83.4424 - val_model_loss: 7.8825 - val_model_1_loss: 7.6401 - val_model_2_loss: 7.1883 - val_model_3_loss: 7.9475 - val_model_4_loss: 7.9777 - val_model_accuracy: 0.0785 - val_model_1_accuracy: 0.0765 - val_model_2_accuracy: 0.0750 - val_model_3_accuracy: 0.0780 - val_model_4_accuracy: 0.0635 - val_loss1: 1.1856 - val_loss2: 4.3621\n","Epoch 71/300\n","30/30 [==============================] - 4s 151ms/step - loss: 46.3367 - model_loss: 0.2750 - model_1_loss: 0.2507 - model_2_loss: 0.2548 - model_3_loss: 0.3265 - model_4_loss: 0.3197 - model_accuracy: 0.9333 - model_1_accuracy: 0.9400 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.9267 - model_4_accuracy: 0.9233 - loss1: 1.1158 - loss2: 4.3794 - val_loss: 85.9539 - val_model_loss: 8.6870 - val_model_1_loss: 7.7305 - val_model_2_loss: 7.4698 - val_model_3_loss: 8.5956 - val_model_4_loss: 8.1348 - val_model_accuracy: 0.0640 - val_model_1_accuracy: 0.0770 - val_model_2_accuracy: 0.0810 - val_model_3_accuracy: 0.0565 - val_model_4_accuracy: 0.0585 - val_loss1: 1.1078 - val_loss2: 4.4228\n","Epoch 72/300\n","30/30 [==============================] - 4s 152ms/step - loss: 45.7065 - model_loss: 0.2121 - model_1_loss: 0.2061 - model_2_loss: 0.2721 - model_3_loss: 0.2553 - model_4_loss: 0.3004 - model_accuracy: 0.9533 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9267 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9333 - loss1: 1.1217 - loss2: 4.3339 - val_loss: 84.7032 - val_model_loss: 8.2371 - val_model_1_loss: 7.1797 - val_model_2_loss: 7.5732 - val_model_3_loss: 7.6828 - val_model_4_loss: 8.5073 - val_model_accuracy: 0.0625 - val_model_1_accuracy: 0.0815 - val_model_2_accuracy: 0.0685 - val_model_3_accuracy: 0.0740 - val_model_4_accuracy: 0.0565 - val_loss1: 1.0912 - val_loss2: 4.4432\n","Epoch 73/300\n","30/30 [==============================] - 4s 149ms/step - loss: 46.1429 - model_loss: 0.1671 - model_1_loss: 0.2047 - model_2_loss: 0.2667 - model_3_loss: 0.2179 - model_4_loss: 0.2892 - model_accuracy: 0.9533 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9267 - model_3_accuracy: 0.9433 - model_4_accuracy: 0.9467 - loss1: 1.0833 - loss2: 4.3914 - val_loss: 82.9431 - val_model_loss: 7.6984 - val_model_1_loss: 7.0021 - val_model_2_loss: 7.3266 - val_model_3_loss: 7.9083 - val_model_4_loss: 8.0133 - val_model_accuracy: 0.0775 - val_model_1_accuracy: 0.0790 - val_model_2_accuracy: 0.0745 - val_model_3_accuracy: 0.0655 - val_model_4_accuracy: 0.0705 - val_loss1: 1.1185 - val_loss2: 4.3876\n","Epoch 74/300\n","30/30 [==============================] - 4s 150ms/step - loss: 46.0535 - model_loss: 0.1463 - model_1_loss: 0.2472 - model_2_loss: 0.1883 - model_3_loss: 0.1953 - model_4_loss: 0.2308 - model_accuracy: 0.9633 - model_1_accuracy: 0.9300 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9433 - model_4_accuracy: 0.9467 - loss1: 1.0667 - loss2: 4.3979 - val_loss: 82.9090 - val_model_loss: 7.9490 - val_model_1_loss: 7.0719 - val_model_2_loss: 7.2143 - val_model_3_loss: 7.2983 - val_model_4_loss: 7.9662 - val_model_accuracy: 0.0790 - val_model_1_accuracy: 0.0830 - val_model_2_accuracy: 0.0825 - val_model_3_accuracy: 0.0790 - val_model_4_accuracy: 0.0740 - val_loss1: 1.0833 - val_loss2: 4.4326\n","Epoch 75/300\n","30/30 [==============================] - 4s 149ms/step - loss: 46.1734 - model_loss: 0.1370 - model_1_loss: 0.2338 - model_2_loss: 0.2564 - model_3_loss: 0.1446 - model_4_loss: 0.2692 - model_accuracy: 0.9767 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9233 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9333 - loss1: 1.0669 - loss2: 4.4066 - val_loss: 83.3120 - val_model_loss: 7.5757 - val_model_1_loss: 7.3883 - val_model_2_loss: 7.4819 - val_model_3_loss: 7.4669 - val_model_4_loss: 7.7789 - val_model_accuracy: 0.0790 - val_model_1_accuracy: 0.0785 - val_model_2_accuracy: 0.0800 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0660 - val_loss1: 1.0634 - val_loss2: 4.4557\n","Epoch 76/300\n","30/30 [==============================] - 4s 150ms/step - loss: 46.7920 - model_loss: 0.2013 - model_1_loss: 0.2129 - model_2_loss: 0.2028 - model_3_loss: 0.1311 - model_4_loss: 0.2169 - model_accuracy: 0.9400 - model_1_accuracy: 0.9367 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9433 - loss1: 1.0065 - loss2: 4.4821 - val_loss: 84.5153 - val_model_loss: 8.1587 - val_model_1_loss: 7.6022 - val_model_2_loss: 7.4108 - val_model_3_loss: 8.2557 - val_model_4_loss: 8.0567 - val_model_accuracy: 0.0780 - val_model_1_accuracy: 0.0765 - val_model_2_accuracy: 0.0795 - val_model_3_accuracy: 0.0670 - val_model_4_accuracy: 0.0780 - val_loss1: 1.1347 - val_loss2: 4.3897\n","Epoch 77/300\n","30/30 [==============================] - 4s 152ms/step - loss: 46.9819 - model_loss: 0.2777 - model_1_loss: 0.2758 - model_2_loss: 0.2281 - model_3_loss: 0.1562 - model_4_loss: 0.2416 - model_accuracy: 0.9333 - model_1_accuracy: 0.9267 - model_2_accuracy: 0.9500 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9333 - loss1: 1.0027 - loss2: 4.4800 - val_loss: 85.5487 - val_model_loss: 8.9932 - val_model_1_loss: 7.2374 - val_model_2_loss: 7.9718 - val_model_3_loss: 8.0367 - val_model_4_loss: 7.8250 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0850 - val_model_2_accuracy: 0.0790 - val_model_3_accuracy: 0.0820 - val_model_4_accuracy: 0.0855 - val_loss1: 1.1260 - val_loss2: 4.4359\n","Epoch 78/300\n","30/30 [==============================] - 4s 151ms/step - loss: 47.0747 - model_loss: 0.2235 - model_1_loss: 0.2701 - model_2_loss: 0.1813 - model_3_loss: 0.1195 - model_4_loss: 0.3124 - model_accuracy: 0.9467 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9200 - loss1: 1.0091 - loss2: 4.4959 - val_loss: 86.0705 - val_model_loss: 8.3798 - val_model_1_loss: 7.9385 - val_model_2_loss: 7.6251 - val_model_3_loss: 7.9565 - val_model_4_loss: 7.6107 - val_model_accuracy: 0.0735 - val_model_1_accuracy: 0.0820 - val_model_2_accuracy: 0.0675 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0765 - val_loss1: 1.0059 - val_loss2: 4.5554\n","Epoch 79/300\n","30/30 [==============================] - 5s 153ms/step - loss: 46.9391 - model_loss: 0.2182 - model_1_loss: 0.1915 - model_2_loss: 0.2175 - model_3_loss: 0.1613 - model_4_loss: 0.2982 - model_accuracy: 0.9433 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9433 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9133 - loss1: 1.0104 - loss2: 4.4842 - val_loss: 82.7225 - val_model_loss: 8.0479 - val_model_1_loss: 7.0768 - val_model_2_loss: 7.1666 - val_model_3_loss: 7.2170 - val_model_4_loss: 7.9877 - val_model_accuracy: 0.0730 - val_model_1_accuracy: 0.0830 - val_model_2_accuracy: 0.0770 - val_model_3_accuracy: 0.0700 - val_model_4_accuracy: 0.0715 - val_loss1: 1.1243 - val_loss2: 4.4102\n","Epoch 80/300\n","30/30 [==============================] - 5s 153ms/step - loss: 47.0926 - model_loss: 0.1626 - model_1_loss: 0.1883 - model_2_loss: 0.2449 - model_3_loss: 0.1138 - model_4_loss: 0.2163 - model_accuracy: 0.9567 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9433 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9300 - loss1: 0.9875 - loss2: 4.5179 - val_loss: 85.5735 - val_model_loss: 7.9317 - val_model_1_loss: 7.2350 - val_model_2_loss: 7.4698 - val_model_3_loss: 7.6601 - val_model_4_loss: 7.7660 - val_model_accuracy: 0.0775 - val_model_1_accuracy: 0.0795 - val_model_2_accuracy: 0.0695 - val_model_3_accuracy: 0.0640 - val_model_4_accuracy: 0.0760 - val_loss1: 0.9378 - val_loss2: 4.6573\n","Epoch 81/300\n","30/30 [==============================] - 4s 150ms/step - loss: 47.7571 - model_loss: 0.1856 - model_1_loss: 0.1536 - model_2_loss: 0.1885 - model_3_loss: 0.1230 - model_4_loss: 0.1864 - model_accuracy: 0.9533 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9500 - loss1: 0.9372 - loss2: 4.5983 - val_loss: 86.0095 - val_model_loss: 7.7106 - val_model_1_loss: 7.2554 - val_model_2_loss: 7.9900 - val_model_3_loss: 7.6703 - val_model_4_loss: 7.9972 - val_model_accuracy: 0.0835 - val_model_1_accuracy: 0.0775 - val_model_2_accuracy: 0.0720 - val_model_3_accuracy: 0.0830 - val_model_4_accuracy: 0.0835 - val_loss1: 0.9620 - val_loss2: 4.6424\n","Epoch 82/300\n","30/30 [==============================] - 5s 154ms/step - loss: 47.8448 - model_loss: 0.1643 - model_1_loss: 0.1238 - model_2_loss: 0.2357 - model_3_loss: 0.1783 - model_4_loss: 0.2242 - model_accuracy: 0.9667 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9400 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9433 - loss1: 0.9122 - loss2: 4.6006 - val_loss: 85.5162 - val_model_loss: 7.6917 - val_model_1_loss: 7.3301 - val_model_2_loss: 7.5695 - val_model_3_loss: 7.8204 - val_model_4_loss: 7.5936 - val_model_accuracy: 0.0775 - val_model_1_accuracy: 0.0815 - val_model_2_accuracy: 0.0705 - val_model_3_accuracy: 0.0745 - val_model_4_accuracy: 0.0855 - val_loss1: 0.9100 - val_loss2: 4.6601\n","Epoch 83/300\n","30/30 [==============================] - 4s 148ms/step - loss: 48.5347 - model_loss: 0.1163 - model_1_loss: 0.0973 - model_2_loss: 0.1715 - model_3_loss: 0.1367 - model_4_loss: 0.1864 - model_accuracy: 0.9733 - model_1_accuracy: 0.9900 - model_2_accuracy: 0.9467 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9500 - loss1: 0.8578 - loss2: 4.6969 - val_loss: 85.9462 - val_model_loss: 7.9352 - val_model_1_loss: 7.0583 - val_model_2_loss: 7.1562 - val_model_3_loss: 8.0142 - val_model_4_loss: 8.1389 - val_model_accuracy: 0.0770 - val_model_1_accuracy: 0.0875 - val_model_2_accuracy: 0.0905 - val_model_3_accuracy: 0.0850 - val_model_4_accuracy: 0.0720 - val_loss1: 0.9224 - val_loss2: 4.6721\n","Epoch 84/300\n","30/30 [==============================] - 4s 149ms/step - loss: 48.4337 - model_loss: 0.1676 - model_1_loss: 0.1369 - model_2_loss: 0.2576 - model_3_loss: 0.1924 - model_4_loss: 0.2448 - model_accuracy: 0.9633 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9300 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9333 - loss1: 0.8897 - loss2: 4.6545 - val_loss: 85.9931 - val_model_loss: 8.0308 - val_model_1_loss: 7.2651 - val_model_2_loss: 7.6312 - val_model_3_loss: 8.7384 - val_model_4_loss: 7.9400 - val_model_accuracy: 0.0660 - val_model_1_accuracy: 0.0920 - val_model_2_accuracy: 0.0750 - val_model_3_accuracy: 0.0715 - val_model_4_accuracy: 0.0710 - val_loss1: 1.0313 - val_loss2: 4.5356\n","Epoch 85/300\n","30/30 [==============================] - 5s 154ms/step - loss: 47.7572 - model_loss: 0.1214 - model_1_loss: 0.2239 - model_2_loss: 0.2637 - model_3_loss: 0.2254 - model_4_loss: 0.2102 - model_accuracy: 0.9667 - model_1_accuracy: 0.9433 - model_2_accuracy: 0.9167 - model_3_accuracy: 0.9400 - model_4_accuracy: 0.9400 - loss1: 0.9366 - loss2: 4.5776 - val_loss: 85.0320 - val_model_loss: 7.4966 - val_model_1_loss: 7.3087 - val_model_2_loss: 8.3387 - val_model_3_loss: 7.8957 - val_model_4_loss: 7.8480 - val_model_accuracy: 0.0750 - val_model_1_accuracy: 0.0805 - val_model_2_accuracy: 0.0585 - val_model_3_accuracy: 0.0625 - val_model_4_accuracy: 0.0645 - val_loss1: 1.0356 - val_loss2: 4.5109\n","Epoch 86/300\n","30/30 [==============================] - 5s 152ms/step - loss: 47.7006 - model_loss: 0.1304 - model_1_loss: 0.2772 - model_2_loss: 0.2923 - model_3_loss: 0.2284 - model_4_loss: 0.2450 - model_accuracy: 0.9733 - model_1_accuracy: 0.9167 - model_2_accuracy: 0.9200 - model_3_accuracy: 0.9300 - model_4_accuracy: 0.9467 - loss1: 0.9926 - loss2: 4.5535 - val_loss: 86.4062 - val_model_loss: 8.1808 - val_model_1_loss: 7.7205 - val_model_2_loss: 8.8266 - val_model_3_loss: 8.2186 - val_model_4_loss: 8.1213 - val_model_accuracy: 0.0755 - val_model_1_accuracy: 0.0810 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0750 - val_model_4_accuracy: 0.0770 - val_loss1: 1.1577 - val_loss2: 4.4181\n","Epoch 87/300\n","30/30 [==============================] - 5s 153ms/step - loss: 47.7555 - model_loss: 0.2319 - model_1_loss: 0.3026 - model_2_loss: 0.2402 - model_3_loss: 0.2913 - model_4_loss: 0.2326 - model_accuracy: 0.9467 - model_1_accuracy: 0.9133 - model_2_accuracy: 0.9433 - model_3_accuracy: 0.9367 - model_4_accuracy: 0.9300 - loss1: 0.9731 - loss2: 4.5484 - val_loss: 89.3405 - val_model_loss: 8.5781 - val_model_1_loss: 8.6044 - val_model_2_loss: 8.8177 - val_model_3_loss: 8.7586 - val_model_4_loss: 8.8401 - val_model_accuracy: 0.0620 - val_model_1_accuracy: 0.0630 - val_model_2_accuracy: 0.0610 - val_model_3_accuracy: 0.0655 - val_model_4_accuracy: 0.0685 - val_loss1: 1.0936 - val_loss2: 4.4648\n","Epoch 88/300\n","30/30 [==============================] - 5s 154ms/step - loss: 47.5438 - model_loss: 0.2168 - model_1_loss: 0.3145 - model_2_loss: 0.1920 - model_3_loss: 0.3035 - model_4_loss: 0.2444 - model_accuracy: 0.9267 - model_1_accuracy: 0.9167 - model_2_accuracy: 0.9533 - model_3_accuracy: 0.9233 - model_4_accuracy: 0.9400 - loss1: 0.9947 - loss2: 4.5278 - val_loss: 88.0018 - val_model_loss: 8.7978 - val_model_1_loss: 8.7052 - val_model_2_loss: 7.5489 - val_model_3_loss: 8.4976 - val_model_4_loss: 7.6877 - val_model_accuracy: 0.0550 - val_model_1_accuracy: 0.0570 - val_model_2_accuracy: 0.0770 - val_model_3_accuracy: 0.0665 - val_model_4_accuracy: 0.0755 - val_loss1: 1.0001 - val_loss2: 4.5765\n","Epoch 89/300\n","30/30 [==============================] - 5s 155ms/step - loss: 48.8414 - model_loss: 0.3117 - model_1_loss: 0.3770 - model_2_loss: 0.2455 - model_3_loss: 0.2893 - model_4_loss: 0.2016 - model_accuracy: 0.9133 - model_1_accuracy: 0.9167 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.9200 - model_4_accuracy: 0.9467 - loss1: 0.9115 - loss2: 4.6505 - val_loss: 89.7992 - val_model_loss: 8.6873 - val_model_1_loss: 8.4566 - val_model_2_loss: 7.6765 - val_model_3_loss: 8.5796 - val_model_4_loss: 7.7134 - val_model_accuracy: 0.0670 - val_model_1_accuracy: 0.0735 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0740 - val_model_4_accuracy: 0.0700 - val_loss1: 0.9083 - val_loss2: 4.7777\n","Epoch 90/300\n","30/30 [==============================] - 4s 151ms/step - loss: 49.4496 - model_loss: 0.2478 - model_1_loss: 0.2256 - model_2_loss: 0.2949 - model_3_loss: 0.3562 - model_4_loss: 0.2545 - model_accuracy: 0.9333 - model_1_accuracy: 0.9400 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.8933 - model_4_accuracy: 0.9400 - loss1: 0.9007 - loss2: 4.7170 - val_loss: 89.7033 - val_model_loss: 8.5287 - val_model_1_loss: 8.0574 - val_model_2_loss: 7.8970 - val_model_3_loss: 9.0288 - val_model_4_loss: 8.4082 - val_model_accuracy: 0.0795 - val_model_1_accuracy: 0.0790 - val_model_2_accuracy: 0.0690 - val_model_3_accuracy: 0.0705 - val_model_4_accuracy: 0.0790 - val_loss1: 0.9856 - val_loss2: 4.6798\n","Epoch 91/300\n","30/30 [==============================] - 5s 153ms/step - loss: 48.5791 - model_loss: 0.1904 - model_1_loss: 0.2381 - model_2_loss: 0.2756 - model_3_loss: 0.2503 - model_4_loss: 0.2402 - model_accuracy: 0.9467 - model_1_accuracy: 0.9267 - model_2_accuracy: 0.9233 - model_3_accuracy: 0.9167 - model_4_accuracy: 0.9400 - loss1: 0.9295 - loss2: 4.6455 - val_loss: 88.2703 - val_model_loss: 8.3497 - val_model_1_loss: 8.4737 - val_model_2_loss: 7.8922 - val_model_3_loss: 8.2633 - val_model_4_loss: 7.8580 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0795 - val_model_2_accuracy: 0.0705 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0735 - val_loss1: 0.9844 - val_loss2: 4.6449\n","Epoch 92/300\n","30/30 [==============================] - 5s 156ms/step - loss: 48.0666 - model_loss: 0.2420 - model_1_loss: 0.2409 - model_2_loss: 0.3185 - model_3_loss: 0.2897 - model_4_loss: 0.2325 - model_accuracy: 0.9333 - model_1_accuracy: 0.9300 - model_2_accuracy: 0.9200 - model_3_accuracy: 0.9167 - model_4_accuracy: 0.9500 - loss1: 0.9631 - loss2: 4.5780 - val_loss: 89.4558 - val_model_loss: 9.4127 - val_model_1_loss: 8.2847 - val_model_2_loss: 8.7516 - val_model_3_loss: 8.6962 - val_model_4_loss: 7.7523 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0690 - val_model_2_accuracy: 0.0640 - val_model_3_accuracy: 0.0720 - val_model_4_accuracy: 0.0830 - val_loss1: 1.0275 - val_loss2: 4.5531\n","Epoch 93/300\n","30/30 [==============================] - 5s 153ms/step - loss: 48.0644 - model_loss: 0.2194 - model_1_loss: 0.1689 - model_2_loss: 0.2754 - model_3_loss: 0.2396 - model_4_loss: 0.1781 - model_accuracy: 0.9500 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9200 - model_3_accuracy: 0.9467 - model_4_accuracy: 0.9633 - loss1: 0.9642 - loss2: 4.6019 - val_loss: 88.1920 - val_model_loss: 8.6411 - val_model_1_loss: 8.0530 - val_model_2_loss: 8.1776 - val_model_3_loss: 8.5533 - val_model_4_loss: 8.1437 - val_model_accuracy: 0.0615 - val_model_1_accuracy: 0.0870 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0680 - val_model_4_accuracy: 0.0785 - val_loss1: 1.0010 - val_loss2: 4.5622\n","Epoch 94/300\n","30/30 [==============================] - 4s 150ms/step - loss: 47.5613 - model_loss: 0.1556 - model_1_loss: 0.1004 - model_2_loss: 0.1359 - model_3_loss: 0.1641 - model_4_loss: 0.0964 - model_accuracy: 0.9533 - model_1_accuracy: 0.9900 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9467 - model_4_accuracy: 0.9767 - loss1: 0.9269 - loss2: 4.5982 - val_loss: 89.4907 - val_model_loss: 8.5852 - val_model_1_loss: 8.5798 - val_model_2_loss: 8.3497 - val_model_3_loss: 8.1807 - val_model_4_loss: 8.3284 - val_model_accuracy: 0.0665 - val_model_1_accuracy: 0.0740 - val_model_2_accuracy: 0.0655 - val_model_3_accuracy: 0.0740 - val_model_4_accuracy: 0.0815 - val_loss1: 0.9192 - val_loss2: 4.6548\n","Epoch 95/300\n","30/30 [==============================] - 5s 154ms/step - loss: 47.9446 - model_loss: 0.1618 - model_1_loss: 0.2128 - model_2_loss: 0.2022 - model_3_loss: 0.1278 - model_4_loss: 0.1362 - model_accuracy: 0.9500 - model_1_accuracy: 0.9400 - model_2_accuracy: 0.9400 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9667 - loss1: 0.9028 - loss2: 4.6201 - val_loss: 89.0427 - val_model_loss: 8.2582 - val_model_1_loss: 8.3072 - val_model_2_loss: 7.6731 - val_model_3_loss: 7.8990 - val_model_4_loss: 8.3316 - val_model_accuracy: 0.0675 - val_model_1_accuracy: 0.0670 - val_model_2_accuracy: 0.0645 - val_model_3_accuracy: 0.0790 - val_model_4_accuracy: 0.0740 - val_loss1: 0.8655 - val_loss2: 4.7708\n","Epoch 96/300\n","30/30 [==============================] - 5s 153ms/step - loss: 49.8499 - model_loss: 0.2319 - model_1_loss: 0.2189 - model_2_loss: 0.2489 - model_3_loss: 0.1946 - model_4_loss: 0.2614 - model_accuracy: 0.9433 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9533 - model_4_accuracy: 0.9233 - loss1: 0.8106 - loss2: 4.7884 - val_loss: 90.8096 - val_model_loss: 8.7200 - val_model_1_loss: 8.4577 - val_model_2_loss: 8.6613 - val_model_3_loss: 7.7902 - val_model_4_loss: 8.7930 - val_model_accuracy: 0.0520 - val_model_1_accuracy: 0.0645 - val_model_2_accuracy: 0.0695 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0725 - val_loss1: 0.9030 - val_loss2: 4.7485\n","Epoch 97/300\n","30/30 [==============================] - 4s 151ms/step - loss: 49.1989 - model_loss: 0.2209 - model_1_loss: 0.1883 - model_2_loss: 0.3482 - model_3_loss: 0.1670 - model_4_loss: 0.1803 - model_accuracy: 0.9433 - model_1_accuracy: 0.9400 - model_2_accuracy: 0.9000 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9467 - loss1: 0.8494 - loss2: 4.7245 - val_loss: 88.6822 - val_model_loss: 8.7433 - val_model_1_loss: 8.2750 - val_model_2_loss: 7.7696 - val_model_3_loss: 8.4955 - val_model_4_loss: 8.4309 - val_model_accuracy: 0.0680 - val_model_1_accuracy: 0.0745 - val_model_2_accuracy: 0.0770 - val_model_3_accuracy: 0.0680 - val_model_4_accuracy: 0.0830 - val_loss1: 0.9989 - val_loss2: 4.5969\n","Epoch 98/300\n","30/30 [==============================] - 4s 152ms/step - loss: 48.7072 - model_loss: 0.2527 - model_1_loss: 0.2418 - model_2_loss: 0.2487 - model_3_loss: 0.2089 - model_4_loss: 0.2557 - model_accuracy: 0.9367 - model_1_accuracy: 0.9300 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9333 - loss1: 0.9010 - loss2: 4.6598 - val_loss: 87.4273 - val_model_loss: 8.8414 - val_model_1_loss: 7.9270 - val_model_2_loss: 7.7895 - val_model_3_loss: 7.9209 - val_model_4_loss: 8.0799 - val_model_accuracy: 0.0630 - val_model_1_accuracy: 0.0770 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0720 - val_model_4_accuracy: 0.0690 - val_loss1: 1.0100 - val_loss2: 4.5859\n","Epoch 99/300\n","30/30 [==============================] - 4s 151ms/step - loss: 48.8182 - model_loss: 0.2259 - model_1_loss: 0.1574 - model_2_loss: 0.1783 - model_3_loss: 0.1362 - model_4_loss: 0.1516 - model_accuracy: 0.9367 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9733 - loss1: 0.8454 - loss2: 4.7123 - val_loss: 90.2754 - val_model_loss: 9.0025 - val_model_1_loss: 8.0743 - val_model_2_loss: 8.3843 - val_model_3_loss: 8.3564 - val_model_4_loss: 8.3960 - val_model_accuracy: 0.0695 - val_model_1_accuracy: 0.0780 - val_model_2_accuracy: 0.0750 - val_model_3_accuracy: 0.0770 - val_model_4_accuracy: 0.0770 - val_loss1: 0.8674 - val_loss2: 4.7194\n","Epoch 100/300\n","30/30 [==============================] - 5s 152ms/step - loss: 49.9497 - model_loss: 0.1391 - model_1_loss: 0.1620 - model_2_loss: 0.1319 - model_3_loss: 0.1646 - model_4_loss: 0.2056 - model_accuracy: 0.9633 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9467 - model_4_accuracy: 0.9533 - loss1: 0.7553 - loss2: 4.8391 - val_loss: 90.1076 - val_model_loss: 8.8193 - val_model_1_loss: 7.7641 - val_model_2_loss: 8.1451 - val_model_3_loss: 8.3081 - val_model_4_loss: 8.1093 - val_model_accuracy: 0.0810 - val_model_1_accuracy: 0.0665 - val_model_2_accuracy: 0.0810 - val_model_3_accuracy: 0.0630 - val_model_4_accuracy: 0.0775 - val_loss1: 0.8226 - val_loss2: 4.8139\n","Epoch 101/300\n","30/30 [==============================] - 4s 151ms/step - loss: 50.2401 - model_loss: 0.1641 - model_1_loss: 0.2076 - model_2_loss: 0.1492 - model_3_loss: 0.2143 - model_4_loss: 0.1819 - model_accuracy: 0.9633 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9433 - loss1: 0.7395 - loss2: 4.8584 - val_loss: 89.7766 - val_model_loss: 8.7355 - val_model_1_loss: 7.8486 - val_model_2_loss: 7.5579 - val_model_3_loss: 8.7411 - val_model_4_loss: 8.1750 - val_model_accuracy: 0.0695 - val_model_1_accuracy: 0.0695 - val_model_2_accuracy: 0.0850 - val_model_3_accuracy: 0.0745 - val_model_4_accuracy: 0.0800 - val_loss1: 0.8137 - val_loss2: 4.7905\n","Epoch 102/300\n","30/30 [==============================] - 4s 151ms/step - loss: 49.2880 - model_loss: 0.1504 - model_1_loss: 0.1571 - model_2_loss: 0.1382 - model_3_loss: 0.1762 - model_4_loss: 0.1918 - model_accuracy: 0.9600 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9433 - loss1: 0.8123 - loss2: 4.7662 - val_loss: 89.8743 - val_model_loss: 8.8806 - val_model_1_loss: 7.7801 - val_model_2_loss: 7.5178 - val_model_3_loss: 8.2708 - val_model_4_loss: 8.4391 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0730 - val_model_2_accuracy: 0.0825 - val_model_3_accuracy: 0.0660 - val_model_4_accuracy: 0.0685 - val_loss1: 0.7923 - val_loss2: 4.8194\n","Epoch 103/300\n","30/30 [==============================] - 5s 153ms/step - loss: 49.9505 - model_loss: 0.1618 - model_1_loss: 0.2493 - model_2_loss: 0.1265 - model_3_loss: 0.1721 - model_4_loss: 0.2076 - model_accuracy: 0.9600 - model_1_accuracy: 0.9267 - model_2_accuracy: 0.9533 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9533 - loss1: 0.7430 - loss2: 4.8290 - val_loss: 90.6788 - val_model_loss: 8.4564 - val_model_1_loss: 8.2440 - val_model_2_loss: 7.5468 - val_model_3_loss: 8.3990 - val_model_4_loss: 9.2205 - val_model_accuracy: 0.0725 - val_model_1_accuracy: 0.0805 - val_model_2_accuracy: 0.0805 - val_model_3_accuracy: 0.0725 - val_model_4_accuracy: 0.0595 - val_loss1: 0.8309 - val_loss2: 4.7981\n","Epoch 104/300\n","30/30 [==============================] - 5s 155ms/step - loss: 49.4464 - model_loss: 0.1919 - model_1_loss: 0.1607 - model_2_loss: 0.1931 - model_3_loss: 0.2180 - model_4_loss: 0.1618 - model_accuracy: 0.9400 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9433 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9467 - loss1: 0.7869 - loss2: 4.7734 - val_loss: 90.7768 - val_model_loss: 8.6286 - val_model_1_loss: 7.9427 - val_model_2_loss: 7.9913 - val_model_3_loss: 8.9029 - val_model_4_loss: 8.2676 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0845 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0725 - val_model_4_accuracy: 0.0660 - val_loss1: 0.7763 - val_loss2: 4.8267\n","Epoch 105/300\n","30/30 [==============================] - 4s 152ms/step - loss: 49.6336 - model_loss: 0.2533 - model_1_loss: 0.1589 - model_2_loss: 0.3003 - model_3_loss: 0.1652 - model_4_loss: 0.2435 - model_accuracy: 0.9200 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9200 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9233 - loss1: 0.7940 - loss2: 4.7718 - val_loss: 90.8560 - val_model_loss: 9.5097 - val_model_1_loss: 7.9233 - val_model_2_loss: 8.6624 - val_model_3_loss: 8.5817 - val_model_4_loss: 8.5827 - val_model_accuracy: 0.0635 - val_model_1_accuracy: 0.0805 - val_model_2_accuracy: 0.0855 - val_model_3_accuracy: 0.0860 - val_model_4_accuracy: 0.0630 - val_loss1: 0.9073 - val_loss2: 4.6689\n","Epoch 106/300\n","30/30 [==============================] - 5s 155ms/step - loss: 49.4223 - model_loss: 0.2076 - model_1_loss: 0.1252 - model_2_loss: 0.2736 - model_3_loss: 0.1376 - model_4_loss: 0.1416 - model_accuracy: 0.9433 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9267 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9667 - loss1: 0.7950 - loss2: 4.7742 - val_loss: 92.1126 - val_model_loss: 8.6823 - val_model_1_loss: 8.6227 - val_model_2_loss: 8.7594 - val_model_3_loss: 8.9918 - val_model_4_loss: 7.9728 - val_model_accuracy: 0.0675 - val_model_1_accuracy: 0.0650 - val_model_2_accuracy: 0.0710 - val_model_3_accuracy: 0.0710 - val_model_4_accuracy: 0.0795 - val_loss1: 0.7992 - val_loss2: 4.8284\n","Epoch 107/300\n","30/30 [==============================] - 5s 155ms/step - loss: 50.3856 - model_loss: 0.1769 - model_1_loss: 0.1445 - model_2_loss: 0.1850 - model_3_loss: 0.1671 - model_4_loss: 0.0882 - model_accuracy: 0.9500 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9833 - loss1: 0.7124 - loss2: 4.8912 - val_loss: 91.2562 - val_model_loss: 8.5541 - val_model_1_loss: 8.2086 - val_model_2_loss: 8.8203 - val_model_3_loss: 8.4703 - val_model_4_loss: 7.3931 - val_model_accuracy: 0.0755 - val_model_1_accuracy: 0.0750 - val_model_2_accuracy: 0.0695 - val_model_3_accuracy: 0.0810 - val_model_4_accuracy: 0.0890 - val_loss1: 0.7114 - val_loss2: 4.9098\n","Epoch 108/300\n","30/30 [==============================] - 5s 158ms/step - loss: 50.7062 - model_loss: 0.1531 - model_1_loss: 0.2203 - model_2_loss: 0.1509 - model_3_loss: 0.1994 - model_4_loss: 0.1839 - model_accuracy: 0.9633 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9433 - model_4_accuracy: 0.9567 - loss1: 0.7087 - loss2: 4.9090 - val_loss: 91.7151 - val_model_loss: 8.4769 - val_model_1_loss: 8.0128 - val_model_2_loss: 8.1407 - val_model_3_loss: 8.8351 - val_model_4_loss: 7.9813 - val_model_accuracy: 0.0850 - val_model_1_accuracy: 0.0875 - val_model_2_accuracy: 0.0790 - val_model_3_accuracy: 0.0780 - val_model_4_accuracy: 0.0920 - val_loss1: 0.6935 - val_loss2: 4.9575\n","Epoch 109/300\n","30/30 [==============================] - 4s 152ms/step - loss: 50.5543 - model_loss: 0.1627 - model_1_loss: 0.1432 - model_2_loss: 0.1535 - model_3_loss: 0.2149 - model_4_loss: 0.2363 - model_accuracy: 0.9533 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9367 - model_4_accuracy: 0.9333 - loss1: 0.7208 - loss2: 4.8923 - val_loss: 90.5386 - val_model_loss: 8.7728 - val_model_1_loss: 8.0239 - val_model_2_loss: 7.7926 - val_model_3_loss: 8.9117 - val_model_4_loss: 8.7357 - val_model_accuracy: 0.0715 - val_model_1_accuracy: 0.0765 - val_model_2_accuracy: 0.0815 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0590 - val_loss1: 0.8575 - val_loss2: 4.7444\n","Epoch 110/300\n","30/30 [==============================] - 5s 154ms/step - loss: 50.1023 - model_loss: 0.1282 - model_1_loss: 0.2093 - model_2_loss: 0.2054 - model_3_loss: 0.2452 - model_4_loss: 0.2576 - model_accuracy: 0.9700 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9467 - model_3_accuracy: 0.9367 - model_4_accuracy: 0.9367 - loss1: 0.7828 - loss2: 4.8274 - val_loss: 91.2240 - val_model_loss: 8.3184 - val_model_1_loss: 8.1456 - val_model_2_loss: 8.5345 - val_model_3_loss: 8.8854 - val_model_4_loss: 8.9892 - val_model_accuracy: 0.0620 - val_model_1_accuracy: 0.0690 - val_model_2_accuracy: 0.0630 - val_model_3_accuracy: 0.0740 - val_model_4_accuracy: 0.0670 - val_loss1: 0.8904 - val_loss2: 4.7460\n","Epoch 111/300\n","30/30 [==============================] - 5s 154ms/step - loss: 49.8524 - model_loss: 0.1028 - model_1_loss: 0.1955 - model_2_loss: 0.1335 - model_3_loss: 0.2934 - model_4_loss: 0.1777 - model_accuracy: 0.9733 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9200 - model_4_accuracy: 0.9567 - loss1: 0.7714 - loss2: 4.8178 - val_loss: 92.2786 - val_model_loss: 8.1716 - val_model_1_loss: 8.4076 - val_model_2_loss: 8.3586 - val_model_3_loss: 9.6430 - val_model_4_loss: 8.6528 - val_model_accuracy: 0.0805 - val_model_1_accuracy: 0.0785 - val_model_2_accuracy: 0.0815 - val_model_3_accuracy: 0.0645 - val_model_4_accuracy: 0.0795 - val_loss1: 0.7755 - val_loss2: 4.8269\n","Epoch 112/300\n","30/30 [==============================] - 4s 149ms/step - loss: 50.3290 - model_loss: 0.0700 - model_1_loss: 0.1584 - model_2_loss: 0.1407 - model_3_loss: 0.1796 - model_4_loss: 0.1213 - model_accuracy: 0.9867 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9567 - loss1: 0.7174 - loss2: 4.8942 - val_loss: 91.6488 - val_model_loss: 8.3305 - val_model_1_loss: 8.1766 - val_model_2_loss: 8.5153 - val_model_3_loss: 8.7430 - val_model_4_loss: 8.3195 - val_model_accuracy: 0.0800 - val_model_1_accuracy: 0.0835 - val_model_2_accuracy: 0.0755 - val_model_3_accuracy: 0.0710 - val_model_4_accuracy: 0.0740 - val_loss1: 0.7517 - val_loss2: 4.8812\n","Epoch 113/300\n","30/30 [==============================] - 5s 155ms/step - loss: 50.4565 - model_loss: 0.1104 - model_1_loss: 0.2399 - model_2_loss: 0.2269 - model_3_loss: 0.1352 - model_4_loss: 0.1419 - model_accuracy: 0.9700 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9267 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9633 - loss1: 0.7260 - loss2: 4.8876 - val_loss: 92.0804 - val_model_loss: 8.6451 - val_model_1_loss: 8.4615 - val_model_2_loss: 8.7555 - val_model_3_loss: 9.0467 - val_model_4_loss: 8.2771 - val_model_accuracy: 0.0780 - val_model_1_accuracy: 0.0820 - val_model_2_accuracy: 0.0695 - val_model_3_accuracy: 0.0860 - val_model_4_accuracy: 0.0920 - val_loss1: 0.8201 - val_loss2: 4.8074\n","Epoch 114/300\n","30/30 [==============================] - 5s 154ms/step - loss: 50.6487 - model_loss: 0.2193 - model_1_loss: 0.1784 - model_2_loss: 0.2466 - model_3_loss: 0.1874 - model_4_loss: 0.1824 - model_accuracy: 0.9567 - model_1_accuracy: 0.9400 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9433 - loss1: 0.7212 - loss2: 4.8913 - val_loss: 92.1848 - val_model_loss: 8.6111 - val_model_1_loss: 8.1880 - val_model_2_loss: 8.7045 - val_model_3_loss: 9.4330 - val_model_4_loss: 8.3308 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0770 - val_model_2_accuracy: 0.0640 - val_model_3_accuracy: 0.0720 - val_model_4_accuracy: 0.0815 - val_loss1: 0.8054 - val_loss2: 4.8112\n","Epoch 115/300\n","30/30 [==============================] - 5s 157ms/step - loss: 50.3329 - model_loss: 0.2845 - model_1_loss: 0.1382 - model_2_loss: 0.2687 - model_3_loss: 0.2307 - model_4_loss: 0.1010 - model_accuracy: 0.9300 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9167 - model_3_accuracy: 0.9433 - model_4_accuracy: 0.9700 - loss1: 0.7442 - loss2: 4.8566 - val_loss: 92.6732 - val_model_loss: 8.7920 - val_model_1_loss: 8.2317 - val_model_2_loss: 8.7293 - val_model_3_loss: 9.5695 - val_model_4_loss: 7.8747 - val_model_accuracy: 0.0630 - val_model_1_accuracy: 0.0720 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0680 - val_model_4_accuracy: 0.0765 - val_loss1: 0.7930 - val_loss2: 4.8683\n","Epoch 116/300\n","30/30 [==============================] - 5s 154ms/step - loss: 50.1369 - model_loss: 0.1229 - model_1_loss: 0.1312 - model_2_loss: 0.2192 - model_3_loss: 0.1854 - model_4_loss: 0.1181 - model_accuracy: 0.9667 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9467 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9700 - loss1: 0.7421 - loss2: 4.8618 - val_loss: 90.8506 - val_model_loss: 8.8989 - val_model_1_loss: 7.8993 - val_model_2_loss: 7.9964 - val_model_3_loss: 8.6170 - val_model_4_loss: 8.5336 - val_model_accuracy: 0.0815 - val_model_1_accuracy: 0.0705 - val_model_2_accuracy: 0.0850 - val_model_3_accuracy: 0.0670 - val_model_4_accuracy: 0.0655 - val_loss1: 0.8102 - val_loss2: 4.8095\n","Epoch 117/300\n","30/30 [==============================] - 5s 153ms/step - loss: 50.5294 - model_loss: 0.0807 - model_1_loss: 0.0861 - model_2_loss: 0.1560 - model_3_loss: 0.0899 - model_4_loss: 0.1105 - model_accuracy: 0.9800 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9733 - loss1: 0.6804 - loss2: 4.9326 - val_loss: 91.9930 - val_model_loss: 8.7253 - val_model_1_loss: 8.1615 - val_model_2_loss: 7.8909 - val_model_3_loss: 8.8830 - val_model_4_loss: 8.0180 - val_model_accuracy: 0.0725 - val_model_1_accuracy: 0.0705 - val_model_2_accuracy: 0.0750 - val_model_3_accuracy: 0.0750 - val_model_4_accuracy: 0.0845 - val_loss1: 0.6668 - val_loss2: 4.9648\n","Epoch 118/300\n","30/30 [==============================] - 4s 149ms/step - loss: 50.7799 - model_loss: 0.1036 - model_1_loss: 0.1142 - model_2_loss: 0.1358 - model_3_loss: 0.0768 - model_4_loss: 0.1110 - model_accuracy: 0.9667 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9700 - loss1: 0.6495 - loss2: 4.9589 - val_loss: 92.1870 - val_model_loss: 8.8720 - val_model_1_loss: 7.8883 - val_model_2_loss: 8.1325 - val_model_3_loss: 8.5060 - val_model_4_loss: 8.6143 - val_model_accuracy: 0.0700 - val_model_1_accuracy: 0.0755 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0715 - val_model_4_accuracy: 0.0885 - val_loss1: 0.6814 - val_loss2: 4.9493\n","Epoch 119/300\n","30/30 [==============================] - 4s 152ms/step - loss: 50.9054 - model_loss: 0.2252 - model_1_loss: 0.0914 - model_2_loss: 0.1935 - model_3_loss: 0.0794 - model_4_loss: 0.1012 - model_accuracy: 0.9267 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9500 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9767 - loss1: 0.6639 - loss2: 4.9551 - val_loss: 91.6702 - val_model_loss: 8.7788 - val_model_1_loss: 7.8344 - val_model_2_loss: 8.0753 - val_model_3_loss: 8.4919 - val_model_4_loss: 8.3708 - val_model_accuracy: 0.0625 - val_model_1_accuracy: 0.0695 - val_model_2_accuracy: 0.0785 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0820 - val_loss1: 0.6950 - val_loss2: 4.9424\n","Epoch 120/300\n","30/30 [==============================] - 4s 151ms/step - loss: 51.5603 - model_loss: 0.2278 - model_1_loss: 0.1394 - model_2_loss: 0.1606 - model_3_loss: 0.0839 - model_4_loss: 0.0985 - model_accuracy: 0.9333 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9767 - loss1: 0.6301 - loss2: 5.0220 - val_loss: 93.3946 - val_model_loss: 9.5245 - val_model_1_loss: 8.1203 - val_model_2_loss: 8.7293 - val_model_3_loss: 8.6473 - val_model_4_loss: 8.6589 - val_model_accuracy: 0.0645 - val_model_1_accuracy: 0.0815 - val_model_2_accuracy: 0.0700 - val_model_3_accuracy: 0.0740 - val_model_4_accuracy: 0.0740 - val_loss1: 0.7706 - val_loss2: 4.8944\n","Epoch 121/300\n","30/30 [==============================] - 5s 153ms/step - loss: 50.9079 - model_loss: 0.0906 - model_1_loss: 0.1039 - model_2_loss: 0.1110 - model_3_loss: 0.0625 - model_4_loss: 0.1233 - model_accuracy: 0.9833 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9667 - loss1: 0.6524 - loss2: 4.9764 - val_loss: 91.9117 - val_model_loss: 9.1121 - val_model_1_loss: 8.0958 - val_model_2_loss: 8.0398 - val_model_3_loss: 8.3787 - val_model_4_loss: 8.3173 - val_model_accuracy: 0.0750 - val_model_1_accuracy: 0.0780 - val_model_2_accuracy: 0.0755 - val_model_3_accuracy: 0.0685 - val_model_4_accuracy: 0.0805 - val_loss1: 0.7235 - val_loss2: 4.9245\n","Epoch 122/300\n","30/30 [==============================] - 5s 153ms/step - loss: 51.4421 - model_loss: 0.1033 - model_1_loss: 0.1448 - model_2_loss: 0.1538 - model_3_loss: 0.0776 - model_4_loss: 0.0812 - model_accuracy: 0.9733 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9800 - loss1: 0.6155 - loss2: 5.0266 - val_loss: 93.5643 - val_model_loss: 9.4134 - val_model_1_loss: 7.9968 - val_model_2_loss: 8.2386 - val_model_3_loss: 8.8259 - val_model_4_loss: 8.3086 - val_model_accuracy: 0.0685 - val_model_1_accuracy: 0.0900 - val_model_2_accuracy: 0.0820 - val_model_3_accuracy: 0.0875 - val_model_4_accuracy: 0.0775 - val_loss1: 0.6390 - val_loss2: 5.0142\n","Epoch 123/300\n","30/30 [==============================] - 5s 156ms/step - loss: 51.5784 - model_loss: 0.1957 - model_1_loss: 0.1489 - model_2_loss: 0.1971 - model_3_loss: 0.2240 - model_4_loss: 0.1962 - model_accuracy: 0.9367 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9533 - model_3_accuracy: 0.9400 - model_4_accuracy: 0.9567 - loss1: 0.6332 - loss2: 4.9983 - val_loss: 92.6572 - val_model_loss: 8.8227 - val_model_1_loss: 8.2482 - val_model_2_loss: 8.1007 - val_model_3_loss: 9.1757 - val_model_4_loss: 8.4332 - val_model_accuracy: 0.0705 - val_model_1_accuracy: 0.0695 - val_model_2_accuracy: 0.0750 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0945 - val_loss1: 0.7148 - val_loss2: 4.9162\n","Epoch 124/300\n","30/30 [==============================] - 5s 155ms/step - loss: 51.5255 - model_loss: 0.2237 - model_1_loss: 0.2298 - model_2_loss: 0.2126 - model_3_loss: 0.2162 - model_4_loss: 0.1509 - model_accuracy: 0.9400 - model_1_accuracy: 0.9167 - model_2_accuracy: 0.9400 - model_3_accuracy: 0.9367 - model_4_accuracy: 0.9533 - loss1: 0.6616 - loss2: 4.9831 - val_loss: 93.6666 - val_model_loss: 9.5648 - val_model_1_loss: 8.6369 - val_model_2_loss: 8.0903 - val_model_3_loss: 9.4657 - val_model_4_loss: 8.9854 - val_model_accuracy: 0.0675 - val_model_1_accuracy: 0.0810 - val_model_2_accuracy: 0.0755 - val_model_3_accuracy: 0.0770 - val_model_4_accuracy: 0.0790 - val_loss1: 0.8895 - val_loss2: 4.8034\n","Epoch 125/300\n","30/30 [==============================] - 5s 153ms/step - loss: 50.6811 - model_loss: 0.2694 - model_1_loss: 0.2055 - model_2_loss: 0.3095 - model_3_loss: 0.2011 - model_4_loss: 0.2458 - model_accuracy: 0.9133 - model_1_accuracy: 0.9367 - model_2_accuracy: 0.9067 - model_3_accuracy: 0.9467 - model_4_accuracy: 0.9433 - loss1: 0.7809 - loss2: 4.8669 - val_loss: 95.3510 - val_model_loss: 9.9212 - val_model_1_loss: 8.0356 - val_model_2_loss: 8.9706 - val_model_3_loss: 9.2723 - val_model_4_loss: 10.2095 - val_model_accuracy: 0.0650 - val_model_1_accuracy: 0.0685 - val_model_2_accuracy: 0.0675 - val_model_3_accuracy: 0.0695 - val_model_4_accuracy: 0.0640 - val_loss1: 0.8557 - val_loss2: 4.8086\n","Epoch 126/300\n","30/30 [==============================] - 5s 153ms/step - loss: 50.3097 - model_loss: 0.1827 - model_1_loss: 0.1606 - model_2_loss: 0.1869 - model_3_loss: 0.1230 - model_4_loss: 0.1684 - model_accuracy: 0.9400 - model_1_accuracy: 0.9567 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9567 - loss1: 0.7464 - loss2: 4.8742 - val_loss: 94.4481 - val_model_loss: 9.8365 - val_model_1_loss: 8.0082 - val_model_2_loss: 8.5202 - val_model_3_loss: 8.7543 - val_model_4_loss: 9.6053 - val_model_accuracy: 0.0650 - val_model_1_accuracy: 0.0755 - val_model_2_accuracy: 0.0685 - val_model_3_accuracy: 0.0855 - val_model_4_accuracy: 0.0665 - val_loss1: 0.7854 - val_loss2: 4.8938\n","Epoch 127/300\n","30/30 [==============================] - 5s 155ms/step - loss: 50.5849 - model_loss: 0.1581 - model_1_loss: 0.1434 - model_2_loss: 0.1321 - model_3_loss: 0.1129 - model_4_loss: 0.1232 - model_accuracy: 0.9533 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9633 - loss1: 0.7154 - loss2: 4.9200 - val_loss: 95.2310 - val_model_loss: 8.6324 - val_model_1_loss: 8.6531 - val_model_2_loss: 8.4233 - val_model_3_loss: 8.9906 - val_model_4_loss: 9.5532 - val_model_accuracy: 0.0800 - val_model_1_accuracy: 0.0755 - val_model_2_accuracy: 0.0835 - val_model_3_accuracy: 0.0765 - val_model_4_accuracy: 0.0665 - val_loss1: 0.6566 - val_loss2: 5.0322\n","Epoch 128/300\n","30/30 [==============================] - 4s 152ms/step - loss: 51.4357 - model_loss: 0.1184 - model_1_loss: 0.1543 - model_2_loss: 0.1605 - model_3_loss: 0.1258 - model_4_loss: 0.1430 - model_accuracy: 0.9733 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9633 - loss1: 0.6385 - loss2: 5.0095 - val_loss: 93.9345 - val_model_loss: 8.6149 - val_model_1_loss: 8.8664 - val_model_2_loss: 8.4252 - val_model_3_loss: 8.6127 - val_model_4_loss: 8.6012 - val_model_accuracy: 0.0800 - val_model_1_accuracy: 0.0670 - val_model_2_accuracy: 0.0805 - val_model_3_accuracy: 0.0850 - val_model_4_accuracy: 0.0840 - val_loss1: 0.6514 - val_loss2: 5.0163\n","Epoch 129/300\n","30/30 [==============================] - 5s 152ms/step - loss: 52.0656 - model_loss: 0.1812 - model_1_loss: 0.2539 - model_2_loss: 0.3683 - model_3_loss: 0.1435 - model_4_loss: 0.2157 - model_accuracy: 0.9600 - model_1_accuracy: 0.9133 - model_2_accuracy: 0.9067 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9367 - loss1: 0.6469 - loss2: 5.0256 - val_loss: 96.9734 - val_model_loss: 9.3715 - val_model_1_loss: 9.6529 - val_model_2_loss: 9.3231 - val_model_3_loss: 9.5368 - val_model_4_loss: 9.0465 - val_model_accuracy: 0.0670 - val_model_1_accuracy: 0.0715 - val_model_2_accuracy: 0.0710 - val_model_3_accuracy: 0.0580 - val_model_4_accuracy: 0.0870 - val_loss1: 0.7704 - val_loss2: 4.9272\n","Epoch 130/300\n","30/30 [==============================] - 5s 155ms/step - loss: 50.1269 - model_loss: 0.0840 - model_1_loss: 0.1506 - model_2_loss: 0.1934 - model_3_loss: 0.1165 - model_4_loss: 0.1116 - model_accuracy: 0.9733 - model_1_accuracy: 0.9567 - model_2_accuracy: 0.9300 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9600 - loss1: 0.7370 - loss2: 4.8734 - val_loss: 93.8317 - val_model_loss: 9.0832 - val_model_1_loss: 8.7240 - val_model_2_loss: 9.2819 - val_model_3_loss: 8.3520 - val_model_4_loss: 8.6852 - val_model_accuracy: 0.0630 - val_model_1_accuracy: 0.0715 - val_model_2_accuracy: 0.0610 - val_model_3_accuracy: 0.0715 - val_model_4_accuracy: 0.0900 - val_loss1: 0.7227 - val_loss2: 4.8983\n","Epoch 131/300\n","30/30 [==============================] - 5s 156ms/step - loss: 50.9828 - model_loss: 0.1152 - model_1_loss: 0.1769 - model_2_loss: 0.2113 - model_3_loss: 0.0916 - model_4_loss: 0.1629 - model_accuracy: 0.9733 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9533 - loss1: 0.6679 - loss2: 4.9557 - val_loss: 91.7786 - val_model_loss: 8.4995 - val_model_1_loss: 8.4727 - val_model_2_loss: 8.5474 - val_model_3_loss: 8.7559 - val_model_4_loss: 8.0714 - val_model_accuracy: 0.0835 - val_model_1_accuracy: 0.0795 - val_model_2_accuracy: 0.0710 - val_model_3_accuracy: 0.0780 - val_model_4_accuracy: 0.0845 - val_loss1: 0.7667 - val_loss2: 4.8665\n","Epoch 132/300\n","30/30 [==============================] - 5s 157ms/step - loss: 50.6819 - model_loss: 0.1312 - model_1_loss: 0.1102 - model_2_loss: 0.1817 - model_3_loss: 0.1080 - model_4_loss: 0.1704 - model_accuracy: 0.9633 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9400 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9567 - loss1: 0.7017 - loss2: 4.9279 - val_loss: 91.7440 - val_model_loss: 8.2557 - val_model_1_loss: 8.3972 - val_model_2_loss: 8.4044 - val_model_3_loss: 8.4257 - val_model_4_loss: 9.5109 - val_model_accuracy: 0.0705 - val_model_1_accuracy: 0.0720 - val_model_2_accuracy: 0.0805 - val_model_3_accuracy: 0.0780 - val_model_4_accuracy: 0.0725 - val_loss1: 0.8196 - val_loss2: 4.7930\n","Epoch 133/300\n","30/30 [==============================] - 6s 194ms/step - loss: 50.7287 - model_loss: 0.1713 - model_1_loss: 0.1920 - model_2_loss: 0.1526 - model_3_loss: 0.2156 - model_4_loss: 0.2354 - model_accuracy: 0.9667 - model_1_accuracy: 0.9367 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9367 - loss1: 0.7190 - loss2: 4.9043 - val_loss: 94.0879 - val_model_loss: 8.6633 - val_model_1_loss: 8.5246 - val_model_2_loss: 8.4269 - val_model_3_loss: 9.2850 - val_model_4_loss: 9.1967 - val_model_accuracy: 0.0730 - val_model_1_accuracy: 0.0735 - val_model_2_accuracy: 0.0750 - val_model_3_accuracy: 0.0720 - val_model_4_accuracy: 0.0855 - val_loss1: 0.7295 - val_loss2: 4.9262\n","Epoch 134/300\n","30/30 [==============================] - 7s 222ms/step - loss: 51.8960 - model_loss: 0.1413 - model_1_loss: 0.1678 - model_2_loss: 0.1010 - model_3_loss: 0.1204 - model_4_loss: 0.2154 - model_accuracy: 0.9567 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9333 - loss1: 0.6044 - loss2: 5.0546 - val_loss: 95.4590 - val_model_loss: 8.4765 - val_model_1_loss: 8.8656 - val_model_2_loss: 8.1470 - val_model_3_loss: 9.4918 - val_model_4_loss: 9.5176 - val_model_accuracy: 0.0750 - val_model_1_accuracy: 0.0750 - val_model_2_accuracy: 0.0780 - val_model_3_accuracy: 0.0670 - val_model_4_accuracy: 0.0770 - val_loss1: 0.6351 - val_loss2: 5.0326\n","Epoch 135/300\n","30/30 [==============================] - 4s 149ms/step - loss: 51.3344 - model_loss: 0.1377 - model_1_loss: 0.1119 - model_2_loss: 0.1463 - model_3_loss: 0.1032 - model_4_loss: 0.2081 - model_accuracy: 0.9633 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9300 - loss1: 0.6378 - loss2: 4.9989 - val_loss: 96.2753 - val_model_loss: 9.3820 - val_model_1_loss: 9.0486 - val_model_2_loss: 8.4724 - val_model_3_loss: 8.9757 - val_model_4_loss: 9.7820 - val_model_accuracy: 0.0610 - val_model_1_accuracy: 0.0800 - val_model_2_accuracy: 0.0690 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0710 - val_loss1: 0.6560 - val_loss2: 4.9959\n","Epoch 136/300\n","30/30 [==============================] - 4s 152ms/step - loss: 51.4099 - model_loss: 0.1188 - model_1_loss: 0.1064 - model_2_loss: 0.1134 - model_3_loss: 0.1555 - model_4_loss: 0.1528 - model_accuracy: 0.9600 - model_1_accuracy: 0.9833 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9533 - loss1: 0.6253 - loss2: 5.0138 - val_loss: 92.4775 - val_model_loss: 8.5280 - val_model_1_loss: 8.8519 - val_model_2_loss: 7.9374 - val_model_3_loss: 8.7693 - val_model_4_loss: 8.5687 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0780 - val_model_2_accuracy: 0.0785 - val_model_3_accuracy: 0.0725 - val_model_4_accuracy: 0.0840 - val_loss1: 0.7527 - val_loss2: 4.9069\n","Epoch 137/300\n","30/30 [==============================] - 5s 153ms/step - loss: 51.2793 - model_loss: 0.1314 - model_1_loss: 0.1221 - model_2_loss: 0.0869 - model_3_loss: 0.1368 - model_4_loss: 0.1596 - model_accuracy: 0.9733 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9633 - loss1: 0.6392 - loss2: 5.0003 - val_loss: 93.9655 - val_model_loss: 8.7545 - val_model_1_loss: 8.6745 - val_model_2_loss: 8.1030 - val_model_3_loss: 8.7071 - val_model_4_loss: 8.4997 - val_model_accuracy: 0.0675 - val_model_1_accuracy: 0.0775 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0835 - val_model_4_accuracy: 0.0950 - val_loss1: 0.6552 - val_loss2: 5.0572\n","Epoch 138/300\n","30/30 [==============================] - 5s 156ms/step - loss: 52.8301 - model_loss: 0.0691 - model_1_loss: 0.0922 - model_2_loss: 0.2264 - model_3_loss: 0.0989 - model_4_loss: 0.1248 - model_accuracy: 0.9800 - model_1_accuracy: 0.9833 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9667 - loss1: 0.5385 - loss2: 5.1680 - val_loss: 94.2196 - val_model_loss: 8.5483 - val_model_1_loss: 8.4780 - val_model_2_loss: 8.4781 - val_model_3_loss: 8.8363 - val_model_4_loss: 8.9605 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0725 - val_model_2_accuracy: 0.0790 - val_model_3_accuracy: 0.0770 - val_model_4_accuracy: 0.0835 - val_loss1: 0.6883 - val_loss2: 5.0230\n","Epoch 139/300\n","30/30 [==============================] - 5s 154ms/step - loss: 51.5642 - model_loss: 0.0546 - model_1_loss: 0.1040 - model_2_loss: 0.2195 - model_3_loss: 0.1762 - model_4_loss: 0.1271 - model_accuracy: 0.9833 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.9367 - model_4_accuracy: 0.9633 - loss1: 0.6440 - loss2: 5.0239 - val_loss: 94.0704 - val_model_loss: 8.3443 - val_model_1_loss: 8.2138 - val_model_2_loss: 8.8225 - val_model_3_loss: 9.5067 - val_model_4_loss: 9.2831 - val_model_accuracy: 0.0700 - val_model_1_accuracy: 0.0735 - val_model_2_accuracy: 0.0655 - val_model_3_accuracy: 0.0695 - val_model_4_accuracy: 0.0655 - val_loss1: 0.7350 - val_loss2: 4.9165\n","Epoch 140/300\n","30/30 [==============================] - 5s 157ms/step - loss: 51.8703 - model_loss: 0.0637 - model_1_loss: 0.0947 - model_2_loss: 0.1389 - model_3_loss: 0.1427 - model_4_loss: 0.0830 - model_accuracy: 0.9900 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9733 - loss1: 0.5964 - loss2: 5.0751 - val_loss: 92.9429 - val_model_loss: 8.4945 - val_model_1_loss: 7.9196 - val_model_2_loss: 8.5411 - val_model_3_loss: 9.3923 - val_model_4_loss: 8.5261 - val_model_accuracy: 0.0755 - val_model_1_accuracy: 0.0740 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0670 - val_model_4_accuracy: 0.0730 - val_loss1: 0.7169 - val_loss2: 4.9353\n","Epoch 141/300\n","30/30 [==============================] - 5s 158ms/step - loss: 52.2224 - model_loss: 0.0483 - model_1_loss: 0.0838 - model_2_loss: 0.1154 - model_3_loss: 0.0461 - model_4_loss: 0.0923 - model_accuracy: 0.9900 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9933 - model_4_accuracy: 0.9800 - loss1: 0.5479 - loss2: 5.1288 - val_loss: 94.1101 - val_model_loss: 8.3567 - val_model_1_loss: 8.0193 - val_model_2_loss: 8.4028 - val_model_3_loss: 8.5534 - val_model_4_loss: 8.8460 - val_model_accuracy: 0.0820 - val_model_1_accuracy: 0.0810 - val_model_2_accuracy: 0.0820 - val_model_3_accuracy: 0.0810 - val_model_4_accuracy: 0.0835 - val_loss1: 0.5588 - val_loss2: 5.1373\n","Epoch 142/300\n","30/30 [==============================] - 5s 154ms/step - loss: 52.9182 - model_loss: 0.0975 - model_1_loss: 0.0996 - model_2_loss: 0.1082 - model_3_loss: 0.1017 - model_4_loss: 0.1203 - model_accuracy: 0.9700 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9533 - loss1: 0.5115 - loss2: 5.1879 - val_loss: 93.9050 - val_model_loss: 8.1897 - val_model_1_loss: 8.8106 - val_model_2_loss: 8.2500 - val_model_3_loss: 8.9629 - val_model_4_loss: 8.2961 - val_model_accuracy: 0.0775 - val_model_1_accuracy: 0.0730 - val_model_2_accuracy: 0.0775 - val_model_3_accuracy: 0.0715 - val_model_4_accuracy: 0.0900 - val_loss1: 0.6202 - val_loss2: 5.0776\n","Epoch 143/300\n","30/30 [==============================] - 5s 156ms/step - loss: 51.9401 - model_loss: 0.0575 - model_1_loss: 0.2031 - model_2_loss: 0.1395 - model_3_loss: 0.0692 - model_4_loss: 0.1850 - model_accuracy: 0.9900 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9467 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9667 - loss1: 0.6037 - loss2: 5.0682 - val_loss: 93.8826 - val_model_loss: 8.2599 - val_model_1_loss: 8.5593 - val_model_2_loss: 8.5227 - val_model_3_loss: 9.3638 - val_model_4_loss: 8.7546 - val_model_accuracy: 0.0800 - val_model_1_accuracy: 0.0790 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0820 - val_model_4_accuracy: 0.0900 - val_loss1: 0.7206 - val_loss2: 4.9702\n","Epoch 144/300\n","30/30 [==============================] - 5s 154ms/step - loss: 51.4970 - model_loss: 0.0389 - model_1_loss: 0.2601 - model_2_loss: 0.1149 - model_3_loss: 0.0773 - model_4_loss: 0.1306 - model_accuracy: 0.9833 - model_1_accuracy: 0.9300 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9667 - loss1: 0.6412 - loss2: 5.0234 - val_loss: 95.6042 - val_model_loss: 8.3290 - val_model_1_loss: 9.2363 - val_model_2_loss: 9.2434 - val_model_3_loss: 9.5450 - val_model_4_loss: 8.7342 - val_model_accuracy: 0.0850 - val_model_1_accuracy: 0.0675 - val_model_2_accuracy: 0.0685 - val_model_3_accuracy: 0.0885 - val_model_4_accuracy: 0.0925 - val_loss1: 0.6885 - val_loss2: 4.9828\n","Epoch 145/300\n","30/30 [==============================] - 5s 157ms/step - loss: 51.2677 - model_loss: 0.0679 - model_1_loss: 0.1150 - model_2_loss: 0.0699 - model_3_loss: 0.0516 - model_4_loss: 0.1072 - model_accuracy: 0.9767 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9900 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9733 - loss1: 0.6350 - loss2: 5.0221 - val_loss: 94.6887 - val_model_loss: 8.6540 - val_model_1_loss: 9.4250 - val_model_2_loss: 8.6238 - val_model_3_loss: 8.8056 - val_model_4_loss: 8.5978 - val_model_accuracy: 0.0835 - val_model_1_accuracy: 0.0665 - val_model_2_accuracy: 0.0735 - val_model_3_accuracy: 0.0745 - val_model_4_accuracy: 0.0880 - val_loss1: 0.6837 - val_loss2: 4.9899\n","Epoch 146/300\n","30/30 [==============================] - 5s 156ms/step - loss: 51.1183 - model_loss: 0.0786 - model_1_loss: 0.0943 - model_2_loss: 0.0529 - model_3_loss: 0.0517 - model_4_loss: 0.0855 - model_accuracy: 0.9833 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9667 - loss1: 0.6220 - loss2: 5.0133 - val_loss: 95.0948 - val_model_loss: 8.6486 - val_model_1_loss: 8.5328 - val_model_2_loss: 8.1792 - val_model_3_loss: 8.5989 - val_model_4_loss: 9.1903 - val_model_accuracy: 0.0815 - val_model_1_accuracy: 0.0795 - val_model_2_accuracy: 0.0800 - val_model_3_accuracy: 0.0820 - val_model_4_accuracy: 0.0840 - val_loss1: 0.5650 - val_loss2: 5.1380\n","Epoch 147/300\n","30/30 [==============================] - 5s 155ms/step - loss: 52.5096 - model_loss: 0.0448 - model_1_loss: 0.1163 - model_2_loss: 0.0622 - model_3_loss: 0.0805 - model_4_loss: 0.0760 - model_accuracy: 0.9900 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9867 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9733 - loss1: 0.5161 - loss2: 5.1614 - val_loss: 95.9965 - val_model_loss: 8.9148 - val_model_1_loss: 8.9565 - val_model_2_loss: 8.7677 - val_model_3_loss: 8.7377 - val_model_4_loss: 8.8421 - val_model_accuracy: 0.0830 - val_model_1_accuracy: 0.0745 - val_model_2_accuracy: 0.0675 - val_model_3_accuracy: 0.0830 - val_model_4_accuracy: 0.0765 - val_loss1: 0.5787 - val_loss2: 5.1199\n","Epoch 148/300\n","30/30 [==============================] - 4s 151ms/step - loss: 53.0976 - model_loss: 0.0794 - model_1_loss: 0.1249 - model_2_loss: 0.0526 - model_3_loss: 0.0506 - model_4_loss: 0.1001 - model_accuracy: 0.9833 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9933 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9633 - loss1: 0.4728 - loss2: 5.2217 - val_loss: 97.6852 - val_model_loss: 9.2513 - val_model_1_loss: 9.5420 - val_model_2_loss: 8.1519 - val_model_3_loss: 8.8721 - val_model_4_loss: 8.9148 - val_model_accuracy: 0.0695 - val_model_1_accuracy: 0.0805 - val_model_2_accuracy: 0.0750 - val_model_3_accuracy: 0.0765 - val_model_4_accuracy: 0.0745 - val_loss1: 0.4826 - val_loss2: 5.2470\n","Epoch 149/300\n","30/30 [==============================] - 4s 152ms/step - loss: 53.3826 - model_loss: 0.0971 - model_1_loss: 0.1794 - model_2_loss: 0.0895 - model_3_loss: 0.1044 - model_4_loss: 0.0845 - model_accuracy: 0.9833 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9733 - loss1: 0.4667 - loss2: 5.2361 - val_loss: 97.7283 - val_model_loss: 9.2465 - val_model_1_loss: 9.6338 - val_model_2_loss: 8.6802 - val_model_3_loss: 8.9400 - val_model_4_loss: 9.2190 - val_model_accuracy: 0.0735 - val_model_1_accuracy: 0.0700 - val_model_2_accuracy: 0.0705 - val_model_3_accuracy: 0.0810 - val_model_4_accuracy: 0.0815 - val_loss1: 0.5992 - val_loss2: 5.1410\n","Epoch 150/300\n","30/30 [==============================] - 4s 150ms/step - loss: 52.7092 - model_loss: 0.1001 - model_1_loss: 0.1267 - model_2_loss: 0.0559 - model_3_loss: 0.2566 - model_4_loss: 0.0621 - model_accuracy: 0.9767 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9900 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9767 - loss1: 0.5427 - loss2: 5.1565 - val_loss: 95.6618 - val_model_loss: 8.7287 - val_model_1_loss: 9.2186 - val_model_2_loss: 8.3543 - val_model_3_loss: 9.1908 - val_model_4_loss: 9.0060 - val_model_accuracy: 0.0835 - val_model_1_accuracy: 0.0720 - val_model_2_accuracy: 0.0820 - val_model_3_accuracy: 0.0775 - val_model_4_accuracy: 0.0825 - val_loss1: 0.6408 - val_loss2: 5.0523\n","Epoch 151/300\n","30/30 [==============================] - 5s 152ms/step - loss: 52.1488 - model_loss: 0.1236 - model_1_loss: 0.0943 - model_2_loss: 0.0625 - model_3_loss: 0.1734 - model_4_loss: 0.1336 - model_accuracy: 0.9633 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9900 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9600 - loss1: 0.5657 - loss2: 5.0996 - val_loss: 96.9071 - val_model_loss: 9.5395 - val_model_1_loss: 8.7585 - val_model_2_loss: 8.5432 - val_model_3_loss: 9.2081 - val_model_4_loss: 9.5355 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0740 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0790 - val_loss1: 0.6053 - val_loss2: 5.0717\n","Epoch 152/300\n","30/30 [==============================] - 4s 152ms/step - loss: 53.5406 - model_loss: 0.1547 - model_1_loss: 0.2163 - model_2_loss: 0.1403 - model_3_loss: 0.2140 - model_4_loss: 0.1080 - model_accuracy: 0.9633 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9633 - loss1: 0.4847 - loss2: 5.2223 - val_loss: 98.7613 - val_model_loss: 9.2506 - val_model_1_loss: 8.9533 - val_model_2_loss: 8.9001 - val_model_3_loss: 9.5249 - val_model_4_loss: 10.1697 - val_model_accuracy: 0.0765 - val_model_1_accuracy: 0.0790 - val_model_2_accuracy: 0.0685 - val_model_3_accuracy: 0.0740 - val_model_4_accuracy: 0.0655 - val_loss1: 0.5943 - val_loss2: 5.1368\n","Epoch 153/300\n","30/30 [==============================] - 5s 163ms/step - loss: 52.3503 - model_loss: 0.1340 - model_1_loss: 0.0837 - model_2_loss: 0.1002 - model_3_loss: 0.2088 - model_4_loss: 0.0832 - model_accuracy: 0.9533 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9800 - loss1: 0.5611 - loss2: 5.1179 - val_loss: 97.2701 - val_model_loss: 9.4446 - val_model_1_loss: 8.9809 - val_model_2_loss: 8.6382 - val_model_3_loss: 10.2370 - val_model_4_loss: 8.7745 - val_model_accuracy: 0.0745 - val_model_1_accuracy: 0.0810 - val_model_2_accuracy: 0.0705 - val_model_3_accuracy: 0.0630 - val_model_4_accuracy: 0.0780 - val_loss1: 0.6344 - val_loss2: 5.0560\n","Epoch 154/300\n","30/30 [==============================] - 5s 153ms/step - loss: 53.1229 - model_loss: 0.1354 - model_1_loss: 0.1189 - model_2_loss: 0.1507 - model_3_loss: 0.3582 - model_4_loss: 0.0758 - model_accuracy: 0.9633 - model_1_accuracy: 0.9567 - model_2_accuracy: 0.9500 - model_3_accuracy: 0.9000 - model_4_accuracy: 0.9767 - loss1: 0.5237 - loss2: 5.1760 - val_loss: 98.7903 - val_model_loss: 9.8197 - val_model_1_loss: 9.0320 - val_model_2_loss: 9.3450 - val_model_3_loss: 9.9363 - val_model_4_loss: 9.1405 - val_model_accuracy: 0.0640 - val_model_1_accuracy: 0.0750 - val_model_2_accuracy: 0.0625 - val_model_3_accuracy: 0.0675 - val_model_4_accuracy: 0.0835 - val_loss1: 0.6319 - val_loss2: 5.0885\n","Epoch 155/300\n","30/30 [==============================] - 4s 151ms/step - loss: 52.5136 - model_loss: 0.1223 - model_1_loss: 0.1935 - model_2_loss: 0.2168 - model_3_loss: 0.3292 - model_4_loss: 0.1737 - model_accuracy: 0.9700 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9400 - model_3_accuracy: 0.9100 - model_4_accuracy: 0.9433 - loss1: 0.6189 - loss2: 5.0859 - val_loss: 99.4004 - val_model_loss: 9.9270 - val_model_1_loss: 9.2563 - val_model_2_loss: 9.8100 - val_model_3_loss: 10.3136 - val_model_4_loss: 9.1245 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0910 - val_model_2_accuracy: 0.0610 - val_model_3_accuracy: 0.0635 - val_model_4_accuracy: 0.0720 - val_loss1: 0.7378 - val_loss2: 5.0231\n","Epoch 156/300\n","30/30 [==============================] - 4s 151ms/step - loss: 51.2548 - model_loss: 0.1944 - model_1_loss: 0.1351 - model_2_loss: 0.2794 - model_3_loss: 0.2446 - model_4_loss: 0.1909 - model_accuracy: 0.9367 - model_1_accuracy: 0.9567 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9467 - loss1: 0.6967 - loss2: 4.9514 - val_loss: 96.5015 - val_model_loss: 9.4100 - val_model_1_loss: 9.0731 - val_model_2_loss: 9.6617 - val_model_3_loss: 9.2345 - val_model_4_loss: 8.2975 - val_model_accuracy: 0.0750 - val_model_1_accuracy: 0.0670 - val_model_2_accuracy: 0.0685 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0965 - val_loss1: 0.7048 - val_loss2: 5.0120\n","Epoch 157/300\n","30/30 [==============================] - 5s 155ms/step - loss: 51.4325 - model_loss: 0.2010 - model_1_loss: 0.1526 - model_2_loss: 0.2111 - model_3_loss: 0.1319 - model_4_loss: 0.1824 - model_accuracy: 0.9300 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9400 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9500 - loss1: 0.6829 - loss2: 4.9870 - val_loss: 96.9567 - val_model_loss: 9.7862 - val_model_1_loss: 9.1183 - val_model_2_loss: 8.7614 - val_model_3_loss: 9.1187 - val_model_4_loss: 8.6069 - val_model_accuracy: 0.0755 - val_model_1_accuracy: 0.0755 - val_model_2_accuracy: 0.0710 - val_model_3_accuracy: 0.0780 - val_model_4_accuracy: 0.1055 - val_loss1: 0.6378 - val_loss2: 5.0927\n","Epoch 158/300\n","30/30 [==============================] - 4s 148ms/step - loss: 52.1377 - model_loss: 0.1133 - model_1_loss: 0.1195 - model_2_loss: 0.1254 - model_3_loss: 0.1226 - model_4_loss: 0.1245 - model_accuracy: 0.9567 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9633 - loss1: 0.5887 - loss2: 5.0944 - val_loss: 97.6071 - val_model_loss: 9.5012 - val_model_1_loss: 8.9050 - val_model_2_loss: 9.5979 - val_model_3_loss: 9.4530 - val_model_4_loss: 9.1496 - val_model_accuracy: 0.0780 - val_model_1_accuracy: 0.0820 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0710 - val_model_4_accuracy: 0.0885 - val_loss1: 0.6832 - val_loss2: 5.0317\n","Epoch 159/300\n","30/30 [==============================] - 4s 150ms/step - loss: 51.7287 - model_loss: 0.1282 - model_1_loss: 0.1353 - model_2_loss: 0.1011 - model_3_loss: 0.1009 - model_4_loss: 0.1227 - model_accuracy: 0.9667 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9667 - loss1: 0.5990 - loss2: 5.0541 - val_loss: 97.7468 - val_model_loss: 10.5784 - val_model_1_loss: 8.9835 - val_model_2_loss: 9.0798 - val_model_3_loss: 9.0576 - val_model_4_loss: 9.1044 - val_model_accuracy: 0.0550 - val_model_1_accuracy: 0.0685 - val_model_2_accuracy: 0.0790 - val_model_3_accuracy: 0.0910 - val_model_4_accuracy: 0.0800 - val_loss1: 0.6535 - val_loss2: 5.0290\n","Epoch 160/300\n","30/30 [==============================] - 4s 149ms/step - loss: 51.5916 - model_loss: 0.0575 - model_1_loss: 0.0430 - model_2_loss: 0.0261 - model_3_loss: 0.0902 - model_4_loss: 0.0905 - model_accuracy: 0.9833 - model_1_accuracy: 0.9867 - model_2_accuracy: 0.9967 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9667 - loss1: 0.5786 - loss2: 5.0706 - val_loss: 96.4338 - val_model_loss: 9.1364 - val_model_1_loss: 9.0862 - val_model_2_loss: 8.4781 - val_model_3_loss: 8.4919 - val_model_4_loss: 9.8291 - val_model_accuracy: 0.0745 - val_model_1_accuracy: 0.0700 - val_model_2_accuracy: 0.0825 - val_model_3_accuracy: 0.0810 - val_model_4_accuracy: 0.0850 - val_loss1: 0.6029 - val_loss2: 5.0809\n","Epoch 161/300\n","30/30 [==============================] - 5s 156ms/step - loss: 52.2020 - model_loss: 0.0881 - model_1_loss: 0.1289 - model_2_loss: 0.0574 - model_3_loss: 0.1131 - model_4_loss: 0.0997 - model_accuracy: 0.9800 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9867 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9633 - loss1: 0.5456 - loss2: 5.1169 - val_loss: 97.2902 - val_model_loss: 9.2810 - val_model_1_loss: 9.3206 - val_model_2_loss: 8.1044 - val_model_3_loss: 8.7322 - val_model_4_loss: 9.4866 - val_model_accuracy: 0.0725 - val_model_1_accuracy: 0.0630 - val_model_2_accuracy: 0.0800 - val_model_3_accuracy: 0.0885 - val_model_4_accuracy: 0.0815 - val_loss1: 0.5441 - val_loss2: 5.1821\n","Epoch 162/300\n","30/30 [==============================] - 5s 154ms/step - loss: 53.0840 - model_loss: 0.1610 - model_1_loss: 0.1744 - model_2_loss: 0.1177 - model_3_loss: 0.1288 - model_4_loss: 0.1110 - model_accuracy: 0.9600 - model_1_accuracy: 0.9400 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9633 - loss1: 0.5121 - loss2: 5.1879 - val_loss: 95.2175 - val_model_loss: 9.1203 - val_model_1_loss: 8.9468 - val_model_2_loss: 8.0905 - val_model_3_loss: 8.9329 - val_model_4_loss: 8.9226 - val_model_accuracy: 0.0730 - val_model_1_accuracy: 0.0860 - val_model_2_accuracy: 0.0735 - val_model_3_accuracy: 0.0700 - val_model_4_accuracy: 0.0845 - val_loss1: 0.6345 - val_loss2: 5.0570\n","Epoch 163/300\n","30/30 [==============================] - 5s 153ms/step - loss: 52.2222 - model_loss: 0.1131 - model_1_loss: 0.1446 - model_2_loss: 0.1440 - model_3_loss: 0.0957 - model_4_loss: 0.1280 - model_accuracy: 0.9733 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9667 - loss1: 0.5636 - loss2: 5.1033 - val_loss: 97.5162 - val_model_loss: 9.4538 - val_model_1_loss: 9.2460 - val_model_2_loss: 8.3493 - val_model_3_loss: 8.8516 - val_model_4_loss: 9.0751 - val_model_accuracy: 0.0735 - val_model_1_accuracy: 0.0780 - val_model_2_accuracy: 0.0750 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0870 - val_loss1: 0.5455 - val_loss2: 5.1995\n","Epoch 164/300\n","30/30 [==============================] - 4s 150ms/step - loss: 54.0160 - model_loss: 0.1120 - model_1_loss: 0.0896 - model_2_loss: 0.1267 - model_3_loss: 0.1101 - model_4_loss: 0.1911 - model_accuracy: 0.9733 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9533 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9533 - loss1: 0.4386 - loss2: 5.2948 - val_loss: 97.9036 - val_model_loss: 9.0503 - val_model_1_loss: 8.9378 - val_model_2_loss: 8.8399 - val_model_3_loss: 8.9794 - val_model_4_loss: 9.5917 - val_model_accuracy: 0.0810 - val_model_1_accuracy: 0.0635 - val_model_2_accuracy: 0.0725 - val_model_3_accuracy: 0.0830 - val_model_4_accuracy: 0.0780 - val_loss1: 0.5572 - val_loss2: 5.1947\n","Epoch 165/300\n","30/30 [==============================] - 4s 150ms/step - loss: 52.9145 - model_loss: 0.0927 - model_1_loss: 0.1157 - model_2_loss: 0.1237 - model_3_loss: 0.1583 - model_4_loss: 0.1156 - model_accuracy: 0.9767 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9733 - loss1: 0.5442 - loss2: 5.1764 - val_loss: 97.5847 - val_model_loss: 8.9958 - val_model_1_loss: 8.7265 - val_model_2_loss: 10.2462 - val_model_3_loss: 9.4004 - val_model_4_loss: 8.8929 - val_model_accuracy: 0.0790 - val_model_1_accuracy: 0.0775 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0785 - val_model_4_accuracy: 0.0775 - val_loss1: 0.6665 - val_loss2: 5.0656\n","Epoch 166/300\n","30/30 [==============================] - 4s 150ms/step - loss: 51.9347 - model_loss: 0.1006 - model_1_loss: 0.0634 - model_2_loss: 0.1507 - model_3_loss: 0.1607 - model_4_loss: 0.0838 - model_accuracy: 0.9700 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9800 - loss1: 0.5867 - loss2: 5.0789 - val_loss: 98.0089 - val_model_loss: 9.9833 - val_model_1_loss: 8.5960 - val_model_2_loss: 10.0766 - val_model_3_loss: 9.5349 - val_model_4_loss: 8.7724 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0845 - val_model_2_accuracy: 0.0730 - val_model_3_accuracy: 0.0740 - val_model_4_accuracy: 0.0770 - val_loss1: 0.6221 - val_loss2: 5.0424\n","Epoch 167/300\n","30/30 [==============================] - 4s 150ms/step - loss: 52.9289 - model_loss: 0.0482 - model_1_loss: 0.0834 - model_2_loss: 0.0836 - model_3_loss: 0.0930 - model_4_loss: 0.0804 - model_accuracy: 0.9867 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9833 - loss1: 0.4902 - loss2: 5.2050 - val_loss: 100.3665 - val_model_loss: 10.0767 - val_model_1_loss: 9.0200 - val_model_2_loss: 9.4331 - val_model_3_loss: 9.6624 - val_model_4_loss: 9.3809 - val_model_accuracy: 0.0615 - val_model_1_accuracy: 0.0815 - val_model_2_accuracy: 0.0775 - val_model_3_accuracy: 0.0725 - val_model_4_accuracy: 0.0910 - val_loss1: 0.5184 - val_loss2: 5.2275\n","Epoch 168/300\n","30/30 [==============================] - 4s 150ms/step - loss: 52.9117 - model_loss: 0.0695 - model_1_loss: 0.1126 - model_2_loss: 0.1118 - model_3_loss: 0.0683 - model_4_loss: 0.1173 - model_accuracy: 0.9800 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9567 - loss1: 0.4997 - loss2: 5.1933 - val_loss: 100.7060 - val_model_loss: 9.9567 - val_model_1_loss: 9.1709 - val_model_2_loss: 9.2628 - val_model_3_loss: 9.6820 - val_model_4_loss: 10.0356 - val_model_accuracy: 0.0660 - val_model_1_accuracy: 0.0890 - val_model_2_accuracy: 0.0735 - val_model_3_accuracy: 0.0705 - val_model_4_accuracy: 0.0815 - val_loss1: 0.5182 - val_loss2: 5.2080\n","Epoch 169/300\n","30/30 [==============================] - 4s 151ms/step - loss: 53.3017 - model_loss: 0.1455 - model_1_loss: 0.1884 - model_2_loss: 0.1362 - model_3_loss: 0.1574 - model_4_loss: 0.1940 - model_accuracy: 0.9767 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9533 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9600 - loss1: 0.4829 - loss2: 5.1997 - val_loss: 102.1275 - val_model_loss: 10.6549 - val_model_1_loss: 9.7009 - val_model_2_loss: 10.2215 - val_model_3_loss: 9.2589 - val_model_4_loss: 10.4403 - val_model_accuracy: 0.0565 - val_model_1_accuracy: 0.0895 - val_model_2_accuracy: 0.0735 - val_model_3_accuracy: 0.0710 - val_model_4_accuracy: 0.0565 - val_loss1: 0.5575 - val_loss2: 5.1293\n","Epoch 170/300\n","30/30 [==============================] - 4s 151ms/step - loss: 54.1304 - model_loss: 0.1627 - model_1_loss: 0.1038 - model_2_loss: 0.1665 - model_3_loss: 0.1635 - model_4_loss: 0.2898 - model_accuracy: 0.9600 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9533 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9300 - loss1: 0.4319 - loss2: 5.2812 - val_loss: 100.4121 - val_model_loss: 9.8097 - val_model_1_loss: 8.7663 - val_model_2_loss: 9.3474 - val_model_3_loss: 9.6641 - val_model_4_loss: 10.1022 - val_model_accuracy: 0.0645 - val_model_1_accuracy: 0.0835 - val_model_2_accuracy: 0.0670 - val_model_3_accuracy: 0.0790 - val_model_4_accuracy: 0.0795 - val_loss1: 0.5175 - val_loss2: 5.2205\n","Epoch 171/300\n","30/30 [==============================] - 4s 152ms/step - loss: 53.8626 - model_loss: 0.1000 - model_1_loss: 0.0674 - model_2_loss: 0.0970 - model_3_loss: 0.1263 - model_4_loss: 0.1088 - model_accuracy: 0.9700 - model_1_accuracy: 0.9833 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9733 - loss1: 0.4479 - loss2: 5.2915 - val_loss: 101.5562 - val_model_loss: 9.6630 - val_model_1_loss: 8.9766 - val_model_2_loss: 9.9827 - val_model_3_loss: 9.6231 - val_model_4_loss: 11.1182 - val_model_accuracy: 0.0665 - val_model_1_accuracy: 0.0890 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0825 - val_model_4_accuracy: 0.0660 - val_loss1: 0.5652 - val_loss2: 5.1627\n","Epoch 172/300\n","30/30 [==============================] - 4s 149ms/step - loss: 52.9461 - model_loss: 0.0788 - model_1_loss: 0.0741 - model_2_loss: 0.1470 - model_3_loss: 0.0813 - model_4_loss: 0.1405 - model_accuracy: 0.9767 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9633 - loss1: 0.5236 - loss2: 5.1901 - val_loss: 99.2864 - val_model_loss: 9.6043 - val_model_1_loss: 8.5091 - val_model_2_loss: 9.3929 - val_model_3_loss: 9.6824 - val_model_4_loss: 9.7909 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0755 - val_model_2_accuracy: 0.0650 - val_model_3_accuracy: 0.0750 - val_model_4_accuracy: 0.0845 - val_loss1: 0.5541 - val_loss2: 5.1753\n","Epoch 173/300\n","30/30 [==============================] - 5s 153ms/step - loss: 53.3305 - model_loss: 0.1021 - model_1_loss: 0.0649 - model_2_loss: 0.2013 - model_3_loss: 0.1606 - model_4_loss: 0.1022 - model_accuracy: 0.9767 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9300 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9667 - loss1: 0.4814 - loss2: 5.2218 - val_loss: 99.0167 - val_model_loss: 9.2071 - val_model_1_loss: 7.7973 - val_model_2_loss: 10.1015 - val_model_3_loss: 9.3681 - val_model_4_loss: 10.0294 - val_model_accuracy: 0.0765 - val_model_1_accuracy: 0.0845 - val_model_2_accuracy: 0.0610 - val_model_3_accuracy: 0.0815 - val_model_4_accuracy: 0.0745 - val_loss1: 0.5225 - val_loss2: 5.1991\n","Epoch 174/300\n","30/30 [==============================] - 5s 152ms/step - loss: 53.1161 - model_loss: 0.0655 - model_1_loss: 0.0650 - model_2_loss: 0.4354 - model_3_loss: 0.1124 - model_4_loss: 0.0876 - model_accuracy: 0.9867 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9033 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9833 - loss1: 0.5116 - loss2: 5.1839 - val_loss: 101.1263 - val_model_loss: 9.6047 - val_model_1_loss: 8.3398 - val_model_2_loss: 11.0838 - val_model_3_loss: 9.2429 - val_model_4_loss: 9.9925 - val_model_accuracy: 0.0730 - val_model_1_accuracy: 0.0770 - val_model_2_accuracy: 0.0545 - val_model_3_accuracy: 0.0850 - val_model_4_accuracy: 0.0805 - val_loss1: 0.5068 - val_loss2: 5.2356\n","Epoch 175/300\n","30/30 [==============================] - 4s 150ms/step - loss: 53.0445 - model_loss: 0.0386 - model_1_loss: 0.0557 - model_2_loss: 0.2203 - model_3_loss: 0.0767 - model_4_loss: 0.0456 - model_accuracy: 0.9867 - model_1_accuracy: 0.9833 - model_2_accuracy: 0.9333 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9933 - loss1: 0.4894 - loss2: 5.2118 - val_loss: 99.7273 - val_model_loss: 9.7495 - val_model_1_loss: 8.5799 - val_model_2_loss: 10.8442 - val_model_3_loss: 9.1750 - val_model_4_loss: 9.6716 - val_model_accuracy: 0.0730 - val_model_1_accuracy: 0.0925 - val_model_2_accuracy: 0.0705 - val_model_3_accuracy: 0.0880 - val_model_4_accuracy: 0.0935 - val_loss1: 0.5837 - val_loss2: 5.1123\n","Epoch 176/300\n","30/30 [==============================] - 5s 154ms/step - loss: 52.3090 - model_loss: 0.0567 - model_1_loss: 0.0839 - model_2_loss: 0.1650 - model_3_loss: 0.0547 - model_4_loss: 0.0892 - model_accuracy: 0.9833 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9800 - loss1: 0.5387 - loss2: 5.1321 - val_loss: 100.8152 - val_model_loss: 9.6431 - val_model_1_loss: 9.3579 - val_model_2_loss: 10.0202 - val_model_3_loss: 8.9864 - val_model_4_loss: 10.0016 - val_model_accuracy: 0.0810 - val_model_1_accuracy: 0.0740 - val_model_2_accuracy: 0.0735 - val_model_3_accuracy: 0.0885 - val_model_4_accuracy: 0.0770 - val_loss1: 0.5241 - val_loss2: 5.2282\n","Epoch 177/300\n","30/30 [==============================] - 4s 149ms/step - loss: 53.5418 - model_loss: 0.0705 - model_1_loss: 0.0816 - model_2_loss: 0.1331 - model_3_loss: 0.0466 - model_4_loss: 0.0832 - model_accuracy: 0.9667 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9833 - loss1: 0.4637 - loss2: 5.2663 - val_loss: 99.8816 - val_model_loss: 9.5274 - val_model_1_loss: 9.2064 - val_model_2_loss: 9.5918 - val_model_3_loss: 9.3941 - val_model_4_loss: 10.1744 - val_model_accuracy: 0.0730 - val_model_1_accuracy: 0.0865 - val_model_2_accuracy: 0.0715 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0865 - val_loss1: 0.5845 - val_loss2: 5.1403\n","Epoch 178/300\n","30/30 [==============================] - 5s 155ms/step - loss: 53.1283 - model_loss: 0.1470 - model_1_loss: 0.1784 - model_2_loss: 0.1685 - model_3_loss: 0.0399 - model_4_loss: 0.1734 - model_accuracy: 0.9600 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9567 - loss1: 0.5052 - loss2: 5.1916 - val_loss: 98.7170 - val_model_loss: 9.7220 - val_model_1_loss: 9.3803 - val_model_2_loss: 8.9685 - val_model_3_loss: 9.8601 - val_model_4_loss: 9.1903 - val_model_accuracy: 0.0710 - val_model_1_accuracy: 0.0715 - val_model_2_accuracy: 0.0825 - val_model_3_accuracy: 0.0745 - val_model_4_accuracy: 0.0830 - val_loss1: 0.6419 - val_loss2: 5.0954\n","Epoch 179/300\n","30/30 [==============================] - 5s 153ms/step - loss: 52.8250 - model_loss: 0.0970 - model_1_loss: 0.1454 - model_2_loss: 0.0991 - model_3_loss: 0.0428 - model_4_loss: 0.0704 - model_accuracy: 0.9633 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9767 - loss1: 0.5269 - loss2: 5.1843 - val_loss: 100.9209 - val_model_loss: 9.6239 - val_model_1_loss: 9.5277 - val_model_2_loss: 8.7764 - val_model_3_loss: 9.0948 - val_model_4_loss: 10.6315 - val_model_accuracy: 0.0795 - val_model_1_accuracy: 0.0840 - val_model_2_accuracy: 0.0830 - val_model_3_accuracy: 0.0770 - val_model_4_accuracy: 0.0780 - val_loss1: 0.4911 - val_loss2: 5.2775\n","Epoch 180/300\n","30/30 [==============================] - 4s 151ms/step - loss: 52.9733 - model_loss: 0.0903 - model_1_loss: 0.1932 - model_2_loss: 0.0949 - model_3_loss: 0.0411 - model_4_loss: 0.0841 - model_accuracy: 0.9667 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9833 - loss1: 0.4914 - loss2: 5.1978 - val_loss: 100.5367 - val_model_loss: 10.0486 - val_model_1_loss: 10.2332 - val_model_2_loss: 9.1959 - val_model_3_loss: 9.0593 - val_model_4_loss: 9.9848 - val_model_accuracy: 0.0735 - val_model_1_accuracy: 0.0755 - val_model_2_accuracy: 0.0705 - val_model_3_accuracy: 0.0830 - val_model_4_accuracy: 0.0845 - val_loss1: 0.5530 - val_loss2: 5.1462\n","Epoch 181/300\n","30/30 [==============================] - 5s 153ms/step - loss: 53.4137 - model_loss: 0.1607 - model_1_loss: 0.1665 - model_2_loss: 0.0975 - model_3_loss: 0.0697 - model_4_loss: 0.1800 - model_accuracy: 0.9667 - model_1_accuracy: 0.9567 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9533 - loss1: 0.4819 - loss2: 5.2257 - val_loss: 101.9866 - val_model_loss: 10.0567 - val_model_1_loss: 10.3244 - val_model_2_loss: 9.4438 - val_model_3_loss: 8.7111 - val_model_4_loss: 11.5880 - val_model_accuracy: 0.0645 - val_model_1_accuracy: 0.0525 - val_model_2_accuracy: 0.0705 - val_model_3_accuracy: 0.0895 - val_model_4_accuracy: 0.0715 - val_loss1: 0.6126 - val_loss2: 5.1250\n","Epoch 182/300\n","30/30 [==============================] - 4s 152ms/step - loss: 52.9117 - model_loss: 0.0893 - model_1_loss: 0.1797 - model_2_loss: 0.0865 - model_3_loss: 0.0532 - model_4_loss: 0.1729 - model_accuracy: 0.9767 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9500 - loss1: 0.5240 - loss2: 5.1806 - val_loss: 100.3235 - val_model_loss: 9.6598 - val_model_1_loss: 9.6346 - val_model_2_loss: 8.9333 - val_model_3_loss: 9.0842 - val_model_4_loss: 11.1634 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0755 - val_model_2_accuracy: 0.0695 - val_model_3_accuracy: 0.0770 - val_model_4_accuracy: 0.0640 - val_loss1: 0.6123 - val_loss2: 5.1236\n","Epoch 183/300\n","30/30 [==============================] - 5s 155ms/step - loss: 52.5615 - model_loss: 0.1419 - model_1_loss: 0.2116 - model_2_loss: 0.0764 - model_3_loss: 0.0565 - model_4_loss: 0.1216 - model_accuracy: 0.9567 - model_1_accuracy: 0.9333 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9633 - loss1: 0.5544 - loss2: 5.1399 - val_loss: 98.9819 - val_model_loss: 10.1641 - val_model_1_loss: 9.7015 - val_model_2_loss: 9.3571 - val_model_3_loss: 9.0757 - val_model_4_loss: 10.3864 - val_model_accuracy: 0.0655 - val_model_1_accuracy: 0.0750 - val_model_2_accuracy: 0.0675 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0700 - val_loss1: 0.6735 - val_loss2: 4.9623\n","Epoch 184/300\n","30/30 [==============================] - 4s 152ms/step - loss: 52.8782 - model_loss: 0.2062 - model_1_loss: 0.1579 - model_2_loss: 0.1589 - model_3_loss: 0.0417 - model_4_loss: 0.1394 - model_accuracy: 0.9467 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9533 - loss1: 0.5241 - loss2: 5.1650 - val_loss: 102.3144 - val_model_loss: 11.6471 - val_model_1_loss: 9.4230 - val_model_2_loss: 8.8174 - val_model_3_loss: 9.1957 - val_model_4_loss: 11.1312 - val_model_accuracy: 0.0600 - val_model_1_accuracy: 0.0780 - val_model_2_accuracy: 0.0790 - val_model_3_accuracy: 0.0780 - val_model_4_accuracy: 0.0670 - val_loss1: 0.6037 - val_loss2: 5.1496\n","Epoch 185/300\n","30/30 [==============================] - 4s 150ms/step - loss: 53.3213 - model_loss: 0.2642 - model_1_loss: 0.1186 - model_2_loss: 0.1184 - model_3_loss: 0.0489 - model_4_loss: 0.1139 - model_accuracy: 0.9500 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9633 - loss1: 0.4886 - loss2: 5.2169 - val_loss: 101.2837 - val_model_loss: 10.0107 - val_model_1_loss: 10.0172 - val_model_2_loss: 9.5765 - val_model_3_loss: 8.6439 - val_model_4_loss: 9.9167 - val_model_accuracy: 0.0655 - val_model_1_accuracy: 0.0745 - val_model_2_accuracy: 0.0715 - val_model_3_accuracy: 0.0830 - val_model_4_accuracy: 0.0890 - val_loss1: 0.4858 - val_loss2: 5.2633\n","Epoch 186/300\n","30/30 [==============================] - 4s 150ms/step - loss: 54.1049 - model_loss: 0.1531 - model_1_loss: 0.1307 - model_2_loss: 0.0949 - model_3_loss: 0.0428 - model_4_loss: 0.1611 - model_accuracy: 0.9500 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9500 - loss1: 0.4209 - loss2: 5.3101 - val_loss: 102.7748 - val_model_loss: 9.9562 - val_model_1_loss: 9.9485 - val_model_2_loss: 9.3058 - val_model_3_loss: 9.2474 - val_model_4_loss: 10.9604 - val_model_accuracy: 0.0580 - val_model_1_accuracy: 0.0705 - val_model_2_accuracy: 0.0675 - val_model_3_accuracy: 0.0785 - val_model_4_accuracy: 0.0625 - val_loss1: 0.4769 - val_loss2: 5.2879\n","Epoch 187/300\n","30/30 [==============================] - 5s 152ms/step - loss: 53.1844 - model_loss: 0.0683 - model_1_loss: 0.0950 - model_2_loss: 0.1409 - model_3_loss: 0.0411 - model_4_loss: 0.0783 - model_accuracy: 0.9833 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9533 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9833 - loss1: 0.4668 - loss2: 5.2294 - val_loss: 100.6822 - val_model_loss: 9.4414 - val_model_1_loss: 9.6406 - val_model_2_loss: 10.3352 - val_model_3_loss: 9.0387 - val_model_4_loss: 10.0468 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0770 - val_model_2_accuracy: 0.0620 - val_model_3_accuracy: 0.0830 - val_model_4_accuracy: 0.0770 - val_loss1: 0.5407 - val_loss2: 5.1639\n","Epoch 188/300\n","30/30 [==============================] - 5s 154ms/step - loss: 53.1473 - model_loss: 0.0965 - model_1_loss: 0.1037 - model_2_loss: 0.1251 - model_3_loss: 0.1383 - model_4_loss: 0.1142 - model_accuracy: 0.9767 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9667 - loss1: 0.4857 - loss2: 5.2084 - val_loss: 99.6831 - val_model_loss: 9.5402 - val_model_1_loss: 8.5736 - val_model_2_loss: 9.9856 - val_model_3_loss: 9.4496 - val_model_4_loss: 9.3276 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0870 - val_model_2_accuracy: 0.0690 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0875 - val_loss1: 0.5225 - val_loss2: 5.2284\n","Epoch 189/300\n","30/30 [==============================] - 5s 154ms/step - loss: 52.7976 - model_loss: 0.0772 - model_1_loss: 0.0780 - model_2_loss: 0.0840 - model_3_loss: 0.1522 - model_4_loss: 0.0834 - model_accuracy: 0.9833 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9900 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9867 - loss1: 0.4994 - loss2: 5.1824 - val_loss: 101.7972 - val_model_loss: 9.8365 - val_model_1_loss: 8.7438 - val_model_2_loss: 9.6021 - val_model_3_loss: 10.3772 - val_model_4_loss: 9.9571 - val_model_accuracy: 0.0795 - val_model_1_accuracy: 0.0890 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0805 - val_model_4_accuracy: 0.0820 - val_loss1: 0.4562 - val_loss2: 5.2824\n","Epoch 190/300\n","30/30 [==============================] - 5s 158ms/step - loss: 54.5824 - model_loss: 0.2084 - model_1_loss: 0.0769 - model_2_loss: 0.0914 - model_3_loss: 0.3396 - model_4_loss: 0.0934 - model_accuracy: 0.9600 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9100 - model_4_accuracy: 0.9767 - loss1: 0.4044 - loss2: 5.3368 - val_loss: 98.6570 - val_model_loss: 9.2750 - val_model_1_loss: 8.9607 - val_model_2_loss: 8.7221 - val_model_3_loss: 9.4976 - val_model_4_loss: 9.6679 - val_model_accuracy: 0.0645 - val_model_1_accuracy: 0.0785 - val_model_2_accuracy: 0.0845 - val_model_3_accuracy: 0.0780 - val_model_4_accuracy: 0.0810 - val_loss1: 0.5347 - val_loss2: 5.1999\n","Epoch 191/300\n","30/30 [==============================] - 5s 155ms/step - loss: 53.1820 - model_loss: 0.0954 - model_1_loss: 0.1005 - model_2_loss: 0.0443 - model_3_loss: 0.2244 - model_4_loss: 0.0779 - model_accuracy: 0.9767 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9867 - model_3_accuracy: 0.9333 - model_4_accuracy: 0.9767 - loss1: 0.4886 - loss2: 5.2151 - val_loss: 100.6506 - val_model_loss: 10.4956 - val_model_1_loss: 9.3525 - val_model_2_loss: 8.8561 - val_model_3_loss: 10.1651 - val_model_4_loss: 9.8864 - val_model_accuracy: 0.0725 - val_model_1_accuracy: 0.0710 - val_model_2_accuracy: 0.0850 - val_model_3_accuracy: 0.0790 - val_model_4_accuracy: 0.0785 - val_loss1: 0.5754 - val_loss2: 5.1319\n","Epoch 192/300\n","30/30 [==============================] - 4s 152ms/step - loss: 53.3239 - model_loss: 0.0980 - model_1_loss: 0.1072 - model_2_loss: 0.1175 - model_3_loss: 0.1810 - model_4_loss: 0.0732 - model_accuracy: 0.9700 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9833 - loss1: 0.4752 - loss2: 5.2272 - val_loss: 101.6685 - val_model_loss: 9.9866 - val_model_1_loss: 9.2856 - val_model_2_loss: 9.1563 - val_model_3_loss: 10.0619 - val_model_4_loss: 9.7031 - val_model_accuracy: 0.0650 - val_model_1_accuracy: 0.0750 - val_model_2_accuracy: 0.0825 - val_model_3_accuracy: 0.0735 - val_model_4_accuracy: 0.0940 - val_loss1: 0.4629 - val_loss2: 5.3012\n","Epoch 193/300\n","30/30 [==============================] - 5s 152ms/step - loss: 53.4073 - model_loss: 0.0974 - model_1_loss: 0.0803 - model_2_loss: 0.1235 - model_3_loss: 0.1796 - model_4_loss: 0.0840 - model_accuracy: 0.9800 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9533 - model_4_accuracy: 0.9733 - loss1: 0.4753 - loss2: 5.2367 - val_loss: 101.4575 - val_model_loss: 9.4271 - val_model_1_loss: 9.6915 - val_model_2_loss: 9.4802 - val_model_3_loss: 11.4208 - val_model_4_loss: 9.9293 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0735 - val_model_2_accuracy: 0.0720 - val_model_3_accuracy: 0.0615 - val_model_4_accuracy: 0.0960 - val_loss1: 0.5854 - val_loss2: 5.0923\n","Epoch 194/300\n","30/30 [==============================] - 4s 151ms/step - loss: 53.8581 - model_loss: 0.0569 - model_1_loss: 0.1778 - model_2_loss: 0.0509 - model_3_loss: 0.1735 - model_4_loss: 0.1968 - model_accuracy: 0.9833 - model_1_accuracy: 0.9467 - model_2_accuracy: 0.9900 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9600 - loss1: 0.4393 - loss2: 5.2763 - val_loss: 103.5507 - val_model_loss: 9.3275 - val_model_1_loss: 10.6598 - val_model_2_loss: 9.5480 - val_model_3_loss: 10.6290 - val_model_4_loss: 9.4272 - val_model_accuracy: 0.0890 - val_model_1_accuracy: 0.0690 - val_model_2_accuracy: 0.0745 - val_model_3_accuracy: 0.0735 - val_model_4_accuracy: 0.0785 - val_loss1: 0.4356 - val_loss2: 5.3524\n","Epoch 195/300\n","30/30 [==============================] - 4s 151ms/step - loss: 53.8945 - model_loss: 0.0246 - model_1_loss: 0.1599 - model_2_loss: 0.0814 - model_3_loss: 0.0774 - model_4_loss: 0.1336 - model_accuracy: 0.9933 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9633 - loss1: 0.4240 - loss2: 5.2994 - val_loss: 102.8245 - val_model_loss: 8.9662 - val_model_1_loss: 11.0448 - val_model_2_loss: 9.1627 - val_model_3_loss: 9.8337 - val_model_4_loss: 10.2418 - val_model_accuracy: 0.0840 - val_model_1_accuracy: 0.0745 - val_model_2_accuracy: 0.0790 - val_model_3_accuracy: 0.0725 - val_model_4_accuracy: 0.0705 - val_loss1: 0.4595 - val_loss2: 5.3116\n","Epoch 196/300\n","30/30 [==============================] - 4s 150ms/step - loss: 54.0723 - model_loss: 0.0408 - model_1_loss: 0.0852 - model_2_loss: 0.0417 - model_3_loss: 0.0761 - model_4_loss: 0.0956 - model_accuracy: 0.9900 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9933 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9767 - loss1: 0.4031 - loss2: 5.3330 - val_loss: 102.2031 - val_model_loss: 9.4750 - val_model_1_loss: 10.0592 - val_model_2_loss: 8.9396 - val_model_3_loss: 9.5813 - val_model_4_loss: 10.0212 - val_model_accuracy: 0.0775 - val_model_1_accuracy: 0.0820 - val_model_2_accuracy: 0.0780 - val_model_3_accuracy: 0.0685 - val_model_4_accuracy: 0.0760 - val_loss1: 0.4036 - val_loss2: 5.3723\n","Epoch 197/300\n","30/30 [==============================] - 5s 155ms/step - loss: 53.8506 - model_loss: 0.0363 - model_1_loss: 0.0728 - model_2_loss: 0.0479 - model_3_loss: 0.0370 - model_4_loss: 0.0477 - model_accuracy: 0.9967 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9867 - loss1: 0.4057 - loss2: 5.3203 - val_loss: 101.0244 - val_model_loss: 9.4298 - val_model_1_loss: 9.3035 - val_model_2_loss: 9.4389 - val_model_3_loss: 9.5377 - val_model_4_loss: 9.2373 - val_model_accuracy: 0.0820 - val_model_1_accuracy: 0.0950 - val_model_2_accuracy: 0.0790 - val_model_3_accuracy: 0.0710 - val_model_4_accuracy: 0.0795 - val_loss1: 0.4005 - val_loss2: 5.3677\n","Epoch 198/300\n","30/30 [==============================] - 5s 154ms/step - loss: 53.7539 - model_loss: 0.1554 - model_1_loss: 0.0821 - model_2_loss: 0.1648 - model_3_loss: 0.1208 - model_4_loss: 0.1643 - model_accuracy: 0.9700 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9433 - model_4_accuracy: 0.9600 - loss1: 0.4384 - loss2: 5.2628 - val_loss: 99.2890 - val_model_loss: 9.6910 - val_model_1_loss: 8.8567 - val_model_2_loss: 8.8634 - val_model_3_loss: 9.9599 - val_model_4_loss: 9.5867 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0860 - val_model_2_accuracy: 0.0750 - val_model_3_accuracy: 0.0815 - val_model_4_accuracy: 0.0755 - val_loss1: 0.5319 - val_loss2: 5.1799\n","Epoch 199/300\n","30/30 [==============================] - 4s 152ms/step - loss: 53.1957 - model_loss: 0.0383 - model_1_loss: 0.1125 - model_2_loss: 0.1082 - model_3_loss: 0.0984 - model_4_loss: 0.0703 - model_accuracy: 0.9833 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9700 - loss1: 0.4610 - loss2: 5.2307 - val_loss: 100.6089 - val_model_loss: 9.2670 - val_model_1_loss: 8.8237 - val_model_2_loss: 9.3537 - val_model_3_loss: 10.5657 - val_model_4_loss: 9.9395 - val_model_accuracy: 0.0700 - val_model_1_accuracy: 0.0765 - val_model_2_accuracy: 0.0770 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0770 - val_loss1: 0.5109 - val_loss2: 5.2148\n","Epoch 200/300\n","30/30 [==============================] - 5s 153ms/step - loss: 53.9676 - model_loss: 0.0711 - model_1_loss: 0.1082 - model_2_loss: 0.1021 - model_3_loss: 0.0911 - model_4_loss: 0.1112 - model_accuracy: 0.9800 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9600 - loss1: 0.4093 - loss2: 5.3075 - val_loss: 99.7997 - val_model_loss: 8.9607 - val_model_1_loss: 8.9588 - val_model_2_loss: 10.4078 - val_model_3_loss: 9.6158 - val_model_4_loss: 9.8102 - val_model_accuracy: 0.0830 - val_model_1_accuracy: 0.0865 - val_model_2_accuracy: 0.0800 - val_model_3_accuracy: 0.0860 - val_model_4_accuracy: 0.0825 - val_loss1: 0.5505 - val_loss2: 5.1496\n","Epoch 201/300\n","30/30 [==============================] - 5s 154ms/step - loss: 53.8924 - model_loss: 0.1272 - model_1_loss: 0.1420 - model_2_loss: 0.1889 - model_3_loss: 0.1873 - model_4_loss: 0.0927 - model_accuracy: 0.9600 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9533 - model_3_accuracy: 0.9533 - model_4_accuracy: 0.9667 - loss1: 0.4398 - loss2: 5.2714 - val_loss: 101.9084 - val_model_loss: 10.0265 - val_model_1_loss: 9.3385 - val_model_2_loss: 9.8081 - val_model_3_loss: 10.5783 - val_model_4_loss: 9.3069 - val_model_accuracy: 0.0665 - val_model_1_accuracy: 0.0895 - val_model_2_accuracy: 0.0760 - val_model_3_accuracy: 0.0710 - val_model_4_accuracy: 0.0885 - val_loss1: 0.5424 - val_loss2: 5.2308\n","Epoch 202/300\n","30/30 [==============================] - 5s 153ms/step - loss: 53.7872 - model_loss: 0.2162 - model_1_loss: 0.1202 - model_2_loss: 0.1527 - model_3_loss: 0.1820 - model_4_loss: 0.1157 - model_accuracy: 0.9467 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9533 - model_3_accuracy: 0.9533 - model_4_accuracy: 0.9667 - loss1: 0.4710 - loss2: 5.2529 - val_loss: 103.7988 - val_model_loss: 10.3970 - val_model_1_loss: 9.6984 - val_model_2_loss: 10.4244 - val_model_3_loss: 10.1155 - val_model_4_loss: 10.6976 - val_model_accuracy: 0.0705 - val_model_1_accuracy: 0.0780 - val_model_2_accuracy: 0.0715 - val_model_3_accuracy: 0.0765 - val_model_4_accuracy: 0.0785 - val_loss1: 0.5443 - val_loss2: 5.1922\n","Epoch 203/300\n","30/30 [==============================] - 5s 152ms/step - loss: 53.4702 - model_loss: 0.1532 - model_1_loss: 0.0873 - model_2_loss: 0.0959 - model_3_loss: 0.1839 - model_4_loss: 0.1428 - model_accuracy: 0.9533 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9567 - loss1: 0.4774 - loss2: 5.2330 - val_loss: 103.0496 - val_model_loss: 9.7351 - val_model_1_loss: 9.9909 - val_model_2_loss: 10.0053 - val_model_3_loss: 9.7151 - val_model_4_loss: 10.8149 - val_model_accuracy: 0.0645 - val_model_1_accuracy: 0.0775 - val_model_2_accuracy: 0.0745 - val_model_3_accuracy: 0.0830 - val_model_4_accuracy: 0.0700 - val_loss1: 0.5029 - val_loss2: 5.2285\n","Epoch 204/300\n","30/30 [==============================] - 5s 155ms/step - loss: 53.7780 - model_loss: 0.0680 - model_1_loss: 0.0633 - model_2_loss: 0.0808 - model_3_loss: 0.1472 - model_4_loss: 0.1807 - model_accuracy: 0.9767 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9800 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9600 - loss1: 0.4381 - loss2: 5.2800 - val_loss: 104.7589 - val_model_loss: 10.1687 - val_model_1_loss: 9.6821 - val_model_2_loss: 9.5414 - val_model_3_loss: 10.0122 - val_model_4_loss: 12.1020 - val_model_accuracy: 0.0750 - val_model_1_accuracy: 0.0740 - val_model_2_accuracy: 0.0845 - val_model_3_accuracy: 0.0765 - val_model_4_accuracy: 0.0795 - val_loss1: 0.4691 - val_loss2: 5.2784\n","Epoch 205/300\n","30/30 [==============================] - 4s 152ms/step - loss: 53.4267 - model_loss: 0.0587 - model_1_loss: 0.0565 - model_2_loss: 0.0696 - model_3_loss: 0.0874 - model_4_loss: 0.1993 - model_accuracy: 0.9767 - model_1_accuracy: 0.9867 - model_2_accuracy: 0.9867 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9467 - loss1: 0.4556 - loss2: 5.2499 - val_loss: 103.9852 - val_model_loss: 9.8502 - val_model_1_loss: 9.8949 - val_model_2_loss: 9.6626 - val_model_3_loss: 10.1894 - val_model_4_loss: 11.4130 - val_model_accuracy: 0.0655 - val_model_1_accuracy: 0.0715 - val_model_2_accuracy: 0.0940 - val_model_3_accuracy: 0.0820 - val_model_4_accuracy: 0.0735 - val_loss1: 0.4716 - val_loss2: 5.2504\n","Epoch 206/300\n","30/30 [==============================] - 5s 153ms/step - loss: 54.7989 - model_loss: 0.1747 - model_1_loss: 0.2183 - model_2_loss: 0.1374 - model_3_loss: 0.1337 - model_4_loss: 0.2233 - model_accuracy: 0.9500 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9500 - model_4_accuracy: 0.9500 - loss1: 0.3921 - loss2: 5.3519 - val_loss: 104.8949 - val_model_loss: 10.7994 - val_model_1_loss: 9.9790 - val_model_2_loss: 9.4632 - val_model_3_loss: 9.7740 - val_model_4_loss: 11.6682 - val_model_accuracy: 0.0545 - val_model_1_accuracy: 0.0730 - val_model_2_accuracy: 0.0880 - val_model_3_accuracy: 0.0775 - val_model_4_accuracy: 0.0650 - val_loss1: 0.5429 - val_loss2: 5.2668\n","Epoch 207/300\n","30/30 [==============================] - 5s 153ms/step - loss: 52.8445 - model_loss: 0.2353 - model_1_loss: 0.0813 - model_2_loss: 0.1234 - model_3_loss: 0.0621 - model_4_loss: 0.1815 - model_accuracy: 0.9333 - model_1_accuracy: 0.9833 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9367 - loss1: 0.5400 - loss2: 5.1621 - val_loss: 103.8482 - val_model_loss: 11.0217 - val_model_1_loss: 8.9844 - val_model_2_loss: 10.4767 - val_model_3_loss: 9.7788 - val_model_4_loss: 10.8000 - val_model_accuracy: 0.0630 - val_model_1_accuracy: 0.0850 - val_model_2_accuracy: 0.0860 - val_model_3_accuracy: 0.0815 - val_model_4_accuracy: 0.0800 - val_loss1: 0.5339 - val_loss2: 5.2253\n","Epoch 208/300\n","30/30 [==============================] - 5s 154ms/step - loss: 54.1398 - model_loss: 0.2599 - model_1_loss: 0.0749 - model_2_loss: 0.0847 - model_3_loss: 0.0348 - model_4_loss: 0.1506 - model_accuracy: 0.9300 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9633 - loss1: 0.4239 - loss2: 5.3111 - val_loss: 103.2712 - val_model_loss: 10.6043 - val_model_1_loss: 9.2170 - val_model_2_loss: 9.9089 - val_model_3_loss: 9.2458 - val_model_4_loss: 12.0003 - val_model_accuracy: 0.0670 - val_model_1_accuracy: 0.0710 - val_model_2_accuracy: 0.0860 - val_model_3_accuracy: 0.0840 - val_model_4_accuracy: 0.0540 - val_loss1: 0.5419 - val_loss2: 5.1753\n","Epoch 209/300\n","30/30 [==============================] - 5s 157ms/step - loss: 54.7788 - model_loss: 0.1358 - model_1_loss: 0.1447 - model_2_loss: 0.1551 - model_3_loss: 0.0442 - model_4_loss: 0.1394 - model_accuracy: 0.9467 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9667 - loss1: 0.3725 - loss2: 5.3787 - val_loss: 101.6334 - val_model_loss: 9.8643 - val_model_1_loss: 9.3686 - val_model_2_loss: 9.1917 - val_model_3_loss: 9.3958 - val_model_4_loss: 10.0218 - val_model_accuracy: 0.0760 - val_model_1_accuracy: 0.0875 - val_model_2_accuracy: 0.0735 - val_model_3_accuracy: 0.0840 - val_model_4_accuracy: 0.0755 - val_loss1: 0.4289 - val_loss2: 5.3362\n","Epoch 210/300\n","30/30 [==============================] - 5s 156ms/step - loss: 53.5849 - model_loss: 0.1745 - model_1_loss: 0.1258 - model_2_loss: 0.0955 - model_3_loss: 0.0267 - model_4_loss: 0.0747 - model_accuracy: 0.9500 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9967 - model_4_accuracy: 0.9833 - loss1: 0.4517 - loss2: 5.2636 - val_loss: 101.4724 - val_model_loss: 10.1986 - val_model_1_loss: 10.9583 - val_model_2_loss: 8.6008 - val_model_3_loss: 9.2706 - val_model_4_loss: 9.7720 - val_model_accuracy: 0.0765 - val_model_1_accuracy: 0.0675 - val_model_2_accuracy: 0.0825 - val_model_3_accuracy: 0.0910 - val_model_4_accuracy: 0.0900 - val_loss1: 0.5170 - val_loss2: 5.2155\n","Epoch 211/300\n","30/30 [==============================] - 5s 153ms/step - loss: 54.0779 - model_loss: 0.0858 - model_1_loss: 0.1817 - model_2_loss: 0.0636 - model_3_loss: 0.0454 - model_4_loss: 0.0800 - model_accuracy: 0.9800 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9800 - loss1: 0.4063 - loss2: 5.3215 - val_loss: 102.5504 - val_model_loss: 10.0069 - val_model_1_loss: 10.2739 - val_model_2_loss: 8.8409 - val_model_3_loss: 9.2638 - val_model_4_loss: 10.2102 - val_model_accuracy: 0.0800 - val_model_1_accuracy: 0.0735 - val_model_2_accuracy: 0.0840 - val_model_3_accuracy: 0.0825 - val_model_4_accuracy: 0.0860 - val_loss1: 0.4138 - val_loss2: 5.3541\n","Epoch 212/300\n","30/30 [==============================] - 5s 152ms/step - loss: 54.5901 - model_loss: 0.0906 - model_1_loss: 0.1620 - model_2_loss: 0.0639 - model_3_loss: 0.0890 - model_4_loss: 0.0882 - model_accuracy: 0.9733 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9800 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9800 - loss1: 0.3821 - loss2: 5.3714 - val_loss: 102.2982 - val_model_loss: 9.9160 - val_model_1_loss: 10.1281 - val_model_2_loss: 9.0498 - val_model_3_loss: 9.6259 - val_model_4_loss: 11.0239 - val_model_accuracy: 0.0695 - val_model_1_accuracy: 0.0820 - val_model_2_accuracy: 0.0770 - val_model_3_accuracy: 0.0750 - val_model_4_accuracy: 0.0760 - val_loss1: 0.5314 - val_loss2: 5.2023\n","Epoch 213/300\n","30/30 [==============================] - 4s 151ms/step - loss: 53.0830 - model_loss: 0.0512 - model_1_loss: 0.1080 - model_2_loss: 0.1234 - model_3_loss: 0.1026 - model_4_loss: 0.0730 - model_accuracy: 0.9900 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9733 - loss1: 0.4746 - loss2: 5.2150 - val_loss: 101.6169 - val_model_loss: 9.5945 - val_model_1_loss: 9.7141 - val_model_2_loss: 9.1011 - val_model_3_loss: 9.7881 - val_model_4_loss: 10.0952 - val_model_accuracy: 0.0800 - val_model_1_accuracy: 0.0800 - val_model_2_accuracy: 0.0800 - val_model_3_accuracy: 0.0850 - val_model_4_accuracy: 0.0885 - val_loss1: 0.4719 - val_loss2: 5.2852\n","Epoch 214/300\n","30/30 [==============================] - 5s 154ms/step - loss: 53.6369 - model_loss: 0.0211 - model_1_loss: 0.0845 - model_2_loss: 0.0675 - model_3_loss: 0.0774 - model_4_loss: 0.0544 - model_accuracy: 1.0000 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9800 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9933 - loss1: 0.4278 - loss2: 5.2904 - val_loss: 102.5009 - val_model_loss: 9.4670 - val_model_1_loss: 10.5308 - val_model_2_loss: 8.9922 - val_model_3_loss: 10.6497 - val_model_4_loss: 10.0616 - val_model_accuracy: 0.0820 - val_model_1_accuracy: 0.0830 - val_model_2_accuracy: 0.0775 - val_model_3_accuracy: 0.0805 - val_model_4_accuracy: 0.0900 - val_loss1: 0.4977 - val_loss2: 5.2302\n","Epoch 215/300\n","30/30 [==============================] - 5s 156ms/step - loss: 54.1078 - model_loss: 0.0472 - model_1_loss: 0.1301 - model_2_loss: 0.1160 - model_3_loss: 0.1497 - model_4_loss: 0.1132 - model_accuracy: 0.9867 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9600 - loss1: 0.4067 - loss2: 5.3145 - val_loss: 101.4265 - val_model_loss: 9.4733 - val_model_1_loss: 9.9337 - val_model_2_loss: 9.3080 - val_model_3_loss: 9.7419 - val_model_4_loss: 9.7108 - val_model_accuracy: 0.0865 - val_model_1_accuracy: 0.0780 - val_model_2_accuracy: 0.0785 - val_model_3_accuracy: 0.0815 - val_model_4_accuracy: 0.0860 - val_loss1: 0.4819 - val_loss2: 5.2777\n","Epoch 216/300\n","30/30 [==============================] - 5s 158ms/step - loss: 53.0763 - model_loss: 0.0427 - model_1_loss: 0.0987 - model_2_loss: 0.1189 - model_3_loss: 0.1606 - model_4_loss: 0.1278 - model_accuracy: 0.9900 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9533 - model_4_accuracy: 0.9600 - loss1: 0.5033 - loss2: 5.2024 - val_loss: 101.3799 - val_model_loss: 10.0851 - val_model_1_loss: 9.7463 - val_model_2_loss: 9.5360 - val_model_3_loss: 10.3303 - val_model_4_loss: 10.9003 - val_model_accuracy: 0.0810 - val_model_1_accuracy: 0.0930 - val_model_2_accuracy: 0.0855 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0815 - val_loss1: 0.6485 - val_loss2: 5.0133\n","Epoch 217/300\n","30/30 [==============================] - 5s 159ms/step - loss: 52.8976 - model_loss: 0.0210 - model_1_loss: 0.0970 - model_2_loss: 0.0639 - model_3_loss: 0.0786 - model_4_loss: 0.0800 - model_accuracy: 0.9967 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9767 - loss1: 0.4833 - loss2: 5.2074 - val_loss: 103.8068 - val_model_loss: 9.3985 - val_model_1_loss: 9.7299 - val_model_2_loss: 9.6528 - val_model_3_loss: 9.5878 - val_model_4_loss: 11.7769 - val_model_accuracy: 0.0890 - val_model_1_accuracy: 0.0915 - val_model_2_accuracy: 0.0835 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0825 - val_loss1: 0.4394 - val_loss2: 5.3221\n","Epoch 218/300\n","30/30 [==============================] - 5s 159ms/step - loss: 53.1481 - model_loss: 0.0203 - model_1_loss: 0.1538 - model_2_loss: 0.0740 - model_3_loss: 0.1723 - model_4_loss: 0.0316 - model_accuracy: 0.9900 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9800 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9933 - loss1: 0.4637 - loss2: 5.2232 - val_loss: 101.5799 - val_model_loss: 9.0973 - val_model_1_loss: 9.7472 - val_model_2_loss: 9.9044 - val_model_3_loss: 9.8426 - val_model_4_loss: 10.1945 - val_model_accuracy: 0.0970 - val_model_1_accuracy: 0.0855 - val_model_2_accuracy: 0.0815 - val_model_3_accuracy: 0.0750 - val_model_4_accuracy: 0.0875 - val_loss1: 0.4833 - val_loss2: 5.2311\n","Epoch 219/300\n","30/30 [==============================] - 5s 153ms/step - loss: 53.7362 - model_loss: 0.0460 - model_1_loss: 0.0936 - model_2_loss: 0.0612 - model_3_loss: 0.0982 - model_4_loss: 0.0636 - model_accuracy: 0.9900 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9833 - loss1: 0.4238 - loss2: 5.2950 - val_loss: 104.3246 - val_model_loss: 9.3867 - val_model_1_loss: 9.9384 - val_model_2_loss: 10.4407 - val_model_3_loss: 10.4470 - val_model_4_loss: 10.1480 - val_model_accuracy: 0.0830 - val_model_1_accuracy: 0.0860 - val_model_2_accuracy: 0.0790 - val_model_3_accuracy: 0.0715 - val_model_4_accuracy: 0.0860 - val_loss1: 0.4203 - val_loss2: 5.3544\n","Epoch 220/300\n","30/30 [==============================] - 4s 150ms/step - loss: 53.8651 - model_loss: 0.0587 - model_1_loss: 0.1132 - model_2_loss: 0.0671 - model_3_loss: 0.0820 - model_4_loss: 0.1378 - model_accuracy: 0.9833 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9800 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9733 - loss1: 0.4217 - loss2: 5.2984 - val_loss: 105.5674 - val_model_loss: 9.6376 - val_model_1_loss: 9.9721 - val_model_2_loss: 10.1051 - val_model_3_loss: 10.6362 - val_model_4_loss: 11.2960 - val_model_accuracy: 0.0870 - val_model_1_accuracy: 0.0820 - val_model_2_accuracy: 0.0745 - val_model_3_accuracy: 0.0715 - val_model_4_accuracy: 0.0735 - val_loss1: 0.4323 - val_loss2: 5.3488\n","Epoch 221/300\n","30/30 [==============================] - 5s 156ms/step - loss: 53.3992 - model_loss: 0.0325 - model_1_loss: 0.0707 - model_2_loss: 0.0848 - model_3_loss: 0.0604 - model_4_loss: 0.1056 - model_accuracy: 0.9933 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9733 - loss1: 0.4450 - loss2: 5.2600 - val_loss: 102.8521 - val_model_loss: 9.7716 - val_model_1_loss: 9.6302 - val_model_2_loss: 9.5592 - val_model_3_loss: 9.9714 - val_model_4_loss: 10.9120 - val_model_accuracy: 0.0800 - val_model_1_accuracy: 0.0935 - val_model_2_accuracy: 0.0855 - val_model_3_accuracy: 0.0765 - val_model_4_accuracy: 0.0820 - val_loss1: 0.4827 - val_loss2: 5.2525\n","Epoch 222/300\n","30/30 [==============================] - 4s 150ms/step - loss: 53.3497 - model_loss: 0.0340 - model_1_loss: 0.0659 - model_2_loss: 0.0569 - model_3_loss: 0.0569 - model_4_loss: 0.1260 - model_accuracy: 0.9900 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9900 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9600 - loss1: 0.4493 - loss2: 5.2561 - val_loss: 101.8540 - val_model_loss: 9.3774 - val_model_1_loss: 9.2264 - val_model_2_loss: 9.2199 - val_model_3_loss: 9.4493 - val_model_4_loss: 11.2678 - val_model_accuracy: 0.0815 - val_model_1_accuracy: 0.0815 - val_model_2_accuracy: 0.0915 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0720 - val_loss1: 0.4531 - val_loss2: 5.2860\n","Epoch 223/300\n","30/30 [==============================] - 4s 152ms/step - loss: 54.1975 - model_loss: 0.0349 - model_1_loss: 0.0433 - model_2_loss: 0.0852 - model_3_loss: 0.0491 - model_4_loss: 0.0973 - model_accuracy: 0.9900 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9733 - loss1: 0.3905 - loss2: 5.3497 - val_loss: 103.2141 - val_model_loss: 9.9024 - val_model_1_loss: 9.9625 - val_model_2_loss: 9.6827 - val_model_3_loss: 9.7025 - val_model_4_loss: 9.9096 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0760 - val_model_2_accuracy: 0.0735 - val_model_3_accuracy: 0.0820 - val_model_4_accuracy: 0.0890 - val_loss1: 0.3986 - val_loss2: 5.3656\n","Epoch 224/300\n","30/30 [==============================] - 5s 155ms/step - loss: 53.8636 - model_loss: 0.0270 - model_1_loss: 0.0370 - model_2_loss: 0.1156 - model_3_loss: 0.1102 - model_4_loss: 0.0810 - model_accuracy: 0.9967 - model_1_accuracy: 0.9967 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9633 - loss1: 0.4027 - loss2: 5.3090 - val_loss: 102.5534 - val_model_loss: 9.6443 - val_model_1_loss: 9.1467 - val_model_2_loss: 10.1238 - val_model_3_loss: 9.6686 - val_model_4_loss: 10.4662 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0935 - val_model_2_accuracy: 0.0820 - val_model_3_accuracy: 0.0750 - val_model_4_accuracy: 0.0900 - val_loss1: 0.4284 - val_loss2: 5.3075\n","Epoch 225/300\n","30/30 [==============================] - 5s 155ms/step - loss: 54.4377 - model_loss: 0.0725 - model_1_loss: 0.0221 - model_2_loss: 0.1119 - model_3_loss: 0.1232 - model_4_loss: 0.0799 - model_accuracy: 0.9767 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9800 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9800 - loss1: 0.3707 - loss2: 5.3657 - val_loss: 102.8352 - val_model_loss: 10.2569 - val_model_1_loss: 8.8564 - val_model_2_loss: 9.8698 - val_model_3_loss: 9.9773 - val_model_4_loss: 9.8742 - val_model_accuracy: 0.0600 - val_model_1_accuracy: 0.0925 - val_model_2_accuracy: 0.0845 - val_model_3_accuracy: 0.0665 - val_model_4_accuracy: 0.0835 - val_loss1: 0.4004 - val_loss2: 5.3600\n","Epoch 226/300\n","30/30 [==============================] - 5s 154ms/step - loss: 53.9533 - model_loss: 0.0472 - model_1_loss: 0.0299 - model_2_loss: 0.0748 - model_3_loss: 0.1330 - model_4_loss: 0.0689 - model_accuracy: 0.9867 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9767 - loss1: 0.3944 - loss2: 5.3205 - val_loss: 102.5290 - val_model_loss: 9.7429 - val_model_1_loss: 8.4885 - val_model_2_loss: 11.3272 - val_model_3_loss: 10.0821 - val_model_4_loss: 10.3871 - val_model_accuracy: 0.0700 - val_model_1_accuracy: 0.0835 - val_model_2_accuracy: 0.0590 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0780 - val_loss1: 0.5023 - val_loss2: 5.1999\n","Epoch 227/300\n","30/30 [==============================] - 5s 155ms/step - loss: 53.9220 - model_loss: 0.0252 - model_1_loss: 0.0277 - model_2_loss: 0.1524 - model_3_loss: 0.1237 - model_4_loss: 0.0810 - model_accuracy: 0.9967 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9800 - loss1: 0.4075 - loss2: 5.3105 - val_loss: 102.8459 - val_model_loss: 9.8813 - val_model_1_loss: 8.8784 - val_model_2_loss: 10.9344 - val_model_3_loss: 10.5959 - val_model_4_loss: 10.8782 - val_model_accuracy: 0.0625 - val_model_1_accuracy: 0.0805 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0705 - val_model_4_accuracy: 0.0715 - val_loss1: 0.5686 - val_loss2: 5.1109\n","Epoch 228/300\n","30/30 [==============================] - 5s 155ms/step - loss: 53.5870 - model_loss: 0.0123 - model_1_loss: 0.0558 - model_2_loss: 0.1392 - model_3_loss: 0.1511 - model_4_loss: 0.1141 - model_accuracy: 1.0000 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9667 - loss1: 0.4297 - loss2: 5.2685 - val_loss: 100.0835 - val_model_loss: 9.5387 - val_model_1_loss: 8.5001 - val_model_2_loss: 9.7007 - val_model_3_loss: 10.1243 - val_model_4_loss: 10.0713 - val_model_accuracy: 0.0660 - val_model_1_accuracy: 0.0890 - val_model_2_accuracy: 0.0685 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0835 - val_loss1: 0.5292 - val_loss2: 5.1619\n","Epoch 229/300\n","30/30 [==============================] - 5s 155ms/step - loss: 53.8856 - model_loss: 0.0447 - model_1_loss: 0.0316 - model_2_loss: 0.1303 - model_3_loss: 0.2206 - model_4_loss: 0.1122 - model_accuracy: 0.9867 - model_1_accuracy: 0.9900 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9533 - model_4_accuracy: 0.9533 - loss1: 0.4320 - loss2: 5.2914 - val_loss: 102.2888 - val_model_loss: 9.2764 - val_model_1_loss: 8.7041 - val_model_2_loss: 10.0396 - val_model_3_loss: 10.6242 - val_model_4_loss: 10.5752 - val_model_accuracy: 0.0745 - val_model_1_accuracy: 0.0770 - val_model_2_accuracy: 0.0785 - val_model_3_accuracy: 0.0570 - val_model_4_accuracy: 0.0830 - val_loss1: 0.4704 - val_loss2: 5.2599\n","Epoch 230/300\n","30/30 [==============================] - 5s 155ms/step - loss: 54.1966 - model_loss: 0.0626 - model_1_loss: 0.0673 - model_2_loss: 0.0750 - model_3_loss: 0.1514 - model_4_loss: 0.0765 - model_accuracy: 0.9867 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9867 - loss1: 0.4051 - loss2: 5.3359 - val_loss: 103.2643 - val_model_loss: 9.9932 - val_model_1_loss: 8.9917 - val_model_2_loss: 10.0494 - val_model_3_loss: 10.2028 - val_model_4_loss: 10.5170 - val_model_accuracy: 0.0800 - val_model_1_accuracy: 0.0875 - val_model_2_accuracy: 0.0800 - val_model_3_accuracy: 0.0635 - val_model_4_accuracy: 0.0825 - val_loss1: 0.4436 - val_loss2: 5.3067\n","Epoch 231/300\n","30/30 [==============================] - 5s 155ms/step - loss: 53.7788 - model_loss: 0.0570 - model_1_loss: 0.1032 - model_2_loss: 0.1944 - model_3_loss: 0.0964 - model_4_loss: 0.0706 - model_accuracy: 0.9900 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9433 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9767 - loss1: 0.4334 - loss2: 5.2824 - val_loss: 104.4256 - val_model_loss: 10.2281 - val_model_1_loss: 9.1989 - val_model_2_loss: 12.0446 - val_model_3_loss: 10.1070 - val_model_4_loss: 10.8852 - val_model_accuracy: 0.0670 - val_model_1_accuracy: 0.0825 - val_model_2_accuracy: 0.0605 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0840 - val_loss1: 0.5802 - val_loss2: 5.1382\n","Epoch 232/300\n","30/30 [==============================] - 5s 158ms/step - loss: 53.2888 - model_loss: 0.0658 - model_1_loss: 0.0649 - model_2_loss: 0.1840 - model_3_loss: 0.0424 - model_4_loss: 0.0802 - model_accuracy: 0.9800 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9867 - loss1: 0.4757 - loss2: 5.2376 - val_loss: 104.7898 - val_model_loss: 9.9260 - val_model_1_loss: 9.8593 - val_model_2_loss: 11.0335 - val_model_3_loss: 9.7402 - val_model_4_loss: 11.0573 - val_model_accuracy: 0.0840 - val_model_1_accuracy: 0.0730 - val_model_2_accuracy: 0.0760 - val_model_3_accuracy: 0.0770 - val_model_4_accuracy: 0.0815 - val_loss1: 0.4861 - val_loss2: 5.2687\n","Epoch 233/300\n","30/30 [==============================] - 5s 155ms/step - loss: 54.0378 - model_loss: 0.0988 - model_1_loss: 0.0509 - model_2_loss: 0.0950 - model_3_loss: 0.0693 - model_4_loss: 0.0668 - model_accuracy: 0.9733 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9733 - loss1: 0.4033 - loss2: 5.3254 - val_loss: 104.9111 - val_model_loss: 9.5720 - val_model_1_loss: 9.5938 - val_model_2_loss: 11.6563 - val_model_3_loss: 10.8025 - val_model_4_loss: 10.0707 - val_model_accuracy: 0.0700 - val_model_1_accuracy: 0.0950 - val_model_2_accuracy: 0.0630 - val_model_3_accuracy: 0.0705 - val_model_4_accuracy: 0.0910 - val_loss1: 0.4711 - val_loss2: 5.2745\n","Epoch 234/300\n","30/30 [==============================] - 5s 156ms/step - loss: 53.9008 - model_loss: 0.1428 - model_1_loss: 0.0639 - model_2_loss: 0.1334 - model_3_loss: 0.1645 - model_4_loss: 0.0823 - model_accuracy: 0.9567 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9733 - loss1: 0.4145 - loss2: 5.2900 - val_loss: 102.6123 - val_model_loss: 10.0652 - val_model_1_loss: 9.6222 - val_model_2_loss: 9.7133 - val_model_3_loss: 10.2151 - val_model_4_loss: 9.9801 - val_model_accuracy: 0.0710 - val_model_1_accuracy: 0.0940 - val_model_2_accuracy: 0.0700 - val_model_3_accuracy: 0.0710 - val_model_4_accuracy: 0.0825 - val_loss1: 0.4595 - val_loss2: 5.2557\n","Epoch 235/300\n","30/30 [==============================] - 5s 153ms/step - loss: 54.6835 - model_loss: 0.2380 - model_1_loss: 0.0887 - model_2_loss: 0.1438 - model_3_loss: 0.1196 - model_4_loss: 0.1063 - model_accuracy: 0.9300 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9600 - model_4_accuracy: 0.9767 - loss1: 0.3700 - loss2: 5.3617 - val_loss: 105.9257 - val_model_loss: 10.9448 - val_model_1_loss: 10.3062 - val_model_2_loss: 10.9493 - val_model_3_loss: 10.1901 - val_model_4_loss: 9.8636 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0805 - val_model_2_accuracy: 0.0715 - val_model_3_accuracy: 0.0705 - val_model_4_accuracy: 0.0850 - val_loss1: 0.4325 - val_loss2: 5.3239\n","Epoch 236/300\n","30/30 [==============================] - 4s 152ms/step - loss: 53.4812 - model_loss: 0.2579 - model_1_loss: 0.1207 - model_2_loss: 0.1025 - model_3_loss: 0.0742 - model_4_loss: 0.1337 - model_accuracy: 0.9333 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9667 - loss1: 0.4793 - loss2: 5.2313 - val_loss: 105.7268 - val_model_loss: 12.0424 - val_model_1_loss: 9.5419 - val_model_2_loss: 11.3850 - val_model_3_loss: 10.2154 - val_model_4_loss: 10.6115 - val_model_accuracy: 0.0735 - val_model_1_accuracy: 0.0870 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0785 - val_model_4_accuracy: 0.0890 - val_loss1: 0.5929 - val_loss2: 5.1338\n","Epoch 237/300\n","30/30 [==============================] - 5s 154ms/step - loss: 53.6687 - model_loss: 0.1388 - model_1_loss: 0.0617 - model_2_loss: 0.1056 - model_3_loss: 0.0499 - model_4_loss: 0.0829 - model_accuracy: 0.9467 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9800 - loss1: 0.4483 - loss2: 5.2782 - val_loss: 106.7630 - val_model_loss: 11.8050 - val_model_1_loss: 9.6306 - val_model_2_loss: 11.6445 - val_model_3_loss: 10.1314 - val_model_4_loss: 10.7425 - val_model_accuracy: 0.0700 - val_model_1_accuracy: 0.0760 - val_model_2_accuracy: 0.0710 - val_model_3_accuracy: 0.0845 - val_model_4_accuracy: 0.0875 - val_loss1: 0.5045 - val_loss2: 5.2304\n","Epoch 238/300\n","30/30 [==============================] - 5s 155ms/step - loss: 52.9816 - model_loss: 0.1535 - model_1_loss: 0.1688 - model_2_loss: 0.1022 - model_3_loss: 0.0546 - model_4_loss: 0.1409 - model_accuracy: 0.9400 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9567 - loss1: 0.4823 - loss2: 5.1879 - val_loss: 107.9908 - val_model_loss: 10.8211 - val_model_1_loss: 10.8408 - val_model_2_loss: 10.8922 - val_model_3_loss: 9.9047 - val_model_4_loss: 12.5617 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0850 - val_model_2_accuracy: 0.0660 - val_model_3_accuracy: 0.0725 - val_model_4_accuracy: 0.0600 - val_loss1: 0.5017 - val_loss2: 5.2469\n","Epoch 239/300\n","30/30 [==============================] - 5s 154ms/step - loss: 54.0269 - model_loss: 0.2212 - model_1_loss: 0.2739 - model_2_loss: 0.1155 - model_3_loss: 0.0487 - model_4_loss: 0.0922 - model_accuracy: 0.9300 - model_1_accuracy: 0.9400 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9767 - loss1: 0.4377 - loss2: 5.2838 - val_loss: 106.7729 - val_model_loss: 11.5704 - val_model_1_loss: 11.4316 - val_model_2_loss: 9.7383 - val_model_3_loss: 10.5079 - val_model_4_loss: 10.7107 - val_model_accuracy: 0.0680 - val_model_1_accuracy: 0.0720 - val_model_2_accuracy: 0.0825 - val_model_3_accuracy: 0.0655 - val_model_4_accuracy: 0.0750 - val_loss1: 0.5231 - val_loss2: 5.2291\n","Epoch 240/300\n","30/30 [==============================] - 5s 155ms/step - loss: 52.5745 - model_loss: 0.2136 - model_1_loss: 0.1999 - model_2_loss: 0.1749 - model_3_loss: 0.0167 - model_4_loss: 0.1126 - model_accuracy: 0.9400 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9500 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9667 - loss1: 0.5453 - loss2: 5.1311 - val_loss: 105.8366 - val_model_loss: 12.5021 - val_model_1_loss: 11.2869 - val_model_2_loss: 10.7936 - val_model_3_loss: 9.8362 - val_model_4_loss: 10.3569 - val_model_accuracy: 0.0685 - val_model_1_accuracy: 0.0810 - val_model_2_accuracy: 0.0645 - val_model_3_accuracy: 0.0770 - val_model_4_accuracy: 0.0960 - val_loss1: 0.6316 - val_loss2: 5.0429\n","Epoch 241/300\n","30/30 [==============================] - 5s 156ms/step - loss: 52.6599 - model_loss: 0.0851 - model_1_loss: 0.1320 - model_2_loss: 0.1580 - model_3_loss: 0.0321 - model_4_loss: 0.1336 - model_accuracy: 0.9800 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9933 - model_4_accuracy: 0.9633 - loss1: 0.5122 - loss2: 5.1607 - val_loss: 104.6213 - val_model_loss: 10.6268 - val_model_1_loss: 10.3625 - val_model_2_loss: 10.3710 - val_model_3_loss: 10.0257 - val_model_4_loss: 10.9965 - val_model_accuracy: 0.0705 - val_model_1_accuracy: 0.0780 - val_model_2_accuracy: 0.0795 - val_model_3_accuracy: 0.0780 - val_model_4_accuracy: 0.0915 - val_loss1: 0.5287 - val_loss2: 5.1710\n","Epoch 242/300\n","30/30 [==============================] - 5s 158ms/step - loss: 53.4978 - model_loss: 0.0442 - model_1_loss: 0.1036 - model_2_loss: 0.1291 - model_3_loss: 0.0322 - model_4_loss: 0.0846 - model_accuracy: 0.9833 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9967 - model_4_accuracy: 0.9800 - loss1: 0.4410 - loss2: 5.2663 - val_loss: 103.5919 - val_model_loss: 9.7910 - val_model_1_loss: 9.5510 - val_model_2_loss: 10.6786 - val_model_3_loss: 9.6198 - val_model_4_loss: 10.6939 - val_model_accuracy: 0.0785 - val_model_1_accuracy: 0.0825 - val_model_2_accuracy: 0.0675 - val_model_3_accuracy: 0.0715 - val_model_4_accuracy: 0.0785 - val_loss1: 0.4538 - val_loss2: 5.2804\n","Epoch 243/300\n","30/30 [==============================] - 5s 156ms/step - loss: 52.8300 - model_loss: 0.0285 - model_1_loss: 0.1204 - model_2_loss: 0.1147 - model_3_loss: 0.0551 - model_4_loss: 0.0963 - model_accuracy: 0.9933 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9667 - loss1: 0.4802 - loss2: 5.1935 - val_loss: 101.6961 - val_model_loss: 9.5038 - val_model_1_loss: 9.5302 - val_model_2_loss: 10.2614 - val_model_3_loss: 10.3599 - val_model_4_loss: 10.3400 - val_model_accuracy: 0.0855 - val_model_1_accuracy: 0.0770 - val_model_2_accuracy: 0.0875 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0835 - val_loss1: 0.5850 - val_loss2: 5.1116\n","Epoch 244/300\n","30/30 [==============================] - 5s 160ms/step - loss: 52.8073 - model_loss: 0.0290 - model_1_loss: 0.0667 - model_2_loss: 0.1108 - model_3_loss: 0.1247 - model_4_loss: 0.0710 - model_accuracy: 0.9933 - model_1_accuracy: 0.9867 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9867 - loss1: 0.4751 - loss2: 5.1930 - val_loss: 102.2135 - val_model_loss: 9.2850 - val_model_1_loss: 9.8160 - val_model_2_loss: 10.3162 - val_model_3_loss: 10.3315 - val_model_4_loss: 10.3128 - val_model_accuracy: 0.0845 - val_model_1_accuracy: 0.0775 - val_model_2_accuracy: 0.0840 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0815 - val_loss1: 0.5307 - val_loss2: 5.1621\n","Epoch 245/300\n","30/30 [==============================] - 5s 156ms/step - loss: 53.1227 - model_loss: 0.0216 - model_1_loss: 0.0741 - model_2_loss: 0.1369 - model_3_loss: 0.0503 - model_4_loss: 0.0824 - model_accuracy: 0.9933 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9700 - loss1: 0.4553 - loss2: 5.2302 - val_loss: 102.7814 - val_model_loss: 9.6977 - val_model_1_loss: 9.2823 - val_model_2_loss: 10.5082 - val_model_3_loss: 9.8122 - val_model_4_loss: 10.8054 - val_model_accuracy: 0.0825 - val_model_1_accuracy: 0.0900 - val_model_2_accuracy: 0.0805 - val_model_3_accuracy: 0.0785 - val_model_4_accuracy: 0.0865 - val_loss1: 0.4951 - val_loss2: 5.2181\n","Epoch 246/300\n","30/30 [==============================] - 5s 157ms/step - loss: 53.8055 - model_loss: 0.0348 - model_1_loss: 0.0424 - model_2_loss: 0.0766 - model_3_loss: 0.0452 - model_4_loss: 0.1847 - model_accuracy: 0.9933 - model_1_accuracy: 0.9900 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9733 - loss1: 0.4146 - loss2: 5.3007 - val_loss: 102.7116 - val_model_loss: 9.9049 - val_model_1_loss: 9.4372 - val_model_2_loss: 9.8435 - val_model_3_loss: 9.9862 - val_model_4_loss: 11.5198 - val_model_accuracy: 0.0740 - val_model_1_accuracy: 0.0800 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0805 - val_model_4_accuracy: 0.0775 - val_loss1: 0.5512 - val_loss2: 5.1469\n","Epoch 247/300\n","30/30 [==============================] - 5s 153ms/step - loss: 52.7954 - model_loss: 0.0704 - model_1_loss: 0.1743 - model_2_loss: 0.0845 - model_3_loss: 0.0754 - model_4_loss: 0.0956 - model_accuracy: 0.9800 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9767 - loss1: 0.4899 - loss2: 5.1805 - val_loss: 101.2662 - val_model_loss: 9.8151 - val_model_1_loss: 9.6188 - val_model_2_loss: 9.2703 - val_model_3_loss: 9.7105 - val_model_4_loss: 10.2594 - val_model_accuracy: 0.0750 - val_model_1_accuracy: 0.0860 - val_model_2_accuracy: 0.0830 - val_model_3_accuracy: 0.0825 - val_model_4_accuracy: 0.0870 - val_loss1: 0.4829 - val_loss2: 5.2109\n","Epoch 248/300\n","30/30 [==============================] - 5s 155ms/step - loss: 53.1608 - model_loss: 0.0430 - model_1_loss: 0.2325 - model_2_loss: 0.1313 - model_3_loss: 0.0344 - model_4_loss: 0.0655 - model_accuracy: 0.9800 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9967 - model_4_accuracy: 0.9800 - loss1: 0.4515 - loss2: 5.2203 - val_loss: 103.7896 - val_model_loss: 9.9368 - val_model_1_loss: 11.0505 - val_model_2_loss: 9.7855 - val_model_3_loss: 9.7242 - val_model_4_loss: 9.7667 - val_model_accuracy: 0.0700 - val_model_1_accuracy: 0.0720 - val_model_2_accuracy: 0.0825 - val_model_3_accuracy: 0.0820 - val_model_4_accuracy: 0.0850 - val_loss1: 0.4395 - val_loss2: 5.3087\n","Epoch 249/300\n","30/30 [==============================] - 5s 156ms/step - loss: 52.9265 - model_loss: 0.0576 - model_1_loss: 0.0812 - model_2_loss: 0.0717 - model_3_loss: 0.0360 - model_4_loss: 0.0664 - model_accuracy: 0.9867 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9867 - loss1: 0.4684 - loss2: 5.2145 - val_loss: 101.3690 - val_model_loss: 10.1002 - val_model_1_loss: 10.2464 - val_model_2_loss: 9.7925 - val_model_3_loss: 9.8910 - val_model_4_loss: 9.6981 - val_model_accuracy: 0.0705 - val_model_1_accuracy: 0.0820 - val_model_2_accuracy: 0.0850 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0840 - val_loss1: 0.5400 - val_loss2: 5.1101\n","Epoch 250/300\n","30/30 [==============================] - 5s 153ms/step - loss: 53.1062 - model_loss: 0.0328 - model_1_loss: 0.0573 - model_2_loss: 0.0707 - model_3_loss: 0.0224 - model_4_loss: 0.0738 - model_accuracy: 0.9900 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9867 - model_3_accuracy: 0.9933 - model_4_accuracy: 0.9800 - loss1: 0.4409 - loss2: 5.2408 - val_loss: 101.6106 - val_model_loss: 10.2543 - val_model_1_loss: 9.6466 - val_model_2_loss: 9.2812 - val_model_3_loss: 9.6483 - val_model_4_loss: 9.4529 - val_model_accuracy: 0.0760 - val_model_1_accuracy: 0.0845 - val_model_2_accuracy: 0.0895 - val_model_3_accuracy: 0.0840 - val_model_4_accuracy: 0.0775 - val_loss1: 0.4173 - val_loss2: 5.2910\n","Epoch 251/300\n","30/30 [==============================] - 5s 156ms/step - loss: 54.1658 - model_loss: 0.1107 - model_1_loss: 0.0568 - model_2_loss: 0.0851 - model_3_loss: 0.0399 - model_4_loss: 0.0683 - model_accuracy: 0.9833 - model_1_accuracy: 0.9867 - model_2_accuracy: 0.9900 - model_3_accuracy: 0.9933 - model_4_accuracy: 0.9767 - loss1: 0.3672 - loss2: 5.3438 - val_loss: 102.6645 - val_model_loss: 10.1080 - val_model_1_loss: 9.0488 - val_model_2_loss: 9.4954 - val_model_3_loss: 9.3041 - val_model_4_loss: 11.3161 - val_model_accuracy: 0.0785 - val_model_1_accuracy: 0.0720 - val_model_2_accuracy: 0.0915 - val_model_3_accuracy: 0.0775 - val_model_4_accuracy: 0.0595 - val_loss1: 0.4138 - val_loss2: 5.2978\n","Epoch 252/300\n","30/30 [==============================] - 5s 156ms/step - loss: 53.2696 - model_loss: 0.0214 - model_1_loss: 0.0205 - model_2_loss: 0.0300 - model_3_loss: 0.0209 - model_4_loss: 0.0912 - model_accuracy: 0.9967 - model_1_accuracy: 0.9967 - model_2_accuracy: 0.9933 - model_3_accuracy: 0.9967 - model_4_accuracy: 0.9700 - loss1: 0.4146 - loss2: 5.2671 - val_loss: 101.4597 - val_model_loss: 10.0328 - val_model_1_loss: 9.2266 - val_model_2_loss: 9.5518 - val_model_3_loss: 9.2083 - val_model_4_loss: 10.6229 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0760 - val_model_2_accuracy: 0.0845 - val_model_3_accuracy: 0.0860 - val_model_4_accuracy: 0.0770 - val_loss1: 0.4481 - val_loss2: 5.2369\n","Epoch 253/300\n","30/30 [==============================] - 5s 156ms/step - loss: 53.0479 - model_loss: 0.0167 - model_1_loss: 0.0264 - model_2_loss: 0.1022 - model_3_loss: 0.0340 - model_4_loss: 0.1013 - model_accuracy: 1.0000 - model_1_accuracy: 0.9900 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9633 - loss1: 0.4274 - loss2: 5.2340 - val_loss: 101.4488 - val_model_loss: 9.7221 - val_model_1_loss: 8.9288 - val_model_2_loss: 9.8559 - val_model_3_loss: 9.5777 - val_model_4_loss: 10.4169 - val_model_accuracy: 0.0640 - val_model_1_accuracy: 0.0925 - val_model_2_accuracy: 0.0835 - val_model_3_accuracy: 0.0815 - val_model_4_accuracy: 0.0820 - val_loss1: 0.4413 - val_loss2: 5.2506\n","Epoch 254/300\n","30/30 [==============================] - 5s 154ms/step - loss: 54.1134 - model_loss: 0.0119 - model_1_loss: 0.0229 - model_2_loss: 0.0442 - model_3_loss: 0.0163 - model_4_loss: 0.0344 - model_accuracy: 1.0000 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9833 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9933 - loss1: 0.3471 - loss2: 5.3637 - val_loss: 101.5453 - val_model_loss: 9.6612 - val_model_1_loss: 8.9497 - val_model_2_loss: 9.6105 - val_model_3_loss: 9.4576 - val_model_4_loss: 10.6700 - val_model_accuracy: 0.0710 - val_model_1_accuracy: 0.0920 - val_model_2_accuracy: 0.0840 - val_model_3_accuracy: 0.0730 - val_model_4_accuracy: 0.0870 - val_loss1: 0.4194 - val_loss2: 5.2777\n","Epoch 255/300\n","30/30 [==============================] - 5s 154ms/step - loss: 53.8745 - model_loss: 0.0107 - model_1_loss: 0.0300 - model_2_loss: 0.0651 - model_3_loss: 0.0188 - model_4_loss: 0.0596 - model_accuracy: 1.0000 - model_1_accuracy: 0.9967 - model_2_accuracy: 0.9833 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9900 - loss1: 0.3527 - loss2: 5.3338 - val_loss: 101.9570 - val_model_loss: 9.4734 - val_model_1_loss: 8.6549 - val_model_2_loss: 9.7632 - val_model_3_loss: 9.3742 - val_model_4_loss: 10.8819 - val_model_accuracy: 0.0735 - val_model_1_accuracy: 0.0900 - val_model_2_accuracy: 0.0840 - val_model_3_accuracy: 0.0725 - val_model_4_accuracy: 0.0800 - val_loss1: 0.3742 - val_loss2: 5.3435\n","Epoch 256/300\n","30/30 [==============================] - 5s 155ms/step - loss: 54.4265 - model_loss: 0.0121 - model_1_loss: 0.0214 - model_2_loss: 0.0233 - model_3_loss: 0.0135 - model_4_loss: 0.1168 - model_accuracy: 0.9967 - model_1_accuracy: 0.9967 - model_2_accuracy: 0.9933 - model_3_accuracy: 1.0000 - model_4_accuracy: 0.9767 - loss1: 0.3182 - loss2: 5.3921 - val_loss: 101.6152 - val_model_loss: 9.4045 - val_model_1_loss: 8.8511 - val_model_2_loss: 9.3681 - val_model_3_loss: 9.4585 - val_model_4_loss: 10.4413 - val_model_accuracy: 0.0760 - val_model_1_accuracy: 0.0875 - val_model_2_accuracy: 0.0905 - val_model_3_accuracy: 0.0770 - val_model_4_accuracy: 0.0795 - val_loss1: 0.3655 - val_loss2: 5.3726\n","Epoch 257/300\n","30/30 [==============================] - 5s 156ms/step - loss: 55.1426 - model_loss: 0.0265 - model_1_loss: 0.0711 - model_2_loss: 0.1278 - model_3_loss: 0.0290 - model_4_loss: 0.0710 - model_accuracy: 0.9900 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9800 - model_3_accuracy: 0.9933 - model_4_accuracy: 0.9833 - loss1: 0.2938 - loss2: 5.4523 - val_loss: 104.0505 - val_model_loss: 9.3471 - val_model_1_loss: 9.5194 - val_model_2_loss: 10.1682 - val_model_3_loss: 9.7654 - val_model_4_loss: 10.9527 - val_model_accuracy: 0.0760 - val_model_1_accuracy: 0.0870 - val_model_2_accuracy: 0.0925 - val_model_3_accuracy: 0.0840 - val_model_4_accuracy: 0.0785 - val_loss1: 0.3737 - val_loss2: 5.3924\n","Epoch 258/300\n","30/30 [==============================] - 5s 156ms/step - loss: 54.6689 - model_loss: 0.0427 - model_1_loss: 0.0470 - model_2_loss: 0.0821 - model_3_loss: 0.0862 - model_4_loss: 0.0789 - model_accuracy: 0.9933 - model_1_accuracy: 0.9900 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9800 - loss1: 0.3396 - loss2: 5.3992 - val_loss: 102.1765 - val_model_loss: 9.5440 - val_model_1_loss: 9.7492 - val_model_2_loss: 9.4472 - val_model_3_loss: 10.0569 - val_model_4_loss: 10.0031 - val_model_accuracy: 0.0690 - val_model_1_accuracy: 0.0920 - val_model_2_accuracy: 0.0890 - val_model_3_accuracy: 0.0795 - val_model_4_accuracy: 0.0830 - val_loss1: 0.4669 - val_loss2: 5.2909\n","Epoch 259/300\n","30/30 [==============================] - 5s 156ms/step - loss: 54.3423 - model_loss: 0.1176 - model_1_loss: 0.0747 - model_2_loss: 0.0210 - model_3_loss: 0.1284 - model_4_loss: 0.0822 - model_accuracy: 0.9733 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9900 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9867 - loss1: 0.3584 - loss2: 5.3560 - val_loss: 104.3545 - val_model_loss: 10.4657 - val_model_1_loss: 9.4078 - val_model_2_loss: 9.1230 - val_model_3_loss: 10.9285 - val_model_4_loss: 10.5365 - val_model_accuracy: 0.0640 - val_model_1_accuracy: 0.0855 - val_model_2_accuracy: 0.0910 - val_model_3_accuracy: 0.0780 - val_model_4_accuracy: 0.0860 - val_loss1: 0.4161 - val_loss2: 5.3477\n","Epoch 260/300\n","30/30 [==============================] - 5s 155ms/step - loss: 54.2678 - model_loss: 0.0677 - model_1_loss: 0.0803 - model_2_loss: 0.0317 - model_3_loss: 0.1071 - model_4_loss: 0.0451 - model_accuracy: 0.9867 - model_1_accuracy: 0.9867 - model_2_accuracy: 0.9900 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9900 - loss1: 0.3696 - loss2: 5.3566 - val_loss: 104.4534 - val_model_loss: 10.4663 - val_model_1_loss: 9.6369 - val_model_2_loss: 9.6662 - val_model_3_loss: 10.9620 - val_model_4_loss: 10.7946 - val_model_accuracy: 0.0670 - val_model_1_accuracy: 0.0850 - val_model_2_accuracy: 0.0815 - val_model_3_accuracy: 0.0735 - val_model_4_accuracy: 0.0840 - val_loss1: 0.4617 - val_loss2: 5.2466\n","Epoch 261/300\n","30/30 [==============================] - 5s 159ms/step - loss: 54.3769 - model_loss: 0.1055 - model_1_loss: 0.1528 - model_2_loss: 0.0614 - model_3_loss: 0.1617 - model_4_loss: 0.0675 - model_accuracy: 0.9800 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9800 - model_3_accuracy: 0.9533 - model_4_accuracy: 0.9700 - loss1: 0.3761 - loss2: 5.3452 - val_loss: 105.9739 - val_model_loss: 10.1461 - val_model_1_loss: 10.0058 - val_model_2_loss: 9.6956 - val_model_3_loss: 10.9813 - val_model_4_loss: 10.6896 - val_model_accuracy: 0.0775 - val_model_1_accuracy: 0.0940 - val_model_2_accuracy: 0.0805 - val_model_3_accuracy: 0.0690 - val_model_4_accuracy: 0.0855 - val_loss1: 0.3849 - val_loss2: 5.4071\n","Epoch 262/300\n","30/30 [==============================] - 5s 160ms/step - loss: 54.1034 - model_loss: 0.0411 - model_1_loss: 0.1139 - model_2_loss: 0.0266 - model_3_loss: 0.1150 - model_4_loss: 0.0259 - model_accuracy: 0.9867 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9867 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9933 - loss1: 0.3667 - loss2: 5.3414 - val_loss: 105.8709 - val_model_loss: 10.8270 - val_model_1_loss: 10.3344 - val_model_2_loss: 9.3111 - val_model_3_loss: 10.5322 - val_model_4_loss: 10.3892 - val_model_accuracy: 0.0670 - val_model_1_accuracy: 0.0780 - val_model_2_accuracy: 0.0735 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0875 - val_loss1: 0.3752 - val_loss2: 5.4102\n","Epoch 263/300\n","30/30 [==============================] - 5s 161ms/step - loss: 54.3830 - model_loss: 0.0694 - model_1_loss: 0.0897 - model_2_loss: 0.0312 - model_3_loss: 0.1099 - model_4_loss: 0.0590 - model_accuracy: 0.9900 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9933 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9800 - loss1: 0.3624 - loss2: 5.3661 - val_loss: 104.5058 - val_model_loss: 9.6453 - val_model_1_loss: 10.2062 - val_model_2_loss: 9.5597 - val_model_3_loss: 10.7630 - val_model_4_loss: 10.5757 - val_model_accuracy: 0.0775 - val_model_1_accuracy: 0.0850 - val_model_2_accuracy: 0.0690 - val_model_3_accuracy: 0.0745 - val_model_4_accuracy: 0.0765 - val_loss1: 0.4240 - val_loss2: 5.3332\n","Epoch 264/300\n","30/30 [==============================] - 5s 157ms/step - loss: 54.5576 - model_loss: 0.0626 - model_1_loss: 0.0420 - model_2_loss: 0.0223 - model_3_loss: 0.1065 - model_4_loss: 0.0716 - model_accuracy: 0.9833 - model_1_accuracy: 0.9867 - model_2_accuracy: 0.9933 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9800 - loss1: 0.3370 - loss2: 5.3916 - val_loss: 105.7863 - val_model_loss: 10.2974 - val_model_1_loss: 9.5547 - val_model_2_loss: 8.9525 - val_model_3_loss: 10.2660 - val_model_4_loss: 11.4897 - val_model_accuracy: 0.0755 - val_model_1_accuracy: 0.0835 - val_model_2_accuracy: 0.0725 - val_model_3_accuracy: 0.0610 - val_model_4_accuracy: 0.0745 - val_loss1: 0.3015 - val_loss2: 5.4924\n","Epoch 265/300\n","30/30 [==============================] - 5s 157ms/step - loss: 55.9726 - model_loss: 0.1215 - model_1_loss: 0.0546 - model_2_loss: 0.0467 - model_3_loss: 0.2399 - model_4_loss: 0.1196 - model_accuracy: 0.9767 - model_1_accuracy: 0.9833 - model_2_accuracy: 0.9933 - model_3_accuracy: 0.9267 - model_4_accuracy: 0.9633 - loss1: 0.2738 - loss2: 5.5117 - val_loss: 108.1183 - val_model_loss: 11.1369 - val_model_1_loss: 9.6991 - val_model_2_loss: 9.5029 - val_model_3_loss: 11.1966 - val_model_4_loss: 11.7144 - val_model_accuracy: 0.0735 - val_model_1_accuracy: 0.0900 - val_model_2_accuracy: 0.0825 - val_model_3_accuracy: 0.0705 - val_model_4_accuracy: 0.0670 - val_loss1: 0.3432 - val_loss2: 5.4525\n","Epoch 266/300\n","30/30 [==============================] - 5s 159ms/step - loss: 54.8947 - model_loss: 0.1478 - model_1_loss: 0.0886 - model_2_loss: 0.0280 - model_3_loss: 0.1457 - model_4_loss: 0.2460 - model_accuracy: 0.9600 - model_1_accuracy: 0.9833 - model_2_accuracy: 0.9967 - model_3_accuracy: 0.9700 - model_4_accuracy: 0.9600 - loss1: 0.3462 - loss2: 5.3892 - val_loss: 109.9646 - val_model_loss: 14.0247 - val_model_1_loss: 9.8775 - val_model_2_loss: 9.2377 - val_model_3_loss: 11.6141 - val_model_4_loss: 11.5191 - val_model_accuracy: 0.0530 - val_model_1_accuracy: 0.0880 - val_model_2_accuracy: 0.0795 - val_model_3_accuracy: 0.0695 - val_model_4_accuracy: 0.0790 - val_loss1: 0.4325 - val_loss2: 5.3259\n","Epoch 267/300\n","30/30 [==============================] - 5s 156ms/step - loss: 55.7135 - model_loss: 0.2276 - model_1_loss: 0.0849 - model_2_loss: 0.0356 - model_3_loss: 0.2686 - model_4_loss: 0.0728 - model_accuracy: 0.9467 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9867 - model_3_accuracy: 0.9433 - model_4_accuracy: 0.9767 - loss1: 0.3063 - loss2: 5.4718 - val_loss: 107.1183 - val_model_loss: 11.4186 - val_model_1_loss: 10.3358 - val_model_2_loss: 9.6387 - val_model_3_loss: 11.0495 - val_model_4_loss: 10.7801 - val_model_accuracy: 0.0615 - val_model_1_accuracy: 0.0860 - val_model_2_accuracy: 0.0855 - val_model_3_accuracy: 0.0680 - val_model_4_accuracy: 0.0765 - val_loss1: 0.4229 - val_loss2: 5.3473\n","Epoch 268/300\n","30/30 [==============================] - 5s 161ms/step - loss: 54.7515 - model_loss: 0.1754 - model_1_loss: 0.1253 - model_2_loss: 0.0209 - model_3_loss: 0.1713 - model_4_loss: 0.1097 - model_accuracy: 0.9400 - model_1_accuracy: 0.9667 - model_2_accuracy: 0.9967 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9700 - loss1: 0.3616 - loss2: 5.3787 - val_loss: 106.3651 - val_model_loss: 10.7801 - val_model_1_loss: 9.5089 - val_model_2_loss: 9.4304 - val_model_3_loss: 10.9567 - val_model_4_loss: 10.8694 - val_model_accuracy: 0.0715 - val_model_1_accuracy: 0.0985 - val_model_2_accuracy: 0.0900 - val_model_3_accuracy: 0.0790 - val_model_4_accuracy: 0.0880 - val_loss1: 0.3521 - val_loss2: 5.4467\n","Epoch 269/300\n","30/30 [==============================] - 5s 154ms/step - loss: 55.2814 - model_loss: 0.2060 - model_1_loss: 0.1164 - model_2_loss: 0.0248 - model_3_loss: 0.1159 - model_4_loss: 0.1412 - model_accuracy: 0.9333 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9933 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9467 - loss1: 0.3284 - loss2: 5.4349 - val_loss: 108.3403 - val_model_loss: 10.9555 - val_model_1_loss: 9.6037 - val_model_2_loss: 9.8089 - val_model_3_loss: 10.7459 - val_model_4_loss: 12.3619 - val_model_accuracy: 0.0665 - val_model_1_accuracy: 0.0855 - val_model_2_accuracy: 0.0765 - val_model_3_accuracy: 0.0720 - val_model_4_accuracy: 0.0765 - val_loss1: 0.4092 - val_loss2: 5.4455\n","Epoch 270/300\n","30/30 [==============================] - 5s 153ms/step - loss: 54.0434 - model_loss: 0.1926 - model_1_loss: 0.0539 - model_2_loss: 0.0128 - model_3_loss: 0.1526 - model_4_loss: 0.1808 - model_accuracy: 0.9467 - model_1_accuracy: 0.9833 - model_2_accuracy: 0.9967 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9500 - loss1: 0.4230 - loss2: 5.3028 - val_loss: 108.3768 - val_model_loss: 11.4075 - val_model_1_loss: 10.2393 - val_model_2_loss: 9.4034 - val_model_3_loss: 10.5628 - val_model_4_loss: 12.3773 - val_model_accuracy: 0.0665 - val_model_1_accuracy: 0.0890 - val_model_2_accuracy: 0.0950 - val_model_3_accuracy: 0.0690 - val_model_4_accuracy: 0.0800 - val_loss1: 0.4028 - val_loss2: 5.3984\n","Epoch 271/300\n","30/30 [==============================] - 5s 160ms/step - loss: 56.0764 - model_loss: 0.2321 - model_1_loss: 0.0350 - model_2_loss: 0.0572 - model_3_loss: 0.1418 - model_4_loss: 0.1506 - model_accuracy: 0.9233 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9800 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9533 - loss1: 0.2829 - loss2: 5.5177 - val_loss: 107.7232 - val_model_loss: 11.7632 - val_model_1_loss: 9.7790 - val_model_2_loss: 9.5470 - val_model_3_loss: 10.3918 - val_model_4_loss: 10.7170 - val_model_accuracy: 0.0665 - val_model_1_accuracy: 0.0825 - val_model_2_accuracy: 0.0905 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0800 - val_loss1: 0.3319 - val_loss2: 5.5193\n","Epoch 272/300\n","30/30 [==============================] - 5s 166ms/step - loss: 55.5900 - model_loss: 0.1123 - model_1_loss: 0.0198 - model_2_loss: 0.0263 - model_3_loss: 0.1767 - model_4_loss: 0.0586 - model_accuracy: 0.9667 - model_1_accuracy: 0.9967 - model_2_accuracy: 0.9967 - model_3_accuracy: 0.9567 - model_4_accuracy: 0.9767 - loss1: 0.3022 - loss2: 5.4894 - val_loss: 106.2201 - val_model_loss: 10.8635 - val_model_1_loss: 9.5501 - val_model_2_loss: 9.4953 - val_model_3_loss: 10.2252 - val_model_4_loss: 11.2250 - val_model_accuracy: 0.0815 - val_model_1_accuracy: 0.0905 - val_model_2_accuracy: 0.0905 - val_model_3_accuracy: 0.0855 - val_model_4_accuracy: 0.0850 - val_loss1: 0.3540 - val_loss2: 5.4507\n","Epoch 273/300\n","30/30 [==============================] - 5s 161ms/step - loss: 55.5981 - model_loss: 0.0557 - model_1_loss: 0.0198 - model_2_loss: 0.0192 - model_3_loss: 0.0637 - model_4_loss: 0.0513 - model_accuracy: 0.9867 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9967 - model_3_accuracy: 0.9933 - model_4_accuracy: 0.9800 - loss1: 0.2797 - loss2: 5.5109 - val_loss: 105.4214 - val_model_loss: 10.4057 - val_model_1_loss: 9.1040 - val_model_2_loss: 9.2823 - val_model_3_loss: 9.9982 - val_model_4_loss: 11.2007 - val_model_accuracy: 0.0810 - val_model_1_accuracy: 0.0875 - val_model_2_accuracy: 0.0865 - val_model_3_accuracy: 0.0815 - val_model_4_accuracy: 0.0785 - val_loss1: 0.3042 - val_loss2: 5.5126\n","Epoch 274/300\n","30/30 [==============================] - 5s 161ms/step - loss: 56.6482 - model_loss: 0.0886 - model_1_loss: 0.0605 - model_2_loss: 0.0463 - model_3_loss: 0.0923 - model_4_loss: 0.0926 - model_accuracy: 0.9833 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9867 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9767 - loss1: 0.2310 - loss2: 5.6037 - val_loss: 105.6268 - val_model_loss: 10.0999 - val_model_1_loss: 9.4515 - val_model_2_loss: 9.6099 - val_model_3_loss: 9.9914 - val_model_4_loss: 11.0907 - val_model_accuracy: 0.0895 - val_model_1_accuracy: 0.0900 - val_model_2_accuracy: 0.0950 - val_model_3_accuracy: 0.0815 - val_model_4_accuracy: 0.0850 - val_loss1: 0.3346 - val_loss2: 5.5049\n","Epoch 275/300\n","30/30 [==============================] - 5s 161ms/step - loss: 56.0328 - model_loss: 0.0432 - model_1_loss: 0.0269 - model_2_loss: 0.1500 - model_3_loss: 0.1484 - model_4_loss: 0.1636 - model_accuracy: 0.9833 - model_1_accuracy: 0.9933 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9700 - loss1: 0.2916 - loss2: 5.5209 - val_loss: 104.4445 - val_model_loss: 10.1299 - val_model_1_loss: 9.8304 - val_model_2_loss: 10.0345 - val_model_3_loss: 10.5911 - val_model_4_loss: 11.0617 - val_model_accuracy: 0.0920 - val_model_1_accuracy: 0.0900 - val_model_2_accuracy: 0.0850 - val_model_3_accuracy: 0.0790 - val_model_4_accuracy: 0.0820 - val_loss1: 0.5341 - val_loss2: 5.2263\n","Epoch 276/300\n","30/30 [==============================] - 5s 157ms/step - loss: 54.7927 - model_loss: 0.0474 - model_1_loss: 0.0298 - model_2_loss: 0.2256 - model_3_loss: 0.0698 - model_4_loss: 0.0962 - model_accuracy: 0.9833 - model_1_accuracy: 0.9900 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9800 - loss1: 0.3656 - loss2: 5.3958 - val_loss: 105.4666 - val_model_loss: 10.5851 - val_model_1_loss: 9.8059 - val_model_2_loss: 10.9104 - val_model_3_loss: 10.6837 - val_model_4_loss: 11.4145 - val_model_accuracy: 0.0745 - val_model_1_accuracy: 0.0925 - val_model_2_accuracy: 0.0720 - val_model_3_accuracy: 0.0755 - val_model_4_accuracy: 0.0850 - val_loss1: 0.5612 - val_loss2: 5.1506\n","Epoch 277/300\n","30/30 [==============================] - 5s 158ms/step - loss: 54.2756 - model_loss: 0.1235 - model_1_loss: 0.0454 - model_2_loss: 0.2213 - model_3_loss: 0.1571 - model_4_loss: 0.0774 - model_accuracy: 0.9800 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.9533 - model_4_accuracy: 0.9767 - loss1: 0.4159 - loss2: 5.3235 - val_loss: 106.4415 - val_model_loss: 10.1163 - val_model_1_loss: 10.0964 - val_model_2_loss: 12.0637 - val_model_3_loss: 11.0833 - val_model_4_loss: 11.9461 - val_model_accuracy: 0.0780 - val_model_1_accuracy: 0.0915 - val_model_2_accuracy: 0.0700 - val_model_3_accuracy: 0.0770 - val_model_4_accuracy: 0.0835 - val_loss1: 0.6245 - val_loss2: 5.0511\n","Epoch 278/300\n","30/30 [==============================] - 5s 159ms/step - loss: 53.2020 - model_loss: 0.0496 - model_1_loss: 0.1110 - model_2_loss: 0.2632 - model_3_loss: 0.1146 - model_4_loss: 0.0451 - model_accuracy: 0.9867 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9367 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9767 - loss1: 0.4885 - loss2: 5.2130 - val_loss: 107.2808 - val_model_loss: 10.1203 - val_model_1_loss: 11.5620 - val_model_2_loss: 10.8335 - val_model_3_loss: 10.4310 - val_model_4_loss: 10.7384 - val_model_accuracy: 0.0780 - val_model_1_accuracy: 0.0815 - val_model_2_accuracy: 0.0720 - val_model_3_accuracy: 0.0770 - val_model_4_accuracy: 0.0895 - val_loss1: 0.4778 - val_loss2: 5.3118\n","Epoch 279/300\n","30/30 [==============================] - 5s 156ms/step - loss: 54.1664 - model_loss: 0.0257 - model_1_loss: 0.2042 - model_2_loss: 0.1542 - model_3_loss: 0.1131 - model_4_loss: 0.0782 - model_accuracy: 0.9967 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9433 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9833 - loss1: 0.4221 - loss2: 5.3169 - val_loss: 106.9349 - val_model_loss: 9.8626 - val_model_1_loss: 11.0593 - val_model_2_loss: 11.5189 - val_model_3_loss: 9.8206 - val_model_4_loss: 11.5290 - val_model_accuracy: 0.0760 - val_model_1_accuracy: 0.0725 - val_model_2_accuracy: 0.0645 - val_model_3_accuracy: 0.0810 - val_model_4_accuracy: 0.0735 - val_loss1: 0.4772 - val_loss2: 5.2667\n","Epoch 280/300\n","30/30 [==============================] - 5s 157ms/step - loss: 53.9296 - model_loss: 0.0237 - model_1_loss: 0.1459 - model_2_loss: 0.1297 - model_3_loss: 0.0818 - model_4_loss: 0.0722 - model_accuracy: 0.9967 - model_1_accuracy: 0.9567 - model_2_accuracy: 0.9500 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9700 - loss1: 0.3991 - loss2: 5.3077 - val_loss: 107.5027 - val_model_loss: 9.6880 - val_model_1_loss: 11.4305 - val_model_2_loss: 12.0297 - val_model_3_loss: 10.1262 - val_model_4_loss: 10.2358 - val_model_accuracy: 0.0815 - val_model_1_accuracy: 0.0665 - val_model_2_accuracy: 0.0625 - val_model_3_accuracy: 0.0790 - val_model_4_accuracy: 0.0960 - val_loss1: 0.4291 - val_loss2: 5.3563\n","Epoch 281/300\n","30/30 [==============================] - 5s 161ms/step - loss: 53.8413 - model_loss: 0.0271 - model_1_loss: 0.1468 - model_2_loss: 0.1545 - model_3_loss: 0.0799 - model_4_loss: 0.0415 - model_accuracy: 0.9967 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9567 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9833 - loss1: 0.4260 - loss2: 5.2965 - val_loss: 106.0550 - val_model_loss: 9.9929 - val_model_1_loss: 11.5603 - val_model_2_loss: 11.9570 - val_model_3_loss: 10.1788 - val_model_4_loss: 9.8448 - val_model_accuracy: 0.0765 - val_model_1_accuracy: 0.0570 - val_model_2_accuracy: 0.0725 - val_model_3_accuracy: 0.0715 - val_model_4_accuracy: 0.0890 - val_loss1: 0.5337 - val_loss2: 5.1988\n","Epoch 282/300\n","30/30 [==============================] - 5s 158ms/step - loss: 53.2949 - model_loss: 0.0663 - model_1_loss: 0.2342 - model_2_loss: 0.1548 - model_3_loss: 0.0542 - model_4_loss: 0.0536 - model_accuracy: 0.9833 - model_1_accuracy: 0.9500 - model_2_accuracy: 0.9433 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9867 - loss1: 0.4608 - loss2: 5.2271 - val_loss: 108.4518 - val_model_loss: 10.1142 - val_model_1_loss: 12.7352 - val_model_2_loss: 11.6385 - val_model_3_loss: 11.2030 - val_model_4_loss: 10.1027 - val_model_accuracy: 0.0785 - val_model_1_accuracy: 0.0665 - val_model_2_accuracy: 0.0720 - val_model_3_accuracy: 0.0715 - val_model_4_accuracy: 0.0925 - val_loss1: 0.5084 - val_loss2: 5.2150\n","Epoch 283/300\n","30/30 [==============================] - 5s 156ms/step - loss: 53.8229 - model_loss: 0.0286 - model_1_loss: 0.2602 - model_2_loss: 0.0845 - model_3_loss: 0.0816 - model_4_loss: 0.0645 - model_accuracy: 0.9900 - model_1_accuracy: 0.9267 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9867 - loss1: 0.4298 - loss2: 5.2874 - val_loss: 107.2377 - val_model_loss: 9.7799 - val_model_1_loss: 12.2656 - val_model_2_loss: 11.0867 - val_model_3_loss: 10.6412 - val_model_4_loss: 10.6103 - val_model_accuracy: 0.0850 - val_model_1_accuracy: 0.0760 - val_model_2_accuracy: 0.0720 - val_model_3_accuracy: 0.0750 - val_model_4_accuracy: 0.0875 - val_loss1: 0.4962 - val_loss2: 5.2358\n","Epoch 284/300\n","30/30 [==============================] - 5s 157ms/step - loss: 53.9813 - model_loss: 0.0373 - model_1_loss: 0.1695 - model_2_loss: 0.1690 - model_3_loss: 0.0523 - model_4_loss: 0.0812 - model_accuracy: 0.9833 - model_1_accuracy: 0.9600 - model_2_accuracy: 0.9533 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9700 - loss1: 0.4111 - loss2: 5.3061 - val_loss: 105.8660 - val_model_loss: 10.1267 - val_model_1_loss: 11.7425 - val_model_2_loss: 11.0340 - val_model_3_loss: 9.8555 - val_model_4_loss: 10.6729 - val_model_accuracy: 0.0755 - val_model_1_accuracy: 0.0735 - val_model_2_accuracy: 0.0800 - val_model_3_accuracy: 0.0785 - val_model_4_accuracy: 0.0900 - val_loss1: 0.5371 - val_loss2: 5.1897\n","Epoch 285/300\n","30/30 [==============================] - 5s 156ms/step - loss: 52.4865 - model_loss: 0.1244 - model_1_loss: 0.0960 - model_2_loss: 0.1114 - model_3_loss: 0.0310 - model_4_loss: 0.1652 - model_accuracy: 0.9800 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9667 - loss1: 0.5107 - loss2: 5.1448 - val_loss: 105.7244 - val_model_loss: 10.6267 - val_model_1_loss: 11.5626 - val_model_2_loss: 10.9487 - val_model_3_loss: 10.0564 - val_model_4_loss: 11.0528 - val_model_accuracy: 0.0735 - val_model_1_accuracy: 0.0855 - val_model_2_accuracy: 0.0695 - val_model_3_accuracy: 0.0745 - val_model_4_accuracy: 0.0820 - val_loss1: 0.5598 - val_loss2: 5.0917\n","Epoch 286/300\n","30/30 [==============================] - 5s 156ms/step - loss: 52.2351 - model_loss: 0.0358 - model_1_loss: 0.1247 - model_2_loss: 0.2316 - model_3_loss: 0.0406 - model_4_loss: 0.0994 - model_accuracy: 0.9933 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9467 - model_3_accuracy: 0.9900 - model_4_accuracy: 0.9733 - loss1: 0.5079 - loss2: 5.1195 - val_loss: 104.8400 - val_model_loss: 10.5080 - val_model_1_loss: 11.5232 - val_model_2_loss: 11.1155 - val_model_3_loss: 9.7088 - val_model_4_loss: 10.5636 - val_model_accuracy: 0.0730 - val_model_1_accuracy: 0.0825 - val_model_2_accuracy: 0.0740 - val_model_3_accuracy: 0.0845 - val_model_4_accuracy: 0.0905 - val_loss1: 0.5337 - val_loss2: 5.0887\n","Epoch 287/300\n","30/30 [==============================] - 5s 159ms/step - loss: 52.6780 - model_loss: 0.0692 - model_1_loss: 0.1530 - model_2_loss: 0.1754 - model_3_loss: 0.0465 - model_4_loss: 0.0661 - model_accuracy: 0.9767 - model_1_accuracy: 0.9533 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9967 - model_4_accuracy: 0.9833 - loss1: 0.4740 - loss2: 5.1694 - val_loss: 106.3220 - val_model_loss: 10.1369 - val_model_1_loss: 11.4119 - val_model_2_loss: 10.8988 - val_model_3_loss: 9.9267 - val_model_4_loss: 10.3182 - val_model_accuracy: 0.0725 - val_model_1_accuracy: 0.0805 - val_model_2_accuracy: 0.0845 - val_model_3_accuracy: 0.0850 - val_model_4_accuracy: 0.0880 - val_loss1: 0.4160 - val_loss2: 5.3214\n","Epoch 288/300\n","30/30 [==============================] - 5s 158ms/step - loss: 52.4311 - model_loss: 0.0518 - model_1_loss: 0.1240 - model_2_loss: 0.1431 - model_3_loss: 0.0309 - model_4_loss: 0.0467 - model_accuracy: 0.9800 - model_1_accuracy: 0.9733 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9933 - model_4_accuracy: 0.9867 - loss1: 0.4883 - loss2: 5.1546 - val_loss: 104.1493 - val_model_loss: 10.3862 - val_model_1_loss: 10.8794 - val_model_2_loss: 11.3200 - val_model_3_loss: 9.7590 - val_model_4_loss: 10.3520 - val_model_accuracy: 0.0760 - val_model_1_accuracy: 0.0720 - val_model_2_accuracy: 0.0705 - val_model_3_accuracy: 0.0785 - val_model_4_accuracy: 0.0890 - val_loss1: 0.5448 - val_loss2: 5.0908\n","Epoch 289/300\n","30/30 [==============================] - 5s 157ms/step - loss: 52.5210 - model_loss: 0.1096 - model_1_loss: 0.1413 - model_2_loss: 0.1425 - model_3_loss: 0.0323 - model_4_loss: 0.0961 - model_accuracy: 0.9767 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9933 - model_4_accuracy: 0.9867 - loss1: 0.4891 - loss2: 5.1510 - val_loss: 107.3807 - val_model_loss: 10.8627 - val_model_1_loss: 11.2693 - val_model_2_loss: 12.3084 - val_model_3_loss: 9.9387 - val_model_4_loss: 10.4820 - val_model_accuracy: 0.0770 - val_model_1_accuracy: 0.0685 - val_model_2_accuracy: 0.0640 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0810 - val_loss1: 0.4918 - val_loss2: 5.2028\n","Epoch 290/300\n","30/30 [==============================] - 5s 160ms/step - loss: 52.9514 - model_loss: 0.1252 - model_1_loss: 0.1560 - model_2_loss: 0.1699 - model_3_loss: 0.0355 - model_4_loss: 0.0424 - model_accuracy: 0.9700 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9467 - model_3_accuracy: 0.9867 - model_4_accuracy: 0.9833 - loss1: 0.4733 - loss2: 5.1949 - val_loss: 105.8274 - val_model_loss: 10.6978 - val_model_1_loss: 11.3373 - val_model_2_loss: 10.8425 - val_model_3_loss: 9.9389 - val_model_4_loss: 11.0124 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0745 - val_model_2_accuracy: 0.0745 - val_model_3_accuracy: 0.0820 - val_model_4_accuracy: 0.0790 - val_loss1: 0.5294 - val_loss2: 5.1469\n","Epoch 291/300\n","30/30 [==============================] - 5s 155ms/step - loss: 52.1593 - model_loss: 0.0715 - model_1_loss: 0.0699 - model_2_loss: 0.0862 - model_3_loss: 0.0586 - model_4_loss: 0.0676 - model_accuracy: 0.9867 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9767 - model_4_accuracy: 0.9767 - loss1: 0.4873 - loss2: 5.1318 - val_loss: 106.6131 - val_model_loss: 11.1504 - val_model_1_loss: 10.6569 - val_model_2_loss: 11.0218 - val_model_3_loss: 10.1729 - val_model_4_loss: 10.6652 - val_model_accuracy: 0.0685 - val_model_1_accuracy: 0.0790 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0805 - val_model_4_accuracy: 0.0900 - val_loss1: 0.4739 - val_loss2: 5.2472\n","Epoch 292/300\n","30/30 [==============================] - 5s 157ms/step - loss: 53.3029 - model_loss: 0.0314 - model_1_loss: 0.1196 - model_2_loss: 0.1360 - model_3_loss: 0.0613 - model_4_loss: 0.0886 - model_accuracy: 0.9967 - model_1_accuracy: 0.9633 - model_2_accuracy: 0.9700 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9800 - loss1: 0.4220 - loss2: 5.2444 - val_loss: 106.3610 - val_model_loss: 10.0447 - val_model_1_loss: 10.7586 - val_model_2_loss: 11.2481 - val_model_3_loss: 10.5042 - val_model_4_loss: 10.9581 - val_model_accuracy: 0.0755 - val_model_1_accuracy: 0.0880 - val_model_2_accuracy: 0.0750 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0820 - val_loss1: 0.4766 - val_loss2: 5.2371\n","Epoch 293/300\n","30/30 [==============================] - 5s 160ms/step - loss: 53.4149 - model_loss: 0.0200 - model_1_loss: 0.1375 - model_2_loss: 0.1066 - model_3_loss: 0.0969 - model_4_loss: 0.0311 - model_accuracy: 0.9967 - model_1_accuracy: 0.9700 - model_2_accuracy: 0.9667 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9933 - loss1: 0.4053 - loss2: 5.2617 - val_loss: 108.2421 - val_model_loss: 9.9330 - val_model_1_loss: 11.2587 - val_model_2_loss: 11.3176 - val_model_3_loss: 10.4456 - val_model_4_loss: 11.3709 - val_model_accuracy: 0.0825 - val_model_1_accuracy: 0.0835 - val_model_2_accuracy: 0.0855 - val_model_3_accuracy: 0.0880 - val_model_4_accuracy: 0.0810 - val_loss1: 0.4223 - val_loss2: 5.3494\n","Epoch 294/300\n","30/30 [==============================] - 5s 157ms/step - loss: 53.1804 - model_loss: 0.0311 - model_1_loss: 0.0708 - model_2_loss: 0.1256 - model_3_loss: 0.0625 - model_4_loss: 0.0413 - model_accuracy: 0.9900 - model_1_accuracy: 0.9833 - model_2_accuracy: 0.9600 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9900 - loss1: 0.4377 - loss2: 5.2411 - val_loss: 106.4204 - val_model_loss: 9.9178 - val_model_1_loss: 11.0510 - val_model_2_loss: 11.2875 - val_model_3_loss: 11.1288 - val_model_4_loss: 10.7605 - val_model_accuracy: 0.0780 - val_model_1_accuracy: 0.0740 - val_model_2_accuracy: 0.0795 - val_model_3_accuracy: 0.0695 - val_model_4_accuracy: 0.0855 - val_loss1: 0.4995 - val_loss2: 5.1775\n","Epoch 295/300\n","30/30 [==============================] - 5s 158ms/step - loss: 53.1512 - model_loss: 0.0334 - model_1_loss: 0.0511 - model_2_loss: 0.1577 - model_3_loss: 0.0846 - model_4_loss: 0.1537 - model_accuracy: 0.9900 - model_1_accuracy: 0.9867 - model_2_accuracy: 0.9633 - model_3_accuracy: 0.9733 - model_4_accuracy: 0.9600 - loss1: 0.4421 - loss2: 5.2229 - val_loss: 105.7718 - val_model_loss: 10.5880 - val_model_1_loss: 9.8915 - val_model_2_loss: 10.6619 - val_model_3_loss: 11.0338 - val_model_4_loss: 11.2899 - val_model_accuracy: 0.0745 - val_model_1_accuracy: 0.0865 - val_model_2_accuracy: 0.0745 - val_model_3_accuracy: 0.0760 - val_model_4_accuracy: 0.0825 - val_loss1: 0.5132 - val_loss2: 5.1794\n","Epoch 296/300\n","30/30 [==============================] - 5s 157ms/step - loss: 53.1768 - model_loss: 0.1142 - model_1_loss: 0.0488 - model_2_loss: 0.0784 - model_3_loss: 0.0935 - model_4_loss: 0.0797 - model_accuracy: 0.9667 - model_1_accuracy: 0.9800 - model_2_accuracy: 0.9767 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9767 - loss1: 0.4367 - loss2: 5.2326 - val_loss: 107.7367 - val_model_loss: 11.1457 - val_model_1_loss: 9.9606 - val_model_2_loss: 11.0387 - val_model_3_loss: 10.1784 - val_model_4_loss: 12.3314 - val_model_accuracy: 0.0785 - val_model_1_accuracy: 0.0825 - val_model_2_accuracy: 0.0770 - val_model_3_accuracy: 0.0860 - val_model_4_accuracy: 0.0745 - val_loss1: 0.4606 - val_loss2: 5.2621\n","Epoch 297/300\n","30/30 [==============================] - 5s 158ms/step - loss: 54.3720 - model_loss: 0.2206 - model_1_loss: 0.0893 - model_2_loss: 0.1182 - model_3_loss: 0.1331 - model_4_loss: 0.0831 - model_accuracy: 0.9567 - model_1_accuracy: 0.9833 - model_2_accuracy: 0.9800 - model_3_accuracy: 0.9667 - model_4_accuracy: 0.9733 - loss1: 0.3791 - loss2: 5.3349 - val_loss: 109.2239 - val_model_loss: 11.1195 - val_model_1_loss: 9.8210 - val_model_2_loss: 11.2641 - val_model_3_loss: 10.9966 - val_model_4_loss: 11.8734 - val_model_accuracy: 0.0785 - val_model_1_accuracy: 0.0855 - val_model_2_accuracy: 0.0665 - val_model_3_accuracy: 0.0745 - val_model_4_accuracy: 0.0795 - val_loss1: 0.3956 - val_loss2: 5.3754\n","Epoch 298/300\n","30/30 [==============================] - 5s 159ms/step - loss: 54.1243 - model_loss: 0.1797 - model_1_loss: 0.0822 - model_2_loss: 0.0866 - model_3_loss: 0.0937 - model_4_loss: 0.1677 - model_accuracy: 0.9467 - model_1_accuracy: 0.9767 - model_2_accuracy: 0.9733 - model_3_accuracy: 0.9633 - model_4_accuracy: 0.9500 - loss1: 0.3853 - loss2: 5.3129 - val_loss: 110.4027 - val_model_loss: 11.8178 - val_model_1_loss: 9.7954 - val_model_2_loss: 12.1498 - val_model_3_loss: 10.9697 - val_model_4_loss: 13.3120 - val_model_accuracy: 0.0640 - val_model_1_accuracy: 0.0860 - val_model_2_accuracy: 0.0685 - val_model_3_accuracy: 0.0775 - val_model_4_accuracy: 0.0800 - val_loss1: 0.5176 - val_loss2: 5.1840\n","Epoch 299/300\n","30/30 [==============================] - 5s 158ms/step - loss: 53.6261 - model_loss: 0.1039 - model_1_loss: 0.0271 - model_2_loss: 0.0500 - model_3_loss: 0.0528 - model_4_loss: 0.1061 - model_accuracy: 0.9733 - model_1_accuracy: 0.9967 - model_2_accuracy: 0.9867 - model_3_accuracy: 0.9833 - model_4_accuracy: 0.9767 - loss1: 0.4011 - loss2: 5.2885 - val_loss: 108.8077 - val_model_loss: 11.1115 - val_model_1_loss: 9.4784 - val_model_2_loss: 10.8100 - val_model_3_loss: 10.5642 - val_model_4_loss: 13.6421 - val_model_accuracy: 0.0720 - val_model_1_accuracy: 0.0925 - val_model_2_accuracy: 0.0865 - val_model_3_accuracy: 0.0750 - val_model_4_accuracy: 0.0540 - val_loss1: 0.4684 - val_loss2: 5.2733\n","Epoch 300/300\n","30/30 [==============================] - 5s 157ms/step - loss: 53.5595 - model_loss: 0.1127 - model_1_loss: 0.0194 - model_2_loss: 0.0513 - model_3_loss: 0.0557 - model_4_loss: 0.0937 - model_accuracy: 0.9767 - model_1_accuracy: 0.9967 - model_2_accuracy: 0.9833 - model_3_accuracy: 0.9800 - model_4_accuracy: 0.9700 - loss1: 0.4041 - loss2: 5.2823 - val_loss: 106.2254 - val_model_loss: 10.9052 - val_model_1_loss: 9.3974 - val_model_2_loss: 10.3252 - val_model_3_loss: 11.4026 - val_model_4_loss: 11.7261 - val_model_accuracy: 0.0770 - val_model_1_accuracy: 0.0870 - val_model_2_accuracy: 0.0890 - val_model_3_accuracy: 0.0685 - val_model_4_accuracy: 0.0835 - val_loss1: 0.4848 - val_loss2: 5.1984\n","Epoch 00274: early stopping and save the model\n"]}],"source":["#construct joint training model for the five base models\n","input_size = (32, 32, 3)\n","model0 = creat_ResNet(input_shape=input_size, num_classes=100, num_filters = 64, random_seed=1)#random_seed: initialization\n","model1 = creat_ResNet(input_shape=input_size, num_classes=100, num_filters = 64, random_seed=2)\n","model2 = creat_ResNet(input_shape=input_size, num_classes=100, num_filters = 64, random_seed=3)\n","model3 = creat_ResNet(input_shape=input_size, num_classes=100, num_filters = 64, random_seed=4)\n","model4 = creat_ResNet(input_shape=input_size, num_classes=100, num_filters = 64, random_seed=5)\n","allinputs = keras.Input(shape=input_size)\n","output0, feature_maps0 = model0(allinputs)\n","output1, feature_maps1 = model1(allinputs)\n","output2, feature_maps2 = model2(allinputs)\n","output3, feature_maps3 = model3(allinputs)\n","output4, feature_maps4 = model4(allinputs)\n","model_train = keras.Model(\n","    inputs=allinputs, outputs=[output0, output1, output2, output3, output4])\n","\n","#implement distance loss\n","loss1, loss2, loss = cosine_euclidean_sum_loss(x=[feature_maps0, feature_maps1, feature_maps2, feature_maps3, feature_maps4], \n","                                      cosine_weight=1, euclidean_weight=10, mask=True, max_norm=False)\n","\n","\n","model_train.add_loss(loss)\n","model_train.add_metric(loss1, name=\"loss1\", aggregation='mean')\n","model_train.add_metric(loss2, name=\"loss2\", aggregation='mean')\n","\n","model_train.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","                    loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'],\n","                    metrics=['accuracy'])\n","\n","#load Cifar100 data\n","(x_origin_train, y_origin_train), (x_test,y_test) = keras.datasets.cifar100.load_data()\n","y_origin_train = y_origin_train.reshape(-1,)\n","y_test = y_test.reshape(-1,)\n","\n","x_train, x_val, y_train, y_val = model_selection.train_test_split(\n","    x_origin_train,\n","    y_origin_train,\n","    test_size=10000,\n","    random_state=0,\n","    stratify=y_origin_train)\n","_, x_val, _, y_val = model_selection.train_test_split(\n","    x_val,\n","    y_val,\n","    test_size=2000,\n","    random_state=0,\n","    stratify=y_val)\n","#select training samples\n","train_index = []\n","random.seed(0)\n","for i in range(100):\n","    train_index += (random.sample(list(np.where(y_train == i)[0]), 3))\n","random.shuffle(train_index)\n","sampled_x_train = x_train[train_index]\n","sampled_y_train = y_train[train_index]\n","del train_index\n","\n","#construct training and validation samples\n","train_sequence = cifar100data(sampled_x_train, sampled_y_train, batch_size=10, train=True)\n","validation_sequence = cifar100data(x_val, y_val, batch_size=10, train=False)\n","\n","#training\n","history = model_train.fit(\n","    train_sequence,\n","    epochs=300,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=CustomEarlyStoppingAndSave(\n","        save_path='100_samples_seed_fix.h5',\n","        patience=10))\n","frame = pd.DataFrame({\n","    'loss':\n","    history.history['loss'],\n","    'loss1':\n","    history.history['loss1'],\n","    'loss2':\n","    history.history['loss2'],\n","    'model_0_loss':\n","    history.history['model_loss'],\n","    'model_1_loss':\n","    history.history['model_1_loss'],\n","    'model_2_loss':\n","    history.history['model_2_loss'],\n","    'model_3_loss':\n","    history.history['model_3_loss'],\n","    'model_4_loss':\n","    history.history['model_4_loss'],\n","    'model_0_accuracy':\n","    history.history['model_accuracy'],\n","    'model_1_accuracy':\n","    history.history['model_1_accuracy'],\n","    'model_2_accuracy':\n","    history.history['model_2_accuracy'],\n","    'model_3_accuracy':\n","    history.history['model_3_accuracy'],\n","    'model_4_accuracy':\n","    history.history['model_4_accuracy'],\n","    'val_loss':\n","    history.history['val_loss'],\n","    'val_loss1':\n","    history.history['val_loss1'],\n","    'val_loss2':\n","    history.history['val_loss2'],\n","    'val_model_0_loss':\n","    history.history['val_model_loss'],\n","    'val_model_1_loss':\n","    history.history['val_model_1_loss'],\n","    'val_model_2_loss':\n","    history.history['val_model_2_loss'],\n","    'val_model_3_loss':\n","    history.history['val_model_3_loss'],\n","    'val_model_4_loss':\n","    history.history['val_model_4_loss'],\n","    'val_model_0_accuracy':\n","    history.history['val_model_accuracy'],\n","    'val_model_1_accuracy':\n","    history.history['val_model_1_accuracy'],\n","    'val_model_2_accuracy':\n","    history.history['val_model_2_accuracy'],\n","    'val_model_3_accuracy':\n","    history.history['val_model_3_accuracy'],\n","    'val_model_4_accuracy':\n","    history.history['val_model_4_accuracy'],\n","})\n","#frame.to_excel('/content/drive/MyDrive/cifar100experiment/resnet/5models300s/table_400_samples_seed_fix.xlsx')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8Q68bw0VAfd","outputId":"56f048bc-ee74-4b71-810b-73660ad98087","executionInfo":{"status":"ok","timestamp":1650056351908,"user_tz":-120,"elapsed":22605,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1000/1000 [==============================] - 16s 14ms/step - loss: 105.0552 - model_loss: 10.0921 - model_1_loss: 9.2972 - model_2_loss: 9.4439 - model_3_loss: 9.8721 - model_4_loss: 10.9657 - model_accuracy: 0.0802 - model_1_accuracy: 0.0836 - model_2_accuracy: 0.0894 - model_3_accuracy: 0.0781 - model_4_accuracy: 0.0807 - loss1: 0.3291 - loss2: 5.5055\n"]}],"source":["#evaluation of the base models\n","x_test = x_test/255.0\n","evaluate = model_train.evaluate(x_test,[keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test),keras.utils.to_categorical(y_test)],batch_size=10)\n","evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mW1xEi9mVP08","outputId":"9098f1a1-104d-4cda-daf5-ae9b65314d65","executionInfo":{"status":"ok","timestamp":1650056402161,"user_tz":-120,"elapsed":50263,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0973"]},"metadata":{},"execution_count":10}],"source":["#hard voting ensemble\n","class HardVotingEnsemble:\n","    def __init__(self, model, testdata ,batch_size):\n","        self.ensemble_model = model\n","        self.testdata = testdata\n","        self.batch_size = batch_size\n","        self.data_size = testdata[1].shape[0]\n","    def prediction(self):\n","        predictions =[]\n","        for i in range(int(self.data_size/self.batch_size)):\n","            batch_predictions = np.argmax(self.ensemble_model.predict(self.testdata[0][i*self.batch_size:(i+1)*self.batch_size]),axis=2) \n","            batch_predictions = np.stack(batch_predictions, axis=1)\n","            batch_predictions = [np.argmax(np.bincount(pre)) for pre in batch_predictions]\n","            predictions = predictions+batch_predictions\n","        return np.array(predictions)\n","\n","    def evaluate(self):\n","        predictions = self.prediction()\n","        accuracy = np.sum(\n","            predictions == self.testdata[1]) / self.data_size\n","        return accuracy\n","HEnsemble = HardVotingEnsemble(model = model_train,testdata = (x_test, y_test),batch_size=10)\n","HEnsemble.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p79zKgdTxTgO","outputId":"9acbd948-3d88-4a14-ebbd-8e562201fa69","executionInfo":{"status":"ok","timestamp":1650056406360,"user_tz":-120,"elapsed":4201,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0996"]},"metadata":{},"execution_count":11}],"source":["#soft voting ensemble\n","def SoftVotingEnsemble(model, x, y):\n","  data_size = x.shape[0]\n","  predictions = tf.argmax(tf.reduce_mean(model.predict(x), axis = 0),axis=1)\n","  accuracy = np.sum(\n","     predictions == y) / data_size\n","  return accuracy\n","SoftVotingEnsemble(model_train, x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ML_FZOLCe79"},"outputs":[],"source":["#callback for ensemble learning\n","class eCustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(eCustomEarlyStoppingAndSave, self).__init__()\n","        self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_accuracy') \n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXwnG-CQCfbJ"},"outputs":[],"source":["class ecifar100data(keras.utils.Sequence):\n","    '''\n","    generate data batch of cifar10\n","    10 classes\n","    '''\n","    def __init__(self, data_x, data_y, batch_size, train):\n","        self.data_x = data_x\n","        self.data_y = data_y\n","        self.train = train\n","        self.batch_size = batch_size\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","\n","        batch_x = self.data_x[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        batch_y = self.data_y[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        if self.train == True:\n","            batch_x = Data_Aug(batch_x)\n","\n","        batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","        batch_y = keras.utils.to_categorical(np.array(batch_y), 100)\n","        return batch_x, batch_y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136370,"status":"ok","timestamp":1650057928908,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"},"user_tz":-120},"id":"Oql4eIoXC5mF","outputId":"fa8bb74b-9386-4026-ffb7-05f97c61936e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","30/30 [==============================] - 7s 114ms/step - loss: 5.2387 - accuracy: 0.0133 - val_loss: 6.8324 - val_accuracy: 0.0135\n","Epoch 2/50\n","30/30 [==============================] - 2s 77ms/step - loss: 4.5463 - accuracy: 0.0400 - val_loss: 5.5845 - val_accuracy: 0.0165\n","Epoch 3/50\n","30/30 [==============================] - 2s 79ms/step - loss: 3.8057 - accuracy: 0.0867 - val_loss: 5.0703 - val_accuracy: 0.0220\n","Epoch 4/50\n","30/30 [==============================] - 2s 77ms/step - loss: 3.2442 - accuracy: 0.2100 - val_loss: 4.8254 - val_accuracy: 0.0320\n","Epoch 5/50\n","30/30 [==============================] - 2s 77ms/step - loss: 2.7393 - accuracy: 0.3700 - val_loss: 4.6852 - val_accuracy: 0.0415\n","Epoch 6/50\n","30/30 [==============================] - 2s 78ms/step - loss: 2.3614 - accuracy: 0.4867 - val_loss: 4.5959 - val_accuracy: 0.0550\n","Epoch 7/50\n","30/30 [==============================] - 2s 76ms/step - loss: 1.9997 - accuracy: 0.6600 - val_loss: 4.5407 - val_accuracy: 0.0615\n","Epoch 8/50\n","30/30 [==============================] - 2s 77ms/step - loss: 1.7162 - accuracy: 0.7600 - val_loss: 4.4982 - val_accuracy: 0.0655\n","Epoch 9/50\n","30/30 [==============================] - 2s 77ms/step - loss: 1.5818 - accuracy: 0.8033 - val_loss: 4.4689 - val_accuracy: 0.0685\n","Epoch 10/50\n","30/30 [==============================] - 2s 77ms/step - loss: 1.3059 - accuracy: 0.8767 - val_loss: 4.4459 - val_accuracy: 0.0735\n","Epoch 11/50\n","30/30 [==============================] - 2s 75ms/step - loss: 1.1614 - accuracy: 0.8900 - val_loss: 4.4294 - val_accuracy: 0.0750\n","Epoch 12/50\n","30/30 [==============================] - 2s 76ms/step - loss: 0.9848 - accuracy: 0.9533 - val_loss: 4.4125 - val_accuracy: 0.0770\n","Epoch 13/50\n","30/30 [==============================] - 2s 76ms/step - loss: 0.8944 - accuracy: 0.9567 - val_loss: 4.3996 - val_accuracy: 0.0825\n","Epoch 14/50\n","30/30 [==============================] - 2s 76ms/step - loss: 0.7507 - accuracy: 0.9867 - val_loss: 4.3901 - val_accuracy: 0.0865\n","Epoch 15/50\n","30/30 [==============================] - 2s 77ms/step - loss: 0.6551 - accuracy: 0.9867 - val_loss: 4.3844 - val_accuracy: 0.0870\n","Epoch 16/50\n","30/30 [==============================] - 2s 78ms/step - loss: 0.6387 - accuracy: 0.9900 - val_loss: 4.3759 - val_accuracy: 0.0900\n","Epoch 17/50\n","30/30 [==============================] - 2s 78ms/step - loss: 0.5264 - accuracy: 0.9833 - val_loss: 4.3647 - val_accuracy: 0.0935\n","Epoch 18/50\n","30/30 [==============================] - 2s 79ms/step - loss: 0.5194 - accuracy: 0.9967 - val_loss: 4.3617 - val_accuracy: 0.0945\n","Epoch 19/50\n","30/30 [==============================] - 2s 74ms/step - loss: 0.4676 - accuracy: 0.9933 - val_loss: 4.3555 - val_accuracy: 0.0935\n","Epoch 20/50\n","30/30 [==============================] - 2s 78ms/step - loss: 0.3879 - accuracy: 1.0000 - val_loss: 4.3536 - val_accuracy: 0.0935\n","Epoch 21/50\n","30/30 [==============================] - 2s 73ms/step - loss: 0.4053 - accuracy: 1.0000 - val_loss: 4.3539 - val_accuracy: 0.0925\n","Epoch 22/50\n","30/30 [==============================] - 2s 78ms/step - loss: 0.3686 - accuracy: 0.9933 - val_loss: 4.3511 - val_accuracy: 0.0960\n","Epoch 23/50\n","30/30 [==============================] - 2s 73ms/step - loss: 0.3275 - accuracy: 0.9967 - val_loss: 4.3460 - val_accuracy: 0.0940\n","Epoch 24/50\n","30/30 [==============================] - 2s 73ms/step - loss: 0.3015 - accuracy: 0.9967 - val_loss: 4.3437 - val_accuracy: 0.0955\n","Epoch 25/50\n","30/30 [==============================] - 2s 76ms/step - loss: 0.2957 - accuracy: 1.0000 - val_loss: 4.3412 - val_accuracy: 0.1005\n","Epoch 26/50\n","30/30 [==============================] - 2s 74ms/step - loss: 0.2437 - accuracy: 1.0000 - val_loss: 4.3416 - val_accuracy: 0.0980\n","Epoch 27/50\n","30/30 [==============================] - 2s 73ms/step - loss: 0.2332 - accuracy: 1.0000 - val_loss: 4.3390 - val_accuracy: 0.0980\n","Epoch 28/50\n","30/30 [==============================] - 2s 72ms/step - loss: 0.2147 - accuracy: 1.0000 - val_loss: 4.3379 - val_accuracy: 0.0970\n","Epoch 29/50\n","30/30 [==============================] - 2s 71ms/step - loss: 0.2183 - accuracy: 1.0000 - val_loss: 4.3392 - val_accuracy: 0.0965\n","Epoch 30/50\n","30/30 [==============================] - 2s 72ms/step - loss: 0.2009 - accuracy: 1.0000 - val_loss: 4.3401 - val_accuracy: 0.0975\n","Epoch 31/50\n","30/30 [==============================] - 2s 72ms/step - loss: 0.1784 - accuracy: 1.0000 - val_loss: 4.3403 - val_accuracy: 0.0980\n","Epoch 32/50\n","30/30 [==============================] - 2s 73ms/step - loss: 0.1864 - accuracy: 1.0000 - val_loss: 4.3416 - val_accuracy: 0.0970\n","Epoch 33/50\n","30/30 [==============================] - 2s 74ms/step - loss: 0.1784 - accuracy: 1.0000 - val_loss: 4.3442 - val_accuracy: 0.0965\n","Epoch 34/50\n","30/30 [==============================] - 2s 75ms/step - loss: 0.1589 - accuracy: 1.0000 - val_loss: 4.3438 - val_accuracy: 0.0975\n","Epoch 35/50\n","30/30 [==============================] - 2s 72ms/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 4.3419 - val_accuracy: 0.0985\n","Epoch 36/50\n","30/30 [==============================] - 2s 72ms/step - loss: 0.1569 - accuracy: 1.0000 - val_loss: 4.3408 - val_accuracy: 0.1000\n","Epoch 37/50\n","30/30 [==============================] - 2s 74ms/step - loss: 0.1242 - accuracy: 1.0000 - val_loss: 4.3404 - val_accuracy: 0.0990\n","Epoch 38/50\n","30/30 [==============================] - 2s 76ms/step - loss: 0.1436 - accuracy: 1.0000 - val_loss: 4.3407 - val_accuracy: 0.0980\n","Epoch 39/50\n","30/30 [==============================] - 2s 72ms/step - loss: 0.1255 - accuracy: 1.0000 - val_loss: 4.3386 - val_accuracy: 0.0990\n","Epoch 40/50\n","30/30 [==============================] - 2s 73ms/step - loss: 0.1272 - accuracy: 1.0000 - val_loss: 4.3369 - val_accuracy: 0.0990\n","Epoch 41/50\n","30/30 [==============================] - 2s 72ms/step - loss: 0.1142 - accuracy: 1.0000 - val_loss: 4.3379 - val_accuracy: 0.0990\n","Epoch 42/50\n","30/30 [==============================] - 2s 73ms/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 4.3359 - val_accuracy: 0.0980\n","Epoch 43/50\n","30/30 [==============================] - 2s 71ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 4.3376 - val_accuracy: 0.1000\n","Epoch 44/50\n","30/30 [==============================] - 2s 73ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 4.3390 - val_accuracy: 0.0985\n","Epoch 45/50\n","30/30 [==============================] - 2s 83ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 4.3418 - val_accuracy: 0.0975\n","Epoch 46/50\n","30/30 [==============================] - 2s 73ms/step - loss: 0.1068 - accuracy: 1.0000 - val_loss: 4.3428 - val_accuracy: 0.0975\n","Epoch 47/50\n","30/30 [==============================] - 2s 72ms/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 4.3433 - val_accuracy: 0.0955\n","Epoch 48/50\n","30/30 [==============================] - 2s 72ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 4.3446 - val_accuracy: 0.0970\n","Epoch 49/50\n","30/30 [==============================] - 2s 74ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 4.3436 - val_accuracy: 0.0965\n","Epoch 50/50\n","30/30 [==============================] - 2s 71ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 4.3417 - val_accuracy: 0.0960\n","Epoch 00025: early stopping and save the model\n","1000/1000 [==============================] - 11s 10ms/step - loss: 4.3010 - accuracy: 0.0920\n"]}],"source":["#feature fusion model\n","model_path = '100_samples_seed_fix.h5'\n","model = keras.models.load_model(model_path)\n","extractor_1 = keras.models.Model(inputs=model.layers[1].inputs,outputs=model.layers[1].layers[42].output)\n","extractor_2 = keras.models.Model(inputs=model.layers[2].inputs,outputs=model.layers[2].layers[42].output)\n","extractor_3 = keras.models.Model(inputs=model.layers[3].inputs,outputs=model.layers[3].layers[42].output)\n","extractor_4 = keras.models.Model(inputs=model.layers[4].inputs,outputs=model.layers[4].layers[42].output)\n","extractor_5 = keras.models.Model(inputs=model.layers[5].inputs,outputs=model.layers[5].layers[42].output)\n","extractor_1.trainable = False\n","extractor_2.trainable = False\n","extractor_3.trainable = False\n","extractor_4.trainable = False\n","extractor_5.trainable = False\n","inputs = keras.Input(shape = input_size)\n","features_1 = extractor_1(inputs, training = False)\n","features_2 = extractor_2(inputs, training = False)\n","features_3 = extractor_3(inputs, training = False)\n","features_4 = extractor_4(inputs, training = False)\n","features_5 = extractor_5(inputs, training = False)\n","\n","x = keras.layers.Concatenate(axis=-1)([features_1,features_2,features_3,features_4,features_5])\n","\n","x = keras.layers.Flatten()(x)\n","x = keras.layers.Dense(512,  name='dense_100')(x)\n","x = keras.layers.BatchNormalization()(x)\n","x = keras.layers.Activation('relu')(x)\n","x = keras.layers.Dropout(0.5)(x)\n","outputs = keras.layers.Dense(100, activation='softmax', name='dense_101')(x)\n","ensemble = keras.Model(inputs = inputs, outputs = outputs)\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","train_sequence = ecifar100data(sampled_x_train, sampled_y_train, batch_size=10, train=True)\n","validation_sequence = ecifar100data(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=50,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FH_Ry7tpC_G_","outputId":"ec4d96a0-4338-4cae-d6ae-3a8aed27051b","executionInfo":{"status":"ok","timestamp":1650058001998,"user_tz":-120,"elapsed":73108,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","30/30 [==============================] - 10s 162ms/step - loss: 0.2854 - accuracy: 1.0000 - val_loss: 4.3348 - val_accuracy: 0.1010\n","Epoch 2/20\n","30/30 [==============================] - 3s 88ms/step - loss: 0.2310 - accuracy: 1.0000 - val_loss: 4.3424 - val_accuracy: 0.0980\n","Epoch 3/20\n","30/30 [==============================] - 3s 94ms/step - loss: 0.2078 - accuracy: 1.0000 - val_loss: 4.3455 - val_accuracy: 0.1030\n","Epoch 4/20\n","30/30 [==============================] - 3s 89ms/step - loss: 0.1704 - accuracy: 1.0000 - val_loss: 4.3421 - val_accuracy: 0.1020\n","Epoch 5/20\n","30/30 [==============================] - 3s 88ms/step - loss: 0.1553 - accuracy: 1.0000 - val_loss: 4.3416 - val_accuracy: 0.1025\n","Epoch 6/20\n","30/30 [==============================] - 3s 88ms/step - loss: 0.1347 - accuracy: 1.0000 - val_loss: 4.3460 - val_accuracy: 0.1000\n","Epoch 7/20\n","30/30 [==============================] - 3s 87ms/step - loss: 0.1253 - accuracy: 1.0000 - val_loss: 4.3434 - val_accuracy: 0.0995\n","Epoch 8/20\n","30/30 [==============================] - 3s 87ms/step - loss: 0.1168 - accuracy: 1.0000 - val_loss: 4.3421 - val_accuracy: 0.0965\n","Epoch 9/20\n","30/30 [==============================] - 3s 88ms/step - loss: 0.0991 - accuracy: 1.0000 - val_loss: 4.3408 - val_accuracy: 0.0960\n","Epoch 10/20\n","30/30 [==============================] - 3s 88ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 4.3356 - val_accuracy: 0.1000\n","Epoch 11/20\n","30/30 [==============================] - 3s 87ms/step - loss: 0.0846 - accuracy: 1.0000 - val_loss: 4.3366 - val_accuracy: 0.0995\n","Epoch 12/20\n","30/30 [==============================] - 3s 89ms/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 4.3357 - val_accuracy: 0.0995\n","Epoch 13/20\n","30/30 [==============================] - 3s 103ms/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 4.3351 - val_accuracy: 0.1015\n","Epoch 14/20\n","30/30 [==============================] - 3s 89ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 4.3339 - val_accuracy: 0.1030\n","Epoch 15/20\n","30/30 [==============================] - 3s 89ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 4.3341 - val_accuracy: 0.1015\n","Epoch 16/20\n","30/30 [==============================] - 3s 91ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 4.3341 - val_accuracy: 0.1020\n","Epoch 17/20\n","30/30 [==============================] - 3s 88ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 4.3373 - val_accuracy: 0.1020\n","Epoch 18/20\n","30/30 [==============================] - 3s 89ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 4.3352 - val_accuracy: 0.1020\n","Epoch 19/20\n","30/30 [==============================] - 3s 87ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 4.3365 - val_accuracy: 0.1000\n","Epoch 20/20\n","30/30 [==============================] - 3s 89ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 4.3375 - val_accuracy: 0.1015\n","Epoch 00003: early stopping and save the model\n","1000/1000 [==============================] - 11s 10ms/step - loss: 4.3006 - accuracy: 0.0951\n"]}],"source":["#finetuning\n","extractor_1.trainable = True\n","extractor_2.trainable = True\n","extractor_3.trainable = True\n","extractor_4.trainable = True\n","extractor_5.trainable = True\n","ensemble.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n","                    loss='categorical_crossentropy',\n","                    metrics=['accuracy'])\n","#train_sequence = ecifar10data(sampled_x_train, sampled_y_train, batch_size=10, train=False)\n","#validation_sequence = ecifar10data(x_val, y_val, batch_size=10, train=False)\n","history = ensemble.fit(\n","    train_sequence,\n","    epochs=20,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=eCustomEarlyStoppingAndSave(\n","        save_path='ensemble.h5',\n","        patience=10))\n","evaluate = ensemble.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601},"id":"y1W3vPZQppO3","executionInfo":{"status":"ok","timestamp":1650058008635,"user_tz":-120,"elapsed":6640,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"4201c622-c164-4f13-abb9-6f173bf7516b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'              precision    recall  f1-score   support\\n\\n           0     0.4091    0.2700    0.3253       100\\n           1     0.0682    0.0300    0.0417       100\\n           2     0.0809    0.1100    0.0932       100\\n           3     0.0000    0.0000    0.0000       100\\n           4     0.0351    0.0200    0.0255       100\\n           5     0.1000    0.0200    0.0333       100\\n           6     0.0263    0.0500    0.0345       100\\n           7     0.6000    0.0300    0.0571       100\\n           8     0.1250    0.0100    0.0185       100\\n           9     0.0635    0.0400    0.0491       100\\n          10     0.0000    0.0000    0.0000       100\\n          11     0.0000    0.0000    0.0000       100\\n          12     0.0938    0.1200    0.1053       100\\n          13     0.2115    0.1100    0.1447       100\\n          14     0.1111    0.0300    0.0472       100\\n          15     0.0190    0.0400    0.0258       100\\n          16     0.0312    0.0200    0.0244       100\\n          17     0.1765    0.1500    0.1622       100\\n          18     0.1196    0.2500    0.1618       100\\n          19     0.0000    0.0000    0.0000       100\\n          20     0.1327    0.1300    0.1313       100\\n          21     0.0545    0.1700    0.0825       100\\n          22     0.0392    0.0200    0.0265       100\\n          23     0.1205    0.3000    0.1719       100\\n          24     0.0747    0.1300    0.0949       100\\n          25     0.0506    0.0400    0.0447       100\\n          26     0.0000    0.0000    0.0000       100\\n          27     0.0833    0.0400    0.0541       100\\n          28     0.0250    0.0100    0.0143       100\\n          29     0.0294    0.0200    0.0238       100\\n          30     0.1220    0.0500    0.0709       100\\n          31     0.0526    0.0400    0.0455       100\\n          32     0.0250    0.0300    0.0273       100\\n          33     0.1000    0.0500    0.0667       100\\n          34     0.0284    0.0600    0.0386       100\\n          35     0.0000    0.0000    0.0000       100\\n          36     0.0810    0.1700    0.1097       100\\n          37     0.0515    0.0500    0.0508       100\\n          38     0.0363    0.0700    0.0478       100\\n          39     0.0730    0.1300    0.0935       100\\n          40     0.0132    0.0100    0.0114       100\\n          41     0.4133    0.3100    0.3543       100\\n          42     0.1014    0.0700    0.0828       100\\n          43     0.0518    0.1000    0.0683       100\\n          44     0.0588    0.0600    0.0594       100\\n          45     0.0353    0.0300    0.0324       100\\n          46     0.0167    0.0100    0.0125       100\\n          47     0.1746    0.1100    0.1350       100\\n          48     0.1176    0.0800    0.0952       100\\n          49     0.1512    0.1300    0.1398       100\\n          50     0.0294    0.0100    0.0149       100\\n          51     0.0163    0.0200    0.0179       100\\n          52     0.2265    0.4100    0.2918       100\\n          53     0.2832    0.3200    0.3005       100\\n          54     0.5000    0.1500    0.2308       100\\n          55     0.0072    0.0200    0.0106       100\\n          56     0.0000    0.0000    0.0000       100\\n          57     0.1023    0.0900    0.0957       100\\n          58     0.1099    0.1000    0.1047       100\\n          59     0.1250    0.0100    0.0185       100\\n          60     0.2723    0.5500    0.3642       100\\n          61     0.0780    0.2300    0.1165       100\\n          62     0.2125    0.1700    0.1889       100\\n          63     0.0282    0.0400    0.0331       100\\n          64     0.0370    0.0100    0.0157       100\\n          65     0.0610    0.0500    0.0549       100\\n          66     0.0556    0.0400    0.0465       100\\n          67     0.2027    0.1500    0.1724       100\\n          68     0.4177    0.3300    0.3687       100\\n          69     0.0133    0.0300    0.0184       100\\n          70     0.0000    0.0000    0.0000       100\\n          71     0.1160    0.2100    0.1495       100\\n          72     0.0256    0.0200    0.0225       100\\n          73     0.2353    0.1600    0.1905       100\\n          74     0.0588    0.0100    0.0171       100\\n          75     0.3333    0.1300    0.1871       100\\n          76     0.1449    0.2000    0.1681       100\\n          77     0.1071    0.0300    0.0469       100\\n          78     0.0508    0.1900    0.0802       100\\n          79     0.0000    0.0000    0.0000       100\\n          80     0.0571    0.0200    0.0296       100\\n          81     0.0323    0.0800    0.0460       100\\n          82     0.3459    0.5500    0.4247       100\\n          83     0.0479    0.0800    0.0599       100\\n          84     0.0000    0.0000    0.0000       100\\n          85     0.0000    0.0000    0.0000       100\\n          86     0.0558    0.1100    0.0741       100\\n          87     0.1429    0.0600    0.0845       100\\n          88     0.0645    0.0200    0.0305       100\\n          89     0.0533    0.0400    0.0457       100\\n          90     0.0217    0.0200    0.0208       100\\n          91     0.0923    0.1200    0.1043       100\\n          92     0.1290    0.2400    0.1678       100\\n          93     0.0000    0.0000    0.0000       100\\n          94     0.1784    0.3300    0.2316       100\\n          95     0.1856    0.1800    0.1827       100\\n          96     0.1519    0.1200    0.1341       100\\n          97     0.0606    0.0600    0.0603       100\\n          98     0.0408    0.0600    0.0486       100\\n          99     0.0952    0.0200    0.0331       100\\n\\n    accuracy                         0.0951     10000\\n   macro avg     0.1019    0.0951    0.0864     10000\\nweighted avg     0.1019    0.0951    0.0864     10000\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}],"source":["#f1 score\n","predict = tf.argmax(ensemble.predict(x_test),axis=-1)\n","classification_report(y_test, predict,digits=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WFiWgx4TgfTQ"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Cifar100ResnetEX.ipynb","provenance":[],"mount_file_id":"1QJFNy19z_KuNu1M7LcKhGevZXSfCDE6t","authorship_tag":"ABX9TyPJMrg9h9vakuVKvqGiWeXC"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}