{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"singlenet.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1kbvz3r74EJkOvUXMzZMEmlc5oayb2RRv","authorship_tag":"ABX9TyPWU9nRvACZ9UJabDt2vfHV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","from tensorflow import keras\n","from sklearn import model_selection\n","import imgaug.augmenters as iaa\n","import imgaug as ia\n","import os"],"metadata":{"id":"Bmh4RXKQxm0N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ia.seed(1)\n","def Data_Aug(samples):\n","    randomaug = iaa.Sometimes(\n","        0.5,\n","        iaa.OneOf([\n","            iaa.Sequential([\n","                iaa.AllChannelsCLAHE(clip_limit=(1, 10)),\n","                iaa.Affine(rotate=(-5, 5))\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(translate_percent={\n","                    \"x\": (-0.2, 0.2),\n","                    \"y\": (-0.2, 0.2)\n","                }),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.Affine(rotate=(-10, 10)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ]),\n","            iaa.Sequential([\n","                iaa.PerspectiveTransform(scale=(0, 0.15)),\n","                iaa.Multiply((0.7, 1.3)),\n","                iaa.AdditiveLaplaceNoise(scale=0.03 * 255, per_channel=True),\n","                iaa.Fliplr(0.3),\n","                iaa.Flipud(0.3)\n","            ])\n","        ]))\n","\n","\n","    return randomaug.augment_images(samples)\n","\n","def resize_images(imgs, hight, width):\n","    seq = iaa.Resize({\"height\": hight, \"width\": width})\n","    aug = seq.augment_images(imgs)\n","    return aug"],"metadata":{"id":"gaUmcnZwK5Z5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RJ3uDY9FgNZ"},"outputs":[],"source":["class cifar10data(keras.utils.Sequence):\n","    '''\n","    generate data batch of cifar10\n","    10 classes\n","    '''\n","    def __init__(self, data_x, data_y, batch_size, train):\n","        self.data_x = data_x\n","        self.data_y = data_y\n","        self.train = train\n","        self.batch_size = batch_size\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.data_y) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","\n","        batch_x = self.data_x[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        batch_y = self.data_y[idx * self.batch_size:(idx + 1) *\n","                              self.batch_size]\n","        if self.train == True:\n","            batch_x = Data_Aug(batch_x)\n","\n","        batch_x = np.clip(batch_x / 255.0, 0, 1).astype(\"float32\")\n","        batch_y = keras.utils.to_categorical(np.array(batch_y), 10)\n","        return batch_x, batch_y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unA7GJ9ofGEv"},"outputs":[],"source":["class CustomEarlyStoppingAndSave(keras.callbacks.Callback):\n","    def __init__(self, save_path, patience=0):\n","        super(CustomEarlyStoppingAndSave, self).__init__()\n","        #self.patience = patience\n","        self.save_path = save_path\n","        self.best_weights = None\n","\n","    def on_train_begin(self, logs=None):\n","        #self.wait = 0\n","        self.stopped_epoch = 0\n","        #self.best_val_distance_loss = np.Inf\n","        self.best_val_acc = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        #val_distance_loss = logs.get('val_MMD_loss')\n","        val_acc = logs.get('val_accuracy') \n","\n","        if  np.greater(val_acc, self.best_val_acc):\n","            #self.best_val_distance_loss = val_distance_loss\n","            self.best_val_acc = val_acc\n","            #self.wait = 0\n","            # Record the best weights if current results is better (less).\n","            self.best_weights = self.model.get_weights()\n","            self.stopped_epoch = epoch\n","        #else:\n","            #self.wait += 1\n","            #if self.wait >= self.patience:\n","                #self.stopped_epoch = epoch\n","                #self.model.stop_training = True\n","                #print(\"Restoring model weights from the end of the best epoch.\")\n","                #self.model.set_weights(self.best_weights)\n","\n","    def on_train_end(self, logs=None):\n","        self.model.set_weights(self.best_weights)\n","        if self.stopped_epoch >= 0:\n","            print(\"Epoch %05d: early stopping and save the model\" %\n","                  (self.stopped_epoch + 1))\n","        self.model.save(self.save_path)"]},{"cell_type":"code","source":["def create_VGGNet(input_shape, num_classes, random_seed):\n","  inputs = keras.Input(shape=input_shape)\n","  x = keras.layers.Conv2D(64, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeUniform(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(64, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeUniform(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  p1 = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.2)(p1)\n","\n","  x = keras.layers.Conv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeUniform(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Conv2D(128, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeUniform(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  p2 = keras.layers.MaxPooling2D((2, 2))(x)\n","  x = keras.layers.Dropout(0.3)(p2)\n","\n","  '''  \n","  x = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeUniform(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  f6 = keras.layers.Conv2D(256, (3, 3), padding='same',  kernel_initializer=keras.initializers.HeUniform(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(f6)\n","  r3 = keras.layers.Activation('relu')(x)\n","  p3 = keras.layers.MaxPooling2D((2, 2))(r3)\n","  x = keras.layers.Dropout(0.4)(p3)\n","  '''\n","\n","  x = keras.layers.Flatten()(x)\n","  x = keras.layers.Dense(128,  kernel_initializer=keras.initializers.HeUniform(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.Dropout(0.5)(x)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=keras.initializers.HeUniform(seed=random_seed))(x)\n","  return keras.Model(inputs=inputs, outputs=outputs)"],"metadata":{"id":"DH1F1AvvbTPe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create single base ResNet architecture\n","def creat_ResNet(input_shape, num_classes=10, num_filters = 64, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x)\n","\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(2*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(2*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  x = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(4*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(4*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  last_acti = keras.layers.MaxPooling2D((2,2))(x) \n","\n","  '''  \n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  y = keras.layers.Conv2D(8*num_filters, (3, 3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(y)\n","  y = keras.layers.BatchNormalization()(y)\n","  y = keras.layers.LeakyReLU(alpha=0.1)(y)\n","  x = keras.layers.Conv2D(8*num_filters, (1, 1), kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.add([x, y])\n","  x = keras.layers.LeakyReLU(alpha=0.1)(x)\n","  last_acti = keras.layers.MaxPooling2D((2,2))(x) \n","  '''\n","\n","  x = keras.layers.GlobalAveragePooling2D()(last_acti)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  model = keras.Model(inputs=inputs, outputs=[outputs,last_acti])\n","  return model\n"],"metadata":{"id":"QieLj9eTLmZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_AlexNet(input_shape, num_classes=10, random_seed=None):\n","  inputs = keras.Input(shape=input_shape)\n","  x = keras.layers.Conv2D(96, (3,3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(inputs)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x)\n","  x = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","  \n","  x = keras.layers.Conv2D(256, (3,3), padding='same', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  x = keras.layers.BatchNormalization()(x)\n","  x = keras.layers.Activation('relu')(x) \n","  x = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","  \n","  x = keras.layers.Conv2D(384, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x) \n","  x = keras.layers.Conv2D(384, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x) \n","  x = keras.layers.Conv2D(256, (3,3), padding='same', activation='relu', kernel_initializer=keras.initializers.HeNormal(seed=random_seed))(x)\n","  feature_maps = keras.layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)\n","\n","  x = keras.layers.Flatten()(feature_maps)\n","  #x = keras.layers.Dense(256,activation='relu')(x)\n","  #x = keras.layers.Dropout(0.5)(x)\n","  x = keras.layers.Dense(128,activation='relu')(x)\n","  x = keras.layers.Dropout(0.5)(x)\n","  outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n","  model = keras.Model(inputs=inputs, outputs=outputs)\n","  return model"],"metadata":{"id":"57au-gFlNLBl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_size= (32,32,3)\n","model = create_VGGNet(input_shape=input_size, num_classes=10,  random_seed=None)\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","                    loss=['categorical_crossentropy'],\n","                    metrics=['accuracy'])\n","\n","(x_origin_train, y_origin_train), (x_test,y_test) = keras.datasets.cifar10.load_data()\n","\n","\n","\n","y_origin_train = y_origin_train.reshape(-1,)\n","y_test = y_test.reshape(-1,)\n","\n","x_train, x_val, y_train, y_val = model_selection.train_test_split(\n","    x_origin_train,\n","    y_origin_train,\n","    test_size=0.25,\n","    random_state=0,\n","    stratify=y_origin_train)\n","_, x_val, _, y_val = model_selection.train_test_split(\n","    x_val,\n","    y_val,\n","    test_size=2000,\n","    random_state=0,\n","    stratify=y_val)\n","\n","#randomly select training samples\n","train_index = []\n","random.seed(0)\n","for i in range(10):\n","    train_index += (random.sample(list(np.where(y_train == i)[0]), 100))\n","random.shuffle(train_index)\n","sampled_x_train = x_train[train_index]\n","sampled_y_train = y_train[train_index]\n","del train_index\n","\n","train_sequence = cifar10data(sampled_x_train, sampled_y_train, batch_size=10, train=True)\n","validation_sequence = cifar10data(x_val, y_val, batch_size=10, train=False)\n","\n","#train base models and save parameters\n","history = model.fit(\n","    train_sequence,\n","    epochs=300,\n","    validation_data=validation_sequence,\n","    #validation_steps=200,\n","    callbacks=CustomEarlyStoppingAndSave(\n","        save_path='3_samples_seed_fix.h5',\n","        patience=10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4a5P5V5OKw8","executionInfo":{"status":"ok","timestamp":1650283869505,"user_tz":-120,"elapsed":740936,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"7d5325cc-6524-4690-8661-111180ad6ae0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","170508288/170498071 [==============================] - 2s 0us/step\n","Epoch 1/300\n","100/100 [==============================] - 14s 27ms/step - loss: 2.5689 - accuracy: 0.1780 - val_loss: 2.5170 - val_accuracy: 0.1755\n","Epoch 2/300\n","100/100 [==============================] - 2s 24ms/step - loss: 2.1952 - accuracy: 0.2440 - val_loss: 1.9420 - val_accuracy: 0.3145\n","Epoch 3/300\n","100/100 [==============================] - 2s 24ms/step - loss: 2.0715 - accuracy: 0.2890 - val_loss: 1.8992 - val_accuracy: 0.3060\n","Epoch 4/300\n","100/100 [==============================] - 2s 23ms/step - loss: 2.0083 - accuracy: 0.2990 - val_loss: 2.0449 - val_accuracy: 0.2575\n","Epoch 5/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.8741 - accuracy: 0.3290 - val_loss: 1.7922 - val_accuracy: 0.3470\n","Epoch 6/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.7402 - accuracy: 0.3750 - val_loss: 1.7231 - val_accuracy: 0.3860\n","Epoch 7/300\n","100/100 [==============================] - 2s 25ms/step - loss: 1.7090 - accuracy: 0.3970 - val_loss: 1.7717 - val_accuracy: 0.3810\n","Epoch 8/300\n","100/100 [==============================] - 3s 25ms/step - loss: 1.5827 - accuracy: 0.4300 - val_loss: 1.6308 - val_accuracy: 0.4185\n","Epoch 9/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.5652 - accuracy: 0.4460 - val_loss: 1.6944 - val_accuracy: 0.3970\n","Epoch 10/300\n","100/100 [==============================] - 2s 23ms/step - loss: 1.4947 - accuracy: 0.4910 - val_loss: 1.6891 - val_accuracy: 0.4125\n","Epoch 11/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.4788 - accuracy: 0.4830 - val_loss: 2.1386 - val_accuracy: 0.3475\n","Epoch 12/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.4091 - accuracy: 0.4990 - val_loss: 1.6034 - val_accuracy: 0.4390\n","Epoch 13/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.3289 - accuracy: 0.5350 - val_loss: 1.8677 - val_accuracy: 0.3840\n","Epoch 14/300\n","100/100 [==============================] - 2s 23ms/step - loss: 1.3008 - accuracy: 0.5600 - val_loss: 1.5857 - val_accuracy: 0.4290\n","Epoch 15/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.2866 - accuracy: 0.5590 - val_loss: 1.6880 - val_accuracy: 0.4420\n","Epoch 16/300\n","100/100 [==============================] - 2s 23ms/step - loss: 1.2148 - accuracy: 0.5900 - val_loss: 1.6319 - val_accuracy: 0.4305\n","Epoch 17/300\n","100/100 [==============================] - 2s 23ms/step - loss: 1.1699 - accuracy: 0.6090 - val_loss: 1.5958 - val_accuracy: 0.4675\n","Epoch 18/300\n","100/100 [==============================] - 2s 23ms/step - loss: 1.1846 - accuracy: 0.6130 - val_loss: 1.5837 - val_accuracy: 0.4540\n","Epoch 19/300\n","100/100 [==============================] - 2s 23ms/step - loss: 1.1045 - accuracy: 0.6150 - val_loss: 1.5858 - val_accuracy: 0.4580\n","Epoch 20/300\n","100/100 [==============================] - 2s 23ms/step - loss: 1.0576 - accuracy: 0.6540 - val_loss: 1.8133 - val_accuracy: 0.3930\n","Epoch 21/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.0942 - accuracy: 0.6420 - val_loss: 1.8011 - val_accuracy: 0.4115\n","Epoch 22/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.9824 - accuracy: 0.6780 - val_loss: 1.6898 - val_accuracy: 0.4450\n","Epoch 23/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.0085 - accuracy: 0.6630 - val_loss: 1.6358 - val_accuracy: 0.4710\n","Epoch 24/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.0316 - accuracy: 0.6620 - val_loss: 1.6080 - val_accuracy: 0.4715\n","Epoch 25/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.9687 - accuracy: 0.6860 - val_loss: 1.5772 - val_accuracy: 0.4905\n","Epoch 26/300\n","100/100 [==============================] - 2s 24ms/step - loss: 1.0128 - accuracy: 0.6630 - val_loss: 1.6076 - val_accuracy: 0.4575\n","Epoch 27/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.9599 - accuracy: 0.6850 - val_loss: 1.6551 - val_accuracy: 0.4850\n","Epoch 28/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.9435 - accuracy: 0.7040 - val_loss: 1.6315 - val_accuracy: 0.4660\n","Epoch 29/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.8742 - accuracy: 0.7170 - val_loss: 1.6052 - val_accuracy: 0.4670\n","Epoch 30/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.9081 - accuracy: 0.7170 - val_loss: 1.5920 - val_accuracy: 0.5045\n","Epoch 31/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.8291 - accuracy: 0.7430 - val_loss: 1.5608 - val_accuracy: 0.5000\n","Epoch 32/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.8524 - accuracy: 0.7170 - val_loss: 1.6941 - val_accuracy: 0.4905\n","Epoch 33/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.8139 - accuracy: 0.7280 - val_loss: 1.5234 - val_accuracy: 0.5125\n","Epoch 34/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.7990 - accuracy: 0.7480 - val_loss: 1.7055 - val_accuracy: 0.4590\n","Epoch 35/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.8497 - accuracy: 0.7160 - val_loss: 1.5912 - val_accuracy: 0.5055\n","Epoch 36/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.7928 - accuracy: 0.7360 - val_loss: 1.6825 - val_accuracy: 0.4595\n","Epoch 37/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.7410 - accuracy: 0.7610 - val_loss: 1.7186 - val_accuracy: 0.4740\n","Epoch 38/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.7686 - accuracy: 0.7460 - val_loss: 1.6830 - val_accuracy: 0.4810\n","Epoch 39/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.8009 - accuracy: 0.7550 - val_loss: 1.8314 - val_accuracy: 0.4720\n","Epoch 40/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.7691 - accuracy: 0.7500 - val_loss: 1.6088 - val_accuracy: 0.5060\n","Epoch 41/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.7443 - accuracy: 0.7630 - val_loss: 1.6287 - val_accuracy: 0.4765\n","Epoch 42/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.7767 - accuracy: 0.7430 - val_loss: 1.6922 - val_accuracy: 0.4965\n","Epoch 43/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.7366 - accuracy: 0.7560 - val_loss: 1.5653 - val_accuracy: 0.5125\n","Epoch 44/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.7136 - accuracy: 0.7730 - val_loss: 1.6689 - val_accuracy: 0.4875\n","Epoch 45/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6726 - accuracy: 0.7950 - val_loss: 1.6776 - val_accuracy: 0.4870\n","Epoch 46/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.7310 - accuracy: 0.7760 - val_loss: 1.8187 - val_accuracy: 0.4700\n","Epoch 47/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.7002 - accuracy: 0.7700 - val_loss: 1.5597 - val_accuracy: 0.5075\n","Epoch 48/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6665 - accuracy: 0.7870 - val_loss: 1.6261 - val_accuracy: 0.5145\n","Epoch 49/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.7185 - accuracy: 0.7590 - val_loss: 1.9648 - val_accuracy: 0.4525\n","Epoch 50/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6385 - accuracy: 0.8030 - val_loss: 1.6267 - val_accuracy: 0.5090\n","Epoch 51/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.6421 - accuracy: 0.7810 - val_loss: 1.8379 - val_accuracy: 0.4610\n","Epoch 52/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.6421 - accuracy: 0.7950 - val_loss: 1.6837 - val_accuracy: 0.4835\n","Epoch 53/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.6655 - accuracy: 0.7940 - val_loss: 1.6169 - val_accuracy: 0.4990\n","Epoch 54/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6210 - accuracy: 0.7960 - val_loss: 1.6157 - val_accuracy: 0.5175\n","Epoch 55/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6711 - accuracy: 0.7870 - val_loss: 1.7083 - val_accuracy: 0.4915\n","Epoch 56/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.5912 - accuracy: 0.8070 - val_loss: 1.6180 - val_accuracy: 0.5210\n","Epoch 57/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6987 - accuracy: 0.7890 - val_loss: 1.8101 - val_accuracy: 0.4955\n","Epoch 58/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.6537 - accuracy: 0.7930 - val_loss: 1.5970 - val_accuracy: 0.5200\n","Epoch 59/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.5793 - accuracy: 0.8200 - val_loss: 1.5613 - val_accuracy: 0.5230\n","Epoch 60/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5701 - accuracy: 0.8230 - val_loss: 1.6446 - val_accuracy: 0.5110\n","Epoch 61/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.6572 - accuracy: 0.7930 - val_loss: 1.6299 - val_accuracy: 0.5235\n","Epoch 62/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5933 - accuracy: 0.8120 - val_loss: 1.8395 - val_accuracy: 0.4960\n","Epoch 63/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6110 - accuracy: 0.7950 - val_loss: 1.5748 - val_accuracy: 0.5380\n","Epoch 64/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6110 - accuracy: 0.8050 - val_loss: 1.7278 - val_accuracy: 0.4780\n","Epoch 65/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6103 - accuracy: 0.7990 - val_loss: 1.5167 - val_accuracy: 0.5350\n","Epoch 66/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.5776 - accuracy: 0.8210 - val_loss: 1.7463 - val_accuracy: 0.5105\n","Epoch 67/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5827 - accuracy: 0.8050 - val_loss: 1.6638 - val_accuracy: 0.5215\n","Epoch 68/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.5195 - accuracy: 0.8350 - val_loss: 1.6292 - val_accuracy: 0.5235\n","Epoch 69/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6561 - accuracy: 0.8080 - val_loss: 1.7444 - val_accuracy: 0.5140\n","Epoch 70/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6003 - accuracy: 0.8060 - val_loss: 1.5771 - val_accuracy: 0.5260\n","Epoch 71/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.5502 - accuracy: 0.8180 - val_loss: 1.6415 - val_accuracy: 0.5020\n","Epoch 72/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.6267 - accuracy: 0.8010 - val_loss: 1.6114 - val_accuracy: 0.5310\n","Epoch 73/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.5836 - accuracy: 0.8210 - val_loss: 1.9772 - val_accuracy: 0.4935\n","Epoch 74/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5310 - accuracy: 0.8300 - val_loss: 1.4894 - val_accuracy: 0.5365\n","Epoch 75/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.5193 - accuracy: 0.8360 - val_loss: 1.9115 - val_accuracy: 0.5060\n","Epoch 76/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5601 - accuracy: 0.8120 - val_loss: 2.0013 - val_accuracy: 0.4460\n","Epoch 77/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4945 - accuracy: 0.8360 - val_loss: 1.5505 - val_accuracy: 0.5455\n","Epoch 78/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5355 - accuracy: 0.8210 - val_loss: 1.8022 - val_accuracy: 0.4920\n","Epoch 79/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.5356 - accuracy: 0.8370 - val_loss: 1.8499 - val_accuracy: 0.5075\n","Epoch 80/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4724 - accuracy: 0.8560 - val_loss: 1.7768 - val_accuracy: 0.5085\n","Epoch 81/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5814 - accuracy: 0.8030 - val_loss: 1.8245 - val_accuracy: 0.5330\n","Epoch 82/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5333 - accuracy: 0.8240 - val_loss: 1.6431 - val_accuracy: 0.5155\n","Epoch 83/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4686 - accuracy: 0.8490 - val_loss: 1.5531 - val_accuracy: 0.5575\n","Epoch 84/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5190 - accuracy: 0.8420 - val_loss: 1.7738 - val_accuracy: 0.5140\n","Epoch 85/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4941 - accuracy: 0.8330 - val_loss: 1.5569 - val_accuracy: 0.5580\n","Epoch 86/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5026 - accuracy: 0.8320 - val_loss: 1.9114 - val_accuracy: 0.5135\n","Epoch 87/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5382 - accuracy: 0.8330 - val_loss: 1.6873 - val_accuracy: 0.5325\n","Epoch 88/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4848 - accuracy: 0.8520 - val_loss: 1.5997 - val_accuracy: 0.5300\n","Epoch 89/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4979 - accuracy: 0.8450 - val_loss: 1.7603 - val_accuracy: 0.5335\n","Epoch 90/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4634 - accuracy: 0.8600 - val_loss: 1.6615 - val_accuracy: 0.5370\n","Epoch 91/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4798 - accuracy: 0.8390 - val_loss: 1.7325 - val_accuracy: 0.5145\n","Epoch 92/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4527 - accuracy: 0.8490 - val_loss: 1.5465 - val_accuracy: 0.5465\n","Epoch 93/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4776 - accuracy: 0.8480 - val_loss: 1.6237 - val_accuracy: 0.5400\n","Epoch 94/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5158 - accuracy: 0.8330 - val_loss: 1.8020 - val_accuracy: 0.5240\n","Epoch 95/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4969 - accuracy: 0.8430 - val_loss: 1.6223 - val_accuracy: 0.5350\n","Epoch 96/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4858 - accuracy: 0.8400 - val_loss: 1.6097 - val_accuracy: 0.5290\n","Epoch 97/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4734 - accuracy: 0.8400 - val_loss: 1.9527 - val_accuracy: 0.5030\n","Epoch 98/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4483 - accuracy: 0.8600 - val_loss: 1.9869 - val_accuracy: 0.4825\n","Epoch 99/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5335 - accuracy: 0.8330 - val_loss: 1.5796 - val_accuracy: 0.5285\n","Epoch 100/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.5014 - accuracy: 0.8380 - val_loss: 1.8831 - val_accuracy: 0.5110\n","Epoch 101/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4733 - accuracy: 0.8530 - val_loss: 1.7223 - val_accuracy: 0.5180\n","Epoch 102/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4771 - accuracy: 0.8510 - val_loss: 1.6882 - val_accuracy: 0.5290\n","Epoch 103/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4119 - accuracy: 0.8580 - val_loss: 2.0359 - val_accuracy: 0.4770\n","Epoch 104/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4365 - accuracy: 0.8540 - val_loss: 2.0151 - val_accuracy: 0.5040\n","Epoch 105/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.4661 - accuracy: 0.8530 - val_loss: 1.6302 - val_accuracy: 0.5375\n","Epoch 106/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4604 - accuracy: 0.8610 - val_loss: 1.6193 - val_accuracy: 0.5335\n","Epoch 107/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4226 - accuracy: 0.8650 - val_loss: 1.7583 - val_accuracy: 0.5200\n","Epoch 108/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4212 - accuracy: 0.8690 - val_loss: 1.6989 - val_accuracy: 0.5490\n","Epoch 109/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4257 - accuracy: 0.8570 - val_loss: 1.8079 - val_accuracy: 0.5305\n","Epoch 110/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3995 - accuracy: 0.8660 - val_loss: 1.5410 - val_accuracy: 0.5655\n","Epoch 111/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.5047 - accuracy: 0.8420 - val_loss: 1.6739 - val_accuracy: 0.5500\n","Epoch 112/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3992 - accuracy: 0.8660 - val_loss: 1.6907 - val_accuracy: 0.5205\n","Epoch 113/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4274 - accuracy: 0.8560 - val_loss: 1.7422 - val_accuracy: 0.5375\n","Epoch 114/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3902 - accuracy: 0.8640 - val_loss: 1.8225 - val_accuracy: 0.5130\n","Epoch 115/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4063 - accuracy: 0.8710 - val_loss: 1.8205 - val_accuracy: 0.5305\n","Epoch 116/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4187 - accuracy: 0.8710 - val_loss: 1.8915 - val_accuracy: 0.5340\n","Epoch 117/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4676 - accuracy: 0.8470 - val_loss: 1.8363 - val_accuracy: 0.5245\n","Epoch 118/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4230 - accuracy: 0.8680 - val_loss: 1.9453 - val_accuracy: 0.5315\n","Epoch 119/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3641 - accuracy: 0.8850 - val_loss: 1.6980 - val_accuracy: 0.5220\n","Epoch 120/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3978 - accuracy: 0.8750 - val_loss: 2.0517 - val_accuracy: 0.5090\n","Epoch 121/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3746 - accuracy: 0.8760 - val_loss: 1.8328 - val_accuracy: 0.5185\n","Epoch 122/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3871 - accuracy: 0.8700 - val_loss: 1.6836 - val_accuracy: 0.5250\n","Epoch 123/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3957 - accuracy: 0.8700 - val_loss: 1.7125 - val_accuracy: 0.5625\n","Epoch 124/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4916 - accuracy: 0.8340 - val_loss: 1.8376 - val_accuracy: 0.5070\n","Epoch 125/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4472 - accuracy: 0.8460 - val_loss: 1.9160 - val_accuracy: 0.5295\n","Epoch 126/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4051 - accuracy: 0.8680 - val_loss: 1.9113 - val_accuracy: 0.4975\n","Epoch 127/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4100 - accuracy: 0.8660 - val_loss: 1.7604 - val_accuracy: 0.5460\n","Epoch 128/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3866 - accuracy: 0.8740 - val_loss: 1.6971 - val_accuracy: 0.5380\n","Epoch 129/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4145 - accuracy: 0.8630 - val_loss: 1.7855 - val_accuracy: 0.5410\n","Epoch 130/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4042 - accuracy: 0.8610 - val_loss: 1.8207 - val_accuracy: 0.5435\n","Epoch 131/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3420 - accuracy: 0.8880 - val_loss: 1.8913 - val_accuracy: 0.5290\n","Epoch 132/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.4489 - accuracy: 0.8550 - val_loss: 1.7733 - val_accuracy: 0.5345\n","Epoch 133/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4065 - accuracy: 0.8730 - val_loss: 1.8035 - val_accuracy: 0.5305\n","Epoch 134/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3637 - accuracy: 0.8920 - val_loss: 1.7568 - val_accuracy: 0.5145\n","Epoch 135/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4366 - accuracy: 0.8640 - val_loss: 2.0193 - val_accuracy: 0.5145\n","Epoch 136/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3660 - accuracy: 0.8830 - val_loss: 1.7788 - val_accuracy: 0.5325\n","Epoch 137/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4092 - accuracy: 0.8660 - val_loss: 1.8603 - val_accuracy: 0.5370\n","Epoch 138/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3547 - accuracy: 0.8840 - val_loss: 1.6390 - val_accuracy: 0.5530\n","Epoch 139/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3895 - accuracy: 0.8640 - val_loss: 1.7610 - val_accuracy: 0.5275\n","Epoch 140/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3612 - accuracy: 0.8820 - val_loss: 1.7239 - val_accuracy: 0.5440\n","Epoch 141/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.4283 - accuracy: 0.8580 - val_loss: 1.7750 - val_accuracy: 0.5450\n","Epoch 142/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3392 - accuracy: 0.8860 - val_loss: 1.7016 - val_accuracy: 0.5225\n","Epoch 143/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3390 - accuracy: 0.8970 - val_loss: 1.6990 - val_accuracy: 0.5535\n","Epoch 144/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3433 - accuracy: 0.8920 - val_loss: 1.7278 - val_accuracy: 0.5415\n","Epoch 145/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3647 - accuracy: 0.8890 - val_loss: 1.8490 - val_accuracy: 0.5245\n","Epoch 146/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4273 - accuracy: 0.8640 - val_loss: 1.6969 - val_accuracy: 0.5355\n","Epoch 147/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4113 - accuracy: 0.8570 - val_loss: 1.6975 - val_accuracy: 0.5370\n","Epoch 148/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3157 - accuracy: 0.9010 - val_loss: 1.7808 - val_accuracy: 0.5375\n","Epoch 149/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3325 - accuracy: 0.8980 - val_loss: 1.7289 - val_accuracy: 0.5165\n","Epoch 150/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3801 - accuracy: 0.8750 - val_loss: 1.8948 - val_accuracy: 0.5325\n","Epoch 151/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3645 - accuracy: 0.8820 - val_loss: 1.6503 - val_accuracy: 0.5460\n","Epoch 152/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4010 - accuracy: 0.8660 - val_loss: 1.7906 - val_accuracy: 0.5220\n","Epoch 153/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3565 - accuracy: 0.8840 - val_loss: 1.8284 - val_accuracy: 0.5180\n","Epoch 154/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3888 - accuracy: 0.8680 - val_loss: 1.7915 - val_accuracy: 0.5190\n","Epoch 155/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3491 - accuracy: 0.8690 - val_loss: 2.0869 - val_accuracy: 0.4910\n","Epoch 156/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4040 - accuracy: 0.8740 - val_loss: 1.6291 - val_accuracy: 0.5435\n","Epoch 157/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3676 - accuracy: 0.8650 - val_loss: 2.0884 - val_accuracy: 0.5320\n","Epoch 158/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3482 - accuracy: 0.8910 - val_loss: 1.8791 - val_accuracy: 0.5430\n","Epoch 159/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3113 - accuracy: 0.8950 - val_loss: 1.8125 - val_accuracy: 0.5245\n","Epoch 160/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2742 - accuracy: 0.9160 - val_loss: 1.6932 - val_accuracy: 0.5320\n","Epoch 161/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3567 - accuracy: 0.8850 - val_loss: 1.8025 - val_accuracy: 0.5325\n","Epoch 162/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3592 - accuracy: 0.8740 - val_loss: 1.8484 - val_accuracy: 0.5295\n","Epoch 163/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3437 - accuracy: 0.8820 - val_loss: 1.8169 - val_accuracy: 0.5490\n","Epoch 164/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3047 - accuracy: 0.9020 - val_loss: 1.7171 - val_accuracy: 0.5520\n","Epoch 165/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3755 - accuracy: 0.8760 - val_loss: 1.9373 - val_accuracy: 0.5150\n","Epoch 166/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3492 - accuracy: 0.8900 - val_loss: 1.6069 - val_accuracy: 0.5440\n","Epoch 167/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4070 - accuracy: 0.8730 - val_loss: 2.1519 - val_accuracy: 0.4915\n","Epoch 168/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3374 - accuracy: 0.8920 - val_loss: 1.6632 - val_accuracy: 0.5550\n","Epoch 169/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3437 - accuracy: 0.8900 - val_loss: 1.7675 - val_accuracy: 0.5340\n","Epoch 170/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3224 - accuracy: 0.8840 - val_loss: 1.7882 - val_accuracy: 0.5295\n","Epoch 171/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3227 - accuracy: 0.8910 - val_loss: 1.7304 - val_accuracy: 0.5315\n","Epoch 172/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3987 - accuracy: 0.8710 - val_loss: 2.0874 - val_accuracy: 0.5305\n","Epoch 173/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3549 - accuracy: 0.8850 - val_loss: 1.7800 - val_accuracy: 0.5510\n","Epoch 174/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3789 - accuracy: 0.8830 - val_loss: 1.8318 - val_accuracy: 0.5240\n","Epoch 175/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2889 - accuracy: 0.9030 - val_loss: 1.8268 - val_accuracy: 0.5400\n","Epoch 176/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3191 - accuracy: 0.8960 - val_loss: 1.8622 - val_accuracy: 0.5000\n","Epoch 177/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3250 - accuracy: 0.9050 - val_loss: 1.7980 - val_accuracy: 0.5275\n","Epoch 178/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3100 - accuracy: 0.9010 - val_loss: 1.5962 - val_accuracy: 0.5660\n","Epoch 179/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3316 - accuracy: 0.8920 - val_loss: 1.6993 - val_accuracy: 0.5580\n","Epoch 180/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.4042 - accuracy: 0.8660 - val_loss: 1.7283 - val_accuracy: 0.5415\n","Epoch 181/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3576 - accuracy: 0.8880 - val_loss: 1.7647 - val_accuracy: 0.5545\n","Epoch 182/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3261 - accuracy: 0.8860 - val_loss: 1.8389 - val_accuracy: 0.5355\n","Epoch 183/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.4001 - accuracy: 0.8690 - val_loss: 1.6417 - val_accuracy: 0.5570\n","Epoch 184/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.3216 - accuracy: 0.9010 - val_loss: 1.7605 - val_accuracy: 0.5550\n","Epoch 185/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3967 - accuracy: 0.8710 - val_loss: 1.7933 - val_accuracy: 0.5275\n","Epoch 186/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3667 - accuracy: 0.8770 - val_loss: 1.9427 - val_accuracy: 0.5580\n","Epoch 187/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2799 - accuracy: 0.9030 - val_loss: 1.6576 - val_accuracy: 0.5610\n","Epoch 188/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3426 - accuracy: 0.8940 - val_loss: 1.7631 - val_accuracy: 0.5350\n","Epoch 189/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2709 - accuracy: 0.9140 - val_loss: 1.7512 - val_accuracy: 0.5380\n","Epoch 190/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2593 - accuracy: 0.9080 - val_loss: 1.8199 - val_accuracy: 0.5360\n","Epoch 191/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3339 - accuracy: 0.8850 - val_loss: 1.8456 - val_accuracy: 0.5465\n","Epoch 192/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2963 - accuracy: 0.9040 - val_loss: 1.6920 - val_accuracy: 0.5520\n","Epoch 193/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3508 - accuracy: 0.8850 - val_loss: 1.9867 - val_accuracy: 0.5465\n","Epoch 194/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2882 - accuracy: 0.9040 - val_loss: 1.6004 - val_accuracy: 0.5645\n","Epoch 195/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3036 - accuracy: 0.9060 - val_loss: 1.7240 - val_accuracy: 0.5295\n","Epoch 196/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3254 - accuracy: 0.8880 - val_loss: 1.7359 - val_accuracy: 0.5465\n","Epoch 197/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2914 - accuracy: 0.9140 - val_loss: 1.8107 - val_accuracy: 0.5540\n","Epoch 198/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3433 - accuracy: 0.8950 - val_loss: 1.8075 - val_accuracy: 0.5455\n","Epoch 199/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3327 - accuracy: 0.9090 - val_loss: 1.8722 - val_accuracy: 0.5385\n","Epoch 200/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.3328 - accuracy: 0.8930 - val_loss: 1.9843 - val_accuracy: 0.5140\n","Epoch 201/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3014 - accuracy: 0.8950 - val_loss: 1.7994 - val_accuracy: 0.5605\n","Epoch 202/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2973 - accuracy: 0.8970 - val_loss: 1.8340 - val_accuracy: 0.5435\n","Epoch 203/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3282 - accuracy: 0.8960 - val_loss: 1.7403 - val_accuracy: 0.5545\n","Epoch 204/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3148 - accuracy: 0.8990 - val_loss: 1.8815 - val_accuracy: 0.5565\n","Epoch 205/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.3976 - accuracy: 0.8740 - val_loss: 1.6467 - val_accuracy: 0.5455\n","Epoch 206/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3127 - accuracy: 0.9000 - val_loss: 1.9030 - val_accuracy: 0.5525\n","Epoch 207/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3128 - accuracy: 0.8930 - val_loss: 1.7781 - val_accuracy: 0.5445\n","Epoch 208/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2270 - accuracy: 0.9310 - val_loss: 1.7752 - val_accuracy: 0.5625\n","Epoch 209/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2919 - accuracy: 0.9040 - val_loss: 1.9264 - val_accuracy: 0.5465\n","Epoch 210/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.3189 - accuracy: 0.8920 - val_loss: 1.8926 - val_accuracy: 0.5420\n","Epoch 211/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.2585 - accuracy: 0.9090 - val_loss: 1.6668 - val_accuracy: 0.5525\n","Epoch 212/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2972 - accuracy: 0.9000 - val_loss: 2.0688 - val_accuracy: 0.4990\n","Epoch 213/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3016 - accuracy: 0.9010 - val_loss: 2.0126 - val_accuracy: 0.5455\n","Epoch 214/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3361 - accuracy: 0.9010 - val_loss: 1.7254 - val_accuracy: 0.5360\n","Epoch 215/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3106 - accuracy: 0.8930 - val_loss: 1.6701 - val_accuracy: 0.5775\n","Epoch 216/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2723 - accuracy: 0.9020 - val_loss: 1.9787 - val_accuracy: 0.5325\n","Epoch 217/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3144 - accuracy: 0.9000 - val_loss: 2.1255 - val_accuracy: 0.5385\n","Epoch 218/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2693 - accuracy: 0.9070 - val_loss: 1.7445 - val_accuracy: 0.5665\n","Epoch 219/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.3497 - accuracy: 0.8880 - val_loss: 1.6660 - val_accuracy: 0.5560\n","Epoch 220/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2615 - accuracy: 0.9060 - val_loss: 1.9441 - val_accuracy: 0.5470\n","Epoch 221/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2787 - accuracy: 0.9090 - val_loss: 1.9040 - val_accuracy: 0.5445\n","Epoch 222/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2332 - accuracy: 0.9150 - val_loss: 2.1626 - val_accuracy: 0.5285\n","Epoch 223/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2761 - accuracy: 0.9110 - val_loss: 1.8195 - val_accuracy: 0.5500\n","Epoch 224/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2937 - accuracy: 0.8890 - val_loss: 2.0831 - val_accuracy: 0.5420\n","Epoch 225/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2544 - accuracy: 0.9150 - val_loss: 1.7924 - val_accuracy: 0.5615\n","Epoch 226/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2885 - accuracy: 0.8980 - val_loss: 1.8378 - val_accuracy: 0.5600\n","Epoch 227/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3022 - accuracy: 0.8930 - val_loss: 1.9264 - val_accuracy: 0.5565\n","Epoch 228/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3248 - accuracy: 0.8990 - val_loss: 1.9752 - val_accuracy: 0.5405\n","Epoch 229/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3295 - accuracy: 0.8990 - val_loss: 1.8325 - val_accuracy: 0.5430\n","Epoch 230/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3342 - accuracy: 0.8890 - val_loss: 1.8479 - val_accuracy: 0.5520\n","Epoch 231/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.3044 - accuracy: 0.8930 - val_loss: 2.1448 - val_accuracy: 0.5220\n","Epoch 232/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2726 - accuracy: 0.9020 - val_loss: 2.1145 - val_accuracy: 0.5185\n","Epoch 233/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2634 - accuracy: 0.9220 - val_loss: 1.9069 - val_accuracy: 0.5350\n","Epoch 234/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2647 - accuracy: 0.9130 - val_loss: 2.0361 - val_accuracy: 0.5280\n","Epoch 235/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2620 - accuracy: 0.9130 - val_loss: 1.6686 - val_accuracy: 0.5700\n","Epoch 236/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2680 - accuracy: 0.9120 - val_loss: 1.8082 - val_accuracy: 0.5490\n","Epoch 237/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2617 - accuracy: 0.9090 - val_loss: 1.8496 - val_accuracy: 0.5585\n","Epoch 238/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.3642 - accuracy: 0.8780 - val_loss: 1.7832 - val_accuracy: 0.5405\n","Epoch 239/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2622 - accuracy: 0.9100 - val_loss: 2.0840 - val_accuracy: 0.5110\n","Epoch 240/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3442 - accuracy: 0.8880 - val_loss: 1.8559 - val_accuracy: 0.5615\n","Epoch 241/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2687 - accuracy: 0.9100 - val_loss: 1.8061 - val_accuracy: 0.5570\n","Epoch 242/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3144 - accuracy: 0.8950 - val_loss: 1.8825 - val_accuracy: 0.5570\n","Epoch 243/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2632 - accuracy: 0.9140 - val_loss: 1.9891 - val_accuracy: 0.5295\n","Epoch 244/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2728 - accuracy: 0.9010 - val_loss: 2.0201 - val_accuracy: 0.5300\n","Epoch 245/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2671 - accuracy: 0.9130 - val_loss: 1.6629 - val_accuracy: 0.5545\n","Epoch 246/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2951 - accuracy: 0.8930 - val_loss: 1.9079 - val_accuracy: 0.5515\n","Epoch 247/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2928 - accuracy: 0.9130 - val_loss: 1.9924 - val_accuracy: 0.5575\n","Epoch 248/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2406 - accuracy: 0.9200 - val_loss: 1.7996 - val_accuracy: 0.5600\n","Epoch 249/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2338 - accuracy: 0.9220 - val_loss: 1.8445 - val_accuracy: 0.5540\n","Epoch 250/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2591 - accuracy: 0.9200 - val_loss: 1.9050 - val_accuracy: 0.5470\n","Epoch 251/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2807 - accuracy: 0.9040 - val_loss: 1.9207 - val_accuracy: 0.5555\n","Epoch 252/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2599 - accuracy: 0.9170 - val_loss: 2.0405 - val_accuracy: 0.5240\n","Epoch 253/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.2511 - accuracy: 0.9180 - val_loss: 1.7989 - val_accuracy: 0.5555\n","Epoch 254/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2312 - accuracy: 0.9270 - val_loss: 1.9128 - val_accuracy: 0.5410\n","Epoch 255/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2646 - accuracy: 0.9160 - val_loss: 1.9438 - val_accuracy: 0.4895\n","Epoch 256/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.2668 - accuracy: 0.9120 - val_loss: 1.9419 - val_accuracy: 0.5455\n","Epoch 257/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2918 - accuracy: 0.9120 - val_loss: 1.9727 - val_accuracy: 0.5485\n","Epoch 258/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2302 - accuracy: 0.9200 - val_loss: 2.0486 - val_accuracy: 0.5040\n","Epoch 259/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2504 - accuracy: 0.9240 - val_loss: 2.0235 - val_accuracy: 0.5335\n","Epoch 260/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2961 - accuracy: 0.9110 - val_loss: 1.9609 - val_accuracy: 0.5550\n","Epoch 261/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2701 - accuracy: 0.9130 - val_loss: 1.8850 - val_accuracy: 0.5425\n","Epoch 262/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2056 - accuracy: 0.9340 - val_loss: 1.8272 - val_accuracy: 0.5545\n","Epoch 263/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2423 - accuracy: 0.9230 - val_loss: 1.8243 - val_accuracy: 0.5545\n","Epoch 264/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2345 - accuracy: 0.9230 - val_loss: 1.9978 - val_accuracy: 0.5395\n","Epoch 265/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2304 - accuracy: 0.9270 - val_loss: 1.8634 - val_accuracy: 0.5565\n","Epoch 266/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2478 - accuracy: 0.9270 - val_loss: 1.7897 - val_accuracy: 0.5605\n","Epoch 267/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2319 - accuracy: 0.9330 - val_loss: 2.0587 - val_accuracy: 0.5270\n","Epoch 268/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2433 - accuracy: 0.9140 - val_loss: 2.0544 - val_accuracy: 0.5465\n","Epoch 269/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2871 - accuracy: 0.9120 - val_loss: 1.9281 - val_accuracy: 0.5545\n","Epoch 270/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2874 - accuracy: 0.8970 - val_loss: 2.0347 - val_accuracy: 0.5125\n","Epoch 271/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2310 - accuracy: 0.9200 - val_loss: 1.9924 - val_accuracy: 0.5490\n","Epoch 272/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.2816 - accuracy: 0.9060 - val_loss: 1.9109 - val_accuracy: 0.5400\n","Epoch 273/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.3084 - accuracy: 0.9000 - val_loss: 2.0389 - val_accuracy: 0.5215\n","Epoch 274/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2907 - accuracy: 0.9210 - val_loss: 2.0896 - val_accuracy: 0.5435\n","Epoch 275/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.3036 - accuracy: 0.9020 - val_loss: 1.9790 - val_accuracy: 0.5390\n","Epoch 276/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2309 - accuracy: 0.9260 - val_loss: 1.8967 - val_accuracy: 0.5480\n","Epoch 277/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2503 - accuracy: 0.9150 - val_loss: 1.9669 - val_accuracy: 0.5185\n","Epoch 278/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2687 - accuracy: 0.9000 - val_loss: 2.1004 - val_accuracy: 0.5220\n","Epoch 279/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2397 - accuracy: 0.9220 - val_loss: 2.0007 - val_accuracy: 0.5500\n","Epoch 280/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2424 - accuracy: 0.9240 - val_loss: 1.8839 - val_accuracy: 0.5680\n","Epoch 281/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2547 - accuracy: 0.9080 - val_loss: 2.1323 - val_accuracy: 0.5350\n","Epoch 282/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2839 - accuracy: 0.9100 - val_loss: 1.6747 - val_accuracy: 0.5500\n","Epoch 283/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2450 - accuracy: 0.9140 - val_loss: 1.7254 - val_accuracy: 0.5690\n","Epoch 284/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.2797 - accuracy: 0.9090 - val_loss: 1.8626 - val_accuracy: 0.5500\n","Epoch 285/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2953 - accuracy: 0.9050 - val_loss: 2.0506 - val_accuracy: 0.5430\n","Epoch 286/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2986 - accuracy: 0.9220 - val_loss: 2.4683 - val_accuracy: 0.5055\n","Epoch 287/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2745 - accuracy: 0.9080 - val_loss: 2.0560 - val_accuracy: 0.5510\n","Epoch 288/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2400 - accuracy: 0.9160 - val_loss: 2.0649 - val_accuracy: 0.5530\n","Epoch 289/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.3001 - accuracy: 0.9060 - val_loss: 2.0435 - val_accuracy: 0.5285\n","Epoch 290/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2506 - accuracy: 0.9160 - val_loss: 1.8364 - val_accuracy: 0.5655\n","Epoch 291/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2590 - accuracy: 0.9170 - val_loss: 1.7895 - val_accuracy: 0.5585\n","Epoch 292/300\n","100/100 [==============================] - 2s 25ms/step - loss: 0.2406 - accuracy: 0.9260 - val_loss: 1.8682 - val_accuracy: 0.5465\n","Epoch 293/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2659 - accuracy: 0.9240 - val_loss: 2.0492 - val_accuracy: 0.5365\n","Epoch 294/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2405 - accuracy: 0.9230 - val_loss: 2.0359 - val_accuracy: 0.5535\n","Epoch 295/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2610 - accuracy: 0.9100 - val_loss: 2.0429 - val_accuracy: 0.5235\n","Epoch 296/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2335 - accuracy: 0.9250 - val_loss: 1.8491 - val_accuracy: 0.5610\n","Epoch 297/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2042 - accuracy: 0.9360 - val_loss: 1.7684 - val_accuracy: 0.5630\n","Epoch 298/300\n","100/100 [==============================] - 2s 24ms/step - loss: 0.2183 - accuracy: 0.9300 - val_loss: 1.9054 - val_accuracy: 0.5630\n","Epoch 299/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.1842 - accuracy: 0.9360 - val_loss: 2.0782 - val_accuracy: 0.5445\n","Epoch 300/300\n","100/100 [==============================] - 2s 23ms/step - loss: 0.2019 - accuracy: 0.9350 - val_loss: 2.0330 - val_accuracy: 0.5450\n","Epoch 00215: early stopping and save the model\n"]}]},{"cell_type":"code","source":["x_test = x_test/255.0"],"metadata":{"id":"xSNqbCzeQdkR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate1 = model.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)\n","evaluate1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_LxZ8TyPmMN","executionInfo":{"status":"ok","timestamp":1650283873050,"user_tz":-120,"elapsed":3548,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"e1e942e8-8420-4daf-d43b-87f69d49bd0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1000/1000 [==============================] - 3s 3ms/step - loss: 1.6682 - accuracy: 0.5559\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.6681857109069824, 0.555899977684021]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["model_train = keras.models.load_model('3_samples_seed_fix.h5')\n","evaluate2 = model_train.evaluate(x_test,keras.utils.to_categorical(y_test),batch_size=10)\n","evaluate2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jawc89TTOjoy","executionInfo":{"status":"ok","timestamp":1650283875737,"user_tz":-120,"elapsed":2691,"user":{"displayName":"shiro Ma","userId":"15301478031333934447"}},"outputId":"1245e05d-b0f6-4ee1-f5c4-2ef779606b36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1000/1000 [==============================] - 3s 2ms/step - loss: 1.6682 - accuracy: 0.5559\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.6681857109069824, 0.555899977684021]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[""],"metadata":{"id":"8YzO5YPIM_8i"},"execution_count":null,"outputs":[]}]}